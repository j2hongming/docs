{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome the docs","text":""},{"location":"hackmd/API/","title":"API","text":"<ul> <li>\u6dfa\u8ac7 REST API \u7684\u8a2d\u8a08\u548c\u898f\u5283</li> <li>Returning http 200 OK with error within response body</li> <li>\u5982\u4f55\u8a2d\u8a08 REST API</li> <li>Principles &amp; Best practices of REST API Design</li> <li>Web API \u8a2d\u8a08\u6700\u4f73\u505a\u6cd5 - Azure Architecture Center | Microsoft Docs<ul> <li>API\u5f88\u50cf\u4e00\u500b\u51fd\u5f0f, \u5305\u542bfunction name, method signatures, return</li> </ul> </li> <li>\u201c\u4e00\u628a\u68ad\uff1aREST API \u5168\u7528 POST\u201d | \u9177 \u58f3 - CoolShell</li> </ul>"},{"location":"hackmd/API/#realworld","title":"RealWorld","text":""},{"location":"hackmd/API/#microsoft","title":"Microsoft","text":"<ul> <li>api-guidelines/azure/Guidelines.md at vNext \u00b7 microsoft/api-guidelines \u00b7 GitHub</li> </ul>"},{"location":"hackmd/API/#paypal","title":"Paypal","text":"<ul> <li>PayPal API Design Patterns.md \u00b7 GitHub</li> <li>Idempotency</li> <li>Get Started with PayPal REST APIs</li> </ul>"},{"location":"hackmd/API/#twitter","title":"Twitter","text":"<ul> <li>Versioning for twitter API</li> <li>Versioning for twitter ads API</li> <li>API status page</li> <li>Documentation</li> <li>Change log</li> <li>Developer Platform</li> </ul>"},{"location":"hackmd/API/#discord","title":"Discord","text":"<ul> <li>Discord Developer Portal \u2014 Documentation \u2014 Reference</li> </ul>"},{"location":"hackmd/API/#_1","title":"\u6587\u4ef6","text":""},{"location":"hackmd/API/#_2","title":"\u683c\u5f0f","text":"<ul> <li>PDF</li> <li>Web<ul> <li>simple html</li> <li>post man</li> </ul> </li> </ul> <p>7 Open-Source OpenAPI Documentation Generators</p>"},{"location":"hackmd/API/#_3","title":"\u7248\u672c\u9032\u7248\u7684\u6642\u6a5f\u548c\u6ce8\u610f\u4e8b\u9805","text":"<ul> <li>Versioning for twitter API</li> <li>Versioning for twitter ads API</li> </ul> <p>\u4ee5\u4f7f\u7528API\u7684\u4f7f\u7528\u8005\u53bb\u601d\u8003, \u76e1\u91cf\u671d\u5411\u4f7f\u7528\u8005\u4e0d\u9808\u7570\u52d5\u7684\u72c0\u6cc1 \u82e5\u9700\u7570\u52d5, \u8981\u901a\u77e5</p> <p>a breaking change is any change that requires a third-party developer to do any migration work to maintain the existing functionality of their application</p> <p>A \"breaking change\" is any change that requires the consumer of an API to make lockstep changes in order for the consuming code to continue to work properly.</p> <p>\u5411\u524d\u76f8\u5bb9 Breaking change and Non-breaking change Breaking change =&gt; \u4fee\u6539\u6b04\u4f4d\u540d\u7a31, \u522a\u9664\u6b04\u4f4d, \u4fee\u6539\u6b04\u4f4d\u8cc7\u6599\u683c\u5f0f(e.g. from an integer to a float), \u56de\u50b3\u683c\u5f0f\u7570\u52d5(e.g. from XML to JSON)</p> <ul> <li>API versioning and breaking changes - Huan-Lin \u5b78\u7fd2\u7b46\u8a18</li> <li>API &amp; SDK Design #3, API \u7684\u5411\u524d\u76f8\u5bb9\u6a5f\u5236</li> <li>How Shopify Manages API Versioning and Breaking Changes</li> <li>REST API Tutorial - REST API Versioning</li> <li>How to Version a REST API</li> <li>When and How Do You Version Your API</li> <li>When Is A Change A Breaking Change For An API</li> <li>serialization - What is the best way to handle versioning using JSON protocol? - Stack Overflow</li> <li>How to (not) do the events versioning? - Event-Driven.io</li> <li>Simple patterns for events schema versioning - Event-Driven.io</li> <li>Compatibility \u00a0|\u00a0 Cloud APIs \u00a0|\u00a0 Google Cloud</li> <li>Ensuring backwards compatibility in distributed systems - Stack Overflow Blog</li> <li>restful-api-guidelines/compatibility.adoc at main \u00b7 zalando/restful-api-guidelines</li> <li>Schema Evolution and Compatibility | Confluent Documentation</li> <li>:star:Read Versioning in an Event Sourced System | Leanpub</li> <li>Event Sourcing: Events Evolution, Versioning, and Migration \u2013 Val's Tech Blog</li> <li>:star:Event Versioning Guidelines - CodeOpinion</li> <li>How to make your API backward compatible (Web, REST, HTTP, etc) :: EasyIT blog \u2014 Ivan Vaskevych personal blog</li> <li>example<ul> <li>Event message structure - Amazon Simple Storage Service</li> <li>Using AWS Lambda with Amazon SNS - AWS Lambda</li> <li>IAM JSON policy elements: Version - AWS Identity and Access Management</li> <li>Working with AWS Lambda proxy integrations for HTTP APIs - Amazon API Gateway</li> </ul> </li> </ul>"},{"location":"hackmd/API/#_4","title":"\u5206\u6790","text":""},{"location":"hackmd/API/#response","title":"response","text":"<p>payload, response code</p> <p>\u55ae\u4e00\u6b04\u4f4d\u8cc7\u6599\u7570\u52d5 \u65b0\u589e\u6b04\u4f4d: \u539f\u672c\u6c92\u6709\"abc\", \u65b0\u589e\u4e00\u500b\"abc\" \u522a\u9664\u6b04\u4f4d: \u539f\u672c\u5b58\u5728\"def\", \u79fb\u9664\"def\" \u4fee\u6539\u6b04\u4f4d\u540d\u7a31: \u539f\u672c\u6b04\u4f4d\u540d\u7a31\"abc\", \u4fee\u6539\u70ba\"abcd\" \u4fee\u6539\u6b04\u4f4d\u578b\u614b: \u539f\u672c\"abc\"\u70baint=&gt;123, \u4fee\u6539\u70bastring=&gt;\"123\"</p> <pre><code>&lt;svg version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 402 349\" width=\"402\" height=\"349\"&gt;\n  &lt;!-- svg-source:excalidraw --&gt;\n\n  &lt;defs&gt;\n    &lt;style&gt;\n      @font-face {\n        font-family: \"Virgil\";\n        src: url(\"https://excalidraw.com/Virgil.woff2\");\n      }\n      @font-face {\n        font-family: \"Cascadia\";\n        src: url(\"https://excalidraw.com/Cascadia.woff2\");\n      }\n    &lt;/style&gt;\n  &lt;/defs&gt;\n  &lt;rect x=\"0\" y=\"0\" width=\"402\" height=\"349\" fill=\"#ffffff\"&gt;&lt;/rect&gt;\n&lt;g stroke-linecap=\"round\" transform=\"translate(95 221) rotate(0 73 59)\"&gt;\n    &lt;path d=\"M1.4 -1.79 C54.57 -0.19, 106.15 -1.34, 145.95 -1.15 M0.68 0.06 C32.45 -0.56, 65.36 0.12, 146.77 -0.18 M145.86 -0.7 C145.76 27.89, 143.26 57.34, 146.84 118.54 M146.11 0.32 C145.45 38.98, 146.87 76.13, 145.49 117.87 M146.8 117.78 C102.59 116.75, 61.17 118.05, -1.78 119.11 M145.86 117.45 C113.5 117.97, 79.81 119.76, -0.7 118.49 M-1 118.8 C-0.97 90.75, 1.08 61.28, 1.97 -0.6 M0.91 118.68 C-0.09 75.88, 1.02 36.41, -0.98 0.92\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;g transform=\"translate(10 10) rotate(0 39 26)\"&gt;&lt;text x=\"0\" y=\"19\" font-family=\"Virgil, Segoe UI Emoji\" font-size=\"20px\" fill=\"#000000\" text-anchor=\"start\" style=\"white-space: pre;\" direction=\"ltr\"&gt;before:&lt;/text&gt;&lt;text x=\"0\" y=\"45\" font-family=\"Virgil, Segoe UI Emoji\" font-size=\"20px\" fill=\"#000000\" text-anchor=\"start\" style=\"white-space: pre;\" direction=\"ltr\"&gt;no \"abc\"&lt;/text&gt;&lt;/g&gt;&lt;g transform=\"translate(274 14) rotate(0 59 26)\"&gt;&lt;text x=\"0\" y=\"19\" font-family=\"Virgil, Segoe UI Emoji\" font-size=\"20px\" fill=\"#000000\" text-anchor=\"start\" style=\"white-space: pre;\" direction=\"ltr\"&gt;after:&lt;/text&gt;&lt;text x=\"0\" y=\"45\" font-family=\"Virgil, Segoe UI Emoji\" font-size=\"20px\" fill=\"#000000\" text-anchor=\"start\" style=\"white-space: pre;\" direction=\"ltr\"&gt;\"abc\": \"hello\"&lt;/text&gt;&lt;/g&gt;&lt;g stroke-linecap=\"round\"&gt;&lt;g transform=\"translate(146 217) rotate(0 -39.812045040465875 -77.26465291405096)\"&gt;&lt;path d=\"M-0.87 -0.65 C-14.24 -26.86, -66.61 -130.15, -79.71 -156.15 M0.88 1.62 C-12.67 -23.88, -67.04 -128.48, -80.5 -154.7\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;g transform=\"translate(146 217) rotate(0 -39.812045040465875 -77.26465291405096)\"&gt;&lt;path d=\"M-59.52 -133.89 C-66.46 -140.58, -74.86 -148.19, -78.61 -152.95 M-58.59 -134.17 C-65.02 -139.88, -70.03 -145.5, -79.78 -155.12\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;g transform=\"translate(146 217) rotate(0 -39.812045040465875 -77.26465291405096)\"&gt;&lt;path d=\"M-77.75 -124.46 C-78.51 -134.25, -80.65 -145.11, -78.61 -152.95 M-76.82 -124.74 C-78.61 -132.79, -78.89 -140.85, -79.78 -155.12\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/g&gt;&lt;g stroke-linecap=\"round\"&gt;&lt;g transform=\"translate(201 216) rotate(0 38.89635766426102 -74.91328799687327)\"&gt;&lt;path d=\"M0.51 1.13 C13.48 -24.2, 65.28 -125.96, 78.48 -150.96 M-0.69 0.68 C12.03 -24.01, 63.93 -124.71, 77.26 -149.92\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;g transform=\"translate(201 216) rotate(0 38.89635766426102 -74.91328799687327)\"&gt;&lt;path d=\"M75.22 -121.05 C72.86 -129.54, 77.75 -141.41, 78.54 -151.75 M74.11 -119.36 C75.16 -129.47, 76.11 -138.2, 78.03 -149.23\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;g transform=\"translate(201 216) rotate(0 38.89635766426102 -74.91328799687327)\"&gt;&lt;path d=\"M57.02 -130.53 C61.15 -135.76, 72.43 -144.29, 78.54 -151.75 M55.91 -128.84 C62.33 -135.97, 68.71 -141.87, 78.03 -149.23\" stroke=\"#000000\" stroke-width=\"1\" fill=\"none\"&gt;&lt;/path&gt;&lt;/g&gt;&lt;/g&gt;&lt;g transform=\"translate(100 267) rotate(0 68 13.5)\"&gt;&lt;text x=\"68\" y=\"19\" font-family=\"Virgil, Segoe UI Emoji\" font-size=\"20px\" fill=\"#000000\" text-anchor=\"middle\" style=\"white-space: pre;\" direction=\"ltr\"&gt;Client/User&lt;/text&gt;&lt;/g&gt;\n&lt;/svg&gt;\n</code></pre> <p>\u7d50\u69cb\u7570\u52d5 {\"abc\": [\"first\", \"half\"]} {\"abc\": [{\"first\": 1}, {\"half\": 9}]}</p> <p>\u683c\u5f0f\u7570\u52d5 json =&gt; xml</p>"},{"location":"hackmd/API/#request","title":"request","text":"<p>payload</p> <p>\u65b0\u589e\u5fc5\u586b\u6b04\u4f4d: \u539f\u672c\u6c92\u6709\"abc\", \u65b0\u589e\u4e00\u500b\u5fc5\u586b\"abc\"</p>"},{"location":"hackmd/API/#auth","title":"Auth","text":"<p>\u53c3\u8003OAuth 2.0 Client Credentials Flow \u5be6\u4f5c - https://auth0.com/docs/get-started/authentication-and-authorization-flow/call-your-api-using-the-client-credentials-flow - https://developer.twitter.com/en/docs/authentication/oauth-2-0/application-only - https://www.jetbrains.com/help/space/client-credentials.html#response</p>"},{"location":"hackmd/API/#rate-limit","title":"Rate limit","text":"<ul> <li>\u4f7f\u7528 Redis \u7576\u4f5c API Rate limit \u7684\u4e09\u7a2e\u65b9\u6cd5 | Yuanchieh's Blog<ul> <li>Scaling Our Rate Limits to Prepare for a Billion Active Certificates - Let's Encrypt</li> </ul> </li> </ul>"},{"location":"hackmd/API/#_5","title":"\u56de\u50b3\u503c","text":"<ul> <li>Error codes</li> <li>Creating Good API Errors in REST, GraphQL and gRPC</li> <li>403 Forbidden vs 401 Unauthorized HTTP responses</li> <li>You're Not Using HTTP Status Codes Right - DEV Community \ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb</li> </ul>"},{"location":"hackmd/API/#error-code-pattern-for-api","title":"Error code pattern for API","text":"<ul> <li>Error Causes, Types and Reactions</li> <li>https://stackoverflow.com/questions/51317619/error-code-pattern-for-api</li> </ul> <p>combination of top-level HTTP status codes and lower level API error codes - HTTP is a ==ubiquitous== protocol and is no doubt understood by your web container.</p> <p>input - syntax     - \u4e0d\u80fd\u651c\u5e36\u5371\u96aa\u7269\u54c1 - schema     - \u4e0d\u80fd\u651c\u5e36\u5371\u96aa\u7269\u54c1 - value     - \u4e0d\u80fd\u651c\u5e36\u5371\u96aa\u7269\u54c1 - exist     - The resource of the URL doesn't exist.         - \u67d0\u4e9b\u7269\u54c1\u6839\u672c\u4e0d\u5b58\u5728\u65bc\u6d3b\u52d5\u6703\u5834</p> <p>auth - caller's credentials were invalid     - \u4e0d\u80fd\u9032\u5165\u6d3b\u52d5\u5834\u5730 - caller's credentials were valid, but their access level isn't sufficient to access the resource     - \u53ef\u4ee5\u9032\u5165\u6d3b\u52d5\u5834\u5730, \u4f46\u4e0d\u80fd\u4f7f\u7528\u6216\u700f\u89bd\u67d0\u4e9b\u7269\u54c1</p> <p>\u6d3b\u52d5\u5834\u5730\u672c\u8eab - Something bad happened inside the server itself, this error could be anything.     - \u5929\u82b1\u677f\u58de\u6389\u6216\u5c55\u793a\u6ac3\u6bc0\u640d - An error occurred when calling downstream service     - \u548c\u4fdd\u5168\u516c\u53f8\u6216\u6e05\u6f54\u516c\u53f8\u7684\u4eba\u54e1\u5931\u806f, \u7121\u6cd5\u57f7\u884c\u4fdd\u5168\u6216\u6e05\u6f54\u670d\u52d9 - A useful response code for when you get hammered with a ton of \"happy\" customers who are inadvertently DDOS'ing your service.     - \u5165\u5834\u4eba\u6578\u5df2\u9054\u5834\u5730\u5bb9\u91cf\u9650\u5236, \u518d\u591a\u6703\u9020\u6210\u6d3b\u52d5\u54c1\u8cea\u4e0b\u964d - a timeout instead of an actual error with the downstream service     - \u4fdd\u5168\u516c\u53f8\u6216\u6e05\u6f54\u516c\u53f8\u53ef\u4ee5\u806f\u7d61, \u4f46\u4ed6\u5011\u525b\u597d\u5728\u5fd9\u5225\u7684\u4e8b\u60c5, \u7121\u6cd5\u5728\u6642\u9650\u5167\u8d95\u5230\u4e8b\u767c\u73fe\u5834</p>"},{"location":"hackmd/API/#_6","title":"\u8cc7\u6599\u66f4\u65b0","text":"<ul> <li>\u4f60\u53ef\u80fd\u4e0d\u77e5\u9053\u7684HTTP Header--If-Match\u548c\u8a72\u600e\u9ebc\u8a2d\u8a08Web API</li> </ul>"},{"location":"hackmd/AWS/","title":"AWS","text":"<ul> <li>Actions, resources, and condition keys for AWS services<ul> <li>Reference for all \ud835\udddc\ud835\uddd4\ud835\udde0 \ud835\uddd4\ud835\uddf0\ud835\ude01\ud835\uddf6\ud835\uddfc\ud835\uddfb\ud835\ude00, \ud835\uddff\ud835\uddf2\ud835\ude00\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\uddf0\ud835\uddf2\ud835\ude00, \ud835\uddee\ud835\uddfb\ud835\uddf1 \ud835\uddf0\ud835\uddfc\ud835\uddfb\ud835\uddf1\ud835\uddf6\ud835\ude01\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddf8\ud835\uddf2\ud835\ude06\ud835\ude00 \ud835\uddf3\ud835\uddfc\ud835\uddff \ud835\uddee\ud835\uddf9\ud835\uddf9 \ud835\uddd4\ud835\uddea\ud835\udde6 \ud835\ude00\ud835\uddf2\ud835\uddff\ud835\ude03\ud835\uddf6\ud835\uddf0\ud835\uddf2\ud835\ude00</li> </ul> </li> <li>Policy Evaluation Logic<ul> <li>Identity-based policies and resource-based policies</li> </ul> </li> <li>AWS Global Condition Context Keys</li> <li>AWS Code Sample</li> <li>AWS Workshop<ul> <li>AWS Management and Governance Tools Workshop</li> <li>Serverless Data Lake Day</li> <li>AWS CI/CD Workshop</li> </ul> </li> <li>AWS Storage Optimization</li> <li>https://github.com/serverless/serverless/issues/4285<ul> <li>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html</li> <li>https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-multifactorauthpresent</li> <li>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html</li> </ul> </li> <li>Cost<ul> <li>Overview of Data Transfer Costs for Common Architectures</li> <li>Your Comprehensive Guide to Understanding AWS Data Transfer Costs</li> </ul> </li> <li>Accounts<ul> <li>AWS Organizations with Terraform Workspaces</li> </ul> </li> <li>Solution Architect Associate Exam<ul> <li>AWS Solution Architect Associate Exam Study Notes</li> </ul> </li> <li>Dashboard<ul> <li>Dashboards as code: A new approach to visualizing AWS APIs | AWS Open Source Blog</li> </ul> </li> <li>Diagram<ul> <li>mhlabs/cfn-diagram: CLI tool to visualise CloudFormation/SAM/CDK stacks as visjs networks, draw.io or ascii-art diagrams.</li> <li>duo-labs/cloudmapper: CloudMapper helps you analyze your Amazon Web Services (AWS) environments.</li> <li>Cloudcraft \u2013 Draw AWS diagrams</li> <li>mingrammer/diagrams: Diagram as Code for prototyping cloud system architectures</li> </ul> </li> </ul>"},{"location":"hackmd/AWS/#rds","title":"RDS","text":"<ul> <li>Modifying an Amazon RDS DB Instance<ul> <li>How do I minimize downtime during required Amazon RDS maintenance</li> <li>HOW TO MODIFY MYSQL RDS WITH ZERO DOWNTIME</li> </ul> </li> <li>Best Practices for Upgrading Amazon RDS for MySQL and Amazon RDS for MariaDB</li> <li>How to export database from Amazon RDS MySQL instance to local instance?</li> <li>Accessing MySQL binary logs</li> <li>Importing data to an Amazon RDS MySQL or MariaDB DB instance with reduced downtime<ul> <li>How can I resolve an error that I received when using mysqldump on Amazon RDS for MySQL or MariaDB?</li> </ul> </li> <li>Amazon RDS DB instance storage<ul> <li>IOPS\u9650\u5236</li> <li>General Purpose SSD volumes (gp2)</li> <li>Monitoring Amazon RDS metrics with Amazon CloudWatch</li> </ul> </li> <li>Increasing DB instance storage capacity<ul> <li> <p>In most cases, scaling storage doesn't require any outage and doesn't degrade performance of the server.</p> </li> </ul> </li> <li>How can I decrease the total provisioned storage size of my Amazon RDS DB instance?</li> <li>How do I reset the master user password for my Amazon RDS DB instance?</li> <li>Best practices for configuring parameters for Amazon RDS for MySQL, part 3: Parameters related to security, operational manageability, and connectivity timeout</li> </ul>"},{"location":"hackmd/AWS/#reinvent","title":"re:Invent","text":"<p>2024 - \u3010re:Invent 2024\u73fe\u5834\u76f4\u64ca\u3011S3\u96f2\u7aef\u5132\u5b58\u5169\u5927\u65b0\u529f\u80fd\u7784\u6e96AI\u9700\u6c42\uff0cIceberg\u8d85\u5927\u578b\u8cc7\u6599\u8868\u67e5\u8a62\u80fd\u5feb3\u500d\uff0c\u9084\u80fd\u81ea\u52d5\u7522\u751fMetadata | iThome - \u3010re:Invent 2024\u73fe\u5834\u76f4\u64ca\u3011AWS\u57f7\u884c\u9577\u63ed2\u6b3e\u8cc7\u6599\u5eab\u670d\u52d9\u65b0\u9032\u5c55\uff0c\u517c\u9867\u9ad8\u53ef\u7528\u3001\u4f4e\u5ef6\u9072\u3001\u7121\u9700\u7ba1\u7406\u57fa\u790e\u8a2d\u65bd\u7b49\u512a\u52e2 | iThome</p>"},{"location":"hackmd/AWS/#s3","title":"S3","text":"<ul> <li>Why is my presigned URL for an Amazon S3 bucket expiring before the expiration time that I specified?<ul> <li>AWS S3 pre signed URL without Expiry date</li> <li>Authenticating Requests: Using Query Parameters (AWS Signature Version 4)</li> </ul> </li> <li>Amazon S3 Path Deprecation Plan \u2013 The Rest of the Story</li> <li>How do I troubleshoot 403 Access Denied errors from Amazon S3</li> <li>IAM Policies and Bucket Policies and ACLs! Oh, My! (Controlling Access to S3 Resources)</li> <li>Why can't I access an object that was uploaded to my Amazon S3 bucket by another AWS account?</li> <li>Why does S3.deleteObject not fail when the specified key doesn't exist?</li> </ul>"},{"location":"hackmd/AWS/#server-side-encryption","title":"Server-side encryption","text":"<ul> <li>Protecting data with server-side encryption using AWS KMS CMKs (SSE-KMS)</li> </ul>"},{"location":"hackmd/AWS/#metadata","title":"Metadata","text":"<ul> <li>How do you search an amazon s3 bucket?</li> <li>Retrieve/List objects using metadata in s3 - aws sdk</li> <li>Amazon S3 : Listing Object with Metadata in single request</li> <li>boto3 find object by metadata or tag</li> <li>Building and Maintaining an Amazon S3 Metadata Index without Servers</li> <li>Amazon S3 Inventory</li> </ul>"},{"location":"hackmd/AWS/#cli","title":"CLI","text":""},{"location":"hackmd/AWS/#download-object-by-prefix","title":"download object by prefix","text":"<p>```shell= aws s3api list-objects-v2 --bucket {bucket name} --prefix {prefix} &gt; download.json jq '.Contents[].Key' download.json | awk -F '\"' '{print $2}' &gt; s3_object_keys <pre><code>```bash=\n#!/bin/bash\n\nFILENAME=\"s3_object_keys\"\nBUCKET_NAME=\"bucket name\"\nPREFIX=\"prefix\"\n\naws s3api list-objects-v2 --bucket ${BUCKET_NAME} --prefix ${PREFIX} &gt; download.json\njq '.Contents[].Key' download.json | awk -F '\"' '{print $2}' &gt; ${FILENAME}\n\nLINES=$(cat $FILENAME)\n\nfor s3_object_key in $LINES\ndo\n    echo $s3_object_key\n    local_file_name=$(echo $s3_object_key | awk -F '/' '{print $2}')  \n    echo $local_file_name\n    aws s3api get-object --bucket {bucket name} --key $s3_object_key $local_file_name\ndone\n</code></pre></p>"},{"location":"hackmd/AWS/#iam","title":"IAM","text":"<ul> <li>Actions, resources, and condition keys for Identity And Access Management</li> <li>IAM tutorial: Delegate access across AWS accounts using IAM roles</li> <li>Creating a condition with multiple keys or values</li> </ul>"},{"location":"hackmd/AWS/#awsmultifactorauthpresent","title":"aws:MultiFactorAuthPresent","text":"<p>aws:MultiFactorAuthPresent is present principal uses temporary credentials to make the request Temporary credentials are used to authenticate  - IAM roles,  - federated users,  - IAM users with temporary tokens from sts:GetSessionToken - users of the AWS Management Console</p> <p>The aws:MultiFactorAuthPresent key is NOT present when an API or CLI command is called with long-term credentials - user access key pairs</p> <p>...IfExists Condition Operators You do this to say \"If the policy key is present in the context of the request, process the key as specified in the policy. If the key is not present, evaluate the condition element as true.\"</p> <ul> <li>MultiFactorAuthPresent</li> <li>...IfExists Condition Operators</li> </ul>"},{"location":"hackmd/AWS/#iampassrole","title":"IAM:PassRole","text":"<ul> <li>AWS IAM:PassRole explained</li> </ul>"},{"location":"hackmd/AWS/#ec2","title":"EC2","text":""},{"location":"hackmd/AWS/#spot-instance","title":"Spot instance","text":"<ul> <li>Launching Spot Instances in Your Auto Scaling Group</li> <li>New Amazon EC2 Spot pricing model: Simplified purchasing without bidding and fewer interruptions</li> </ul> <p>You set the maximum price you are willing to pay as part of the launch configuration or launch template. If the Spot price is within your maximum price, whether your request is fulfilled depends on Spot Instance capacity. You pay only the Spot price for the Spot Instances that you launch. </p>"},{"location":"hackmd/AWS/#vcpu","title":"vCPU","text":"<ul> <li>Optimizing CPU options<ul> <li>The number of vCPUs for the instance is the number of CPU cores multiplied by the threads per core</li> <li>CPU cores and threads per CPU core per instance type</li> </ul> </li> </ul>"},{"location":"hackmd/AWS/#ebs","title":"EBS","text":"<ul> <li>Extend a Linux file system after resizing a volume</li> </ul>"},{"location":"hackmd/AWS/#ssh","title":"SSH","text":"<ul> <li>New: Using Amazon EC2 Instance Connect for SSH access to your EC2 Instances</li> </ul>"},{"location":"hackmd/AWS/#dns","title":"DNS","text":"<ul> <li>Viewing DNS hostnames for your EC2 instance</li> <li>How can I avoid DNS resolution failures with an Amazon EC2 Linux instance</li> <li>How do I assign a static DNS server to the EC2 instance that persists during reboot</li> </ul>"},{"location":"hackmd/AWS/#ami","title":"AMI","text":"<ul> <li>Share an AMI with specific AWS accounts</li> </ul>"},{"location":"hackmd/AWS/#elb","title":"ELB","text":"<p>Q. \u8acb\u554f Application Load Balancer (ALB) DNS name \u7684 IP \u662f\u5426\u6703\u6539\u8b8a? \u662f\u7684\uff0cELB \u6703\u66f4\u65b0 Load balancer \u7684 DNS \u7d00\u9304\uff0c\u6240\u4ee5\u7576 ELB \u65b0\u589e\u8cc7\u6e90\u6642\uff0c\u6bcf\u500b\u65b0\u589e\u7684\u8cc7\u6e90\u90fd\u6709\u76f8\u5c0d\u8a3b\u518a\u5728 DNS \u88e1\u7684 IP</p> <p>ELB \u5f8c\u9762\u6709\u4e00\u7fa4 EC2 \u7684\u96c6\u5408\uff0c\u5176\u4e2d\u4e00\u500b EC2 \u5982\u679c malfunction/unhealthy \u7684\u8a71      \u5c31\u6703\u66ff\u63db\u53e6\u4e00\u500b\u6b63\u5e38\u904b\u4f5c\u7684 EC2 \u4e0a\u53bb\uff0c\u6b64\u6642 IP \u5c31\u6703\u6539\u8b8a</p> <p>Application Load Balancer \u4e5f\u6709 Auto Scaling \u7684\u6a5f\u5236 \u5047\u8a2d: \u4e00\u53f0 ALB \u5f8c\u9762\u63a5 2 \u500b EC2\uff0c\u56e0\u6b64\u67092\u500b IP A, B\u6d41\u91cf\u589e\u52a0\u6642\uff0c\u9019\u4e9b\u65b0\u589e\u9577\u51fa\u7684 EC2 \u4e5f\u90fd\u6703\u6709\u76f8\u5c0d\u61c9\u7684IP \u5982 C, D\u4f46\u7576\u6d41\u91cf\u8b8a\u5c11 Scale in \u6642\uff0c\u4e0d\u6703\u6709\u56fa\u5b9a\u7684\u6a21\u5f0f\u5148\u53bb\u522a\u9664\u54ea\u4e9b EC2\u6709\u53ef\u80fdScale in \u6642\uff0c\u5148\u7e2e\u6e1b A, B \u7684 EC2\uff0c\u6b64\u6642\u5269 C, D \u7684 EC2\u6b64\u6642IP\u5c31\u6703\u8b8a\u66f4\u70ba C, D \u7684 IP</p> <p>Q: wildcard \u662f\u5426\u5305\u542b slash? \u4ee5\u6587\u4ef6\u4e2d\u7684\u4f8b\u5b50\u70ba\u4f8b\uff0c\u6211\u5728ALB \u8a2d\u5b9a\u5169\u500b rule /img/ =&gt; forward to Target Group A /img//pics =&gt; forward to Target Group B \u8acb\u554f rule 1 \u662f\u5426\u5305\u542b rule 2\uff0c\u6c38\u9060\u4e0d\u6703\u6709 /img \u958b\u982d\u7684 request \u5230 Target Group B \u5462?</p> <p>\u662f\u7684\uff0c rule 2 \u7684\u78ba\u6709\u88ab\u5305\u542b\u5728 rule 1 \u4e2d\u3002 \u81f3\u65bc\u662f\u5426\u6703\u6709 request \u9001\u81f3 Target Group B \u5167\uff0c\u9700\u8981\u53d6\u6c7a\u65bc\u60a8 rule \u7684\u512a\u5148\u9806\u5e8f\u3002 load balancer \u6703\u4f9d\u64da\u512a\u5148\u9806\u5e8f\u6700\u4f4e\u503c\u7684 rule \u5f80\u9ad8\u503c rule \u57f7\u884c\uff0c\u9810\u8a2d\u7684 rule \u5247\u6703\u6700\u5f8c\u57f7\u884c\u3002 \u82e5\u60a8\u7684 /img//pics \u512a\u5148\u9806\u5e8f\u8f03 /img/ \u524d\u9762\uff0c\u60a8\u7684 request \u9084\u662f\u53ef\u4ee5\u9001\u5230 Target Group B\u3002</p> <p>Q: \u8b8a\u66f4 ALB rule \u6642\uff0c\u662f\u5426\u6703\u7acb\u5373\u5957\u7528\u81f3\u5f8c\u7e8c\u7684request \u5462? \u662f\u5426\u9700\u7b49\u5f85\u4e00\u6bb5\u6642\u9593\u5f8c\uff0c\u624d\u6703\u5957\u7528\u81f3 ALB?</p> <p>\u5728\u8b8a\u66f4 rule \u6642\uff0c\u4e26\u4e0d\u6703\u7acb\u5373\u5957\u7528\u751f\u6548\u3002 \u6b63\u5982\u60a8\u6240\u8aaa\uff0c\u65b0\u7684 rule \u6703\u9700\u7b49\u5f85\u4e00\u6bb5\u6642\u9593\u5f8c\uff0c\u624d\u6703\u5957\u7528\u81f3 ALB\u3002</p> <ul> <li>Best Practices in Evaluating Elastic Load Balancing</li> <li>Using static IP addresses for Application Load Balancers</li> <li>Update Rule Priority</li> <li>Troubleshoot your Application Load Balancers</li> </ul> <p>Integration options - Using AWS Lambda with an Application Load Balancer - AWS APPLICATION LOAD BALANCER (ALB) AND ECS WITH FLASK APP</p> <p>Troubleshoot - The load balancer generates an HTTP error - Access logs for your Application Load Balancer</p>"},{"location":"hackmd/AWS/#ecs","title":"ECS","text":"<ul> <li>Is it possible to define a task timeout on AWS ECS</li> </ul>"},{"location":"hackmd/AWS/#lambda","title":"Lambda","text":"<p>Overview - What is AWS Lambda - Lambda concepts     - Managing Lambda reserved concurrency         - :star: Understanding AWS Lambda scaling and throughput | AWS Compute Blog     - Lambda function scaling     - Working with Lambda function metrics     - Runtime deprecation policy - Security     - Lambda operator guide         - Understanding the Lambda execution environment         - Encrypting data in Lambda-based applications     - Security in AWS Lambda - Using AWS Lambda with Amazon API Gateway     - Handling errors with an API Gateway API         - If the Lambda API rejects the invocation request, API Gateway returns a 500 error code.         - If the function runs but returns an error, or returns a response in the wrong format, API Gateway returns a 502.         - In both cases, the body of the response from API Gateway is {\"message\": \"Internal server error\"}.     - Handle Lambda errors in API Gateway - Amazon API Gateway     - Resolve HTTP 502 errors from API Gateway REST APIs with Lambda functions - SNS to Lambda or SNS to SQS to Lambda, what are the trade-offs? | theburningmonk.com</p> <p>https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html https://aws.amazon.com/amazon-linux-ami/2018-03-packages/ https://www.openssl.org/news/openssl-1.0.2-notes.html Exploring the AWS Lambda Execution Environment</p> <pre><code>import json\nimport subprocess\n\ndef lambda_handler(event, context):\n    # TODO implement\n    openssl_cmd_subprocess = subprocess.Popen('openssl version', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    output = openssl_cmd_subprocess.communicate()[0]\n    print(output)\n    openssl_cmd_subprocess = subprocess.Popen('touch /tmp/key.txt &amp;&amp; echo 456 &gt;&gt; /tmp/key.txt', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    openssl_cmd_subprocess = subprocess.Popen('touch /tmp/test.txt &amp;&amp; echo 123 &gt;&gt; /tmp/test.txt', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    openssl_cmd_subprocess = subprocess.Popen('openssl aes-256-cbc -k 456 -salt -in /tmp/test.txt -out /tmp/test.enc', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    openssl_cmd_subprocess = subprocess.Popen('file /tmp/test.enc', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    output = openssl_cmd_subprocess.communicate()[0]\n    for file in output.splitlines():\n        print(file)\n    openssl_cmd_subprocess = subprocess.Popen('openssl aes-256-cbc -d -k 456 -in /tmp/test.enc -out /tmp/test.dec', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    openssl_cmd_subprocess = subprocess.Popen('ls -la /tmp &amp;&amp; md5sum /tmp/*', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    output = openssl_cmd_subprocess.communicate()[0]\n    for file in output.splitlines():\n        print(file)\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n</code></pre> <pre><code>Function logs:\nFunction logs:\nSTART RequestId: cd75f4ff-b209-44ac-bfc5-fcf3deee287e Version: $LATEST\nb'OpenSSL 1.0.2k-fips  26 Jan 2017\\n'\nb\"/tmp/test.enc: openssl enc'd data with salted password\"\nb'total 24'\nb'drwx------  2 sbx_user1051  991 4096 Sep 21 10:00 .'\nb'dr-xr-xr-x 21 root         root 4096 Aug 31 10:28 ..'\nb'-rw-rw-r--  1 sbx_user1051  991    4 Sep 21 10:00 key.txt'\nb'-rw-rw-r--  1 sbx_user1051  991    4 Sep 21 10:00 test.dec'\nb'-rw-rw-r--  1 sbx_user1051  991   32 Sep 21 10:00 test.enc'\nb'-rw-rw-r--  1 sbx_user1051  991    4 Sep 21 10:00 test.txt'\nb'd2d362cdc6579390f1c0617d74a7913d  /tmp/key.txt'\nb'ba1f2511fc30423bdbb183fe33f3dd0f  /tmp/test.dec'\nb'189671449c7e95e7bf09942b654df82f  /tmp/test.enc'\nb'ba1f2511fc30423bdbb183fe33f3dd0f  /tmp/test.txt'\nEND RequestId: cd75f4ff-b209-44ac-bfc5-fcf3deee287eREPORT RequestId: cd75f4ff-b209-44ac-bfc5-fcf3deee287e Duration: 588.25 ms Billed Duration: 600 ms Memory Size: 128 MB Max Memory Used: 48 MB Init Duration: 1.40 ms\n</code></pre> <p>Hit the 6MB Lambda payload limit? Here\u2019s what you can do</p> <p>AWS KMS, Boto3 and Python: Complete Guide with examples</p>"},{"location":"hackmd/AWS/#layer","title":"Layer","text":"<ul> <li>Using Lambda layers to simplify your development process</li> <li>AWSome Lambda Layers</li> <li>How to publish and use AWS Lambda Layers with the Serverless Framework</li> </ul>"},{"location":"hackmd/AWS/#parameters","title":"Parameters","text":"<ul> <li>variable sources</li> <li>Sharing Secrets with AWS Lambda Using AWS Systems Manager Parameter Store</li> <li>Managing secrets, API keys and more with Serverless</li> <li>Secrets Management for AWS Powered Serverless Applications</li> </ul>"},{"location":"hackmd/AWS/#extensions","title":"Extensions","text":"<ul> <li>Caching data and configuration settings with AWS Lambda extensions</li> <li>Overview of AWS Lambda Extensions</li> </ul>"},{"location":"hackmd/AWS/#local-test","title":"Local test","text":"<ul> <li>AWS base images for Lambda<ul> <li>AWS base images for Python</li> </ul> </li> <li>New for AWS Lambda \u2013 Container Image Support</li> <li>Testing Lambda container images locally</li> </ul>"},{"location":"hackmd/AWS/#support","title":"Support","text":"<p>:::info I understand that you would like to know why is CloudWatch \"ConcurrentExecutions\" metric only 826 for all Lambda functions in us-east-1 region and you are still facing Throttle error?</p> <p>To investigate this issue further, I discuss with internal Lambda expert, kindly refer to the following explanation:</p> <p>Since Lambda service uses a counter-like mechanism to count the number of current execution environments. In addition, the CloudWatch ConcurrentExecutions metric is recorded by sampling and may cause some gaps due to time intervals. For example, even though the current sample value of ConcurrentExecutions is 826, due to too many invocations, the next moment ConcurrentExecution is likely to suddenly exceed the upper limit of 1000. </p> <p>Later, when some Lambdas function execution is completed, the available execution environment is released. Therefore, before the time of the next sampling, ConcurrentExecution returns to normal again. This is why, we would advise our customer to observe that when ConcurrentExecution metrics and the upper limit value is extremely close, customer can consider raising the limit of \"ConcurrentExecutions\", which should help reduce Throttle errors. :::</p>"},{"location":"hackmd/AWS/#vpc","title":"VPC","text":"<ul> <li>AWS Elastic IP\u5373\u5c07\u6536\u8cbb\u6211\u8a72\u600e\u9ebc\u8fa6?-Road to IPv6-VPC&amp;EC2 - Tonychung - Medium</li> </ul>"},{"location":"hackmd/AWS/#api-gateway","title":"API Gateway","text":"<ul> <li>API Gateway mapping template and access logging variable reference</li> <li>Introducing HTTP APIs: A Better, Cheaper, Faster Way to Build APIs - AWS Online Tech Talks</li> <li>Handling Errors in Amazon API Gateway</li> <li>API Gateway quotas for configuring and running a REST API<ul> <li>Integration timeout =&gt; 50 milliseconds - 29 seconds for all integration types, including Lambda, Lambda proxy, HTTP, HTTP proxy, and AWS integrations.</li> </ul> </li> <li>Getting \u201cx-amzn-Remapped-WWW-Authenticate instead of WWW-Authenticate and jetty client not able to recognise<ul> <li>Amazon API Gateway important notes</li> </ul> </li> <li>Wildcard custom domain names</li> <li>A Detailed Overview of AWS API Gateway</li> </ul>"},{"location":"hackmd/AWS/#lambda-integration","title":"Lambda integration","text":"<ul> <li>Why am I getting \u201cExecution failed due to configuration\u201d errors from API Gateway after using a CloudFormation template or OpenAPI definition to create a REST API with a Lambda integration</li> </ul>"},{"location":"hackmd/AWS/#custom-http-status-code","title":"Custom HTTP Status Code","text":"<ul> <li>Error Handling Patterns in Amazon API Gateway and AWS Lambda</li> </ul> <p>The routing of Lambda function errors to HTTP responses in API Gateway is achieved by pattern matching against this \u201cerrorMessage\u201d field in the Lambda response. The Lambda function must exit with an error in order for the response pattern to be evaluated \u2013 it is not possible to \u201cfake\u201d an error response by simply returning an \u201cerrorMessage\u201d field in a successful Lambda response.</p> <ul> <li>Send Custom HTTP Status Code from Lambda to API Gateway</li> <li>How to Return Custom HTTP Status codes from a Lambda function in Amazon API Gateway</li> </ul>"},{"location":"hackmd/AWS/#metrics","title":"Metrics","text":"<ul> <li>How to dig latencies and 4xx/5xx errors on AWS API Gateway</li> </ul>"},{"location":"hackmd/AWS/#usage-plan","title":"Usage plan","text":"<ul> <li>What are usage plans and API keys<ul> <li>Throttling and quota limits apply to requests for individual API keys that are aggregated across all API stages within a usage plan.</li> <li>Do different API keys associated on the same usage plan share the same quota limit too</li> </ul> </li> </ul>"},{"location":"hackmd/AWS/#acm","title":"ACM","text":"<ul> <li>How can I upload and import an SSL certificate to AWS Identity and Access Management (IAM)</li> </ul>"},{"location":"hackmd/AWS/#supported-regions","title":"Supported Regions","text":"<ul> <li>Supported Regions <p>Certificates in ACM are regional resources. To use a certificate with Elastic Load Balancing for the same fully qualified domain name (FQDN) or set of FQDNs in more than one AWS region, you must request or import a certificate for each region. For certificates provided by ACM, this means you must revalidate each domain name in the certificate for each region. You cannot copy a certificate between regions.</p> </li> </ul> <p>To use an ACM certificate with Amazon CloudFront, you must request or import the certificate in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution. </p>"},{"location":"hackmd/AWS/#system-manager","title":"System Manager","text":"<ul> <li>Stop and start EC2 instances automatically on a schedule using Quick Setup - AWS Systems Manager</li> </ul> <p>SSM\u4e5f\u53ef\u4ee5\u7ba1\u7406\u6a5f\u623f\u7684\u6a5f\u5668\u548cVM \u5fc5\u9808\u5728\u9700\u8981\u88abSSM\u7ba1\u7406\u7684\u6a5f\u5668\u6216VM\u5167\u5b89\u88ddSSM agent Session Manager: \u597d\u8655, \u53ef\u4ee5\u5c07inbound port\u95dc\u6389; Windows RDP\u4e5f\u53ef\u4ee5 Distributor: \u88dd\u8edf\u9ad4\u5957\u4ef6</p> <p>\u4ee5\u4e0b\u662fAWS Senior SA\u7684\u88dc\u5145\u8cc7\u8a0a\uff1a</p> <ol> <li>Automation with rollback \u2013 \u53ef\u4ee5\u53c3\u8003\u4e0b\u9762\u9019\u500bdocument\uff0c\u8f03\u8907\u96dc\u7684\u6d41\u7a0b\u9084\u662f\u9700\u8981\u642d\u914dLambda\u4f86\u5b8c\u6210\uff1a</li> </ol> <p>AWS-PatchInstanceWithRollback: https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-aws-patchinstancewithrollback.html</p> <ol> <li>AWS Health Events automation (EC2 Retired)</li> </ol> <p>\u5148\u8a2d\u5b9aAWS Health Event\u505a\u70baCloudWatch Events (EventBridge)\u4f86\u6e90\uff1a https://docs.aws.amazon.com/health/latest/ug/cloudwatch-events-health.html How can I receive notifications for scheduled events for my EC2 instance using CloudWatch Events? https://aws.amazon.com/tw/premiumsupport/knowledge-center/cloudwatch-notification-scheduled-events/</p> <p>CloudWatch Events\u53ef\u4ee5\u76f4\u63a5\u89f8\u767cSSM Automation: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/SSM_Automation_as_Target.html</p> <p>\u5982\u679c\u8981\u900f\u904eSSM OpsCenter\u96c6\u4e2d\u7ba1\u7406ops\u4e8b\u4ef6\u7684\u8a71\uff1a https://docs.aws.amazon.com/systems-manager/latest/userguide/OpsCenter-automatically-create-OpsItems-2.html</p>"},{"location":"hackmd/AWS/#route-53","title":"Route 53","text":"<ul> <li>Why is my third-party SSL provider unable to verify my Route 53 domain ownership</li> <li>RRSet of type CNAME with DNS name foo.com. is not permitted at apex in zone bar.com<ul> <li>Choosing between alias and non-alias records</li> </ul> </li> </ul> <p>Unlike a CNAME record, you can create an alias record at the top node of a DNS namespace, also known as the zone apex. For example, if you register the DNS name example.com, the zone apex is example.com. You can't create a CNAME record for example.com, but you can create an alias record for example.com that routes traffic to www.example.com.</p>"},{"location":"hackmd/AWS/#tag","title":"tag","text":""},{"location":"hackmd/AWS/#overview","title":"Overview","text":"<ul> <li>Focus on Required and Conditionally Required Tags</li> <li>Consider naming your tags using all lowercase, with hyphens separating words, and a prefix identifying the organization name or abbreviated name</li> <li>In 2016, the number of tags per resource was increased to 50 (with a few exceptions, such as S3 objects)</li> <li>it\u2019s generally recommended to follow good data management practice by including only one data attribute per tag</li> <li>Remediate Untagged Resources</li> <li>Tag Editor is a feature of the AWS Management Console that allows you to search for resources using a variety of search criteria and add, modify, or delete tags in bulk.</li> <li>The AWS Resource Tagging API allows you to perform these same functions programmatically.</li> </ul>"},{"location":"hackmd/AWS/#practice","title":"Practice","text":"<ul> <li>purpose</li> <li>key and value</li> <li>product</li> <li>component</li> <li>application</li> <li>owner</li> <li>department</li> <li>environment</li> <li>version</li> <li>required, conditionally required</li> </ul> <p>examples: anycompany:cost-center anycompany:environment-type anycompany:application-id</p>"},{"location":"hackmd/AWS/#sns","title":"SNS","text":"<ul> <li>Public SNS security group<ul> <li>Verifying the signatures of Amazon SNS messages</li> <li>Verifying the signatures of Amazon SNS messages</li> </ul> </li> <li>Subscribing an HTTP/S endpoint to a topic</li> </ul>"},{"location":"hackmd/AWS/#sqs","title":"SQS","text":"<ul> <li>Lessons learned from combining SQS and Lambda in a data project - Solita Data</li> <li>AWS Lambda and SQS: What Nobody Tells You About Their Mix | by Ehsan Yazdanparast | Geek Culture | Medium</li> <li>Lambda SQS Triggers and Concurrency | by Shilpi Gupta | Better Programming</li> </ul>"},{"location":"hackmd/AWS/#deplicated-messages","title":"deplicated messages","text":"<p>SQS message may be duplicated on some situlations - Resolve Duplicate Messages in Amazon SQS for the Same Amazon S3 Event - At-least-once delivery</p> <pre><code>Warm Greetings from AWS Premium Support. Thank you for contacting AWS Premium Support. \nThis is Jennifer and I will be assisting you with your case today.\n\nFrom the case note, I understand that you would like to confirm that the message ID of standard SQS Queue will be the same for the following two scenarios. Kindly refer to the following information:\n\n### case1 ### Producer application sends a message, but the consumer application receive two duplication messages\n\nAs you may alredy know, there are some inherent characteristics of a Standard SQS Queue that allows for duplicative messaging. As per the note on this document [1]:\n\nFor Standard SQS Queues, the `Visibility Timeout` is not a guarantee against receiving a message more than once.\n\n\u279c As per this document [2], a Standard SQS Queue ensures \\\"at-least-once delivery\\\" which implies that it is possible for the same message to be delivered more than once.\n\u279c When messages are added to a Standard SQS Queue, a unique Message ID is allocated to each message. Amazon SQS returns the Message ID in the response of the \\\"SendMessage\\\" [3] API call.\n\u279c Amazon SQS stores copies of the messages on multiple servers for redundancy and high availability.\n\u279c On rare occasions, one of the servers that stores a copy of a message might be unavailable when you receive or delete a message.\n\u279c This can result in a duplicate message being received when the server becomes available again.\n\nI would like to highlight that, duplicate messages (introduced by Amazon SQS as a result of the above mentioned point) will contain the SAME Message ID.\n\n\n### case2 ### Put a single file to S3 bucket and then trigger duplicated SQS messages for the PutObject action\n\nTo investigate this issue, I have setup the configuration and performed the testing in my environment. Based on my test, when I upload the same object 3 times in a row, normally, the ` sequencer key` and `message ID` of the 3 responses are totally different. However, it is difficult to reproduce the phenomenon of sequencer key duplication, as it occurs in rare cases [4]. After delving into this issue, I am able to confirm from internal sources: \\\"For S3 event notifications, it is expected to see duplicates. However, they'd show up as DIFFERENT SQS messages id if they were generated by the events system\\\".\n\nFurthermore, for case1, here is an example of the application logic that would need to be implemented in order to facilitate idempotency:\n\n1. Extract the value of a unique attribute of the input event (such as, the Message ID).\n2. Check if the attribute value already exists in a control database. Depending on the outcome, do the following:\n\u279c If a unique value exists, end the action without producing an error.\n\u279c If a unique value does not exist, proceed with the actions that you designed.\n3. Thereafter, include a record of the attribute value in the control database.\n\nI hope the above information helps.\nHave a nice day :)\n\n\u25a0 References:\n============\n[1] Amazon SQS Visibility Timeout: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html \n[2] At-least-once Delivery: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html#standard-queues-at-least-once-delivery \n[3] SendMessage: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_SendMessage.html \n[4] https://aws.amazon.com/tw/premiumsupport/knowledge-center/s3-duplicate-sqs-messages/ \n</code></pre>"},{"location":"hackmd/AWS/#cloudwatch","title":"CloudWatch","text":"<ul> <li>AWS Services That Publish CloudWatch Metrics</li> </ul>"},{"location":"hackmd/AWS/#metrics_1","title":"Metrics","text":"<p>Metric data is kept for 15 months</p> <p>Publishing Single Data Points Each metric is one of the following: - Standard resolution, with data having a one-minute granularity     - Metrics produced by AWS services are standard resolution by default - High resolution, with data at a granularity of one second     - :money_with_wings:  Keep in mind that every PutMetricData call for a custom metric is charged, so calling PutMetricData more often on a high-resolution metric can lead to higher charges.</p> <p>Namespace: \u985e\u4f3c\u5206\u985e Dimension: \u985e\u4f3c\u4e0a\u6a19\u7c64\u505agrouping SampleCount: record\u6578\u91cf</p>"},{"location":"hackmd/AWS/#others","title":"Others","text":"<ul> <li>Publish Amazon CloudWatch metrics to a comma-separated values output</li> <li>how to export CloudWatch Metrics to CSV</li> </ul>"},{"location":"hackmd/AWS/#alarms","title":"Alarms","text":"<p>Using Amazon CloudWatch Alarms Why did my CloudWatch alarm trigger when its metric doesn't have any breaching data points</p> <ul> <li>Type<ul> <li>metric alarm</li> <li>composite alarm</li> </ul> </li> <li>Alarm States<ul> <li>OK</li> <li>ALARM</li> <li>INSUFFICIENT_DATA</li> </ul> </li> </ul> <p>An alarm invokes actions only when the alarm changes state</p> <p>The exception is for alarms with Auto Scaling actions. For Auto Scaling actions, the alarm continues to invoke the action once per minute that the alarm remains in the new state.</p> <p>==Three settings== to enable CloudWatch to evaluate when to change the alarm state - Period: \u6aa2\u67e5\u7684\u9593\u9694, \u8f38\u51fa data point     - the length of time to evaluate the metric or expression to create each individual data point for an alarm     - If you choose one minute as the period, the alarm evaluates the metric once per minute.     - each specific data point reported to CloudWatch falls under one of three categories         - Not breaching (within the threshold)         - Breaching (violating the threshold)         - Missing     - missing data points - Evaluation Periods: \u6700\u8fd1\u7684\u5019\u9078\u6aa2\u67e5\u9ede\u500b\u6578, \u6709\u9ede\u985e\u4f3ccheck window     - the number of the most recent periods, or data points, to evaluate when determining alarm state - Datapoints to Alarm: \u6eff\u8db3\u7684\u6aa2\u67e5\u9ede\u500b\u6578     - the number of data points within the Evaluation Periods that must be breaching to cause the alarm to go to the ALARM state</p> <p>When you configure Evaluation Periods and Datapoints to Alarm as different values, you're setting an \"M out of N\" alarm.  Datapoints to Alarm is (\"M\") and Evaluation Periods is (\"N\").  The evaluation interval is the number of data points multiplied by the period.  For example, if you configure 4 out of 5 data points with a period of 1 minute, the evaluation interval is 5 minutes. If you configure 3 out of 3 data points with a period of 10 minutes, the evaluation interval is 30 minutes.</p>"},{"location":"hackmd/AWS/#logs","title":"Logs","text":"<p>MetricFilter - Filter and pattern syntax</p>"},{"location":"hackmd/AWS/#insight","title":"Insight","text":""},{"location":"hackmd/AWS/#file_search_api-log","title":"file_search_api log","text":"<p>file info done <pre><code>fields @timestamp, @message\n| filter @message like /File Info Status: 5/\n</code></pre></p> <pre><code>fields @timestamp, @message\n| filter @message like /File Info Status: 5/ or @message like /File Info Status: 6/ or @message like /File Info Status: 7/ or @message like /File Info Status: 8/ or @message like /File Info Status: 9/\n</code></pre> <p>Hit prefilter cache <pre><code>fields @timestamp, @message\n| filter @message like 'File with valid score'\n| filter @message like '-1'\n</code></pre></p> <p>get uplod url <pre><code>fields @timestamp, @message\n| filter @message like /Response json string of new file case/\n</code></pre></p> <p>Undefined or unsupported file type</p> <p>sum <pre><code>fields @timestamp, @message, @logStream\n| filter @message like 'Undefined or unsupported file type'\n| filter @message like 'file_type'\n| parse @message '\"hash\": \"*\"' as hash\n| parse @message '\"file_type\": *,' as file_type\n| parse @logStream '*/*/*/[$LATEST]' as year, month, day\n| stats count_distinct(hash) as sum by day\n</code></pre></p> <p>group results <pre><code>fields @timestamp, @message\n| filter @message like 'Undefined or unsupported file type'\n| filter @message like 'file_type'\n| parse @message '\"hash\": \"*\"' as hash\n| parse @message '\"file_type\": *,' as file_type\n| stats count_distinct(hash) as sum by hash, file_type\n</code></pre></p>"},{"location":"hackmd/AWS/#scan-task-forwarder-log","title":"scan task forwarder log","text":"<p>send vendor <pre><code>fields @timestamp, @message, @logStream\n| filter @message like 'handle sandbox reply task id' or @message like 'handle sandbox reply report'\n| parse @logStream '*/*/*/[$LATEST]' as year, month, day\n| stats count(*) as sum by day\n</code></pre></p>"},{"location":"hackmd/AWS/#report-forwarder-log","title":"report forwarder log","text":"<p>score distribution <pre><code>fields @timestamp, @message\n| filter @message like 'virus_score'\n| parse @message 'virus_score * is' as score\n| stats count(score) as sum by bin(1d), score\n</code></pre></p>"},{"location":"hackmd/AWS/#quarantine","title":"quarantine","text":"<p>file type distribution</p> <pre><code>fields @timestamp, @message\n| filter @message like 'filter queue msg'\n| parse message '\"file_type\": *}' as file_type\n| stats count(file_type) as sum by bin(1d), file_type\n</code></pre>"},{"location":"hackmd/AWS/#cloud-query","title":"cloud query","text":"<p>hit cache and score <pre><code>fields @timestamp, @message\n| filter @message like 'has been cached'\n| parse @message /(?&lt;md5&gt;[0-9a-z]{32}) has been cached and score is (?&lt;score&gt;-?[0-9]+)/\n| filter score &gt; 0\n| stats count(md5) as sum by md5, score\n</code></pre></p>"},{"location":"hackmd/AWS/#eventbriedge","title":"EventBriedge","text":"<ul> <li>How to get the event content in ECS when it is invoked by cloudwatch/eventbridge event?</li> <li>How to extract event relayed from AWS EventBridge to ECS Fargate</li> <li>Passing event data from Amazon EventBridge into an AWS Fargate task</li> <li>AWS question - How can I get Cloudwatch event data in a Fargate task with Python</li> <li>Passing input to ECS task from CloudWatch rule</li> </ul>"},{"location":"hackmd/AWS/#cloudfront","title":"CloudFront","text":"<ul> <li>How can I redirect one domain to another in Route 53?</li> </ul>"},{"location":"hackmd/AWS/#cloudtrail","title":"CloudTrail","text":"<ul> <li>Logging data events for trails<ul> <li>Tutorial: Run an Amazon ECS Task When a File is Uploaded to an Amazon S3 Bucket</li> </ul> </li> </ul>"},{"location":"hackmd/AWS/#elasticsearch","title":"Elasticsearch","text":"<ul> <li>Amazon Elasticsearch Service Best Practices</li> <li>Sizing Amazon ES Domains</li> </ul>"},{"location":"hackmd/AWS/#dynamodb","title":"DynamoDB","text":"<ul> <li>30\u5929\u9435\u4eba\u8cfd\u4ecb\u7d39 AWS \u96f2\u7aef\u4e16\u754c - 26: AWS \u63d0\u4f9b\u7684 Managed NoSQL DBMS - DynamoDB</li> <li>AWS\u529f\u80fd\u6574\u7406- Dynamodb</li> <li>DynamoDB in 15 minutes</li> <li>DynamoDBGuide</li> <li>How to model one-to-many relationships in DynamoDB<ul> <li>With one-to-many relationships, there\u2019s one core problem: how do I fetch information about the parent entity when retrieving one or more of the related entities<ul> <li>Denormalization by using a complex attribute<ul> <li>Do you have any access patterns based on the values in the complex attribute?</li> <li>Is the amount of data in the complex attribute unbounded?</li> </ul> </li> <li>Denormalization by duplicating data<ul> <li>Is the duplicated information immutable?</li> <li>If the data does change, how often does it change and how many items include the duplicated information?</li> </ul> </li> <li>Composite primary key + the Query API action<ul> <li>This is a pretty common way to model one-to-many relationships</li> </ul> </li> <li>Secondary index + the Query API action<ul> <li>You may need to use this pattern instead of the previous pattern because the primary keys in your table are reserved for another purpose</li> </ul> </li> <li>Composite sort keys with hierarchical data<ul> <li>You have many levels of hierarchy (&gt;2), and you have access patterns for different levels within the hierarchy.</li> </ul> </li> </ul> </li> </ul> </li> <li>The What, Why, and When of Single-Table Design with DynamoDB</li> <li>\u5b98\u65b9<ul> <li>Core Components of Amazon DynamoDB</li> <li>Amazon DynamoDB \u5165\u9580\u5f71\u7247</li> <li>Getting Started Developing with Python and DynamoDB<ul> <li>QueryFilter<ul> <li>This parameter does not support attributes of type List or Map</li> </ul> </li> </ul> </li> <li>Creating a single-table design with Amazon DynamoDB</li> <li>Example Tables and Data</li> <li>AWS DynamoDB and Schema Design</li> <li>Comparison Operator and Function Reference</li> <li>aws-samples/amazon-dynamodb-design-patterns<ul> <li>NoSQL Workbench for Amazon DynamoDB</li> </ul> </li> <li>AWS re:Invent 2019: Data modeling with Amazon DynamoDB (CMY304)<ul> <li>https://twitter.com/angelo_randazzo/status/1510362054489739267?s=12&amp;t=mGlZq948otytJT6q4RjaIg<ul> <li>This video (from AWS events) is very interesting to understand the key concepts behind designing a DB model in DynamoDB (totally different vs a classical relational SQL DB)</li> </ul> </li> </ul> </li> <li>How to switch from RDBMS to DynamoDB in 20 easy steps</li> <li>Capacity units consumed by query<ul> <li>DynamoDB calculates the number of read capacity units consumed based on item size, not on the amount of data that is returned to an application. For this reason, the number of capacity units consumed is the same whether you request all of the attributes (the default behavior) or just some of them (using a projection expression). The number is also the same whether or not you use a filter expression.</li> </ul> </li> </ul> </li> <li>\u8ab2\u7a0b<ul> <li>DynamoDB Deep Dive Advence Design</li> </ul> </li> </ul>"},{"location":"hackmd/AWS/#primary-key","title":"Primary key","text":"<p>The primary key uniquely identifies each item in the table, so that no two items can have the same key. </p> <p>Each primary key attribute must be a scalar (meaning that it can hold only a single value). The only data types allowed for primary key attributes are string, number, or binary</p> <ul> <li>Choosing the Right DynamoDB Partition Key</li> <li>Designing Partition Keys to Distribute Your Workload Evenly</li> </ul>"},{"location":"hackmd/AWS/#local-secondary-indexes-max-is-5","title":"Local secondary indexes (max is 5)","text":"<p>At table creation</p>"},{"location":"hackmd/AWS/#docker-for-local-dev","title":"docker for local dev","text":"<p>https://github.com/instructure/dynamo-local-admin-docker</p>"},{"location":"hackmd/AWS/#updateexpression","title":"UpdateExpression","text":"<ul> <li>UpdateExpression</li> <li>Update Expressions</li> <li>DynamoDB if_not_exists on UpdateItem</li> </ul>"},{"location":"hackmd/AWS/#rcu-wcu","title":"RCU &amp; WCU","text":"<ul> <li>How to Calculate a DynamoDB Item\u2019s Size and Consumed Capacity<ul> <li>dynamodb-calculator</li> </ul> </li> </ul>"},{"location":"hackmd/AWS/#efs","title":"EFS","text":"<p>I understand that you want to find out the 12 additional connections that shows in Cloudwatch.  I would like to share some information with you after speaking with EFS service team:  1. The connections in Cloudwatch can get overcounted when connections get closed and re-established within the same period.  2. The issue might be caused by a specific behavior of the Linux NFS client with regards to TCP reconnection events. When a reconnection event occurs, the Linux NFS client reuses the TCP source port. This behavior is not conformant with the TCP RFC, and can cause a network issue where NFS responses from EFS to an EC2 instance are blocked for multiple minutes.</p> <p>To resolve this issue, we recommend to add the \"noresvport\" mount option when mounting an EFS file system. This option has the effect that a new port is allocated when a reconnection event occurs.</p> <ul> <li>noresvport \u2013 Tells the NFS client to use a new Transmission Control Protocol (TCP) source port when a network connection is reestablished. Doing this helps make sure that the EFS file system has uninterrupted availability after a network recovery event.</li> </ul>"},{"location":"hackmd/AWS/#dms","title":"DMS","text":"<ul> <li>Getting started with AWS Database Migration Service</li> <li>Using a MySQL-compatible database as a source for AWS DMS</li> <li>Using a MySQL-compatible database as a target for AWS Database Migration Service </li> </ul>"},{"location":"hackmd/AWS/#athena","title":"Athena","text":"<ul> <li>Best practices when using Athena with AWS Glue</li> <li>Presto 0.172 Documentation<ul> <li>STRING FUNCTIONS AND OPERATORS</li> </ul> </li> <li>Why does my Athena query fail with the error \"HIVE_PARTITION_SCHEMA_MISMATCH\"</li> <li>HIVE_PARTITION_SCHEMA_MISMATCH</li> </ul> <p>:::success S3 \u5efa\u8b70\u4f7f\u7528 YYYY/MM/dd/1.log\uff0c\u539f\u56e0\u662fGlue\u505aparse\u6642\u53ef\u4ee5\u76f4\u63a5\u5efa\u7acbpartition :::</p>"},{"location":"hackmd/AWS/#basic","title":"Basic","text":"<p>``` sql= SHOW PARTITIONS dc_log <pre><code>``` sql=\nALTER TABLE dc_log DROP PARTITION (year='2020', month='04');\n</code></pre></p>"},{"location":"hackmd/AWS/#get-duts-to-dc-total-request-counts-per-daymonth","title":"Get DUTs to DC Total Request Counts Per Day/Month","text":"<p>Per day per DUT</p> <p>``` sql= SELECT date_format(CAST(dc.time_stamp as timestamp), '%Y%m%d') as day, dc.device_info.sn, count(*) as requests FROM dc_log as dc  WHERE dc.category = 'file-search-api' AND dc.extra_info.system_tag['device-request-counter'] is not null GROUP BY date_format(CAST(dc.time_stamp as timestamp), '%Y%m%d'), dc.device_info.sn order by day asc <pre><code>``` sql=\nSELECT DAY(CAST(dc.time_stamp as timestamp)) as day, dc.device_info.sn, count(*) as requests \nFROM dc_log as dc \nWHERE dc.category = 'cloud-anti-malware-query' AND\ndc.extra_info.system_tag['device-request-counter'] is not null AND\nYEAR(CAST(dc.time_stamp as timestamp)) = 2019 AND\nMONTH(CAST(dc.time_stamp as timestamp)) = 6\nGROUP BY DAY(CAST(dc.time_stamp as timestamp)), dc.device_info.sn\norder by day asc\n</code></pre></p>"},{"location":"hackmd/AWS/#glue","title":"Glue","text":"<ul> <li>Easily query AWS service logs using Amazon Athena</li> </ul>"},{"location":"hackmd/AWS/#polly","title":"Polly","text":"<ul> <li>Amazon Polly - \u6587\u5b57\u8f49\u8072\u97f3\uff0c\u6548\u679c\u5341\u5206\u986f\u8457</li> </ul>"},{"location":"hackmd/AWS/#_1","title":"\u6574\u5408\u60c5\u5883","text":"<ul> <li>EC2\u900f\u904eSNS\u767c\u9001Mail</li> </ul>"},{"location":"hackmd/Ansible%20Practice/","title":"Ansible Practice","text":""},{"location":"hackmd/Ansible%20Practice/#install-network-manager-package-and-add-the-user-devops_user","title":"install network manager package and add the user devops_user","text":""},{"location":"hackmd/Ansible%20Practice/#yml","title":"``` yml=","text":"<ul> <li> <p>name: Display installed packages   hosts: web   tasks:</p> <ul> <li>name: Install the package   apt:     name:<ul> <li>apache2=2.4.41-4ubuntu3.12</li> <li>network-manager</li> </ul> </li> <li> <p>name: Gather info on installed packages   package_facts:     manager: auto</p> </li> <li> <p>name: List installed packages   debug:     var: ansible_facts.packages</p> </li> <li> <p>name: Display NetworkManager version   debug:     msg: \"Version {{ansible_facts.packages['network-manager'][0].version}}\"   when: \"'network-manager' in ansible_facts.packages\"</p> </li> <li>name: New user devops   hosts: web   tasks:</li> <li>name: Verify that auditors group exists   group:     name: \"{{ item }}\"     state: present   loop:<ul> <li>sys_admins</li> <li>developers</li> </ul> </li> <li>name: Add new user to the development machine and assign the appropriate groups.   user:     name: devops_user     shell: /bin/bash     groups: sys_admins,developers     append: yes     generate_ssh_key: yes     ssh_key_bits: 2048     ssh_key_file: .ssh/id_my_rsa <pre><code>## customized tool installation\ngroup_vars/all.yml\n\n``` yml\nenv=production\ninstallation_folder_dir: /tmp/sumtool\nsumtool_folder: \"{{ installation_folder_dir }}/sum_2.9.0_Linux_x86_64\"\nsumtool_url: https://www.supermicro.com/Bios/sw_download/466/sum_2.9.0_Linux_x86_64_20220804.tar.gz\ncluster_bmc_credential: \"/foo/{{ env }}/config/cluster-bmc-credential.txt\"\n</code></pre></li> </ul> </li> </ul> <p>playbook.yml <pre><code>- name: create `temp-installation` folder\n  file:\n    path: \"{{ installation_folder_dir }}\"\n    state: directory\n\n- name: check sumtool directory exists\n  stat:\n    path: \"{{ sumtool_folder }}\"\n  register: sum_command\n\n- name: download the Supermicro SUM tool\n  get_url:\n    url: \"{{ sumtool_url }}\"\n    dest: \"{{ installation_folder_dir }}\"\n  when: sum_command.stat.exists == False\n\n- name: uncompress the tar file\n  unarchive:\n    src: \"{{ installation_folder_dir }}/{{ sumtool_url | basename}}\"\n    dest: \"{{ installation_folder_dir }}\"\n    remote_src: yes\n    list_files: yes\n  register: unzip_contents\n\n- name: set variable\n  set_fact:\n    sumtool_dir: \"{{ installation_folder_dir }}/{{ unzip_contents.files[0] }}\"\n    cpu_series: \"{{ 7002 if ansible_processor[2] | regex_search('7[0-9][0-9]2') is not none else 7003}}\"\n\n- name: show cpu_series\n  debug:\n    msg: \n      - \"{{ cpu_series }}\"\n      - \"{{ ansible_processor[2] }}\"\n\n- name: check python-lxml is installed\n  shell: pip3 list | grep lxml\n  register: pip3_list\n  ignore_errors: true\n\n# NOTE: To use ansible xml, it's necessary to install python3 and python3-lxml.\n- name: install python-lxml\n  pip:\n    name: lxml\n  when: pip3_list.rc != 0\n- name: get ipmi ip\n  shell: |\n      cat \"{{cluster_bmc_credential}}\" | grep \"{{target_host}}\" | awk '{split($4,a,\"/\");print a[2]}'\n  register: ipmi_ip\n- name: get ipmi password\n  shell: |\n      cat \"{{cluster_bmc_credential}}\" | grep \"{{target_host}}\" | awk '{print $6}'\n  register: ipmi_password\n- name: get the current BIOS configurations\n  shell:\n    chdir: \"{{ sumtool_dir }}\"\n    cmd: \"./sum -i {{ipmi_ip.stdout}} -u ADMIN -p {{ipmi_password.stdout}} -c GetCurrentBiosCfg --overwrite --file {{ sumtool_dir }}/{{original_bios_config_file}}\"\n  ignore_errors: true\n  become: true\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#install-ansible","title":"install ansible","text":"<pre><code>  - name: Install the package group\n    ansible.builtin.yum:\n      name: \"{{ item }}\"\n      state: present\n    become: yes\n    loop:\n      - \"@Infiniband Support\"\n      - \"@Performance Tools\"\n      - \"@Development Tools\" \n      - \"@Scientific Support\"\n      - \"@System Tools\"\n      - python39\n    when: ansible_distribution==\"RedHat\"\n  - include_role:\n      name: ipmitool_package\n  - name: Install ansible\n    ansible.builtin.pip:\n      name: ansible-core==2.14\n      executable: pip3.9\n</code></pre>"},{"location":"hackmd/Ansible%20Practice/#check-sw-status-and-use-template","title":"check sw status and use template","text":"<pre><code>---\n- name: Validate Cluster Preparation\n  hosts: cluster_sn,cluster_ln,cluster_an\n  vars:\n    default_owner: kapl\n    default_group: kapl\n  tasks:\n  - name: Node Type\n    set_fact:\n      node_type: \"{{ group_names[1].split(\\\"_\\\")[1] }}\"\n  - name: Debug Node Type\n    debug:\n      msg: \"node type: {{ node_type }}\"\n  - name: Passwordless - root - authorized_keys\n    stat:\n      path: /root/.ssh/authorized_keys\n    register: passwordless_root_authorized_keys\n  - name: Passwordless - root - cn001 public key\n    shell: grep 'root@k22cn001' /root/.ssh/authorized_keys\n    register: passwordless_root_control_node_1\n  - name: Passwordless - root - cn002 public key\n    shell: grep 'root@k22cn002' /root/.ssh/authorized_keys\n    register: passwordless_root_control_node_2\n  - name: Passwordless - kapl - authorized_keys\n    stat:\n      path: /home/kapl/.ssh/authorized_keys\n    register: passwordless_kapl_authorized_keys\n  - name: Passwordless - kapl - cn001 public key\n    shell: grep 'kapl@k22cn001' /home/kapl/.ssh/authorized_keys\n    register: passwordless_kapl_control_node_1\n  - name: Passwordless - kapl - cn002 public key\n    shell: grep 'kapl@k22cn002' /home/kapl/.ssh/authorized_keys\n    register: passwordless_kapl_control_node_2\n  - name: Passwordless - status\n    set_fact:\n      passwordless_status: \n        control_node_1:\n          root: \"{{ passwordless_root_authorized_keys.stat.exists and passwordless_root_control_node_1.rc == 0 }}\"\n          kapl: \"{{ passwordless_kapl_authorized_keys.stat.exists and passwordless_kapl_control_node_1.rc == 0 }}\"\n        control_node_2:\n          root: \"{{  passwordless_root_authorized_keys.stat.exists and passwordless_root_control_node_2.rc == 0 }}\"\n          kapl: \"{{  passwordless_kapl_authorized_keys.stat.exists and passwordless_kapl_control_node_2.rc == 0 }}\"\n  - name: Debug Passwordless - kapl\n    debug:\n      var: passwordless_status\n  - name: Get CPU SMT\n    shell: cat /sys/devices/system/cpu/smt/active\n    register: cpu_smt\n  - name: CPU - SMT status\n    set_fact:\n      cpu_smt_status: \"{% if (cpu_smt.stdout == '1' ) %}true{% else %}false{% endif %}\"\n  - name: Fetch interface names\n    debug:\n      msg: \"{{ item }}\"\n    loop: \"{{ ansible_facts.interfaces | select('match', '^enp[0-9]+s0f0$')}}\"\n  - name:  Fetch interface and set \n    set_fact:\n      network_10g_interface_name: \"{{ item }}\"\n    loop: \"{{ ansible_facts.interfaces | select('match', '^enp[0-9]+s0f0$')}}\"\n  - name: Set fact for network - 10g\n    set_fact:\n      network_10g:\n        name: \"{{ network_10g_interface_name }}\"\n        mtu: \"{{ ansible_facts[network_10g_interface_name].mtu }}\"\n        speed: \"{{ ansible_facts[network_10g_interface_name].speed  }}\"\n        driver: {}\n        firmware: {}\n      network_100g:\n        name: ib0\n        mtu: \"{{ ansible_facts['ib0'].mtu }}\"\n        speed: \"{{ ansible_facts['ib0'].speed  }}\"\n        driver: {}\n        firmware: {}\n  - name: Get network driver - 10g\n    shell: ethtool -i {{ network_10g.name }} | grep version | head -n 1 | awk '{print $2}'\n    register: network_10g_driver\n  - name: Get network firmware - 10g\n    shell: ethtool -i {{ network_10g.name }} | grep firmware-version | awk '{print $3}'\n    register: network_10g_firmware\n  - name: Get network driver - 100g\n    shell: ethtool -i {{ network_100g.name }} | grep version | head -n 1 | awk '{print $2}'\n    register: network_100g_driver\n  - name: Get network firmware - 100g\n    shell: ethtool -i {{ network_100g.name }} | grep firmware-version | awk '{print $2}'\n    register: network_100g_firmware\n  - name: Update network driver, firmware\n    ansible.utils.update_fact:\n      updates:\n      - path: network_10g.driver.version\n        value: \"{{ network_10g_driver.stdout }}\"\n      - path: network_10g.firmware.version\n        value: \"{{ network_10g_firmware.stdout }}\"\n      - path: network_100g.driver.version\n        value: \"{{ network_100g_driver.stdout }}\"\n      - path: network_100g.firmware.version\n        value: \"{{ network_100g_firmware.stdout }}\"\n    register: updated\n  - name: Update fact for network\n    set_fact:\n      network_10g: \"{{ updated.network_10g }}\"\n      network_100g: \"{{ updated.network_100g }}\"\n  - name: Debug network variables\n    debug:\n      msg: \n      - \"{{ network_10g }}\"\n      - \"{{ network_100g }}\"\n  - name: Get subscription info\n    shell: subscription-manager status\n    register: subscription_info\n    become: yes\n  - name: set_status either to True or False\n    set_fact:\n      subscription_status: \"{% if (subscription_info.stdout_lines | regex_search('Overall Status: Current')) %}true{% else %}false{% endif %}\"\n  - name: Benchmark - HPL code drop\n    stat:\n      path: /tmp/Ansible_HPL/install_packages/amd-zen-hpl-avx2-2023_01.tar\n    register: hpl_code_drop\n  - name: Benchmark - HPL prebuilt env\n    stat:\n      path: /AMD-HPL\n    register: hpl_prebuilt_env\n  - name: Benchmark - HPL status\n    set_fact:\n      benchmark_hpl_status: \"{% if (hpl_code_drop.stat.exists and hpl_prebuilt_env.stat.exists ) %}true{% else %}false{% endif %}\"\n  - name: Benchmark - MPI spack\n    shell: source /tmp/spack/share/spack/setup-env.sh; spack --version\n    register: mpi_spack\n    ignore_errors: yes\n  - name: Benchmark - MPI status\n    set_fact:\n      benchmark_mpi_status: \"{% if (mpi_spack.rc == 0 ) %}true{% else %}false{% endif %}\"\n      benchmark_mpi_spack_version: \"{{ mpi_spack.stdout }}\"\n  - name: Benchmark - SPECRate install directory\n    stat:\n      path: /tmp/Ansible_SPEC-CPU-2017/cpu2017\n    register: spec_rate_install_directory\n  - name: Benchmark - SPECRate config\n    stat:\n      path: /tmp/Ansible_SPEC-CPU-2017/install_packages/config/spec-cpu_fprate_amd-7742_2_aocc_320_linux_x86.tar.xz\n    register: spec_rate_config\n  - name: Benchmark - SPECRate status\n    set_fact:\n      benchmark_spec_rate_status: \"{% if (spec_rate_install_directory.stat.exists and spec_rate_config.stat.exists ) %}true{% else %}false{% endif %}\"\n  - name: Benchmark - SPECAccel install directory\n    stat:\n      path: /tmp/Ansible_SPEC-ACCEL/accel\n    register: spec_accel_install_directory\n  - name: Benchmark - SPECAccel config\n    stat:\n      path: /tmp/Ansible_SPEC-ACCEL/install_packages/config/spec-accel_openacc_amd-7742_2_aocc_320_linux_x86.cfg\n    register: spec_accel_config\n  - name: Benchmark - SPECAccel flag\n    stat:\n      path: /tmp/Ansible_SPEC-ACCEL/install_packages/config/nvidia_flags.xml\n    register: spec_accel_flag\n  - name: Benchmark - SPECAccel status\n    set_fact:\n      benchmark_spec_accel_status: \"{% if (spec_accel_install_directory.stat.exists and spec_accel_config.stat.exists and spec_accel_flag.stat.exists ) %}true{% else %}false{% endif %}\"\n  - name: Benchmark - iperf3\n    shell: rpm -qa | grep iperf3\n    register: iperf3_installed\n    ignore_errors: yes\n    when: ansible_os_family == \"RedHat\"\n  - name: Benchmark - iperf3 status\n    set_fact:\n      benchmark_iperf3_status: \"{% if ( iperf3_installed.rc == 0  ) %}true{% else %}false{% endif %}\"\n  - name: Mount - /opt_shared\n    shell: mount | grep /opt_shared | awk '{print $1, $2, $3, $4, $5}'\n    register: mount_opt_shared_result\n  - name: Mount - /opt_shared info\n    set_fact:\n      nfs_client:\n        mount_opt_shared_status: \"{{ mount_opt_shared_result.rc == 0 and 'nfs' in mount_opt_shared_result.stdout }}\"\n        mount_opt_shared_info: \"{{ mount_opt_shared_result.stdout }}\"\n  - name: lsblk info\n    shell: lsblk\n    register: lsblk_result\n  - name: df -hT info\n    shell: df -hT\n    register: df_result\n  - name: Fetch disk name and set\n    set_fact:\n      disk_names: \"{{ ansible_facts.devices.keys() | select('match', '^nvme[0-9]{1}n[0-9]{1}') | map('regex_replace', '^(.*)$', '/dev/\\\\1') | list }}\"\n  - name: Debug disk names\n    debug:\n      var: disk_names\n  - name: smartctl info\n    shell: \"smartctl --all {{ item }}\"\n    loop: \"{{ disk_names }}\"\n    register: smartctl_result\n  - name: Debug directory for data file\n    debug:\n      msg: \n      - \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}\"\n  - name: Create directory for data file\n    file:\n      path: \"{{ item }}\"\n      state: directory\n      owner: \"{{ default_owner }}\"\n      group: \"{{ default_group }}\"\n      mode: '0777'\n    loop:\n      - \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}\"\n  - name: Generate host bom txt\n    template:\n      src: ../templates/host_bom.txt.j2\n      dest: \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}/{{ node_type }}-bom.txt\"\n      owner: \"{{ default_owner }}\"\n      group: \"{{ default_group }}\"\n  - name: Generate host bom json\n    template:\n      src: ../templates/host_bom.json.j2\n      dest: \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}/{{ node_type }}-bom.json\"\n      owner: \"{{ default_owner }}\"\n      group: \"{{ default_group }}\"\n  - name: Generate lsblk file\n    template:\n      src: ../templates/host_lsblk.txt.j2\n      dest: \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}/lsblk.txt\"\n      owner: \"{{ default_owner }}\"\n      group: \"{{ default_group }}\"\n  - name: Generate df file\n    template:\n      src: ../templates/host_df.txt.j2\n      dest: \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}/df.txt\"\n      owner: \"{{ default_owner }}\"\n      group: \"{{ default_group }}\"\n  - name: Generate smartctl file\n    template:\n      src: ../templates/host_smartctl.txt.j2\n      dest: \"{{ cluster_node_bom_host }}/{{ inventory_hostname }}/smartctl.txt\"\n      owner: \"{{ default_owner }}\"\n      group: \"{{ default_group }}\"\n</code></pre> <p>host_bom.json.j2 <pre><code>{\n    \"os_version\": \"{{ ansible_distribution_version }}\",\n    \"kernel_version\": \"{{ ansible_kernel }}\",\n    \"cpu\": {\n        \"smt\": {{ cpu_smt_status | to_json }}\n    }\n    \"network\": {\n        \"10g\": {{ network_10g | to_json }},\n        \"100g\": {{ network_100g | to_json }}\n        }\n    },\n    \"license\": {{ subscription_status | to_json }},\n    \"benchmark\": {\n        \"hpl\": {\"installed\": {{ benchmark_hpl_status | to_json }} },\n        \"mpi\": {\"installed\": {{ benchmark_mpi_status | to_json }} },\n        \"spec_rate\": {\"installed\": {{ benchmark_spec_rate_status | to_json }} },\n        \"spec_accel\": {\"installed\": {{ benchmark_spec_accel_status | to_json }} },\n        \"iperf3\": {\"installed\": {{ benchmark_iperf3_status | to_json }} }\n    },\n    \"passwordless\": {{ passwordless_status | to_json }},\n    \"nfs_client\": {{ nfs_client | to_json }}\n}\n</code></pre></p> <p>host_bom.txt.j2 <pre><code>##! Title: Get Node Bom {{ node_type | upper }} ({{ inventory_hostname }})\n##! Priority: 1\n##! TimeStamp: {{ \"%m%d:%H%M\" | strftime(ansible_date_time.epoch) }}\n{{ \"%-35s%-30s%-30s\" | format(\"Name\", \"Value\", \"Notes\") }}\n---------------------------------------------------------------------\n{{ \"%-35s%-30s%-30s\" | format(\"OS-Version\", ansible_distribution_version, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Kernel-Version\", ansible_kernel, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"CPU-SMT\", cpu_smt_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-10G-Name\", network_10g.name, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-10G-Driver-Version\", network_10g.driver.version, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-10G-FW-Version\", network_10g.firmware.version, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-10G-MTU\", network_10g.mtu, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-10G-Speed\", network_10g.speed, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-100G-Name\", network_100g.name, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-100G-Driver-Version\", network_100g.driver.version, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-100G-FW-Version\", network_100g.firmware.version, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-100G-MTU\", network_100g.mtu, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Net-100G-Speed\", network_100g.speed, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"License-Registered\", subscription_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Benchmarks-HPL-Installed\", benchmark_hpl_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Benchmarks-MPI-Installed\", benchmark_mpi_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Benchmarks-SPECRate-Installed\", benchmark_spec_rate_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Benchmarks-SPECAccel-Installed\", benchmark_spec_accel_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Benchmarks-Iperf-Installed\", benchmark_iperf3_status, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Passwordless-cn001-root\", passwordless_status.control_node_1.root, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Passwordless-cn001-kapl\", passwordless_status.control_node_1.kapl, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Passwordless-cn002-root\", passwordless_status.control_node_2.root, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"Passwordless-cn002-kapl\", passwordless_status.control_node_2.kapl, \"-\") }}\n{{ \"%-35s%-30s%-30s\" | format(\"NFS-Client-Mount\", nfs_client.mount_opt_shared_status, nfs_client.mount_opt_shared_info) }}\n</code></pre></p> <p>host_smartctl.txt.j2 <pre><code>------------------------------------------------------------------\n{{ smartctl_result.results[0].item }}\n------------------------------------------------------------------\n{{ smartctl_result.results[0].stdout }}\n\n\n------------------------------------------------------------------\n{{ smartctl_result.results[1].item }}\n------------------------------------------------------------------\n{{ smartctl_result.results[1].stdout }}\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#cron","title":"cron","text":""},{"location":"hackmd/Ansible%20Practice/#yml_1","title":"```yml=","text":"<ul> <li>name: Control Node Crontab setting   hosts: cluster_cn   vars:<ul> <li>root_dir: \"{{ project_root }}/{{ project_env }}\"</li> <li>primary_control_node: k22cn001</li> <li>stop_cron_job: false   become: yes   tasks:</li> </ul> </li> <li>name: set_fact     set_fact:         stop_cron_job: true     when: \"inventory_hostname != primary_control_node and primary_control_node in ansible_play_hosts\"</li> <li>name: check stop_cron_job     debug:       var: stop_cron_job</li> <li>name: Creates an entry like SMC_ROOT_DIR on top of crontab     ansible.builtin.cron:       name: SMC_ROOT_DIR       user: root       env: yes       job: \"{{ root_dir }}\"</li> <li>name: Creates an entry like CRON_ENV to indicate if invaking by crontab     ansible.builtin.cron:       name: CRON_ENV       user: root       env: yes       job: 1</li> <li>name: Cron for root user - fetch pdu power     ansible.builtin.cron:       name: \"fetch the metrics about PDU power\"       user: root       minute: \"1-59\"       job: \"${SMC_ROOT_DIR}/bin/pdu-power/fetch-metrics-multiple-node.sh pdu\"       disabled: \"{{stop_cron_job}}\"</li> <li>name: Cron for root user - retention pdu power     ansible.builtin.cron:       name: \"retention the metrics about PDU power\"       user: root       hour: \"1\"       minute: \"0\"       job: \"${SMC_ROOT_DIR}/bin/pdu-power/retention-metrics-multiple-node.sh pdu\"       disabled: \"{{stop_cron_job}}\"</li> <li>name: Creates an entry like SMC_ROOT_DIR on top of crontab     ansible.builtin.cron:       name: SMC_ROOT_DIR       user: kapl       env: yes       job: \"{{root_dir}}\"</li> <li>name: Cron for kapl user - txt to csv     ansible.builtin.cron:       name: \"transfer txt to csv\"       user: kapl       minute: \"2-59/5\"       job: \"${SMC_ROOT_DIR}/bin/supports-misc/403-cron-txt-to-csv.sh.x\"       disabled: \"{{stop_cron_job}}\"</li> <li>name: Cron for kapl user - csv to html     ansible.builtin.cron:       name: \"transfer csv to html\"       user: kapl       minute: \"3-59/5\"       job: \"${SMC_ROOT_DIR}/bin/supports-misc/404-cron-csv-to-html.sh.x\"       disabled: \"{{ stop_cron_job }}\"</li> <li>name: Cron for kapl user - csv to json     ansible.builtin.cron:       name: \"transfer csv to json\"       user: kapl       minute: \"4-59/5\"       job: \"${SMC_ROOT_DIR}/bin/supports-misc/405-cron-csv-to-json.sh.x\"       disabled: \"{{ stop_cron_job }}\" </li> <li>name: Compute Node Crontab setting   hosts: cluster_sn, cluster_ln, cluster_an   vars:<ul> <li>root_dir: \"{{ project_root }}/{{ project_env }}\"   become: yes   gather_facts: no   tasks:</li> </ul> </li> <li>name: Creates an entry like SMC_ROOT_DIR on top of crontab     ansible.builtin.cron:       name: SMC_ROOT_DIR       user: root       env: yes       job: \"{{ root_dir }}\"</li> <li>name: Cron for root user - fetch power temparature     ansible.builtin.cron:       name: \"fetch the metrics about Power Temparature\"       user: root       minute: \"1-59\"       job: \"${SMC_ROOT_DIR}/bin/pdu-power/fetch-metrics-single-node.sh\"</li> <li>name: Cron for root user - retention power temparature     ansible.builtin.cron:       name: \"retention the metrics about Power Temparature\"       user: root       hour: \"1\"       minute: \"0\"       job: \"${SMC_ROOT_DIR}/bin/pdu-power/retention-metrics-single-node.sh\"</li> </ul> <pre><code>## nagios\n### install\n\n``` yml\n---\n- name: Install Nagios Core and Plugins\n  hosts: cluster_cn\n  vars:\n    core_version: 4.4.8\n    plugins_version: 2.4.0\n    core_install_dir: /tmp/nagios-{{core_version}}\n    plugins_install_dir: /tmp/nagios-plugins-release-{{ plugins_version }}\n    user_file: /usr/local/nagios/etc/htpasswd.users\n  vars_files:\n    - ../../vars/rhel.yml\n  become: yes\n  tasks:\n  - name: Reset project root\n    set_fact:\n      project_root: /opt_shared-master/smci/kapl\n    when: inventory_hostname == 'k22cn002'\n  - name: Debug\n    debug:\n      msg: \"{{ ansible_distribution_major_version }} {{ project_root }}\"\n  - name: Disale SELINUX\n    shell: sed -i 's/^SELINUX=.*$/SELINUX=disabled/' /etc/selinux/config\n  - name: Install Nagios Prerequisites\n    yum:\n      name:\n        - gcc\n        - glibc\n        - glibc-common\n        - perl\n        - httpd\n        - php\n        - wget\n        - gd\n        - gd-devel\n        - openssl-devel\n      state: present\n    when: ansible_distribution == \"RedHat\" and ansible_distribution_major_version == \"8\"\n  # https://support.nagios.com/kb/article.php?id=569#RHEL\n  - name: Install epel rpm from a local file\n    yum:\n      name: \"{{ project_repo }}/linux/rpm/epel-release-latest-8.noarch.rpm\"\n      state: present\n  - name: Enable repo\n    shell: subscription-manager repos --enable \"codeready-builder-for-rhel-8-x86_64-rpms\"\n  - name: Install Nagios Plugins Prerequisites\n    yum:\n      name:\n        - make\n        - gettext\n        - automake\n        - autoconf\n        - net-snmp\n        - net-snmp-utils\n        - perl-Net-SNMP\n        - fping\n        - lm_sensors\n      state: present\n    when: ansible_distribution == \"RedHat\" and ansible_distribution_major_version == \"8\"\n  - name: Get rid of semi-created installation dir\n    file:\n      path: \"{{ item }}\"\n      state: absent\n    loop:\n      - \"{{ core_install_dir }}\"\n      - \"{{ plugins_install_dir }}\"\n  - name: Copy core file\n    copy:\n      src: \"{{ project_repo }}/linux/tar-gz/nagios-{{core_version}}.tar.gz\"\n      dest: \"{{ core_install_dir }}.tar.gz\"\n  - name: Copy plugins file\n    copy:\n      src: \"{{ project_repo }}/linux/tar-gz/nagios-plugins-release-{{ plugins_version }}.tar.gz\"\n      dest: \"{{ plugins_install_dir }}.tar.gz\"\n  - name: Create directory for uncompressed\n    file:\n      path: \"{{ item }}\"\n      state: directory\n      mode: '0777'\n    loop:\n      - \"{{ core_install_dir }}\"\n      - \"{{ plugins_install_dir }}\"\n      - \"{{ project_log }}/nagios\"\n  - name: Extract Nagios Core\n    unarchive:\n      src: \"{{ core_install_dir }}.tar.gz\"\n      dest: \"{{ core_install_dir }}\"\n      extra_opts:\n        - --strip-components=1\n  - name: Extract Nagios Pligins\n    unarchive:\n      src: \"{{ plugins_install_dir }}.tar.gz\"\n      dest: \"{{ plugins_install_dir }}\"\n      extra_opts:\n        - --strip-components=1\n  - name: Compile\n    shell: \"{{ item }} &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-compile.log\"\n    args:\n      chdir: \"{{ core_install_dir }}\"\n    loop:\n      - ./configure\n      - make all\n  - name: Create User And Group\n    shell: \"{{ item }} &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-install-groups-users.log\"\n    args:\n      chdir: \"{{ core_install_dir }}\"\n    loop:\n      - make install-groups-users\n      - usermod -a -G nagios apache\n  - name: Install Binaries, Service / Daemon\n    shell: \"{{ item }} &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-install.log\"\n    args:\n      chdir: \"{{ core_install_dir }}\"\n    loop:\n      - make install\n      - make install-daemoninit\n  - name: Install Command Mode\n    shell: \"make install-commandmode &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-install-commandmode.log\"\n    args:\n      chdir: \"{{ core_install_dir }}\"\n  - name: Install Configuration Files\n    shell: \"make install-config &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-install-config.log\"\n    args:\n      chdir: \"{{ core_install_dir }}\"\n  - name: Install Apache Config Files\n    shell: \"make install-webconf &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-install-webconf.log\"\n    args:\n      chdir: \"{{ core_install_dir }}\"\n  - name: Configure Firewall for Nagios Core web interface\n    shell: \"{{ item }}\"\n    loop:\n      - firewall-cmd --zone=public --add-port=80/tcp\n      - firewall-cmd --zone=public --add-port=80/tcp --permanent\n  - name: Get rid of nagios pass file\n    file:\n      path: \"{{ user_file }}\"\n      state: absent\n  - name: Create nagiosadmin User Account\n    shell: \"htpasswd -b -c {{ user_file }} nagiosadmin {{ kapl_password }}\"\n  - name: Create kapl User Account\n    shell: \"htpasswd -b {{ user_file }} {{kapl_username}} {{ kapl_password }}\"\n  - name: Plugins - Compile \n    shell: \"{{ item }} &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-plugins-compile.log\"\n    args:\n      chdir: \"{{ plugins_install_dir }}\"\n    loop:\n      - ./tools/setup\n      - ./configure\n      - make\n  - name: Plugins - Install \n    shell: \"make install &gt;&gt; {{ project_log }}/nagios/nagios-{{ inventory_hostname }}-plugins-install.log\"\n    args:\n      chdir: \"{{ plugins_install_dir }}\"\n  - name: Plugins - Verify if installed\n    stat:\n      path: /usr/local/nagios/libexec/check_ping\n    register: plugins_installed\n  - name: Debug Plugins - Verify if installed\n    debug:\n      msg: \"Plugins are installed: {{ plugins_installed.stat.exists }}\"\n  - name: run and enable systemd service\n    service:\n      name: \"{{ item }}\"\n      state: restarted\n      enabled: yes\n    become: yes\n    loop:\n      - httpd\n      - nagios\n</code></pre>"},{"location":"hackmd/Ansible%20Practice/#config","title":"config","text":"<pre><code>---\n- name: Config Nagios Core and Plugins\n  hosts: cluster_cn\n  vars:\n    config_dir: /usr/local/nagios/etc\n  vars_files:\n    - ../../vars/rhel.yml\n  become: yes\n  tasks:\n  - name: Reset project root\n    set_fact:\n      project_root: /opt_shared-master/smci/kapl\n    when: inventory_hostname == 'k22cn002'\n  - name: Debug\n    debug:\n      msg: \"{{ groups['cluster_cn'] | join(',') }} {{ project_root }}\"\n  - name: Check user privilege\n    shell: \"grep 'nagiosadmin,{{ kapl_username }}' {{ config_dir }}/cgi.cfg\"\n    register: check_user_priv\n  - name: Config users privilege\n    replace:\n      path: \"{{ config_dir }}/cgi.cfg\"\n      regexp: 'nagiosadmin'\n      replace: \"nagiosadmin,{{ kapl_username }}\"\n      backup: no\n    when: check_user_priv.rc == 1\n  - name: Ensure swiches configuration dir\n    lineinfile:\n      path: \"{{ config_dir }}/nagios.cfg\"\n      regexp: \"^cfg_dir={{ config_dir }}/switches\"\n      insertafter: \"^#cfg_dir={{ config_dir }}/switches\"\n      line: \"cfg_dir={{ config_dir }}/switches\"\n  - name: Ensure server configuration dir\n    lineinfile:\n      path: \"{{ config_dir }}/nagios.cfg\"\n      regexp: \"^cfg_dir={{ config_dir }}/servers\"\n      insertafter: \"^#cfg_dir={{ config_dir }}/servers\"\n      line: \"cfg_dir={{ config_dir }}/servers\"\n  - name: Ensure pdu configuration dir\n    lineinfile:\n      path: \"{{ config_dir }}/nagios.cfg\"\n      regexp: \"^cfg_dir={{ config_dir }}/routers\"\n      insertafter: \"^#cfg_dir={{ config_dir }}/routers\"\n      line: \"cfg_dir={{ config_dir }}/pdus\"\n  - name: Create directory for configuration\n    file:\n      path: \"{{ item }}\"\n      state: directory\n      owner: nagios\n      group: nagios\n      mode: '0755'\n    loop:\n      - \"{{ config_dir }}/servers\"\n      - \"{{ config_dir }}/switches\"\n      - \"{{ config_dir }}/pdus\"\n  - name: Generate control node config\n    template:\n      src: ../../templates/nagios/control_node.cfg.j2\n      dest: \"{{ config_dir }}/servers/{{ inventory_hostname }}.cfg\"\n      owner: nagios\n      group: nagios\n  - name: Generate group config\n    template:\n      src: ../../templates/nagios/group_node_type.cfg.j2\n      dest: \"{{ config_dir }}/servers/group_node_type.cfg\"\n      owner: nagios\n      group: nagios\n</code></pre> <p>control_node.cfg.j2 <pre><code>###############################################################################\n# LOCALHOST.CFG - SAMPLE OBJECT CONFIG FILE FOR MONITORING THIS MACHINE\n#\n#\n# NOTE: This config file is intended to serve as an *extremely* simple\n#       example of how you can create configuration entries to monitor\n#       the local (Linux) machine.\n#\n###############################################################################\n\n\n\n###############################################################################\n#\n# HOST DEFINITION\n#\n###############################################################################\n\n# Define a host for the local machine\n\ndefine host {\n\n    use                     linux-server            ; Name of host template to use\n                                                    ; This host definition will inherit all variables that are defined\n                                                    ; in (or inherited by) the linux-server host template definition.\n    host_name               {{ inventory_hostname }}\n    alias                   {{ inventory_hostname }}\n    address                 {{ hostvars[inventory_hostname]['ansible_host'] }}\n}\n\n\n\n\n\n###############################################################################\n#\n# SERVICE DEFINITIONS\n#\n###############################################################################\n\n# Define a service to \"ping\" the local machine\n\ndefine service {\n\n    use                     generic-service           ; Name of service template to use\n    host_name               {{ inventory_hostname }}\n    service_description     PING\n    check_command           check_ping!100.0,20%!500.0,60%\n}\n\n\n\ndefine service {\n\n    use                     generic-service           ; Name of service template to use\n    host_name               {{ inventory_hostname }}\n    service_description     SSH\n    check_command           check_ssh\n    notifications_enabled   0\n}\n\n# Define a service to check HTTP on the local machine.\n# Disable notifications for this service by default, as not all users may have HTTP enabled.\n\ndefine service {\n\n    use                     generic-service           ; Name of service template to use\n    host_name               {{ inventory_hostname }}\n    service_description     HTTP\n    check_command           check_http\n    notifications_enabled   0\n}\n</code></pre></p> <p>group_node_type.cfg.j2 <pre><code>###############################################################################\n#\n# HOST GROUP DEFINITION\n#\n###############################################################################\n\n# Define an optional hostgroup for Linux machines\n\ndefine hostgroup {\n\n    hostgroup_name          cn           ; The name of the hostgroup\n    alias                   Control Node           ; Long name of the group\n    members                 {{ groups['cluster_cn'] | join(',') }}               ; Comma separated list of hosts that belong to this group\n}\n\n\ndefine hostgroup {\n\n    hostgroup_name          sn           ; The name of the hostgroup\n    alias                   Small Node           ; Long name of the group\n    members                 {{ groups['cluster_sn'] | join(',') }}               ; Comma separated list of hosts that belong to this group\n}\n\ndefine hostgroup {\n\n    hostgroup_name          ln           ; The name of the hostgroup\n    alias                   Large Node           ; Long name of the group\n    members                 {{ groups['cluster_ln'] | join(',') }}               ; Comma separated list of hosts that belong to this group\n}\n\ndefine hostgroup {\n\n    hostgroup_name          an           ; The name of the hostgroup\n    alias                   Accelerated Node           ; Long name of the group\n    members                 {{ groups['cluster_an'] | join(',') }}               ; Comma separated list of hosts that belong to this group\n}\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#install-package-and-verify-network","title":"install package and verify network","text":"<pre><code>---\n- name: Initial validation for control node\n  hosts: cluster_cn\n  vars_files:\n    - ../vars/rhel.yml\n  tasks:\n  - name:  Fetch interface and set\n    set_fact:\n      network_10g_interface_name: \"{{ item }}\"\n    loop: \"{{ ansible_facts.interfaces | select('match', '^enp[0-9]+s0f0$')}}\"\n  - name: set interface MTU 9000\n    shell: |\n      ifconfig {{ item }} mtu 9000\n    loop:\n      - \"{{ network_10g_interface_name }}\"\n  - name: set interface MTU 9000 permanent\n    lineinfile:\n      path: /etc/sysconfig/network-scripts/ifcfg-{{item}}\n      line: MTU=9000\n      state: present\n    loop:\n      - \"{{ network_10g_interface_name }}\"\n    become: yes\n  - name: Verify foo account and subscription\n    include_role:\n      name: rhel_account\n  - name: Prevent Kernel Upgrades \n    ansible.builtin.lineinfile:\n      path: /etc/yum.conf\n      line: exclude=kernel* redhat-release* kmod-kvdo\n    become: yes\n  - name: Allow chronyd works\n    ansible.builtin.lineinfile:\n      path: /etc/chrony.conf\n      line: allow 167.22.10.2\n    become: yes\n    when: inventory_hostname == primary_control_node\n  - name: Set timezone\n    community.general.timezone:\n      name: America/Los_Angeles\n  - name: stop and disable systemd service\n    service:\n      name: \"{{ item }}\"\n      state: stopped\n      enabled: no\n    become: yes\n    loop:\n      - firewalld\n    when: inventory_hostname == primary_control_node\n  - name: run and enable systemd service\n    service:\n      name: \"{{ item }}\"\n      state: started\n      enabled: yes\n    become: yes\n    loop:\n      - firewalld\n    when: inventory_hostname == backup_control_node\n  - name: run and enable systemd service\n    service:\n      name: \"{{ item }}\"\n      state: started\n      enabled: yes\n    become: yes\n    loop:\n      - chronyd\n      - nfs-server\n  - name: check network reachability - internet and dns\n    shell: ping -c 2 \"{{ item }}\"\n    loop:\n      - 8.8.8.8\n      - www.google.com\n  - name: check network reachability - 10gb network\n    shell: ping -c 2 167.22.10.2 -I enp33s0f0\n    become: yes\n    register: ping_result\n    failed_when: ping_result.rc != 0\n    ignore_errors: yes\n  - name: check network reachability - infiniband network\n    shell: ping -c 2 167.122.10.2 -I ib0\n    become: yes\n    register: ping_result\n    failed_when: ping_result.rc != 0\n    ignore_errors: yes\n  - name: check network reachability - BMC network\n    shell: ping -c 2 167.222.10.2\n    register: ping_result\n    failed_when: ping_result.rc != 0\n    ignore_errors: yes\n  - name: check chronyd \n    shell: chronyc tracking\n    register: chronyc_tracking\n    failed_when: \"'Leap status     : Normal' not in chronyc_tracking.stdout\"\n  - name: Install the package group\n    ansible.builtin.yum:\n      name: \"{{ item }}\"\n      state: present\n      disablerepo: '*'\n      enablerepo: local-rhels8.7.0-x86_64--install-rhels8.7.0-x86_64-AppStream,local-rhels8.7.0-x86_64--install-rhels8.7.0-x86_64-BaseOS\n    become: yes\n    loop:\n      - \"@Infiniband Support\"\n      - \"@Performance Tools\"\n      - \"@Development Tools\" \n      - \"@Scientific Support\"\n      - \"@System Tools\"\n      - python39\n      - sshpass\n    when: ansible_distribution==\"RedHat\"\n  - include_role:\n      name: ipmitool_package\n  - name: Install ansible\n    ansible.builtin.pip:\n      name:\n      - ansible-core==2.14\n      - python-ipmi==0.5.4\n      - ansible-pylibssh==1.1.0 # for cisco switch\n      executable: pip3.9\n  - name: Install ansible collections\n    shell: ansible-galaxy collection install {{ item }}\n    loop:\n      - community.general\n      - ansible.posix\n      - ansible.utils\n      - cisco.nxos # for cisco switch\n</code></pre>"},{"location":"hackmd/Ansible%20Practice/#get-a-list-of-unreachable-hosts-in-an-ansible-playbook","title":"Get a list of unreachable hosts in an ansible playbook","text":"<ul> <li>Is there a way to get a list of unreachable hosts in an ansible playbook - Stack Overflow</li> </ul> <p>``` yml= - name Unreachable servers   set_fact:     down: \"{{ ansible_play_hosts_all | difference(ansible_play_hosts)}}\" <pre><code>## Node Sync \n\n### sync from cn001 to cn002\n\nMethod 1: if execute it on cn001\n``` bash\nansible-playbook  playbook/playbook_sync.yml --limit 'cn002' --extra-vars \"mode=push\"\n</code></pre></p> <p>Method 2: if execute it on cn002 and mode is pull, use sudo <pre><code>sudo ansible-playbook  playbook/playbook_sync.yml --limit 'cn001' --extra-vars \"mode=pull\"\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#sync-from-cn002-to-cn001","title":"sync from cn002 to cn001","text":"<p>Method 1: if execute it on cn001 and mode is pull, use sudo <pre><code>sudo ansible-playbook  playbook/playbook_sync.yml --limit 'cn002' --extra-vars \"mode=pull\"\n</code></pre></p> <p>Method 2: if execute it on cn002 <pre><code>ansible-playbook  playbook/playbook_sync.yml --limit 'cn001' --extra-vars \"mode=push\"\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#sync-only-development-content-like-script-config-from-cn001-to-cn002","title":"sync only development content like script, config from cn001 to cn002","text":"<p>if execute it on cn002 and mode is pull, use sudo <pre><code>sudo ansible-playbook  playbook/playbook_sync.yml --tags develop --limit 'cn001' --extra-vars \"mode=pull\"\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#sync-only-ha-content-like-data-reports-logs-from-cn001-to-cn002","title":"sync only ha content like data, reports, logs from cn001 to cn002","text":"<p>if execute it on cn002 and mode is pull, use sudo <pre><code>sudo ansible-playbook  playbook/playbook_sync.yml --tags data --limit 'cn001' --extra-vars \"mode=pull\"\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#yml_2","title":"``` yml=","text":"<ul> <li>name: Sync Process   hosts: cluster_cn   become: yes   vars:<ul> <li>devlopment_content:</li> <li>bin</li> <li>config</li> <li>scripts</li> <li>data_content:</li> <li>data</li> <li>reports</li> <li>logs   tasks:</li> </ul> </li> <li>name: Show the sync mode     debug:       msg:          - \"{{ mode }} mode\"         - \"push mode from machine which execute ansible to {{ inventory_hostname }}\"         - \"pull mode from {{ inventory_hostname }} to machine which execute ansible\"</li> <li>name: Synchronization development content like script, config using rsync protocol     ansible.posix.synchronize:       mode: \"{{ mode }}\"       src: \"{{ project_root }}/{{ project_env }}/{{ item }}/\"       dest: \"{{ project_root }}/{{ project_env }}/{{ item }}/\"     loop: \"{{ devlopment_content }}\"     register: develop_sync_result     tags:<ul> <li>develop</li> </ul> </li> <li>name: Show sync result     debug:       msg: \"{{ item.stdout_lines }}\"     loop: \"{{ develop_sync_result.results }}\"     tags:<ul> <li>develop</li> </ul> </li> <li>name: Synchronization ha content like data, reports, logs using rsync protocol     ansible.posix.synchronize:       mode: \"{{ mode }}\"       src: \"{{ project_root }}/{{ project_env }}/{{ item }}/\"       dest: \"{{ project_root }}/{{ project_env }}/{{ item }}/\"       rsync_opts:<ul> <li>\"--min-size=1\" loop: \"{{ data_content }}\" register: develop_sync_result tags:</li> <li>data</li> </ul> </li> <li>name: Show sync result     debug:       msg: \"{{ item.stdout_lines }}\"     loop: \"{{ develop_sync_result.results }}\"     tags:<ul> <li>data</li> </ul> </li> </ul> <pre><code>## Template for loop from ansible_play_hosts and register with hostvars\n\n``` yml=\n---\n- name: Get cluster name\n  hosts: all\n  gather_facts: true\n  vars:\n    cluster_cn_name: /root/foo/cn_name.txt\n    default_owner: foo\n    default_group: foo\n  tasks:\n    - name: Read contents of file\n      slurp:\n        src: \"{{ cluster_cn_name }}\"\n      register: control_host\n    - name: Print contents of file\n      debug:\n        msg: \"{{ control_host['content'] | b64decode }}\"\n    - name: Generate host bom txt\n      template:\n        src: ../templates/ha_cluster_cn_name_bom.txt.j2\n        dest: \"{{ project_root }}/{{ project_env }}/data/ha/cluster_cn_name_bom.txt\"\n        owner: \"{{ default_owner }}\"\n        group: \"{{ default_group }}\"\n      delegate_to: localhost\n</code></pre> <p>ha_cluster_cn_name_bom.txt.j2 <pre><code>{% for play_hostname in ansible_play_hosts %}\n{{ play_hostname }} {{ hostvars[play_hostname].control_host['content'] | b64decode | trim }}\n{% endfor %}\n</code></pre></p>"},{"location":"hackmd/Ansible%20Practice/#generate-the-known_host-on-the-control-node","title":"generate the known_host on the control node","text":"<pre><code>---\n- name: Generate SSH keys and add to known_hosts\n  hosts: all  # Replace with the target hosts you want to add to the known_hosts file\n  gather_facts: false\n  tasks:\n    - name: Add public key to known_hosts\n      shell: ssh-keyscan  {{ hostvars[inventory_hostname].ansible_host }}\n      register: keyscan_output\n      delegate_to: localhost\n    - name: Ensure unique entries in known_hosts\n      ansible.builtin.lineinfile:\n        path: ~/.ssh/known_hosts\n        line: \"{{ item }}\"\n        create: yes\n      loop: \"{{ keyscan_output.stdout_lines }}\"\n      when: keyscan_output.stdout_lines is defined\n      delegate_to: localhost\n</code></pre>"},{"location":"hackmd/Ansible%20Practice/#copy-files-with-wildcard","title":"copy files with wildcard","text":"<ul> <li>Ansible copy files with wildcard? - Stack Overflow<ul> <li>ansible.builtin.fileglob lookup \u2013 list files matching a pattern \u2014 Ansible Documentation</li> </ul> </li> </ul>"},{"location":"hackmd/Ansible%20Practice/#get-ip-address-from-inventory-group","title":"get ip address from inventory group","text":"<ul> <li>The extract filter is used to map from a list of indices to a list of values from a container (hash or array)</li> <li>jinja2 - Ansible: Get all the IP addresses of a group - Stack Overflow</li> </ul> <pre><code>{{ groups['mainnodes'] | map('extract', hostvars, ['ansible_host']) | join(',') }}\n</code></pre>"},{"location":"hackmd/Ansible%20Practice/#block-and-condition-with-group","title":"block and condition with group","text":"<pre><code>- hosts: all\n  tasks:\n  - name: Install packages for Redhat\n    block:\n    - name: Installation for all nodes\n      ansible.builtin.dnf:\n        name:\n          - munge\n          - slurm\n          - slurm-contribs\n          - slurm-perlapi\n        state: latest\n    - name: Installation for login nodes\n      ansible.builtin.dnf:\n        name:\n          - slurm-devel\n          - slurm-pmi\n          - slurm-pmi-devel\n        state: latest\n      when: \"'loginNode' in group_names\"\n    - name: Installation for control nodes\n      ansible.builtin.dnf:\n        name:\n          - slurm-slurmctld\n        state: latest\n      when: \"'controlNode' in group_names\"\n    - name: Install the singularity ce\n      # https://docs.sylabs.io/guides/latest/admin-guide/installation.html#install-from-provided-rpm-deb-packages\n      ansible.builtin.dnf:\n        name: 'https://github.com/sylabs/singularity/releases/download/v{{ options.singularity_ce_version }}/singularity-ce-{{ options.singularity_ce_version }}-1.el8.x86_64.rpm'\n        state: present\n        disable_gpg_check: True\n      when: \"'databaseNode' in group_names\"\n    - name: Installation for database nodes\n      ansible.builtin.dnf:\n        name:\n          - mariadb-server\n          - slurm-slurmdbd\n        state: latest\n      when: \"'databaseNode' in group_names\"\n    - name: Installation for compute nodes\n      ansible.builtin.dnf:\n        name:\n          - slurm-slurmd\n          - slurm-pmi\n        state: latest\n      when: \"'computeNode' in group_names or 'acceleratorNode' in group_names\"\n    when: (ansible_distribution == \"Rocky\" or ansible_distribution == \"RedHat\") and ansible_distribution_major_version == \"8\"\n</code></pre>"},{"location":"hackmd/Ansible%20Practice/#inventory-for-localhost","title":"inventory for localhost","text":"<pre><code>all:\n  hosts:\n     localhost:\n      ansible_connection: local\n</code></pre>"},{"location":"hackmd/Ansible/","title":"Ansible","text":"<ul> <li>Learning Ansible basics</li> <li>30 \u5929\u5165\u9580 Ansible \u53ca Jenkins</li> <li>GitHub - geerlingguy/ansible-for-devops: Ansible for DevOps examples.</li> <li>video<ul> <li>What is Ansible | Ansible Playbook explained | Ansible Tutorial for Beginners - YouTube</li> <li>Ansible Full Course | Zero to Hero - YouTube</li> </ul> </li> <li>labs<ul> <li>Ansible Lab environment using Docker<ul> <li>change the ansible/base/Dockerfile from ubuntu:17.10 to ubuntu:20.04</li> <li>docker compose build base</li> <li>docker compose build master</li> <li>docker compose build host</li> <li>docker compose up -d</li> </ul> </li> </ul> </li> <li>workshop<ul> <li>GitHub - ansible/workshops: Training Course for Ansible Automation Platform</li> <li>GitHub - LMtx/ansible-lab-docker: Ansible Lab environment using Docker</li> </ul> </li> <li>config<ul> <li>Configuring Ansible \u2014 Ansible Documentation</li> <li>Ansible Configuration Settings \u2014 Ansible Documentation</li> </ul> </li> <li>User Guide \u2014 Ansible Documentation</li> <li>Tips and tricks \u2014 Ansible Documentation</li> <li>Collection Index \u2014 Ansible Documentation<ul> <li>In Ansible 2.10 and later, most modules are hosted in collections.</li> <li>Using collections \u2014 Ansible Documentation</li> <li>\u5982\u4f55\u8ca2\u737b\u4f60\u7684\u7b2c\u4e00\u652f Ansible Collection \u4ee5\u53ca Ansible Tower Workflow \u61c9\u7528\u7c21\u4ecb | \u91ce\u751f\u7684\u5de5\u7a0b\u5e2b</li> </ul> </li> <li>CLI<ul> <li>ansible-playbook \u2014 Ansible Documentation</li> </ul> </li> <li>Parallelism<ul> <li>How to implement parallelism and rolling updates in Ansible | Enable Sysadmin</li> <li>8 ways to speed up your Ansible playbooks | Enable Sysadmin</li> <li>How to speed up Ansible playbooks drastically ?</li> <li>Controlling where tasks run: delegation and local actions \u2014 Ansible Documentation</li> <li>Asynchronous actions and polling \u2014 Ansible Documentation</li> </ul> </li> <li>variables<ul> <li>Ansible \u8b8a\u6578\u4e0d\u5b58\u5728\u6642\u6307\u5b9a\u9810\u8a2d\u503c - Yowko's Notes</li> <li>ansible: reference to a variable from the same list - Stack Overflow<ul> <li>Can't reference a dict key inside the same dict \u00b7 Issue #50280 \u00b7 ansible/ansible \u00b7 GitHub</li> <li>Advanced playbook syntax \u2014 Ansible Documentation</li> </ul> </li> </ul> </li> <li>GUI<ul> <li>Ansible UI: Semaphore UI vs Tower - Semaphore UI</li> <li>jenkins - Is it a good idea to make Ansible and Rundeck work together, or using either one is enough? - Stack Overflow</li> <li>Is there any existing UI for Ansible? - Quora</li> <li>Intro to RedHat Ansible Automation Platform | NetGru - YouTube</li> <li>Semaphore, RunDeck and AWX Ansible : r/devops</li> <li>AWX vs Ansible Automation Platform : r/ansible</li> <li>Ansible Tower vs. AWX vs. Red Hat Ansible Automation Platform : r/ansible</li> <li>Integrating Ansible Core with Rundeck for Simplified Automation Is good idea ? : r/ansible</li> </ul> </li> <li>Red Hat Enterprise Linux Automation with Ansible (RH294)</li> </ul> <ul> <li>control node<ul> <li>python</li> <li>inventory file</li> <li>ssh</li> </ul> </li> <li>managed nodes<ul> <li>ssh</li> </ul> </li> <li>inventory file<ul> <li>organize managed nodes in centralized files</li> <li>static, dynamic</li> <li>format<ul> <li>YAML</li> <li>INI</li> </ul> </li> <li>group, variables<ul> <li>Groups can contain child groups, and hosts can be members of multiple groups. </li> </ul> </li> </ul> </li> <li>playbook<ul> <li>automation blueprints that Ansible uses to deploy and configure managed nodes.</li> <li>format<ul> <li>YAML</li> </ul> </li> <li>play, task, module<ul> <li>Index of all Modules \u2014 Ansible Documentation</li> <li>A task is the application of a module to perform a specific unit of work.</li> <li>A play is a sequence of tasks to be applied, in order, to one or more hosts selected from your inventory.</li> </ul> </li> </ul> </li> <li>RH294<ul> <li>RH294 Red Hat Enterprise Linux Automation with Ansible - Basic and Variable data</li> <li>RH294 Red Hat Enterprise Linux Automation with Ansible - Task flow</li> <li>RH294 Red Hat Enterprise Linux Automation with Ansible - advanced and debug</li> <li>RH294 Red Hat Enterprise Linux Automation with Ansible - Automating Linux Administration Tasks</li> </ul> </li> </ul> <p>idempotent In general, tasks in Ansible Playbooks are idempotent, and it is safe to run a playbook multiple times. If the targeted managed hosts are already in the correct state, no changes should be made. ``` yml=</p>"},{"location":"hackmd/Ansible/#not-idempotent","title":"not idempotent","text":""},{"location":"hackmd/Ansible/#every-time-the-play-is-run-it-rewrites-etcresolvconf-even-if-it-already-consists-of-the-line-nameserver-192021","title":"Every time the play is run, it rewrites /etc/resolv.conf even if it already consists of the line nameserver 192.0.2.1.","text":"<ul> <li>name: Non-idempotent approach with shell module   shell: echo \"nameserver 192.0.2.1\" &gt; /etc/resolv.conf</li> </ul>"},{"location":"hackmd/Ansible/#idempotent","title":"idempotent","text":""},{"location":"hackmd/Ansible/#does-not-rewrite-the-etcresolvconf-file-if-it-already-consists-of-the-correct-content","title":"does not rewrite the /etc/resolv.conf file if it already consists of the correct content","text":"<ul> <li>name: Idempotent approach with copy module   copy:     dest: /etc/resolv.conf     content: \"nameserver 192.0.2.1\\n\" <pre><code>## inventory\n- [Passing multiple inventory sources](https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html#passing-multiple-inventory-sources)\n- [Using inventory directories and multiple inventory sources](https://docs.ansible.com/ansible/latest/inventory_guide/intro_dynamic_inventory.html#using-inventory-directories-and-multiple-inventory-sources)\n- [Is there any option to list groups in Ansible? - Stack Overflow](https://stackoverflow.com/questions/33363023/is-there-any-option-to-list-groups-in-ansible)\n- Nested Groups\n- Host Specifications with Ranges\n    - server[01:20].example.com matches all hosts named server01.example.com through server20.example.com.\n- Dynamic Inventory\n    - For example, a dynamic inventory program could contact your Red Hat Satellite server or Amazon EC2 account, and use information stored there to construct an Ansible inventory\n\n``` bash=\n# ansible {host pattern} --list-hosts\nansible canada --list-hosts -v\n</code></pre></li> </ul> <p>``` bash= ansible-inventory --list ansible-inventory --list | jq \"keys\" ansible-inventory --graph <pre><code>### Inline inventory\n- [Is possible to not have an inventory file and just provide an ip at command line ? : r/ansible](https://www.reddit.com/r/ansible/comments/z7ehm7/is_possible_to_not_have_an_inventory_file_and/)\n    - [ansible.builtin.advanced\\_host\\_list inventory \u2013 Parses a \u2018host list\u2019 with ranges \u2014 Ansible Community Documentation](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/advanced_host_list_inventory.html)\n\n``` bash\nansible -i 192.0.2.5, all -m ping\n</code></pre></p>"},{"location":"hackmd/Ansible/#config","title":"config","text":"<p>``` bash= ansible --version <pre><code>- [ansible/ansible.cfg at devel \u00b7 ansible/ansible \u00b7 GitHub](https://github.com/ansible/ansible/blob/devel/examples/ansible.cfg)\n- [\u907f\u514d Ansible \u7121\u6cd5\u5b58\u53d6\u7b2c\u4e00\u6b21\u767b\u5165\u7684 Server - Yowko's Notes](https://blog.yowko.com/ansible-bypass-fingerprint-check/)\n- [ansible.builtin.sh shell \u2013 POSIX shell (/bin/sh) \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/sh_shell.html#parameter-remote_tmp)\n\n\\&gt;=2.12\n``` bash=\nansible-config init --disabled &gt; ansible.cfg\n</code></pre></p>"},{"location":"hackmd/Ansible/#module","title":"module","text":"<p>``` bash=</p>"},{"location":"hackmd/Ansible/#lists-all-modules-installed-on-a-system","title":"lists all modules installed on a system","text":"<p>ansible-doc -l</p>"},{"location":"hackmd/Ansible/#display-detailed-documentation-for-a-module","title":"display detailed documentation for a module.","text":""},{"location":"hackmd/Ansible/#ansible-doc-module-name","title":"ansible-doc [module name]","text":"<p>ansible-doc ping</p>"},{"location":"hackmd/Ansible/#produces-example-output-that-can-serve-as-a-model-for-how-to-use-a-particular-module","title":"produces example output that can serve as a model for how to use a particular module","text":"<p>ansible-doc -s ping</p> <pre><code>- [Module Index \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/modules/modules_by_category.html)\n    - [Files modules \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/modules/list_of_files_modules.html)\n\n### Files modules\n\nEnsuring a File Exists on Managed Hosts\n``` yml\n- name: Touch a file and set permissions\n  file:\n    path: /path/to/file\n    owner: user1\n    group: group1\n    mode: 0640\n    state: touch\n</code></pre> <pre><code>[user@host ~]$ ls -l file\n-rw-r-----.  user1 group1 0 Nov 25 08:00 file\n</code></pre> <p>Copying and Editing Files on Managed Hosts ``` yml= - name: Copy a file to managed hosts   copy:     src: file     dest: /path/to/file <pre><code>``` yml=\n- name: Retrieve SSH key from reference host\n  fetch:\n    src: \"/home/{{ user }}/.ssh/id_rsa.pub\"\n    dest: \"files/keys/{{ user }}.pub\"\n</code></pre></p> <p>To ensure a specific single line of text exists in an existing file, ``` yml= - name: Add a line of text to a file   lineinfile:     path: /path/to/file     line: 'Add this line to the file'     state: present <pre><code>To add a block of text to an existing file, use the blockinfile module:\n``` yml=\n- name: Add additional lines to a file\n  blockinfile:\n    path: /path/to/file\n    block: |\n      First line in the additional block of text\n      Second line in the additional block of text\n    state: present\n</code></pre></p> <p>Removing a File from Managed Hosts ``` yml= - name: Make sure a file does not exist on managed hosts   file:     dest: /path/to/file     state: absent <pre><code>Retrieving the Status of a File on Managed Hosts\n``` yml=\n- name: Verify the checksum of a file\n  stat:\n    path: /path/to/file\n    checksum_algorithm: md5\n  register: result\n\n- debug\n    msg: The checksum of the file is {{ result.stat.checksum }}\n</code></pre></p> <pre><code>TASK [Get md5 checksum of a file] *****************************************\nok: [hostname]\n\nTASK [debug] **************************************************************\nok: [hostname] =&gt; {\n    \"msg\": \"The checksum of the file is 5f76590425303022e933c43a7f2092a3\"\n}\n</code></pre> <p>``` yml= - name: Examine all stat output of /etc/passwd   hosts: localhost</p> <p>tasks:     - name: stat /etc/passwd       stat:         path: /etc/passwd       register: results</p> <pre><code>- name: Display stat results\n  debug:\n    var: results\n</code></pre> <p><code>The **synchronize** module is a wrapper around the rsync tool, which simplifies common file management tasks in your playbooks.</code> yml= - name: synchronize local file to remote files   synchronize:     src: file     dest: /path/to/file ```</p>"},{"location":"hackmd/Ansible/#apt","title":"apt","text":"<ul> <li>Installing specific apt version with ansible - Stack Overflow</li> </ul>"},{"location":"hackmd/Ansible/#ad-hoc-command","title":"ad hoc command","text":"<p>a way of executing a single Ansible task quickly ``` bash=</p>"},{"location":"hackmd/Ansible/#ansible-host-pattern-m-module-a-module-arguments-i-inventory","title":"ansible {host-pattern} -m {module} [-a 'module arguments'] [-i inventory]","text":"<p>ansible localhost -m ping</p>"},{"location":"hackmd/Ansible/#know-the-difference-between-command-and-shell-module","title":"know the difference between 'command' and 'shell' module","text":"<p>ansible localhost -m command -a /usr/bin/hostname ansible localhost -m shell -a set</p> <pre><code>## variables\n- [Using Variables \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable)\n- [Using Variables: Variables discovered from systems: Facts \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/user_guide/playbooks_variables.html#variables-discovered-from-systems-facts)\n    - Facts are information derived from speaking with your remote systems. You can find a complete set under the ansible_facts variable, most facts are also \u2018injected\u2019 as top level variables preserving the `ansible_` prefix\n- [Discovering variables: facts and magic variables \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_vars_facts.html#information-about-ansible-magic-variables)\n    - access information about Ansible operations, including the python version being used, the hosts and groups in inventory, and the directories for playbooks and roles, using \"magic\" variables\n- [Special Variables \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/reference_appendices/special_variables.html#special-variables)\n- [Using Variables: Accessing information about other hosts with magic variables \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/user_guide/playbooks_variables.html#accessing-information-about-other-hosts-with-magic-variables)\n- [Using Variables: Variable precedence: Where should I put a variable? \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/user_guide/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable)\n- [variables - Ansible - set\\_facts Set a boolean value based on register.stdout\\_lines containing a string - Stack Overflow](https://stackoverflow.com/questions/75316547/ansible-set-facts-set-a-boolean-value-based-on-register-stdout-lines-containin)\n- [vars from a JSON or YAML file](https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_variables.html#vars-from-a-json-or-yaml-file)\n\nprecedence determines which value is used\nsimplified list of ways to define a variable, ordered from lowest precedence to highest:\n- Group variables defined in the **inventory**.\n- Group variables defined in files in a **group_vars** subdirectory in the same directory as the inventory or the playbook.\n- Host variables defined in the **inventory**.\n- Host variables defined in files in a **host_vars** subdirectory in the same directory as the inventory or the playbook.\n- **Host facts**, discovered at runtime.\n- Play variables in the playbook (vars and vars_files).\n- Task variables.\n- Extra variables defined on the **command line**.\n\n``` bash=\n# Overriding Variables from the Command Line\nansible-playbook main.yml -e \"package=apache\"\n</code></pre> <pre><code># Capturing Command Output with Registered Variables\n---\n- name: Installs a package and prints the result\n  hosts: all\n  tasks:\n    - name: Install the package\n      yum:\n        name: httpd\n        state: present\n      register: install_result\n\n    - debug:\n        var: install_result\n</code></pre>"},{"location":"hackmd/Ansible/#secrets","title":"secrets","text":"<p>To use Ansible Vault, a command-line tool named <code>ansible-vault</code> is used to create, edit, encrypt, decrypt, and view files.</p> <p>Files are protected with symmetric encryption using AES256 with a password as the secret key.</p> <p>``` bash= ansible-vault create secret.yml</p>"},{"location":"hackmd/Ansible/#you-can-use-a-vault-password-file-to-store-the-vault-password","title":"you can use a vault password file to store the vault password","text":"<p>ansible-vault create --vault-password-file=vault-pass secret.yml</p>"},{"location":"hackmd/Ansible/#viewing-an-encrypted-file","title":"Viewing an Encrypted File","text":"<p>ansible-vault view secret1.yml</p>"},{"location":"hackmd/Ansible/#editing-an-existing-encrypted-file","title":"Editing an Existing Encrypted File","text":"<p>ansible-vault edit secret.yml</p>"},{"location":"hackmd/Ansible/#encrypting-an-existing-file","title":"Encrypting an Existing File","text":"<p>ansible-vault encrypt secret1.yml secret2.yml</p>"},{"location":"hackmd/Ansible/#decrypting-an-existing-file","title":"Decrypting an Existing File","text":"<p>ansible-vault decrypt secret1.yml --output=secret1-decrypted.yml</p>"},{"location":"hackmd/Ansible/#changing-the-password-of-an-encrypted-file","title":"Changing the Password of an Encrypted File","text":"<p>ansible-vault rekey secret.yml</p>"},{"location":"hackmd/Ansible/#to-run-a-playbook-that-accesses-files-encrypted-with-ansible-vault","title":"To run a playbook that accesses files encrypted with Ansible Vault,","text":""},{"location":"hackmd/Ansible/#provide-the-vault-password-interactively","title":"provide the vault password interactively","text":"<p>ansible-playbook --vault-id @prompt site.yml</p>"},{"location":"hackmd/Ansible/#specify-a-file-that-stores-the-encryption-password-in-plain-text","title":"specify a file that stores the encryption password in plain text.","text":""},{"location":"hackmd/Ansible/#you-can-also-use-the-ansible_vault_password_file-environment-variable-to-specify-the-default-location-of-the-password-file","title":"You can also use the ANSIBLE_VAULT_PASSWORD_FILE environment variable to specify the default location of the password file.","text":"<p>ansible-playbook --vault-password-file=vault-pw-file site.yml</p> <p><pre><code>### Recommended Practices for Variable File Management\n:::success\nThe recommended practice is to define inventory variables using host_vars and group_vars directories, and not to define them directly in the inventory files.\n:::\n</code></pre> . \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 group_vars \u2502   \u2514\u2500\u2500 webservers \u2502       \u2514\u2500\u2500 vars \u251c\u2500\u2500 host_vars \u2502   \u2514\u2500\u2500 demo.example.com \u2502       \u251c\u2500\u2500 vars \u2502       \u2514\u2500\u2500 vault \u251c\u2500\u2500 inventory \u2514\u2500\u2500 playbook.yml <pre><code>### Facts\n- [ansible - How to loop through interface facts - Server Fault](https://serverfault.com/questions/762079/how-to-loop-through-interface-facts)\n- [Ansible combine registered variable from multiple hosts - Stack Overflow](https://stackoverflow.com/questions/74213702/ansible-combine-registered-variable-from-multiple-hosts)\n- [ansible.utils.update\\_fact module \u2013 Update currently set facts \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/collections/ansible/utils/update_fact_module.html)\n\n\nAnsible facts are variables that are automatically discovered by Ansible on a **managed host**.\nAlso, Administrators can create custom facts which are stored locally on each managed host.\n\nSome variables are not facts or configured through the setup module, but are also automatically set by Ansible, it's called **magic variables**\n``` bash=\n# test magic variables\nansible localhost -m debug -a 'var=hostvars[\"localhost\"]'\n</code></pre></p> <p>Normally, every play runs the setup module automatically before the first task in order to gather facts. </p> <p>Some of the facts gathered for a managed host might include: - The host name - The kernel version - The network interfaces - The IP addresses - The version of the operating system - Various environment variables - The number of CPUs - The available or free memory - The available disk space</p> <p>``` bash=</p>"},{"location":"hackmd/Ansible/#facts","title":"\u6aa2\u67e5facts","text":"<p>ansible localhost -m setup ansible localhost -m setup &gt; /tmp/localhost_setup_dump</p>"},{"location":"hackmd/Ansible/#hostvars","title":"\u6aa2\u67e5hostvars","text":"<p>ansible localhost -m debug -a \"var=hostvars[inventory_hostname]\" ansible localhost -m debug -a \"var=ansible_host\" ansible localhost -m debug -a \"var=ansible_version\" ansible localhost -m debug -a \"var=group_names\" ansible localhost -m debug -a \"var=groups\"</p> <p>ansible -i inventory test001 -m debug -a \"var=hostvars[inventory_hostname]\"</p> <p>/tmp/host_vars_test001</p>"},{"location":"hackmd/Ansible/#same-result","title":"same result","text":"<p>ansible localhost -m ansible.builtin.setup <pre><code>result from\nansible localhost -m debug -a \"var=hostvars[inventory_hostname]\"\n</code></pre> localhost | SUCCESS =&gt; {     \"hostvars[inventory_hostname]\": {         \"ansible_check_mode\": false,         \"ansible_config_file\": null,         \"ansible_connection\": \"local\",         \"ansible_diff_mode\": false,         \"ansible_facts\": {},         \"ansible_forks\": 5,         \"ansible_inventory_sources\": [             \"/etc/ansible/hosts\"         ],         \"ansible_playbook_python\": \"/home/supermicro/.pyenv/versions/3.10.0/bin/python\",         \"ansible_python_interpreter\": \"/home/supermicro/.pyenv/versions/3.10.0/bin/python\",         \"ansible_verbosity\": 0,         \"ansible_version\": {             \"full\": \"2.13.6\",             \"major\": 2,             \"minor\": 13,             \"revision\": 6,             \"string\": \"2.13.6\"         },         \"group_names\": [],         \"groups\": {             \"all\": [],             \"ungrouped\": []         },         \"inventory_hostname\": \"localhost\",         \"inventory_hostname_short\": \"localhost\",         \"omit\": \"__omit_place_holder__f658d3d6364c746326fb9b151c3079026761b9e9\",         \"playbook_dir\": \"/home/supermicro/srccode/customers\"     } }</p> <pre><code>``` yaml=\n- name: Fact dump\n  hosts: all\n  tasks:\n    - name: Print all facts\n      debug:\n        var: ansible_facts\n</code></pre>"},{"location":"hackmd/Ansible/#yaml","title":"``` yaml=","text":"<ul> <li>hosts: all   tasks:</li> <li>name: Prints various Ansible facts     debug:       msg: &gt;         The default IPv4 address of {{ ansible_facts.fqdn }}         is {{ ansible_facts.default_ipv4.address }} <pre><code>To disable fact gathering for a play\n\n``` yaml=\n---\n- name: This play gathers no facts automatically\n  hosts: large_farm\n  gather_facts: no\n</code></pre></li> </ul> <p>you can manually gather facts at any time by running a task that uses the setup module</p> <p>``` yaml=   tasks:     - name: Manually gather facts       setup: <pre><code>:::info\nBefore Ansible 2.5, facts were injected as individual variables prefixed with the string ansible_ instead of being part of the ansible_facts variable. For example, the ansible_facts['distribution'] fact would have been called ansible_distribution.\n:::\n\n#### Custom Facts\nThese facts are integrated into the list of standard facts gathered by the setup module when it runs on the managed host. \n\nBy default, the setup module loads custom facts from files and scripts in each managed host's ==/etc/ansible/facts.d== directory. \n\nCustom facts can be defined in a static file, formatted as an INI file or using JSON. They can also be executable scripts which generate JSON output.\n\nDynamic custom facts allow the values for these facts, or even which facts are provided, to be determined programmatically when the play is run.\n\nThe name of each file or script must end in .fact in order to be used. Dynamic custom fact scripts must output JSON-formatted facts and must be executable.\n\nan example of a static custom facts file\n\n``` ini=\n[packages]\nweb_package = httpd\ndb_package = mariadb-server\n\n[users]\nuser1 = joe\nuser2 = jane\n</code></pre></p> <p>``` json= {   \"packages\": {     \"web_package\": \"httpd\",     \"db_package\": \"mariadb-server\"   },   \"users\": {     \"user1\": \"joe\",     \"user2\": \"jane\"   } } <pre><code>For example, assume that the preceding custom facts are produced by a file saved as /etc/ansible/facts.d/custom.fact on the managed host. In that case, the value of ansible_facts['ansible_local']['custom']['users']['user1'] is joe.\n\n##### practice\nsetup_facts.yml\n\n``` yaml=\n---\n- name: Install remote facts\n  hosts: webserver\n  vars:\n    remote_dir: /etc/ansible/facts.d\n    facts_file: custom.fact\n  tasks:\n    - name: Create the remote directory\n      file:\n        state: directory\n        recurse: yes\n        path: \"{{ remote_dir }}\"\n    - name: Install the new facts\n      copy:\n        src: \"{{ facts_file }}\"\n        dest: \"{{ remote_dir }}\"\n</code></pre></p> <p>/home/student/data-facts/custom.fact</p> <p>``` INI= [general] package = httpd service = httpd state = started enabled = true <pre><code>``` bash=\nansible-playbook setup_facts.yml\n</code></pre></p> <p>playbook.yml</p>"},{"location":"hackmd/Ansible/#yaml_1","title":"``` yaml=","text":"<ul> <li>name: Install Apache and starts the service   hosts: webserver</li> </ul> <p>tasks:     - name: Install the required package       yum:         name: \"{{ ansible_facts['ansible_local']['custom']['general']['package'] }}\"         state: latest</p> <pre><code>- name: Start the service\n  service:\n    name: \"{{ ansible_facts['ansible_local']['custom']['general']['service'] }}\"\n    state: \"{{ ansible_facts['ansible_local']['custom']['general']['state'] }}\"\n    enabled: \"{{ ansible_facts['ansible_local']['custom']['general']['enabled'] }}\"\n</code></pre> <p><code></code> bash= ansible-playbook playbook.yml ```</p>"},{"location":"hackmd/Ansible/#task-control","title":"Task control","text":"<ul> <li>Loops \u2014 Ansible Documentation</li> <li>Conditionals \u2014 Ansible Documentation</li> <li>Handlers: Running Operations On Change</li> <li>Using conditionals in loops</li> </ul>"},{"location":"hackmd/Ansible/#loop","title":"loop","text":"<p>:::warning - Migrating from with_X to loop \u2014 Ansible Documentation - Ansible: Register iterating with the loop - Stack Overflow</p> <p>Before Ansible\u00a02.5, most playbooks used a different syntax for loops. Multiple loop keywords were provided, which were prefixed with with_, followed by the name of an Ansible look-up plug-in </p> <ul> <li>with_items</li> <li>with_file</li> <li>with_sequence</li> </ul> <p>``` yml=   vars:     data:       - user0       - user1       - user2   tasks:     - name: \"with_items\"       debug:         msg: \"{{ item }}\"       with_items: \"{{ data }}\" <pre><code>:::\n``` yml=\n- name: Postfix is running\n  service:\n    name: postfix\n    state: started\n\n- name: Dovecot is running\n  service:\n    name: dovecot\n    state: started\n</code></pre></p> <p>rewritten by loop</p> <p>``` yml= - name: Postfix and Dovecot are running   service:     name: \"{{ item }}\"     state: started   loop:     - postfix     - dovecot <pre><code>The list used by loop can be provided by a variable\n``` yml=\nvars:\n  mail_services:\n    - postfix\n    - dovecot\n\ntasks:\n  - name: Postfix and Dovecot are running\n    service:\n      name: \"{{ item }}\"\n      state: started\n    loop: \"{{ mail_services }}\"\n</code></pre></p> <p>a List of Hashes or Dictionaries ``` yml= - name: Users exist and are in the correct groups   user:     name: \"{{ item.name }}\"     state: present     groups: \"{{ item.groups }}\"   loop:     - name: jane       groups: wheel     - name: joe       groups: root <pre><code>Using Register Variables\n``` yml=\n---\n- name: Loop Register Test\n  gather_facts: no\n  hosts: localhost\n  tasks:\n    - name: Looping Echo Task\n      shell: \"echo This is my item: {{ item }}\"\n      loop:\n        - one\n        - two\n      register: echo_results\n\n    - name: Show echo_results variable\n      debug:\n        var: echo_results\n</code></pre></p>"},{"location":"hackmd/Ansible/#yml","title":"``` yml=","text":"<ul> <li> <p>name: Loop Register Test   gather_facts: no   hosts: localhost   tasks:</p> <ul> <li> <p>name: Looping Echo Task   shell: \"echo This is my item: {{ item }}\"   loop:</p> <ul> <li>one</li> <li>two   register: echo_results</li> </ul> </li> <li> <p>name: Show stdout from the previous task.   debug:     msg: \"STDOUT from previous task: {{ item.stdout }}\"   loop: \"{{ echo_results['results'] }}\" <pre><code>### Conditionally\nusecase of conditionals in Ansible:\n- A hard limit can be defined in a variable (for example, min_memory) and compared against the available memory on a managed host.\n- The output of a command can be captured and evaluated by Ansible to determine whether or not a task completed before taking further action. For example, if a program fails, then a batch is skipped.\n- Use Ansible facts to determine the managed host network configuration and decide which template file to send (for example, network bonding or trunking).\n- The number of CPUs can be evaluated to determine how to properly tune a web server.\n- Compare a registered variable with a predefined variable to determine if a service changed. For example, test the MD5 checksum of a service configuration file to see if the service is changed.\n\nconditionals can be combined with either the **and** or **or** keywords, and grouped with parentheses.\n\nWhen a list is provided to the when keyword, all of the conditionals are combined using the and operation. \n\nThe expressions used with **when** clauses in Ansible Playbooks are **Jinja2 expressions**.\n\n:::info\nA common convention places any when keyword that might be present after the task's name and the module (and module arguments).\n:::\n\n``` yml=\n---\n- name: Simple Boolean Task Demo\n  hosts: all\n  vars:\n    run_my_task: true\n\n  tasks:\n    - name: httpd package is installed\n      yum:\n        name: httpd\n      when: run_my_task\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"hackmd/Ansible/#yml_1","title":"``` yml=","text":"<ul> <li>name: Test Variable is Defined Demo   hosts: all   vars:     my_service: httpd</li> </ul> <p>tasks:     - name: \"{{ my_service }} package is installed\"       yum:         name: \"{{ my_service }}\"       when: my_service is defined <pre><code>the ansible_distribution variable is a fact determined during the Gathering Facts task, and identifies the managed host's operating system distribution. \n``` yml=\n---\n- name: Demonstrate the \"in\" keyword\n  hosts: all\n  gather_facts: yes\n  vars:\n    supported_distros:\n      - RedHat\n      - Fedora\n  tasks:\n    - name: Install httpd using yum, where supported\n      yum:\n        name: http\n        state: present\n      when: ansible_distribution in supported_distros\n</code></pre></p> Operation Example Equal (value is a string) ansible_machine == \"x86_64\" Equal (value is numeric) max_memory == 512 Less than min_memory &lt; 128 Greater than min_memory &gt; 256 Less than or equal to min_memory &lt;= 256 Greater than or equal to min_memory &gt;= 512 Not equal to min_memory != 512 Variable exists min_memory is defined Variable does not exist min_memory is not defined Boolean variable is true. The values of 1, True, or yes evaluate to true. memory_available Boolean variable is false. The values of 0, False, or no evaluate to false. not memory_available First variable's value is present as a value in second variable's list ansible_distribution in supported_distros <p>:::info When you use when with loop for a task, the when statement is checked for each item. :::</p> <p>Combining Loops and Conditional Tasks, the mariadb-server package is installed by the yum module if there is a file system mounted on / with more than 300\u00a0MB free.</p> <p>``` yml= - name: install mariadb-server if enough space on root   yum:     name: mariadb-server     state: latest   loop: \"{{ ansible_mounts }}\"   when: item.mount == \"/\" and item.size_available &gt; 300000000 <pre><code>Combining register variables and Conditional Tasks, Evaluates the output of the Postfix task. If the exit code of the systemctl command is 0, then Postfix is active and this task restarts the httpd service.\n\n``` yml=\n---\n- name: Restart HTTPD if Postfix is Running\n  hosts: all\n  tasks:\n    - name: Get Postfix server status\n      command: /usr/bin/systemctl is-active postfix\n      ignore_errors: yes\n      register: result\n\n    - name: Restart Apache HTTPD based on Postfix status\n      service:\n        name: httpd\n        state: restarted\n      when: result.rc == 0\n</code></pre></p>"},{"location":"hackmd/Ansible/#handlers","title":"Handlers","text":"<p>Handlers are tasks that respond to a notification triggered by other tasks.</p> <p>Tasks only notify their handlers when the task changes something on a managed host.</p> <p>If a task that includes a notify statement does not report a changed result (for example, a package is already installed and the task reports ok), the handler is not notified. The handler is skipped unless another task notifies it. Ansible notifies handlers only if the task reports the changed status.</p> <p>When a task makes a change to a managed host, it reports the changed state and notifies handlers. When a task does not need to make a change, it reports ok and does not notify handlers.</p> <p>Handlers can be considered as inactive tasks that only get triggered when explicitly invoked using a notify statement.</p> <p>Handlers always run in the order specified by the handlers section of the play. They do not run in the order in which they are listed by notify statements in a task, or in the order in which tasks notify them.</p> <p>If no task notifies the handler by name then the handler will not run.</p> <p>If one or more tasks notify the handler, the handler will run exactly once after all other tasks in the play have completed.</p> <p>Normally, handlers are used to reboot hosts and restart services.</p> <p>the Apache server is only restarted by the restart apache handler when a configuration file is updated and notifies it ``` yml= tasks:   - name: copy demo.example.conf configuration template     template:       src: /var/lib/templates/demo.example.conf.template       dest: /etc/httpd/conf.d/demo.example.conf     notify:       - restart apache</p> <p>handlers:   - name: restart apache     service:       name: httpd       state: restarted <pre><code>### Task Failure\n\nBy default, if a task fails, the play is aborted.\n\nHowever, this behavior can be overridden by ignoring failed tasks. You can use the **ignore_errors** keyword in a task to accomplish this.\n\nif the notapkg package does not exist then the yum module fails, but having ignore_errors set to yes allows execution to continue.\n``` yml=\n- name: Latest version of notapkg is installed\n  yum:\n    name: notapkg\n    state: latest\n  ignore_errors: yes\n</code></pre></p> <p>Normally when a task fails and the play aborts on that host, any handlers that had been notified by earlier tasks in the play will not run. </p> <p>If you set the force_handlers: yes keyword on the play, then notified handlers are called even if the play aborted because a later task failed.</p> <p>Forcing Execution of Handlers ``` yml=</p> <ul> <li> <p>hosts: all   force_handlers: yes   tasks:</p> <ul> <li> <p>name: a task which always notifies its handler   command: /bin/true   notify: restart the database</p> </li> <li> <p>name: a task which fails because the package doesn't exist   yum:     name: notapkg     state: latest</p> </li> </ul> </li> </ul> <p>handlers:     - name: restart the database       service:         name: mariadb         state: restarted <pre><code>You can use the **failed_when** keyword on a task to specify which conditions indicate that the task has failed. \n\nThis is often used with **command** modules that may successfully execute a command, but the command's output indicates a failure.\n\nThe **fail** module can also be used to force a task failure.\nYou can use the fail module to provide a clear failure message for the task.\n\n\n``` yml=\ntasks:\n  - name: Run user creation script\n    shell: /usr/local/bin/create_users.sh\n    register: command_result\n    failed_when: \"'Password missing' in command_result.stdout\"\n</code></pre></p> <p>rewrite by fail module ``` yml= tasks:   - name: Run user creation script     shell: /usr/local/bin/create_users.sh     register: command_result     ignore_errors: yes</p> <ul> <li>name: Report script failure     fail:       msg: \"The password is missing in the output\"     when: \"'Password missing' in command_result.stdout\" <pre><code>### Task report changed\n\n``` yml=\ntasks:\n  - shell:\n      cmd: /usr/local/bin/upgrade-database\n    register: command_result\n    changed_when: \"'Success' in command_result.stdout\"\n    notify:\n      - restart_database\n\nhandlers:\n  - name: restart_database\n     service:\n       name: mariadb\n       state: restarted\n</code></pre></li> </ul>"},{"location":"hackmd/Ansible/#block","title":"block","text":"<p>In playbooks, blocks are clauses that logically group tasks, and can be used to control how tasks are executed. </p> <p>Blocks also allow for error handling in combination with the rescue and always statements.</p> <p>If any task in a block fails, tasks in its rescue block are executed in order to recover. After the tasks in the block clause run, as well as the tasks in the rescue clause if there was a failure, then tasks in the always clause run. </p> <p>a task block can have a when keyword to apply a conditional to multiple tasks ``` yml= - name: block example   hosts: all   tasks:     - name: installing and configuring Yum versionlock plugin       block:       - name: package needed by yum         yum:           name: yum-plugin-versionlock           state: present       - name: lock version of tzdata         lineinfile:           dest: /etc/yum/pluginconf.d/versionlock.list           line: tzdata-2016j-1           state: present       when: ansible_distribution == \"RedHat\" <pre><code>- block: Defines the main tasks to run.\n- rescue: Defines the tasks to run if the tasks defined in the block clause fail.\n- always: Defines the tasks that will always run independently of the success or failure of tasks defined in the block and rescue clauses.\n``` yml=\ntasks:\n    - name: Upgrade DB\n      block:\n        - name: upgrade the database\n          shell:\n            cmd: /usr/local/lib/upgrade-database\n      rescue:\n        - name: revert the database upgrade\n          shell:\n            cmd: /usr/local/lib/revert-database\n      always:\n        - name: always restart the database\n          service:\n            name: mariadb\n            state: restarted\n</code></pre></p>"},{"location":"hackmd/Ansible/#privilege","title":"privilege","text":"<p><pre><code>ansible-playbook playbook_verify.yml -kK\n</code></pre> \u5728 target node /etc/sudoers \u589e\u52a0ansible ALL=(ALL) NOPASSWD:ALL \u5c31\u53ef\u4ee5\u4e0d\u7528\u6253\u5bc6\u78bc</p>"},{"location":"hackmd/Ansible/#template","title":"template","text":"<ul> <li>template \u2013 Template a file out to a remote server \u2014 Ansible Documentation</li> <li>Ansible Template with Jinja formatting - Stack Overflow</li> </ul> <p>Ansible uses the Jinja2 templating system for template files. </p> <p>Ansible also uses Jinja2 syntax to reference variables in playbooks</p> <p>Variables and logic expressions are placed between tags, or delimiters. - Jinja2 templates use {% EXPR %} for expressions or logic (for example, loops) - {{ EXPR }} are used for outputting the results of an expression or a variable - Use {# COMMENT #} syntax to enclose comments that should not appear in the final file.</p> <p>The following example shows how to create a template for /etc/ssh/sshd_config with variables and facts retrieved by Ansible from managed hosts. </p> <p>When the associated playbook is executed, any facts are replaced by their values in the managed host being configured.</p> <p>jinja2 template(/tmp/j2-template.j2) <pre><code># {{ ansible_managed }}\n# DO NOT MAKE LOCAL MODIFICATIONS TO THIS FILE AS THEY WILL BE LOST\n\nPort {{ ssh_port }}\nListenAddress {{ ansible_facts['default_ipv4']['address'] }}\n\nHostKey /etc/ssh/ssh_host_rsa_key\nHostKey /etc/ssh/ssh_host_ecdsa_key\nHostKey /etc/ssh/ssh_host_ed25519_key\n\nSyslogFacility AUTHPRIV\n\nPermitRootLogin {{ root_allowed }}\nAllowGroups {{ groups_allowed }}\n\nAuthorizedKeysFile /etc/.rht_authorized_keys .ssh/authorized_keys\n\nPasswordAuthentication {{ passwords_allowed }}\n\nChallengeResponseAuthentication no\n\nGSSAPIAuthentication yes\nGSSAPICleanupCredentials no\n\nUsePAM yes\n\nX11Forwarding yes\nUsePrivilegeSeparation sandbox\n\nAcceptEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES\nAcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT\nAcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGE\nAcceptEnv XMODIFIERS\n\nSubsystem sftp  /usr/libexec/openssh/sftp-server\n</code></pre></p> <p>When the Jinja2 template for a configuration file has been created, it can be deployed to the managed hosts using the template module, which supports the transfer of a local file on the control node to the managed hosts.</p> <p>``` yml= tasks:   - name: template render     template:       src: /tmp/j2-template.j2       dest: /tmp/dest-config-file.txt <pre><code>The ansible_managed directive is set in the ansible.cfg file\n</code></pre> ansible_managed = Ansible managed <pre><code>Current time\n</code></pre> - name: time   debug:     msg: \"current time: {{ now(fmt='%m-%d-%Y %H:%M:%S') }}\" <pre><code>### Control Structures\nYou can use Jinja2 control structures in template files to reduce repetitive typing, to enter entries for each host in a play dynamically, or conditionally insert text into a file.\n\nuses a for statement to run through all the values in the users variable\n</code></pre> {# for statement #} {% for myuser in users if not myuser == \"root\" %} User number {{ loop.index }} - {{ myuser }} {% endfor %} <pre><code>assumes a myhosts variable has been defined in the inventory file being used\n</code></pre> {% for myhost in groups['myhosts'] %} {{ myhost }} {% endfor %} <pre><code>you can use this to generate an /etc/hosts file from host facts dynamically.\n\n``` yml=\n- name: /etc/hosts is up to date\n  hosts: all\n  gather_facts: yes\n  tasks:\n    - name: Deploy /etc/hosts\n      template:\n        src: templates/hosts.j2\n        dest: /etc/hosts\n</code></pre></p> <p>templates/hosts.j2 <pre><code>{% for host in groups['all'] %}\n{{ hostvars[host]['ansible_facts']['default_ipv4']['address'] }} {{ hostvars[host]['ansible_facts']['fqdn'] }} {{ hostvars[host]['ansible_facts']['hostname'] }}\n{% endfor %}\n</code></pre></p> <p>formats the expression output using JSON/YAML <pre><code>{{ output | to_json }}\n{{ output | to_yaml }}\n</code></pre></p> <p>formats the expression output using JSON/YAML human readable format <pre><code>{{ output | to_nice_json }}\n{{ output | to_nice_yaml }}\n</code></pre></p> <p>expect strings in either JSON or YAML format, respectively, to parse them. <pre><code>{{ output | from_json }}\n{{ output | from_yaml }}\n</code></pre></p>"},{"location":"hackmd/Ansible/#ip_addr","title":"ip_addr","text":"<ul> <li>Using the ipaddr filter \u2014 Ansible Community Documentation</li> </ul> <p>local test - GitHub - network-automation/ipaddr_filter: examples with the ipaddr filter</p> <p>``` bash= ansible-playbook ipaddr_test.yml <pre><code>playbook\nipaddr_test.yml\n\n``` yaml=\n---\n- hosts: localhost\n  connection: local\n  gather_facts: false\n  vars:\n    sean_subnet: \"192.168.1.0/24\"\n  tasks:\n    - template:\n        src: ./template.j2\n        dest: ./rendered\n</code></pre></p> <p>template template.j2</p> <pre><code>ipaddr filter examples:\nThe var sean_subnet is: {{ sean_subnet }}\n\nJinja2: {% raw %} IP Address: {{sean_subnet | ipaddr }} {% endraw %}\nRenders: IP Address: {{ sean_subnet | ipaddr }}\n\nJinja2: {% raw %} IP Address: {{sean_subnet | ipaddr('netmask') }} {% endraw %}\nRenders: IP Address: {{ sean_subnet | ipaddr('netmask') }}\n\nJinja2: {% raw %} IPv4 Address: {{ sean_subnet | ipv4 }} {% endraw %}\nRenders: IPv4 Address: {{ sean_subnet | ipv4 }}\n\nJinja2: {% raw %} IPv6 Address: {{ sean_subnet | ipv6 }} {% endraw %}\nRenders: IPv6 Address: {{ sean_subnet | ipv6 }}\n\nJinja2: {% raw %} Network: {{ sean_subnet | ipaddr('network') }} {% endraw %}\nRenders: Network: {{ sean_subnet | ipaddr('network') }}\n\nJinja2: {% raw %} Prefix: {{ sean_subnet | ipaddr('prefix') }} {% endraw %}\nRenders: Prefix: {{ sean_subnet | ipaddr('prefix') }}\n\nJinja2: {% raw %} What is the first usable IP on {{sean_subnet}}? {{ sean_subnet | ipaddr('next_usable') }} {% endraw %}\nRenders: What is the first usable IP on {{sean_subnet}}? {{ sean_subnet | ipaddr('next_usable') }}\n\nJinja2: {% raw %} What is the range of usable IP address on {{sean_subnet}}? {{ sean_subnet | ipaddr('range_usable') }} {% endraw %}\nRenders:  What is the range of usable IP address on {{sean_subnet}}? {{ sean_subnet | ipaddr('range_usable') }}\n\nJinja2: {% raw %} What is the last usable IP address on {{sean_subnet}}? {{ sean_subnet | ipaddr('last_usable') }} {% endraw %}\nRenders: What is the last usable IP address on {{sean_subnet}}? {{ sean_subnet | ipaddr('last_usable') }}\n\nJinja2: {% raw %} What is the 2nd usable address on {{sean_subnet}}? {{ sean_subnet | next_nth_usable(2) }} {% endraw %}\nRenders: What is the 2nd usable address on {{sean_subnet}}? {{ sean_subnet | next_nth_usable(2) }}\n--------\nLoop method for providing  multiple IP addresses for use:\n\nJinja: {% raw %}\n{% for n in range(10) %}\n  {{ sean_subnet | next_nth_usable(n) }}\n{% endfor %} {% endraw %}\n\nRenders:\n{% for n in range(10) %}\n  {{ sean_subnet | next_nth_usable(n) }}\n{% endfor %}\n</code></pre>"},{"location":"hackmd/Ansible/#advanced-playbook","title":"advanced playbook","text":"<ul> <li>GitHub - haidaraM/ansible-playbook-grapher: A command line tool to create a graph representing your Ansible playbook tasks and roles</li> </ul>"},{"location":"hackmd/Ansible/#host-patterns","title":"host patterns","text":"<ul> <li>Patterns: targeting hosts and groups \u2014 Ansible Documentation</li> </ul> <p>It is a recommended practice to enclose host patterns used on the command line in single quotes to protect them from unwanted shell expansion.</p> <p>sample inventory</p> <pre><code>[student@controlnode ~]$ cat myinventory\nweb.example.com\ndata.example.com\n\n[lab]\nlabhost1.example.com\nlabhost2.example.com\n\n[test]\ntest1.example.com\ntest2.example.com\n\n[datacenter1]\nlabhost1.example.com\ntest1.example.com\n\n[datacenter2]\nlabhost2.example.com\ntest2.example.com\n\n[datacenter:children]\ndatacenter1\ndatacenter2\n\n[new]\n192.168.2.1\n192.168.2.2\n</code></pre> <ul> <li>the name for a single managed host listed in the inventory.</li> <li>inventory host groups<ul> <li>there is a special group named all that matches all managed hosts in the inventory</li> <li>There is also a special group named ungrouped, which includes all managed hosts in the inventory that are not members of any other group</li> <li>asterisk (*) wildcard character<ul> <li>The wildcard host patterns match all inventory names, hosts, and host groups. They do not distinguish between names that are DNS names, IP addresses, or groups, which can lead to some unexpected matches.</li> <li>accomplishing the same thing as the all host pattern<ul> <li>'*'</li> </ul> </li> <li>contain a particular substring<ul> <li>'*.example.com'<ul> <li>matches all inventory names that end in .example.com</li> </ul> </li> <li>'192.168.2.*'<ul> <li>match the names of hosts or host groups that start with 192.168.2.</li> </ul> </li> <li>'datacenter*'<ul> <li>match the names of hosts or host groups that begin with datacenter</li> </ul> </li> </ul> </li> </ul> </li> <li>comma-separated list<ul> <li>labhost1.example.com,test2.example.com,192.168.2.2<ul> <li>list of managed hosts</li> </ul> </li> <li>lab,datacenter1<ul> <li>list of groups</li> </ul> </li> </ul> </li> <li>You can also mix managed hosts, host groups, and wildcards<ul> <li>lab,data*,192.168.2.2</li> </ul> </li> <li>logical AND, an item in a list starts with an ampersand character (&amp;)<ul> <li>lab,&amp;datacenter1<ul> <li>machines in the lab group only if they are also in the datacenter1 group</li> </ul> </li> </ul> </li> <li>logical NOT, a list by using the exclamation point or \"bang\" character (!) in front of the host pattern<ul> <li>datacenter,!test2.example.com<ul> <li>datacenter group, except test2.example.com</li> </ul> </li> <li>all,!datacenter1<ul> <li>all hosts in the test inventory, except the managed hosts in the datacenter1 group</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>It is possible to point an alias at a particular IP address in your inventory by setting the ==ansible_host== host variable. </p> <p>For example, you could have a host in your inventory named ==dummy.example==, and then direct connections using that name to the IP address ==192.168.2.1== by creating a ==host_vars/dummy.example== file containing the following host variable:</p> <pre><code>ansible_host: 192.168.2.1\n</code></pre> <p>regular expression and exclude example <pre><code>ansible-playbook -i config/inventory.all --limit '~k22is[0-9]{3},~k22il[0-9]{3},!k22is001,!k22is002' -f 50 -kK playbooks/install.yml\n</code></pre></p>"},{"location":"hackmd/Ansible/#includeimport","title":"include/import","text":"<ul> <li>Creating Reusable Playbooks \u2014 Ansible Documentation</li> <li>Including and Importing \u2014 Ansible Documentation</li> </ul> <p>manage large playbooks by importing or including other playbooks or tasks from external files, either unconditionally or based on a conditional test</p> <p>There are two operations that Ansible can use to bring content into a playbook. You can include content, or you can import content.</p> <p>When you include content, it is a dynamic operation. Ansible processes included content during the run of the playbook, as content is reached.</p> <p>When you import content, it is a static operation. Ansible preprocesses imported content when the playbook is initially parsed, before the run starts.</p> <p>:star:dynamic include vs a static import</p> <p>You can create a dedicated directory for task files, and save all task files in that directory. Then your playbook can simply include or import task files from that directory. </p> <p>``` yml= - name: Prepare the web server   import_playbook: web.yml</p> <ul> <li>name: Prepare the database server   import_playbook: db.yml <pre><code>``` yml=\n- name: Play 1\n  hosts: localhost\n  tasks:\n    - debug:\n        msg: Play 1\n\n- name: Import Playbook\n  import_playbook: play2.yml\n</code></pre></li> </ul>"},{"location":"hackmd/Ansible/#yml_2","title":"``` yml=","text":"<ul> <li>name: Install web server   hosts: webservers   tasks:</li> <li> <p>import_tasks: webserver_tasks.yml <pre><code>- When using the import_tasks feature, conditional statements set on the import, such as **when**, are applied to each of the tasks that are imported.\n- You **cannot use loops** with the import_tasks feature.\n- If you use a variable to specify the name of the file to import, then you cannot use a host or group inventory variable.\n\n### role\n- [Roles \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/user_guide/playbooks_reuse_roles.html)\n    - [Roles - using-roles-at-the-play-level \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_reuse_roles.html#using-roles-at-the-play-level)\n        - roles\n    - [Roles - Including roles: dynamic reuse \u2014 Ansible Documentation](https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_reuse_roles.html#including-roles-dynamic-reuse)\n        - include_role\n- [Best way to organize roles/directory structure? : r/ansible](https://www.reddit.com/r/ansible/comments/g2s6wt/best_way_to_organize_rolesdirectory_structure/)\n\nAnsible roles provide a way for you to make it easier to **reuse** Ansible code generically. \n\nYou can package, in a standardized directory structure, all the tasks, variables, files, templates, and other resources needed to provision infrastructure or deploy applications.\n\nA well-written role will allow you to pass variables to the role from the playbook that adjust its behavior, setting all the site-specific hostnames, IP addresses, user names, secrets, or other locally-specific details you need. \n\nIn addition to writing, using, reusing, and sharing your own roles, you can get roles from other sources. Some roles are included as part of Red\u00a0Hat Enterprise\u00a0Linux, in the rhel-system-roles package. You can also get numerous community-supported roles from the Ansible Galaxy website.\n\nThe top-level directory defines the name of the role itself. Files are organized into subdirectories that are named according to each file's purpose in the role, such as **tasks** and **handlers**. The **files** and **templates** subdirectories contain files referenced by tasks in other YAML files.\n\nWhen you use a roles section to import roles into a play, the roles will run first, before any tasks that you define for that play.\n\nFor each play in a playbook, tasks execute as ordered in the tasks list. After all tasks execute, any notified handlers are executed.\n\nWhen a role is added to a play, role tasks are added to the beginning of the tasks list. If a second role is included in a play, its tasks list is added after the first role.\n\nRole handlers are added to plays in the same manner that role tasks are added to plays. Each play defines a handlers list. Role handlers are added to the handlers list first, followed by any handlers defined in the handlers section of the play.\n\nIf a role is not in the project's roles directory, the roles_path will be checked to see if the role is installed in one of those directories, first match being used. \n\n\n``` bash=\n[user@host roles]$ tree user.example\nuser.example/\n\u251c\u2500\u2500 defaults\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 files\n\u251c\u2500\u2500 handlers\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 meta\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 tasks\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 templates\n\u251c\u2500\u2500 tests\n\u2502   \u251c\u2500\u2500 inventory\n\u2502   \u2514\u2500\u2500 test.yml\n\u2514\u2500\u2500 vars\n    \u2514\u2500\u2500 main.yml\n</code></pre> :::info Not every role will have all of these directories. :::</p> </li> <li> <p>defaults</p> <ul> <li>The main.yml file in this directory contains the default values of role variables that can be overwritten when the role is used. These variables have low precedence and are intended to be changed and customized in plays.</li> </ul> </li> <li>files<ul> <li>This directory contains static files that are referenced by role tasks.</li> </ul> </li> <li>handlers<ul> <li>The main.yml file in this directory contains the role's handler definitions.</li> </ul> </li> <li>meta<ul> <li>The main.yml file in this directory contains information about the role, including author, license, platforms, and optional role dependencies.</li> </ul> </li> <li>tasks<ul> <li>The main.yml file in this directory contains the role's task definitions.</li> </ul> </li> <li>templates<ul> <li>This directory contains Jinja2 templates that are referenced by role tasks.</li> </ul> </li> <li>tests<ul> <li>This directory can contain an inventory and test.yml playbook that can be used to test the role.</li> </ul> </li> <li>vars<ul> <li>The main.yml file in this directory defines the role's variable values. Often these variables are used for internal purposes within the role. These variables have high precedence, and are not intended to be changed when used in a playbook.   </li> </ul> </li> </ul> <p>Define a specific variable in either vars/main.yml or defaults/main.yml, but not in both places. Default variables should be used when it is intended that their values will be overridden.</p> <p>:::warning Roles should not have site-specific data in them. They definitely should not contain any secrets like passwords or private keys. :::</p> <p>one way to call Ansible roles.</p>"},{"location":"hackmd/Ansible/#yml_3","title":"``` yml=","text":"<ul> <li>hosts: remote.example.com   roles:<ul> <li>role1</li> <li>role2 <pre><code>sets values for two role variables of role2, var1 and var2.\n``` yml=\n---\n- hosts: remote.example.com\n  roles:\n    - role: role1\n    - role: role2\n      var1: val1\n      var2: val2\n</code></pre></li> </ul> </li> </ul> <p>In certain scenarios, it may be necessary to execute some play tasks before the roles. To support such scenarios, plays can be configured with a pre_tasks section. Any task listed in this section executes before any roles are executed. If any of these tasks notify a handler, those handler tasks execute before the roles or normal tasks.</p> <p>Plays also support a post_tasks keyword. These tasks execute after the play's normal tasks, and any handlers they notify, are run.</p> <p>``` yml= - name: Play to illustrate order of execution   hosts: remote.example.com   pre_tasks:     - debug:         msg: 'pre-task'       notify: my handler   roles:     - role1   tasks:     - debug:         msg: 'first task'       notify: my handler   post_tasks:     - debug:         msg: 'post-task'       notify: my handler   handlers:     - name: my handler       debug:         msg: Running my handler <pre><code>Roles can be added to a play using an ordinary task, not just by including them in the roles section of a play. Use the include_role module to dynamically include a role, and use the import_role module to statically import a role.\n\n``` yml=\n- name: Execute a role as a task\n  hosts: remote.example.com\n  tasks:\n    - name: A normal task\n      debug:\n        msg: 'first task'\n    - name: A task to include role2 here\n      include_role: role2\n</code></pre></p>"},{"location":"hackmd/Ansible/#tag","title":"tag","text":"<ul> <li>Tags \u2014 Ansible Documentation</li> <li>Use Ansible tags to save time on playbook runs | Enable Sysadmin</li> </ul> <p>Tags are metadata that you can attach to the tasks in an Ansible playbook. They allow you to selectively target certain tasks at runtime, telling Ansible to run (or not run) certain tasks.</p> <p>When using an import (such as import_tasks), Ansible also applies related tags to all of the imported tasks. </p> <p>When a dynamic include_task is used, the tags apply only to the include itself. The tasks within the include do not inherit the tags, so they must also be defined on the included tasks</p> <p>``` bash= ansible-playbook example.yml --list-tags ansible-playbook example.yml --tags \"configuration,packages\" --list-tasks <pre><code>## dubug\n- [debug \u2013 Print statements during execution \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/modules/debug_module.html)\n- [Best Practices \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/user_guide/playbooks_best_practices.html)\n- [Check Mode (\u201cDry Run\u201d) \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/user_guide/playbooks_checkmode.html)\n- [Testing Strategies \u2014 Ansible Documentation](https://docs.ansible.com/ansible/2.9/reference_appendices/test_strategies.html)\n- [8 ways to speed up your Ansible playbooks | Enable Sysadmin](https://www.redhat.com/sysadmin/faster-ansible-playbook-execution)\n- [Ansible: No python interpreters found for host - DEV Community](https://dev.to/vidyasagarmsc/ansible-no-python-interpreters-found-for-host-4dpf)\n- [How to fix 'Permission denied' error in Ansible script module | LabEx](https://labex.io/tutorials/ansible-how-to-fix-permission-denied-error-in-ansible-script-module-415726)\n    - AppArmor on Ubuntu\n\n\n-v, -vv\n``` bash=\n# syntax check\nansible-playbook --syntax-check webserver.yml\n\n# The `ansible-playbook` command also provides a `--diff` option. This option reports the changes made to the template files on managed hosts. If used with the --check option, those changes are displayed in the command's output but not actually made.\nansible-playbook --check --diff webserver.yml\n</code></pre></p>"},{"location":"hackmd/Ansible/#log-files","title":"Log Files","text":"<p>By default, Ansible is not configured to log its output to any log file. </p> <p>It provides a built-in logging infrastructure that can be configured through the <code>log_path</code> parameter in the <code>default</code> section of the <code>ansible.cfg</code> configuration file, or through the <code>$ANSIBLE_LOG_PATH</code> environment variable.</p>"},{"location":"hackmd/Ansible/#debug-module","title":"Debug Module","text":"<p>This module can display the value for a certain variable at a certain point in the play. </p> <p>displays the value at run time of the ansible_facts['memfree_mb'] fact as part of a message printed to the output of ansible-playbook ``` yml= - name: Display free memory   debug:     msg: \"Free memory for this system is {{ ansible_facts['memfree_mb'] }}\" <pre><code>displays the value of the output variable.\n``` yml=\n- name: Display the \"output\" variable\n  debug:\n    var: output\n    verbosity: 2\n</code></pre></p>"},{"location":"hackmd/Ansible/#troubleshooting-ansible-managed-hosts","title":"Troubleshooting Ansible Managed Hosts","text":"<p>You can use the <code>ansible-playbook --check</code> command to run smoke tests on a playbook. </p> <p>This option executes the playbook without making changes to the managed hosts' configuration. </p>"},{"location":"hackmd/Ansible/#collections","title":"collections","text":""},{"location":"hackmd/Ansible/#offiline-installation","title":"offiline installation","text":"<ul> <li>https://docs.ansible.com/ansible/latest/collections_guide/collections_downloading.html</li> </ul> <pre><code>mkdir -p /tmp/ansible-collections-offiline\nansible-galaxy collection download -r /tmp/self-requirements.yml -p /tmp/ansible-collections-offiline\n</code></pre> <p>self-requirements.yml <pre><code>---\ncollections:\n  - name: ansible.posix\n    version: 1.5.4\n  - name: ansible.utils\n    version: 2.10.3\n  - name: community.general\n    version: 7.3.0\n  - name: community.crypto\n    version: 2.15.1\n  - name: cisco.nxos\n    version: 5.1.0\n</code></pre></p> <pre><code>cd /tmp/ansible-collections-offiline/\nansible-galaxy collection install -r requirements.yml\n</code></pre>"},{"location":"hackmd/Ansible/#ipaddr-filter","title":"ipaddr filter","text":"<ul> <li>Ansible.Utils \u2014 Ansible Documentation<ul> <li>Using the ipaddr filter \u2014 Ansible Documentation</li> </ul> </li> </ul>"},{"location":"hackmd/Ansible/#report","title":"Report","text":"<ul> <li>GitHub - ansible-community/ara: ARA Records Ansible and makes it easier to understand and troubleshoot.<ul> <li>Demo site</li> <li>Ansible reporting with ARA: Ansible Run Analysis | Sebiwi</li> <li>\u4f7f\u7528 ara \u4f86\u5074\u9304 Ansible Playbook - Be an Ansible Pro</li> </ul> </li> </ul>"},{"location":"hackmd/Ansible/#network","title":"Network","text":"<ul> <li>Ansible - VLAN Provisioning</li> </ul>"},{"location":"hackmd/Ansible/#practice","title":"Practice","text":"<p>Ansible Practice</p>"},{"location":"hackmd/Ansys/","title":"Ansys","text":"<ul> <li>Silent installation of ANSYS suite when using multiple ISO images are mounted to different folders/drives - Ansys Knowledge</li> <li>Run Ansys Fluent workloads \u00a0|\u00a0 Cloud HPC Toolkit \u00a0|\u00a0 Google Cloud</li> <li>What is Explicit Dynamics?</li> <li>\u864e\u9580\u79d1\u6280\u80a1\u4efd\u6709\u9650\u516c\u53f8 Taiwan Auto Design Co (TADC)</li> <li>debug<ul> <li>Ansys 2021R2 crashing (sigsegv) on new RHEL8 system</li> <li>Ansys2021R2 ansys212 seg faults immediately on RHEL8.2</li> <li>Running MAPDL 2021 R1 (or prior releases) distributed solving on newer version Linux (such as SLES 15.X, RHEL 8.X) with default Intel MPI 2018.3 may get below error: forrtl: severe (174): SIGSEGV, segmentation fault occurred Image PC Routine Line Source libifcoremt.so.5 00007F4D6B351522 for__signal_handl Unknown Unknown libpthread-2.26.s 00007F4D3861E2D0 Unknown Unknown Unknown libc-2.26.so 00007F4D35EA27A2 strtok_r Unknown Unknown libmpi.so.12.0 00007F4D34E9B591 __I_MPI___intel_s Unknown Unknown libmpi.so.12.0 00007F4D34D5D8F5 Unknown Unknown Unknown libmpi.so.12.0 00007F4D34D606... - Ansys Knowledge</li> </ul> </li> <li>journal file<ul> <li>Writing Fluent journal files \u2014 Sheffield HPC Documentation</li> </ul> </li> </ul> <p>/etc/hosts <pre><code>172.24.0.1   ansys-lic-srv\n172.24.0.2   ansys-compute-01\n172.24.0.3   ansys-compute-02\n</code></pre></p> <pre><code># /etc/hosts are prepared done\nmkdir -p /mnt/ansys1\nmkdir -p /mnt/ansys2\nmkdir -p /mnt/ansys3\nsudo mount -o loop ANSYS2023R1_LINX64_DISK1.iso /mnt/ansys1\nsudo mount -o loop ANSYS2023R1_LINX64_DISK2.iso /mnt/ansys2\nsudo mount -o loop ANSYS2023R1_LINX64_DISK3.iso /mnt/ansys3\ncd /mnt/ansys1\n./INSTALL -silent -install_dir /home/foo/ansys_inc -media_dir2 /mnt/ansys2 -media_dir3 /mnt/ansys3\n</code></pre> <p>license server configuration /home/foo/ansys_inc/shared_files/licensing/ansyslmd.ini</p> <pre><code>SERVER=1055@ansys-lic-srv\nANSYSLI_SERVERS=2325@ansys-lic-srv\n</code></pre>"},{"location":"hackmd/Ansys/#verify","title":"Verify","text":"<p>/home/foo/ansys_inc/v231/licensingclient/linx64</p> <pre><code>./lmutil lmstat -a -c 1055@ansys-lic-srv 2&gt;&amp;1|egrep -i \"cfx|fluent|ansys|dyna\" \n</code></pre> <p>mpi test</p> <pre><code>foo@ansys-compute-01:~&gt; /home/foo/ansys_inc/v231/ansys/bin/mpitest231 -mpi intelmpi2019 -machines ansys-compute-01:16:ansys-compute-02:16\n</code></pre> <pre><code>latency =     42.8230 microseconds\nbytes         bandwidth MB/s\n-----         --------------\n        8        0.1868\n     1024       31.9512\n     4096      118.1913\n    16384      235.5924\n    65536      359.5767\n   262144      681.7651\n  1048576      744.0079\n  4194304      945.1639\n  MPI Test has successfully completed!\n</code></pre>"},{"location":"hackmd/Ansys/#fluent-benchmark","title":"fluent benchmark","text":""},{"location":"hackmd/Ansys/#prerequisite","title":"prerequisite","text":"<p>RAM: 1TB</p> <p>change the max locked memory</p> <pre><code>ulimit -a\n</code></pre> <p>edit the /etc/security/limit.conf <pre><code>* soft memlock unlimited\n* hard memlock unlimited\n</code></pre></p>"},{"location":"hackmd/Ansys/#operations","title":"operations","text":"<p>6,7 and 8 take effects</p> <ol> <li>I_MPI_FABRICS=shm:ofa =&gt; I_MPI_FABRICS=shm:ofi</li> <li> <p>https://learn.microsoft.com/zh-tw/azure/virtual-machines/setup-mpi</p> </li> <li> <p>install the mft on ansys-4b</p> </li> <li>https://www.ibm.com/support/pages/firmware-update-mellonox-adapter-fails-sles-15-sp3-using-mlnx-ofed-49-3-and-later-releases</li> <li> <p>https://network.nvidia.com/products/adapter-software/firmware-tools/</p> </li> <li> <p>enlarge the ulimit and reboot for ansys-4b, ansys-9b</p> </li> <li>stack</li> <li>file descriptor</li> </ol> <p>/etc/security/limits.conf <pre><code>* soft stack unlimited\n* hard stack unlimited\n* soft nofile unlimited\n* hard nofile unlimited\n</code></pre></p> <ol> <li>enable mpi debug, I_MPI_DEBUG=5</li> </ol> <pre><code>I_MPI_DEBUG=5 USE_UCX=1 UCX_NET_DEVICES=mlx5_0:1 I_MPI_FABRICS=shm:ofi FI_PROVIDER=mlx /home/foo/ansys_inc/v231/ansys/bin/mpitest231 -mpi intelmpi2021 -machines ansys-4b:32:ansys-9b:32\n</code></pre> <ol> <li>run aircraft_wing_14m</li> </ol> <pre><code>/home/foo/ansys_inc/v231/fluent/bin/fluentbench.pl aircraft_wing_14m -pib -t128 -mpi=intelmpi2021 -cnf=hostfile -mpiopt=\"-genv I_MPI_DEBUG=8 -genv USE_UCX=1 -genv UCX_NET_DEVICES=mlx5_0:1 -genv I_MPI_FABRICS=shm:ofi -genv FI_PROVIDER=mlx\" -noloadchk  -nosyslog\n</code></pre> <ol> <li>run exhaust_system_33m by tcp</li> </ol> <pre><code>/home/foo/ansys_inc/v231/fluent/bin/fluentbench.pl exhaust_system_33m -t128 -mpi=intelmpi2018 -cnf=hostfile  -mpiopt=\"-genv I_MPI_DEBUG=8 -genv USE_UCX=1 -genv FI_PROVIDER=tcp\" \n</code></pre> <ol> <li>run aircraft_wing_2m by tcp</li> </ol> <pre><code>/home/foo/ansys_inc/v231/fluent/bin/fluentbench.pl aircraft_wing_2m -t128 -mpi=intelmpi2018 -cnf=hostfile  -mpiopt=\"-genv I_MPI_DEBUG=8 -genv USE_UCX=1 -genv FI_PROVIDER=tcp\" \n/home/foo/ansys_inc/v231/fluent/bin/fluentbench.pl aircraft_wing_2m -t128 -cnf=hostfile  -mpiopt=\"-genv I_MPI_DEBUG=8 -genv USE_UCX=1 -genv FI_PROVIDER=tcp\" \n</code></pre> <ol> <li>install the infiniband driver, MLNX_OFED_LINUX-23.10-1.1.9.0-sles15sp4-x86_64, on the ansys-4b</li> </ol> <p>InfiniBand - Linux InfiniBand Drivers</p> <pre><code>sudo ethtool -i ib0\nsudo zypper install createrepo_c insserv-compat tk\nsudo ./mlnxofedinstall --force --add-kernel-support\nsudo /etc/init.d/openibd restart\nsudo ethtool -i ib0\n</code></pre> <pre><code>foo@ansys-4b:~/ansys_inc/v231/fluent/bench/fluent/v6/aircraft_wing_2m&gt; sudo ethtool -i ib0\n[sudo] password for root:\ndriver: mlx5_core[ib_ipoib]\nversion: 23.10-1.1.9\nfirmware-version: 20.28.1002 (SM_1271000001000)\nexpansion-rom-version:\nbus-info: 0000:81:00.0\nsupports-statistics: yes\nsupports-test: yes\nsupports-eeprom-access: no\nsupports-register-dump: no\nsupports-priv-flags: yes\nfoo@ansys-4b:~/ansys_inc/v231/fluent/bench/fluent/v6/aircraft_wing_2m&gt;\n</code></pre> <pre><code>/home/foo/ansys_inc/v231/fluent/bin/fluentbench.pl aircraft_wing_2m -t128 -mpi=intelmpi2018 -cnf=hostfile  -mpiopt=\"-genv I_MPI_DEBUG=8 -genv USE_UCX=1 -genv FI_PROVIDER=mlx -genv I_MPI_FABRICS=shm:ofi -genv UCX_NET_DEVICES=mlx5_0:1\" \n/home/foo/ansys_inc/v231/fluent/bin/fluentbench.pl aircraft_wing_2m -t128 -cnf=hostfile  -mpiopt=\"-genv I_MPI_DEBUG=8 -genv USE_UCX=1 -genv FI_PROVIDER=mlx -genv I_MPI_FABRICS=shm:ofi -genv UCX_NET_DEVICES=mlx5_0:1\" \n</code></pre>"},{"location":"hackmd/Ansys/#uniform","title":"uniform","text":"<p>with turbostat</p> <pre><code>turbostat --interval 1 -S --quiet --out freq_analysis_240.out &amp; echo $! &gt; /home/smci/tbs_log.pid ; /home/smci/ansys_inc/v231/fluent/bin/fluent 3d -g -nmon -ssh -peth -mpi=intel -platform=intel -t240 -cnf=/home/smci/hostfile -i run.jou |tee log.txt &amp;&amp; pkill turbostat &amp;&amp; cat /home/smci/tbs_log.pid; ps -ef |grep turbostat ; kill -9 `cat /home/smci/tbs_log.pid`\n</code></pre>"},{"location":"hackmd/Computer%20Networking/","title":"Computer Networking","text":"<ul> <li>\u96f2\u7aef\u6642\u4ee3\u5fc5\u5099\u7db2\u8def\u7d2e\u6839\u6982\u5ff5\uff08\u542bTCP/IP\u8207IPV6\uff09 | Udemy</li> <li>Computer Networking Introduction - Ethernet and IP (Heavily Illustrated)</li> <li>\u7b2c 9 \u5802\u8ab2 - \u9818\u57df\u540d\u7a31\u4f3a\u670d\u5668 (DNS)<ul> <li>FAQ4: Hostnames short or long?</li> <li>What is the difference between a hostname and a fully qualified domain name? - Server Fault</li> <li>networking - What is the difference between hostname, hostname --fqdn, and hostname -A - Unix &amp; Linux Stack Exchange</li> <li>linux - Setting the hostname: FQDN or short name? - Server Fault</li> </ul> </li> <li>\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u6f2b\u8c08 | \u5361\u74e6\u90a6\u5676\uff01</li> <li>How to disable IPv6 on Linux? | NordVPN support</li> <li>\u73a9\u5177\u70cf\u6258\u90a6: (\u5e7e\u4e4e\u4e0d\u8ac7\u6307\u4ee4) \u6982\u5ff5\u6027\u7684 netplan \u7c21\u4ecb<ul> <li>Configuring networks | Ubuntu</li> <li>[\u6a5f\u6d3eX] Day 6 - Linux \u6c92\u7db2\u8def\uff0c\u6211\u8981\u600e\u9ebc\u767c\u9435\u4eba\u8cfd\u7684\u6587\u7ae0</li> </ul> </li> <li>Learn the networking basics every sysadmin needs to know | Enable Sysadmin<ul> <li>Cheat sheet: Linux networking | Opensource.com</li> </ul> </li> <li>\u7406\u89e3\u7f51\u7edc\u7684\u5206\u5c42\u6a21\u578b | \u5361\u74e6\u90a6\u5676\uff01</li> <li>Cisco\u5b78\u7fd2\u8cc7\u8a0a\u5206\u4eab: \u804a\u4e00\u804aSpine/Leaf\u662f\u4ec0\u9ebc</li> <li>[\u8bd1] \u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\uff1aSpine-Leaf \u67b6\u6784\u8bbe\u8ba1\u7efc\u8ff0\uff082016\uff09</li> <li>bridge<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u516d\u7ae0\u3001\u5340\u57df\u7db2\u8def\u6574\u9ad4\u74b0\u5883\u898f\u5283</li> <li>[Linux] \u5167\u6838\u865b\u64ecBridge, veth\u539f\u7406\u8207\u5be6\u4f5c | Hands on Linux Kernel: bridge, veth | \u9ec3\u5927\u4ed9\u7684\u96f2\u7aef\u4fee\u884c\u5ba4</li> <li>Linux \u2013 Bridge \u2013 Benjr.tw</li> <li>Proxmox VE \u5229\u7528 Linux Bridge + isc -dhcp-server \u5feb\u901f\u8a2d\u5b9a\u865b\u64ec\u6a5f\u5167\u7db2 | by Kerwin Tsai | Medium</li> </ul> </li> <li>2024-COSCUP-\u591a\u5ba2\u6a5f\u4e0a\u7684 NAT \u7ba1\u7406\u7cfb\u7d71\u5c08\u6848\u7d93\u9a57\u5206\u4eab - Google \u7c21\u5831</li> <li>\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u9ad8\u53ef\u7528\u6280\u672f\uff1a\u5e8f | \u5361\u74e6\u90a6\u5676\uff01<ul> <li>\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u9ad8\u53ef\u7528\u6280\u672f\u4e4b\u4ece\u4ea4\u6362\u673a\u5230\u4ea4\u6362\u673a\uff1aMLAG, \u5806\u53e0\u6280\u672f | \u5361\u74e6\u90a6\u5676\uff01</li> <li>\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u9ad8\u53ef\u7528\u6280\u672f\u4e4b\u4ece\u670d\u52a1\u5668\u5230\u7f51\u5173\uff1a\u9996\u8df3\u5197\u4f59\u534f\u8bae VRRP | \u5361\u74e6\u90a6\u5676\uff01</li> <li>Google \u7684\u5341\u5e74\u4e94\u4ee3\u7f51\u7edc\u67b6\u6784 | \u5361\u74e6\u90a6\u5676\uff01</li> </ul> </li> <li>\u5167\u7db2\u7a7f\u900f<ul> <li>ZeroTier\u4f7f\u7528\u6559\u5b78\uff1a\u5efa\u7acb\u865b\u64ec\u5340\u7db2\u7684VPN\u8edf\u9ad4 \u00b7 Ivon\u7684\u90e8\u843d\u683c<ul> <li>Self-hosting\u81ea\u67b6 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> <li>Tailscale\u8a2d\u5b9a\u6559\u5b78\uff0c\u514d\u8cbb\u5167\u7db2\u7a7f\u900fVPN \u00b7 Ivon\u7684\u90e8\u843d\u683c<ul> <li>\u5c07Tailscale\u7576\u8de8\u5340VPN\u7528\uff1a\u5982\u4f55\u8a2d\u5b9a\u51fa\u53e3\u7bc0\u9ede(Exit Node) \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Computer%20Networking/#_1","title":"\u6982\u89c0","text":"<p>\u63d0\u4f9b\u670d\u52d9\u7d66\u61c9\u7528\u7a0b\u5f0f\u7684\u57fa\u790e\u67b6\u69cb</p>"},{"location":"hackmd/Computer%20Networking/#_2","title":"\u57fa\u672c\u5143\u7d20","text":"<p>\u5f9e\u908a\u969b\u5230\u6838\u5fc3</p> <p>==\u7d42\u7aef\u7cfb\u7d71==(end system)</p> <p>\u53e6\u4e00\u500b\u540d\u7a31\u70ba\u4e3b\u6a5f(host) \u684c\u96fb, \u7b46\u96fb, \u624b\u4e0a\u7684\u667a\u6167\u578b\u624b\u6a5f</p> <p></p> <p>==\u901a\u8a0a\u9023\u7d50==(communication links)</p> <p>\u7d42\u7aef\u7cfb\u7d71\u901a\u5f80\u7db2\u8def\u6838\u5fc3\u7684\u5be6\u9ad4\u7269\u7406\u5a92\u4ecb \u4f8b\u5982: \u540c\u8ef8\u96fb\u7e9c, \u9285\u7dda, \u5149\u7e96\u548c\u7121\u7dda\u96fb\u983b\u8b5c</p> <p></p> <p>==\u5c01\u5305\u4ea4\u63db\u5668==(packet switches)</p> <p>\u5f15\u8def\u8005, \u77e5\u9053\u5c01\u5305\u5f9e\u4f55\u800c\u4f86\u4e26\u6307\u5f15\u5c01\u5305\u8a72\u524d\u5f80\u4f55\u8655 \u5c01\u5305(packet)\u662f\u96fb\u8166\u7db2\u8def\u4e2d\u7684\u8cc7\u8a0a\u5c01\u88dd\u55ae\u4f4d \u4e3b\u8981\u6709\u8def\u7531\u5668(router), \u93c8\u7d50\u5c64\u4ea4\u63db\u5668(link-layer switch)</p> <p></p>"},{"location":"hackmd/Computer%20Networking/#_3","title":"\u5143\u7d20\u8981\u5982\u4f55\u6e9d\u901a?","text":"<p>==\u5354\u5b9a== \u5354\u5b9a\u5b9a\u7fa9\u4e86\u5169\u500b\u4ee5\u4e0a\u7684\u901a\u8a0a\u5be6\u9ad4\u4e4b\u9593 1. \u4ea4\u63db\u8a0a\u606f\u7684\u683c\u5f0f\u548c\u9806\u5e8f 2. \u50b3\u9001\u63a5\u6536\u8a0a\u606f\u6216\u767c\u751f\u5176\u4ed6\u4e8b\u4ef6\u6642\u6240\u8981\u63a1\u53d6\u7684\u52d5\u4f5c</p> <p>\u985e\u5225?\u5c6c\u6027\u548c\u64cd\u4f5c</p>"},{"location":"hackmd/Computer%20Networking/#_4","title":"\u985e\u6bd4","text":"<p>\u8eca\u8f1b\u904b\u8f38\u7db2\u8def\uff0c\u7531\u9ad8\u901f\u516c\u8def\u3001\u4e00\u822c\u9053\u8def\u548c\u4ea4\u6d41\u9053\u7d44\u6210\u3002\u8eca\u8f1b\u985e\u4f3c\u5c01\u5305\uff0c\u9ad8\u901f\u516c\u8def\u3001\u4e00\u822c\u9053\u8def\u985e\u4f3c\u901a\u8a0a\u9023\u7d50\uff0c\u4ea4\u6d41\u9053\u985e\u4f3c\u5c01\u5305\u4ea4\u63db\u5668\uff0c\u5efa\u7bc9\u7269\u985e\u4f3c\u7d42\u7aef\u7cfb\u7d71\u3002</p>"},{"location":"hackmd/Computer%20Networking/#_5","title":"\u9023\u7dda\u7db2\u8def","text":"<p>\u5c07\u7d42\u7aef\u7cfb\u7d71\u9023\u7d50\u5230\u908a\u969b\u8def\u7531\u5668(edge router)\u7684\u9023\u7dda\u65b9\u5f0f \u908a\u969b\u8def\u7531\u5668: end-to-end\u8def\u5f91\u4e0a\u7684\u7b2c\u4e00\u500b\u8def\u7531\u5668</p>"},{"location":"hackmd/Computer%20Networking/#_6","title":"\u9023\u7dda\u985e\u578b","text":""},{"location":"hackmd/Computer%20Networking/#_7","title":"\u5bb6\u7528\u9023\u7dda","text":"<p>==\u64a5\u63a5\u6578\u64da\u6a5f==(dial-up modem) \u900f\u904e\u4e00\u822c\u7684\u985e\u6bd4\u96fb\u8a71\u7dda\u9023\u7dda\u5230\u5bb6\u7528ISP \u985e\u6bd4\u96fb\u8a71\u7dda\u70ba\u96d9\u7d5e\u540c\u5fc3\u7dda</p> <p>==DSL\u6578\u4f4d\u7528\u6236\u5c08\u7dda==(digital subscriber line) \u901a\u5e38\u7531\u96fb\u8a71\u516c\u53f8\u63d0\u4f9b, \u4e5f\u662f\u5728\u65e2\u5b58\u7684\u96d9\u7d5e\u96fb\u8a71\u7dda\u4e0a\u904b\u4f5c \u900f\u904e\u983b\u7387\u5206\u5272\u7684\u591a\u5de5\u8655\u7406\u6280\u8853, \u53ef\u540c\u6642\u63a5\u807d\u64a5\u6253\u96fb\u8a71\u548c\u4f7f\u7528\u7db2\u969b\u7db2\u8def</p> <p>\u4e0a\u50b3\u548c\u4e0b\u8f09\u81f3ISP\u8def\u7531\u5668\u7684\u901f\u7387\u662f\u4e0d\u5c0d\u7a31\u7684, \u4e0b\u8f09 &gt; \u4e0a\u50b3</p> <p>==HFC\u6df7\u5408\u5149\u7e96\u540c\u8ef8\u96fb\u7e9c==(hybrid fiber coaxial cable) \u812b\u80ce\u81ea\u76ee\u524d\u64ad\u9001\u6709\u7dda\u96fb\u8996\u6240\u4f7f\u7528\u7684\u96fb\u7e9c\u7db2\u8def \u4f7f\u7528\u7e9c\u7dda\u6578\u64da\u6a5f(cable modem), \u662f\u4e00\u7a2e\u5171\u7528\u7684\u64ad\u9001\u5a92\u4ecb</p> \u64a5\u63a5\u6578\u64da\u6a5f DSL HFC \u5be6\u9ad4\u7dda\u8def \u985e\u6bd4\u96fb\u8a71\u7dda \u985e\u6bd4\u96fb\u8a71\u7dda \u540c\u8ef8\u96fb\u7e9c \u540c\u6642\u63a5\u807d\u64a5\u6253\u96fb\u8a71\u548c\u4f7f\u7528\u7db2\u969b\u7db2\u8def X V V"},{"location":"hackmd/Computer%20Networking/#_8","title":"\u516c\u53f8\u9023\u7dda","text":"<p>==\u5340\u57df\u7db2\u8def(Local area network)== \u6709\u591a\u7a2e\u5340\u57df\u7db2\u8def\u7684\u6280\u8853, \u5e38\u7528\u7684\u662f\u4e59\u592a\u7db2\u8def\u6280\u8853, \u4e59\u592a\u7db2\u8def\u53ef\u5206\u70ba\u5171\u7528\u5f0f\u548c\u4ea4\u63db\u5f0f</p>"},{"location":"hackmd/Computer%20Networking/#_9","title":"\u7121\u7dda\u9023\u7dda","text":"<p>==\u7121\u7dda\u5340\u57df\u7db2\u8def==(wireless LAN) \u53ef\u5f9e\u534a\u5f91\u6578\u5341\u516c\u5c3a\u5167\u7684\u57fa\u5730\u53f0(\u7121\u7dda\u5b58\u53d6\u9023\u63a5\u9ede)\u50b3\u8f38\u548c\u63a5\u6536\u5c01\u5305</p> <p>==\u5ee3\u57df\u7121\u7dda\u9023\u7dda\u7db2\u8def==(wide-area wireless access networks) \u63d0\u4f9b\u4f7f\u7528\u8005\u5728\u57fa\u5730\u53f0\u65b9\u5713\u6578\u5341\u516c\u91cc\u5167\u7684\u7121\u7dda\u7db2\u8def\u9023\u7dda</p>"},{"location":"hackmd/Computer%20Networking/#_10","title":"\u570b\u969b\u5316\u57df\u540d","text":"<ul> <li>https://xn--fiq228c.xn--kpry57d/domain_name01.html</li> <li>https://xn--fiq228c.xn--kpry57d/technology/punycode.htm</li> </ul>"},{"location":"hackmd/Computer%20Networking/#bgp","title":"BGP","text":"<ul> <li>Internet \u8ddf\u4f60\u60f3\u7684\u4e0d\u4e00\u6a23\uff1aIP \u5730\u5740\u4e0d\u662f\u552f\u4e00\uff0c\u6709\u8a31\u591a\u76f8\u540c IP \u7684\u4e3b\u6a5f\u6563\u843d\u5404\u5730-\u9ed1\u6697\u57f7\u884c\u7dd2</li> </ul>"},{"location":"hackmd/Computer%20Networking/#nat","title":"NAT","text":"<ul> <li>NAT \u2014 SNAT, DNAT, PAT &amp; Port Forwarding | by Geeky much! | Networks &amp; Security | Medium</li> <li>NAT \u7db2\u8def\u4f4d\u5740\u8f49\u63db - Jan Ho \u7684\u7db2\u7d61\u4e16\u754c</li> <li>How do SNAT and DNAT work on Linux? | by adil | Medium</li> </ul> <p>\u65b9\u5411\u6027 \u4f7f\u7528port</p> <p>DNAT vs PAT DNAT: pool of available public IP addresses PAT: a single public IP address and multiplexes incoming and outgoing network traffic using port numbers.</p>"},{"location":"hackmd/Computer%20Networking/#dynamic-nat","title":"dynamic NAT","text":"<p>dynamic NAT is a good choice when you need to allow outgoing connections from a network that has a limited number of public IP addresses.</p>"},{"location":"hackmd/Computer%20Networking/#static-nat","title":"static NAT","text":"<p>with static NAT, the NAT device uses a fixed one-to-one mapping between private and public IP addresses.</p>"},{"location":"hackmd/Computer%20Networking/#port-address-translation-pat","title":"Port Address Translation (PAT)","text":"<p>Port Address Translation (PAT) is a type of Network Address Translation (NAT) that is used to map multiple private IP addresses to a single public IP address. It is also known as Network Address Port Translation (NAPT) or IP masquerading.</p> <ul> <li>PAT works by using a single public IP address and multiplexing incoming and outgoing network traffic using port numbers.</li> <li>It allows multiple devices on the private network to share a single public IP address and access the internet simultaneously.</li> </ul>"},{"location":"hackmd/Computer%20Networking/#port-forwarding","title":"Port forwarding","text":"<p>Port forwarding is a networking technique that is used to allow incoming internet connections to reach a specific device on a private network.</p> <ul> <li>This allows external devices to connect to the device on the private network using its public IP address and the forwarded port number.</li> </ul>"},{"location":"hackmd/Computer%20Networking/#under-the-hood","title":"Under the hood","text":"<p>\u5c31\u662f\u8981\u4f60\u61c2\u7f51\u7edc--\u4e00\u4e2a\u7f51\u7edc\u5305\u7684\u65c5\u7a0b | plantegg os\u5148\u6839\u64da\u76ee\u6a19IP\u548c\u672c\u6a5f\u7684route\u898f\u5247\u8a08\u7b97\u4f7f\u7528\u54ea\u500binterface(nic) input: target ip, route rule output: interface</p> <p>if same subnet, arp protocol(arp cache)</p> <p>if different subnet, ask the gateway, and gateway use its route rule and arp cache</p> <p>one interface can support multiple ip address</p>"},{"location":"hackmd/Computer%20Networking/#vlan","title":"VLAN","text":"<ul> <li>(83) \u3010\u7db2\u7d61\u57fa\u790e\u3011 VLAN \u57fa\u790e\u6982\u5ff5 \u6559\u5b78 (\u4e2d\u6587\u5b57\u5e55) (\u53ef\u8abf\u7bc0\u901f\u5ea6) - YouTube</li> <li>VLAN\u865b\u64ec\u5340\u57df\u7db2\u8def\u7c21\u4ecb</li> <li>(83) \u7db2\u8def\u57fa\u790e27 - Switch1:\u8a8d\u8b58VLAN - YouTube</li> </ul> <p>Unmanaged Switch managed Switch</p> <p>Access port: \u53ea\u6709\u4e00\u500bVLAN\u7684port Trunk port: \u591a\u500bVLAN\u7684port</p> <p>Trunk link</p>"},{"location":"hackmd/Computer%20Networking/#route","title":"Route","text":"<p>what meas about \"ip route\" result</p> <pre><code>default via 167.22.10.1 dev enp33s0f0 proto static metric 101\n167.22.0.0/16 dev enp33s0f0 proto kernel scope link src 167.22.0.15 metric 101\n167.122.0.0/16 dev ib0 proto kernel scope link src 167.122.0.15 metric 105\n</code></pre> <p>The output you provided is the result of running the \"ip route\" command, which displays the current routing table on a Linux system. Here is a breakdown of each line of the output:</p> <p>default via 167.22.10.1 dev enp33s0f0 proto static metric 101: This line represents the default route, which is used when a packet needs to be sent to a destination that is not covered by any other more specific route. In this case, the default gateway is 167.22.10.1, and the outgoing interface is enp33s0f0. The \"proto\" field indicates that this is a static route, which is configured manually rather than learned dynamically, and the \"metric\" field represents the cost of this route relative to other routes in the table.</p> <p>167.22.0.0/16 dev enp33s0f0 proto kernel scope link src 167.22.0.15 metric 101: This line represents a directly connected network, meaning that the system is directly connected to a subnet with the specified address range. In this case, the network address is 167.22.0.0/16, the outgoing interface is enp33s0f0, and the \"proto\" field indicates that this is a kernel route, which is automatically generated by the system. The \"scope\" field indicates the visibility of the route, with \"link\" meaning that it is only visible within the local network segment. The \"src\" field specifies the source IP address to use when sending packets to this subnet, and the \"metric\" field represents the cost of this route relative to other routes in the table.</p> <p>167.122.0.0/16 dev ib0 proto kernel scope link src 167.122.0.15 metric 105: This line is similar to the previous one, but it represents a different network that is connected to a different interface. Specifically, the network address is 167.122.0.0/16, the outgoing interface is ib0, and the \"proto\", \"scope\", \"src\", and \"metric\" fields have the same meanings as in the previous line.</p> <p>how to debug route if connection is break</p> <p>If you are experiencing a network connectivity issue and suspect that there might be a problem with your routing configuration, there are a few steps you can take to troubleshoot the issue. Here are some tips on how to debug your routing configuration:</p> <p>Check the routing table: Use the \"ip route\" command to check the current routing table on your system. Verify that the routes in the table are correct and that there are no conflicting routes. Make sure that the default gateway is set correctly and that the routing table is up-to-date.</p> <p>Ping the default gateway: Use the \"ping\" command to verify that you can reach the default gateway. If the ping fails, it could indicate a problem with the default gateway or the routing configuration.</p> <p>Trace the route to the destination: Use the \"traceroute\" or \"tracepath\" command to trace the route to the destination. This will help you identify where the connection is being lost and whether there are any routing issues along the way.</p> <p>Check the network topology: If you have access to the network topology, check it to make sure that there are no misconfigured devices or routing loops that could be causing the connectivity issue.</p> <p>Check the firewall: Make sure that any firewalls or security policies are not blocking the traffic. Check the firewall logs to see if any traffic is being dropped or rejected.</p> <p>Check the network interface: Verify that the network interface is up and running, and that it is configured correctly with the correct IP address, subnet mask, and gateway.</p> <pre><code>ip r\nip route get 172.19.51.6\n</code></pre> <pre><code>ip route del 172.19.51.0/24 via 172.19.41.1\n\nip route add 192.168.2.0/24 via 192.168.1.2 dev eth0\nip route del 192.168.2.0/24\n# To make it permanent, add it to /etc/network/interfaces (Debian) or /etc/sysconfig/network-scripts/route-eth0 (RHEL).\n\nsudo arp-scan -I eth15 172.19.51.0/24\n</code></pre> <ol> <li>Learn about IP routing and how packets move through a Linux system.</li> <li>Understand routing table concepts, including:     Default gateway     Static routes     Dynamic routes     Routing policies Sure! Let\u2019s break these topics down step by step.</li> </ol> <p>Linux Routing Basic by chatgpt</p>"},{"location":"hackmd/Computer%20Networking/#1-learn-about-ip-routing-and-how-packets-move-through-a-linux-system","title":"1. Learn About IP Routing and How Packets Move Through a Linux System","text":""},{"location":"hackmd/Computer%20Networking/#what-is-ip-routing","title":"What is IP Routing?","text":"<p>IP routing is the process of determining the path that packets take from a source to a destination across a network. In Linux, the kernel makes these decisions based on the system\u2019s routing table.</p>"},{"location":"hackmd/Computer%20Networking/#how-packets-move-through-a-linux-system","title":"How Packets Move Through a Linux System","text":"<p>When a packet is sent from a Linux system, the following steps occur:</p> <ol> <li>Packet Creation </li> <li>A user-space application (e.g., <code>ping</code>, <code>curl</code>, or a web browser) generates a packet.</li> <li> <p>The packet is passed to the transport layer (TCP/UDP) and then to the network layer (IP).</p> </li> <li> <p>Route Lookup </p> </li> <li>The kernel checks the routing table to determine the appropriate next hop.</li> <li>If a matching route is found, the packet is forwarded to the corresponding network interface.</li> <li> <p>If no route is found, the packet is dropped, and an error (e.g., \"Network unreachable\") is generated.</p> </li> <li> <p>Packet Forwarding (if applicable) </p> </li> <li>If the system is configured as a router (<code>net.ipv4.ip_forward=1</code>), it forwards packets between interfaces.</li> <li> <p>The packet may be NAT-ed (if applicable) before being sent out.</p> </li> <li> <p>Packet Transmission </p> </li> <li> <p>The packet is encapsulated into an Ethernet frame and transmitted over the network.</p> </li> <li> <p>Reply Handling </p> </li> <li>If a reply is received, it follows the same path in reverse.</li> </ol>"},{"location":"hackmd/Computer%20Networking/#routing-decision-example","title":"Routing Decision Example","text":"<ul> <li>Suppose a Linux machine with the IP <code>192.168.1.10/24</code> wants to send a packet to <code>8.8.8.8</code>:</li> <li>The system checks the routing table.</li> <li>If there is a default gateway (<code>192.168.1.1</code>), the packet is sent to it.</li> <li>The gateway forwards it to the next router until it reaches <code>8.8.8.8</code>.</li> </ul> <p>You can inspect this process using: <pre><code>ip route get 8.8.8.8\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#2-understand-routing-table-concepts","title":"2. Understand Routing Table Concepts","text":""},{"location":"hackmd/Computer%20Networking/#a-default-gateway","title":"a) Default Gateway","text":"<ul> <li>The default gateway is the router that the system uses when no specific route is found for a destination.</li> <li>It is defined as:   <pre><code>ip route add default via 192.168.1.1 dev eth0\n</code></pre></li> <li>To view the current default route:   <pre><code>ip route show | grep default\n</code></pre></li> <li>This tells the system, \u201cIf you don\u2019t know where to send the packet, send it to 192.168.1.1.\u201d</li> </ul>"},{"location":"hackmd/Computer%20Networking/#b-static-routes","title":"b) Static Routes","text":"<ul> <li>Static routes are manually defined routes that do not change unless modified by the admin.</li> <li>Used for networks that are not reachable via the default gateway.</li> <li>Example: Add a route to <code>192.168.2.0/24</code> via <code>192.168.1.2</code>:   <pre><code>ip route add 192.168.2.0/24 via 192.168.1.2 dev eth0\n</code></pre></li> <li>To delete a static route:   <pre><code>ip route del 192.168.2.0/24\n</code></pre></li> <li>To make it permanent, add it to <code>/etc/network/interfaces</code> (Debian) or <code>/etc/sysconfig/network-scripts/route-eth0</code> (RHEL).</li> </ul>"},{"location":"hackmd/Computer%20Networking/#c-dynamic-routes","title":"c) Dynamic Routes","text":"<ul> <li>Dynamic routing is managed by routing protocols like:</li> <li>OSPF (Open Shortest Path First)</li> <li>BGP (Border Gateway Protocol)</li> <li>RIP (Routing Information Protocol)</li> <li>Instead of static routes, dynamic routing updates routes automatically based on network conditions.</li> <li>Dynamic routing is configured using software like:</li> <li>Quagga</li> <li>FRRouting (FRR)</li> <li>BIRD</li> <li>Example: Using FRRouting (for OSPF)   <pre><code>vtysh -c 'show ip route'\n</code></pre></li> </ul>"},{"location":"hackmd/Computer%20Networking/#d-routing-policies-policy-based-routing","title":"d) Routing Policies (Policy-Based Routing)","text":"<ul> <li>Policy-Based Routing (PBR) allows packets to be routed based on criteria other than just the destination IP.</li> <li>Example: If you want traffic from <code>192.168.1.100</code> to use a different gateway (<code>192.168.1.2</code>), you can do:   <pre><code>ip rule add from 192.168.1.100 table 100\nip route add default via 192.168.1.2 table 100\n</code></pre></li> <li>View existing rules:   <pre><code>ip rule show\n</code></pre></li> <li>Example use cases:</li> <li>Different ISPs for different traffic types.</li> <li>Specific traffic (e.g., VoIP) using a dedicated gateway.</li> </ul>"},{"location":"hackmd/Computer%20Networking/#conclusion","title":"Conclusion","text":"<ul> <li>IP routing controls how packets move in a Linux system.</li> <li>Default gateway is the fallback route for unknown destinations.</li> <li>Static routes are manually set and do not change dynamically.</li> <li>Dynamic routes are automatically updated using routing protocols.</li> <li>Policy-based routing enables advanced traffic control.</li> </ul> <p>Would you like me to provide practical exercises or a lab setup for hands-on learning? \ud83d\ude80</p>"},{"location":"hackmd/Computer%20Networking/#vpn","title":"VPN","text":"<ul> <li>Tailscale quickstart \u00b7 Tailscale</li> <li>How Tailscale works \u00b7 Tailscale</li> <li>Tailscale+Headscale \u81ea\u67b6VPN\u5168\u7d00\u9304 - \u5496\u5561\u5076-IT\u65e5\u5e38</li> <li>laisky-blog: \u8fd1\u671f\u6298\u817e tailscale \u7684\u4e00\u4e9b\u5fc3\u5f97</li> <li>IPsec VPN \u8207 SSL VPN | Cloudflare</li> </ul>"},{"location":"hackmd/Computer%20Networking/#arp","title":"ARP","text":"<ul> <li>Day 14 \u9023\u7d50\u5c64\u653b\u64ca\u5be6\u4f5c - ARP Spoofing</li> <li>Day 16 : \u5be6\u4f5c\u7bc7 - \u5982\u4f55\u4f7f\u7528 ARP \u6b3a\u9a19\uff08ARP Spoofing\uff09\u9032\u884c\u4e2d\u9593\u4eba\u653b\u64ca\uff1f - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul>"},{"location":"hackmd/Computer%20Networking/#dns","title":"DNS","text":"<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u516b\u7ae0\u3001\u9818\u57df\u540d\u7a31\u4f3a\u670d\u5668 DNS \u670d\u52d9<ul> <li>How To Configure BIND as a Private Network DNS Server on Ubuntu 18.04 | DigitalOcean</li> <li>Ubuntu Linux\u5982\u4f55\u4fee\u6539DNS\u4f3a\u670d\u5668\uff08\u6307\u4ee4 \uff0b GUI\uff09 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> <li>Chapter\u00a030.\u00a0Configuring the order of DNS servers Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>Chapter\u00a033.\u00a0Manually configuring the /etc/resolv.conf file Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>\u963b\u64cb\u8272\u60c5\u7db2\u7ad9\u7684 DNS \u8a2d\u5b9a | \u54c8\u90e8\u843d</li> <li>\u642d\u5efaDNS\u670d\u52a1(\u4e8c) - \u59dc\u6d77\u6d9b\u7684\u535a\u5ba2 | Jht Blog</li> <li>/etc/resolv.conf<ul> <li>Chapter\u00a033.\u00a0Manually configuring the /etc/resolv.conf file Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>Chapter\u00a030.\u00a0Configuring the order of DNS servers Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>not going to next nameserver<ul> <li>resolv.conf(5) - Linux manual page</li> <li>domain name system - Ubuntu resolv.conf, not going to next nameserver? - Server Fault</li> <li>domain name system - Why don't my server query the 2nd entry in my resolv.conf? - Server Fault</li> </ul> </li> </ul> </li> <li>hostname<ul> <li>domain name system - Is the hostname case sensitive? - Server Fault</li> <li>php - Does HTTP hostname case (upper/lower) matter? - Stack Overflow</li> </ul> </li> </ul>"},{"location":"hackmd/Computer%20Networking/#dnssec","title":"DNSSEC","text":"<ul> <li>DNSSEC \u5982\u4f55\u904b\u4f5c\uff1f | Cloudflare</li> <li>Validate and secure DNS responses using DNSSEC on DNS Server in Windows Server | Microsoft Learn</li> <li>dns - Bind 9 DNSSEC not returning SERVFAIL when it should - Super User</li> </ul>"},{"location":"hackmd/Computer%20Networking/#bind","title":"bind","text":"<ul> <li>Chapter\u00a03.\u00a0Install and Configure Bind9 | Red Hat Product Documentation</li> </ul> <p>bind for Ubuntu Domain Name Service (DNS) | Ubuntu <pre><code>/etc/bind/named.conf\n/var/lib/bind/db*\n/etc/resolv.conf\n</code></pre></p> <p>bind for Redhat Chapter\u00a03.\u00a0Install and Configure Bind9 | Red Hat Product Documentation <pre><code>/etc/named.conf\n/var/named\n/etc/resolv.conf\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#verify","title":"Verify","text":"<pre><code>named-checkconf /etc/named.conf\nsystemctl status named\nrndc status\nnetstat -tap | grep named\nnetstat -tulpn | grep 53\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#rndc","title":"rndc","text":"<ul> <li>Manual Pages \u2014 BIND 9 9.16.26 documentation</li> <li>10.2.4.\u00a0Using the rndc Utility</li> <li>17.2.3.\u00a0Using the rndc Utility | Red Hat Product Documentation</li> <li>RNDC Bind9 | Setup Guide</li> <li>domain name system - rndc fails to add zone, bind99 freebsd - Server Fault</li> </ul>"},{"location":"hackmd/Computer%20Networking/#nsupdate","title":"nsupdate","text":"<ul> <li>Add dynamic DNS records to bind using nsupdate \u00b7 GitHub</li> <li>nsupdate \u6307\u4ee4 - IBM \u8aaa\u660e\u6587\u4ef6</li> <li>How to add TTL value to nsupdate while adding record in dns server for dynamic update? - Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/Computer%20Networking/#coredns","title":"CoreDNS","text":"<ul> <li>Running CoreDNS as a DNS Server in a Container - DEV Community</li> <li>CoreDNS\u7c21\u55ae\u9664\u932f\uff1a\u89e3\u6c7a\u4f60\u9047\u5230\u7684\u4e00\u822c\u554f\u984c. \u6700\u8fd1\u5728\u90e8\u7f72\u4e00\u4e9b\u89e3\u6c7a\u65b9\u6848\u6642\uff0c\u78b0\u5230\u4e86\u95dc\u65bc\u540d\u7a31\u89e3\u6790\u4e0a\u7684\u4e00\u4e9b\u554f\u984c\uff0c\u96d6\u7136\u6709\u6642\u5019\u4e0d\u96e3\u89e3\u6c7a\uff0c\u4f46\u2026 | by Albert Weng | Medium</li> <li>CoreDNS: DNS and Service Discovery</li> </ul> <p><pre><code>docker run -d --name coredns \\\n--restart=always \\\n--volume=/root/coredns:/root/ \\\n-p 53:53/udp \\\ncoredns/coredns -conf /root/Corefile\n</code></pre> /root/coredns/Corefile <pre><code>.:53 {\n    forward . 8.8.8.8 9.9.9.9\n    log\n    errors\n}\n\nfoo.bar:53 {\n    file /root/db.foo.bar\n    log\n    errors\n}\n</code></pre></p> <p>/root/coredns/db.foo.bar <pre><code>$ORIGIN foo.bar.\n@       3600 IN SOA dns.foo.bar. mail.foo.bar. (\n                                2024123016 ; serial\n                                7200       ; refresh (2 hours)\n                                3600       ; retry (1 hour)\n                                1209600    ; expire (2 weeks)\n                                3600       ; minimum (1 hour)\n                                )\n\ndns    IN  A   172.19.57.10\ntest   IN  A   172.19.57.10\nbeta-test IN  CNAME   test\n</code></pre></p> <pre><code>dig @192.168.1.10  test.foo.bar\ndig @192.168.1.10  beta-test.foo.bar\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#dhcp","title":"DHCP","text":"<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u4e5d\u7ae0\u3001\u5340\u57df\u7db2\u8def\u53c3\u6578\u4f9b\u61c9\u8005\uff1aDHCP, NTP</li> <li>Dynamic Host Configuration Protocol (DHCP) and Bootstrap Protocol (BOOTP) Parameters</li> <li>dhcpd.leases(5): DHCP client lease database - Linux man page<ul> <li>Ubuntu server dhcp - duplicate leases - Server Fault</li> </ul> </li> <li>Chapter\u00a03.\u00a0Providing DHCP services Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>14.2.\u00a0Configuring a DHCP Server Red Hat Enterprise Linux 7 | Red Hat Customer Portal</li> <li>dhcpd.conf(5): dhcpd config file - Linux man page</li> <li>Can't activate connection and get error \"Activation failed: IP configuration could not be reserved (no available address, timeout, etc.)\" - Red Hat Customer Portal</li> <li>DHCP Server \u8a2d\u5b9a\u53ca\u4f7f\u7528\u6559\u5b78-\u4f7f\u7528 isc-dhcp \u5957\u4ef6 | KJie Notes</li> <li>A Basic Guide to Configuring DHCP Failover</li> <li>authoritative<ul> <li>Problem: DHCP \"not authoritative for...\" - Knowledge Base / Community - Univention Help</li> <li>dhcpd: DHCPINFORM from 192.168.1.3 via bce1: not authoritative for subnet</li> </ul> </li> </ul> <pre><code>wget https://ftp.isc.org/isc/dhcp/4.4.3-P1/dhcp-4.4.3-P1.tar.gz\ntar xvf dhcp-4.4.3-P1.tar.gz\nsudo apt-get install build-essential\ncd dhcp-4.4.3-P1\n./configure --prefix=/usr --sysconfdir=/etc/dhcp --enable-binary-leases\nmake\nsudo make install\nvim /etc/init.d/isc-dhcp-server\nsystemctl daemon-reload\n</code></pre> <p>/etc/init.d/isc-dhcp-server <pre><code>#!/bin/sh\n\n### BEGIN INIT INFO\n# Provides:          isc-dhcp-server\n# Required-Start:    $remote_fs $network $syslog\n# Required-Stop:     $remote_fs $network $syslog\n# Should-Start:      $local_fs slapd $named\n# Should-Stop:       $local_fs slapd\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-Description: DHCP server\n# Description:       Dynamic Host Configuration Protocol Server\n### END INIT INFO\n\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\n\ntest -f /usr/sbin/dhcpd || exit 0\n\nDHCPD_DEFAULT=\"${DHCPD_DEFAULT:-/etc/default/isc-dhcp-server}\"\n\n# It is not safe to start if we don't have a default configuration...\nif [ ! -f \"$DHCPD_DEFAULT\" ]; then\n        echo \"$DHCPD_DEFAULT does not exist! - Aborting...\"\n        if [ \"$DHCPD_DEFAULT\" = \"/etc/default/isc-dhcp-server\" ]; then\n                echo \"Run 'dpkg-reconfigure isc-dhcp-server' to fix the problem.\"\n        fi\n        exit 0\nfi\n\n. /lib/lsb/init-functions\n\n# Read init script configuration\n[ -f \"$DHCPD_DEFAULT\" ] &amp;&amp; . \"$DHCPD_DEFAULT\"\n\nNAME4=dhcpd\nNAME6=dhcpd6\n\nDESC4=\"ISC DHCPv4 server\"\nDESC6=\"ISC DHCPv6 server\"\n\n# use already specified config file or fallback to defaults\nDHCPDv4_CONF=${DHCPDv4_CONF:-/etc/dhcp/dhcpd.conf}\nDHCPDv6_CONF=${DHCPDv6_CONF:-/etc/dhcp/dhcpd6.conf}\n\n# try to read pid file name from config file or fallback to defaults\nif [ -z \"$DHCPDv4_PID\" ]; then\n        DHCPDv4_PID=$(sed -n -e 's/^[ \\t]*pid-file-name[ \\t]*\"\\(.*\\)\"[ \\t]*;.*$/\\1/p' &lt; \"$DHCPDv4_CONF\" 2&gt;/dev/null | head -n 1)\nfi\nif [ -z \"$DHCPDv6_PID\" ]; then\n        DHCPDv6_PID=$(sed -n -e 's/^[ \\t]*dhcpv6-pid-file-name[ \\t]*\"\\(.*\\)\"[ \\t]*;.*$/\\1/p' &lt; \"$DHCPDv6_CONF\" 2&gt;/dev/null | head -n 1)\nfi\nDHCPDv4_PID=\"${DHCPDv4_PID:-/var/run/dhcpd.pid}\"\nDHCPDv6_PID=\"${DHCPDv6_PID:-/var/run/dhcpd6.pid}\"\n\ntest_config()\n{\n        VERSION=\"$1\"\n        CONF=\"$2\"\n\n        if ! /usr/sbin/dhcpd -t $VERSION -q -cf \"$CONF\" &gt; /dev/null 2&gt;&amp;1; then\n                echo \"dhcpd self-test failed. Please fix $CONF.\"\n                echo \"The error was: \"\n                /usr/sbin/dhcpd -t $VERSION -cf \"$CONF\"\n                exit 1\n        fi\n}\n\ncheck_status()\n{\n        OPTION=\"$1\"\n        PIDFILE=\"$2\"\n        NAME=\"$3\"\n\n        if [ ! -r \"$PIDFILE\" ]; then\n                test \"$OPTION\" != -v || echo \"$NAME is not running.\"\n                return 3\n        fi\n\n        if read pid &lt; \"$PIDFILE\" &amp;&amp; ps -p \"$pid\" &gt; /dev/null 2&gt;&amp;1; then\n                test \"$OPTION\" != -v || echo \"$NAME is running.\"\n                return 0\n        else\n                test \"$OPTION\" != -v || echo \"$NAME is not running but $PIDFILE exists.\"\n                return 1\n        fi\n}\n\nstart_daemon()\n{\n        VERSION=\"$1\"\n        CONF=\"$2\"\n        NAME=\"$3\"\n        PIDFILE=\"$4\"\n        DESC=\"$5\"\n\n        shift 5\n        INTERFACES=\"$*\"\n\n        test_config \"$VERSION\" \"$CONF\"\n        log_daemon_msg \"Starting $DESC\" \"$NAME\"\n\n        if [ -e \"$PIDFILE\" ]; then\n                log_failure_msg \"dhcpd service already running (pid file $PIDFILE currenty exists)\"\n                exit 1\n        fi\n\n        touch /var/lib/dhcp/$NAME.leases\n\n        start-stop-daemon --start --quiet --pidfile $PIDFILE \\\n                --exec /usr/sbin/dhcpd -- $VERSION -q -cf $CONF $INTERFACES\n        sleep 2\n\n        if check_status -q $PIDFILE $NAME; then\n                log_end_msg 0\n        else\n                log_failure_msg \"check syslog for diagnostics.\"\n                log_end_msg 1\n                exit 1\n        fi\n}\n\nstop_daemon()\n{\n        if check_status -q $DHCPDv4_PID $NAME4; then\n                log_daemon_msg \"Stopping $DESC4\" \"$NAME4\"\n                start-stop-daemon --stop --quiet --pidfile $DHCPDv4_PID\n                log_end_msg $?\n                rm -f \"$DHCPDv4_PID\"\n        fi\n\n        if check_status -q $DHCPDv6_PID $NAME6; then\n                log_daemon_msg \"Stopping $DESC6\" \"$NAME6\"\n                start-stop-daemon --stop --quiet --pidfile $DHCPDv6_PID\n                log_end_msg $?\n                rm -f \"$DHCPDv6_PID\"\n        fi\n}\n\ncase \"$1\" in\n        start)\n                if test -n \"$INTERFACES\" -a -z \"$INTERFACESv4\"; then\n                        echo \"DHCPv4 interfaces are no longer set by the INTERFACES variable in\" &gt;&amp;2\n                        echo \"/etc/default/isc-dhcp-server.  Please use INTERFACESv4 instead.\" &gt;&amp;2\n                        echo \"Migrating automatically for now, but this will go away in the future.\" &gt;&amp;2\n                        INTERFACESv4=\"$INTERFACES\"\n                fi\n                if test -n \"$INTERFACESv4\"; then\n                        echo \"Launching IPv4 server only.\"\n                        start_daemon \"-4\" \"$DHCPDv4_CONF\" \"$NAME4\" \\\n                                \"$DHCPDv4_PID\" \"$DESC4\" \"$INTERFACESv4\"\n                fi\n                if test -n \"$INTERFACESv6\"; then\n                        echo \"Launching IPv6 server only.\"\n                        start_daemon \"-6\" \"$DHCPDv6_CONF\" \"$NAME6\" \\\n                                \"$DHCPDv6_PID\" \"$DESC6\" \"$INTERFACESv6\"\n                fi\n                if test -z \"$INTERFACESv4\" -a -z \"$INTERFACESv6\"; then\n                        echo \"Launching both IPv4 and IPv6 servers (please configure INTERFACES in /etc/default/isc-dhcp-server if you only want one or the other).\"\n                        start_daemon \"-4\" \"$DHCPDv4_CONF\" \"$NAME4\" \\\n                                \"$DHCPDv4_PID\" \"$DESC4\" \"\"\n                        start_daemon \"-6\" \"$DHCPDv6_CONF\" \"$NAME6\" \\\n                                \"$DHCPDv6_PID\" \"$DESC6\" \"\"\n                fi\n                ;;\n        stop)\n                stop_daemon\n                ;;\n        restart | force-reload)\n                $0 stop\n                sleep 2\n                $0 start\n                if [ \"$?\" != \"0\" ]; then\n                        exit 1\n                fi\n                ;;\n        status)\n                if test -n \"$INTERFACES\" -a -z \"$INTERFACESv4\"; then\n                        INTERFACESv4=\"$INTERFACES\"\n                fi\n                if test -n \"$INTERFACESv4\"; then\n                        echo -n \"Status of $DESC4: \"\n                        check_status -v $DHCPDv4_PID $NAME4 || exit $?\n                fi\n                if test -n \"$INTERFACESv6\"; then\n                        echo -n \"Status of $DESC6: \"\n                        check_status -v $DHCPDv6_PID $NAME6 || exit $?\n                fi\n                ;;\n        *)\n                echo \"Usage: $0 {start|stop|restart|force-reload|status}\"\n                exit 1\nesac\n\nexit 0\n</code></pre></p> <p>/etc/dhcp/dhcpd.conf <pre><code>lease-file-name \"/var/lib/dhcp/dhcpd.leases\";\noption client-architecture code 93 = unsigned integer 16;\n\n\nshared-network ens160 {\n    subnet 192.168.1.0 netmask 255.255.255.0 {\n        max-lease-time 43200;\n        min-lease-time 43200;\n        default-lease-time 43200;\n        range 192.168.1.100 192.168.1.200;\n        option routers 192.168.1.1;\n        option subnet-mask 255.255.255.0;\n        option domain-name-servers 8.8.8.8;\n        option domain-name \"yourdomain.local\";\n\n        next-server 192.168.1.10;  # IP of your PXE server\n\n        if option client-architecture = 00:07 {\n           filename \"mboot.efi\";\n        }\n        else if option client-architecture = 00:09 {\n           filename \"mboot.efi\";\n        }\n    }\n}\n</code></pre></p> <p>/etc/default/isc-dhcp-server <pre><code># Defaults for isc-dhcp-server (sourced by /etc/init.d/isc-dhcp-server)\n\n# Path to dhcpd's config file (default: /etc/dhcp/dhcpd.conf).\nDHCPDv4_CONF=/etc/dhcp/dhcpd.conf\n#DHCPDv6_CONF=/etc/dhcp/dhcpd6.conf\n\n# Path to dhcpd's PID file (default: /var/run/dhcpd.pid).\nDHCPDv4_PID=/var/run/dhcpd.pid\n#DHCPDv6_PID=/var/run/dhcpd6.pid\n\n# Additional options to start dhcpd with.\n#       Don't use options -cf or -pf here; use DHCPD_CONF/ DHCPD_PID instead\n#OPTIONS=\"\"\n\n# On what interfaces should the DHCP server (dhcpd) serve DHCP requests?\n#       Separate multiple interfaces with spaces, e.g. \"eth0 eth1\".\n#INTERFACESv4=\"ens160\"\nINTERFACESv4=\"ens160\"\n</code></pre></p> <pre><code># Ubunut isc-dhcp-server service\ndhcp-lease-list\n\nls -la /var/lib/dhcp/dhcpd.leases\n</code></pre> <pre><code>wget https://sources.debian.org/data/main/i/isc-dhcp/4.4.3-P1-5/contrib/dhcp-lease-list.pl\nchmod +x dhcp-lease-list.pl\n./dhcp-lease-list.pl --parsable\n</code></pre> <pre><code>/var/lib/dhcpd/dhcpd.leases\n/etc/dhcp/dhcpd.conf\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#detect-dhcp-server-in-the-subnet","title":"detect dhcp server in the subnet","text":"<pre><code>sudo tcpdump -i &lt;interface&gt; port 67 or port 68 -n\n</code></pre> <p><pre><code>14:04:36.123456 IP 192.168.1.1.67 &gt; 192.168.1.100.68: BOOTP/DHCP, Reply, length 300\n</code></pre> 192.168.1.1 is the dhcp server</p> <p>release and renew <pre><code># release and renew\nip link set &lt;interface&gt; down &amp;&amp; ip link set &lt;interface&gt; up\n</code></pre></p> <p>OR</p> <pre><code># release and renew\ndhclient -r &lt;interface&gt; &amp;&amp; dhclient &lt;interface&gt;\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#configure-linux-as-a-router","title":"Configure Linux as a Router","text":"<ul> <li>Configure Linux as a Router (IP Forwarding) | Linode Docs</li> <li>Installing and configuring a Linux gateway | TechRepublic</li> <li>How to Turn a Linux Server into a Router to Handle Traffic Statically and Dynamically - Part 10<ul> <li>How to Turn a Linux Server into a Router to Handle Traffic Statically and Dynamically - GeeksforGeeks</li> </ul> </li> <li>[SOLVED] Configuring firewalld to act as a router - CentOS</li> <li> <p>DNS</p> <ul> <li>14.04 - Connection timed out; no servers could be reached error - Ask Ubuntu</li> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u5341\u4e5d\u7ae0\u3001\u4e3b\u6a5f\u540d\u7a31\u63a7\u5236\u8005\uff1a DNS \u4f3a\u670d\u5668</li> </ul> </li> <li> <p>check ipforward is enable <pre><code>sudo sysctl net.ipv4.ip_forward\n</code></pre></p> </li> </ul> <p>(optional) If this parameter is disabled (0)</p> <p>/etc/sysctl.conf <pre><code>net.ipv4.ip_forward = 1\n</code></pre></p> <p>apply the changes <pre><code>sysctl -p\n</code></pre></p> <ol> <li>check the iptable eno1 is the interface to internet eno3 is the interface to intranet</li> </ol> <p>if using the firewalld - Named and firewalld - Fedora Discussion <pre><code>firewall-cmd --get-active-zones\nfirewall-cmd --change-interface=eno1 --zone=external\nfirewall-cmd --change-interface=eno3 --zone=internal\nfirewall-cmd --add-service=dns --zone=internal\nfirewall-cmd --list-all --zone=external\nfirewall-cmd --list-all --zone=internal\n</code></pre></p> <p>(optional: using iptables directly) =&gt; not complete for dns query <pre><code>iptables -t nat -A POSTROUTING -o eno1 -j MASQUERADE\niptables -A FORWARD -i eno1 -o eno3 -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -A FORWARD -i eno3 -o eno1 -j ACCEPT\n</code></pre></p> <p>Add direct rules to firewalld. Add the --permanent option to keep these rules across restarts. <pre><code>firewall-cmd --direct --add-rule ipv4 nat POSTROUTING 0 -o eno1 -j MASQUERADE\nfirewall-cmd --direct --add-rule ipv4 filter FORWARD 0 -i eno3 -o eno1 -j ACCEPT\nfirewall-cmd --direct --add-rule ipv4 filter FORWARD 0 -i eno1 -o eno3 -m state --state RELATED,ESTABLISHED -j ACCEPT\n</code></pre></p> <ol> <li>DNS cache-only and forward /etc/named.conf</li> </ol> <pre><code>options {\n        listen-on port 53 { any; };\n        listen-on-v6 port 53 { ::1; };\n        directory       \"/var/named\";\n        dump-file       \"/var/named/data/cache_dump.db\";\n        statistics-file \"/var/named/data/named_stats.txt\";\n        memstatistics-file \"/var/named/data/named_mem_stats.txt\";\n        secroots-file   \"/var/named/data/named.secroots\";\n        recursing-file  \"/var/named/data/named.recursing\";\n        allow-query     { 167.23.0.0/16; };\n\n        /*\n         - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion.\n         - If you are building a RECURSIVE (caching) DNS server, you need to enable\n           recursion.\n         - If your recursive DNS server has a public IP address, you MUST enable access\n           control to limit queries to your legitimate users. Failing to do so will\n           cause your server to become part of large scale DNS amplification\n           attacks. Implementing BCP38 within your network would greatly\n           reduce such attack surface\n        */\n        recursion yes;\n        forward only ;\n        forwarders {\n         8.8.8.8;\n        };\n\n        dnssec-enable yes;\n        dnssec-validation yes;\n\n        managed-keys-directory \"/var/named/dynamic\";\n\n        pid-file \"/run/named/named.pid\";\n        session-keyfile \"/run/named/session.key\";\n\n        /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */\n        include \"/etc/crypto-policies/back-ends/bind.config\";\n};\n\nlogging {\n        channel default_debug {\n                file \"data/named.run\";\n                severity dynamic;\n        };\n};\n\nzone \".\" IN {\n        type hint;\n        file \"named.ca\";\n};\n\ninclude \"/etc/named.rfc1912.zones\";\ninclude \"/etc/named.root.key\";\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#troubshooting-for-connection-problems","title":"Troubshooting for connection problems","text":"<ul> <li>Why does ethtool show 'no link' for ethernet interface even though cable is physically connected? - Red Hat Customer Portal</li> <li>error while trying to activate the new network : - CentOS</li> <li>Wired connection no more working after system update - English / Network/Internet - openSUSE Forums</li> <li>Why am I seeing the error \"Error: Connection activation failed: No suitable device found for this connection (device nic0 not available because device is strictly unmanaged).\" - Red Hat Customer Portal</li> <li>linux \u7db2\u8def\u547d\u4ee4ethtool\u8207mii-tool\u53canm-tool<ul> <li>\"No link detected\" from ethtool and mii-tool - Red Hat Customer Portal</li> </ul> </li> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u4f7f\u7528 10G switch \u9700\u8981\u6ce8\u610f\u7684\u6548\u80fd\u554f\u984c</li> </ul> <pre><code>ip link show\nsudo mii-tool -v eno7\n</code></pre> <p>\"LOWER_UP\" means the cable is plugged in and has physical link</p>"},{"location":"hackmd/Computer%20Networking/#no-carrier","title":"NO-CARRIER","text":"<ul> <li>\u4e00\u500b\u95dc\u65bcLINUX\u7db2\u8def\u51fa\u554f\u984c\u7684\u89e3\u6c7a\u7d93\u9a57</li> <li>NO CARRIER - Wikipedia</li> <li>Why does an interface show NO-CARRIER? - Red Hat Customer Portal</li> </ul> <p>Linux's network stack uses the NO CARRIER status for a network interface that is turned on (\"up\") but cannot be connected because the physical layer is not operating properly, e.g. because an ethernet cable is not plugged in.</p>"},{"location":"hackmd/Computer%20Networking/#linkdown-from-ip-route","title":"linkdown from ip route","text":"<ul> <li>What's the meaning of `linkdown` and `onlink' in Linux Route? - Unix &amp; Linux Stack Exchange</li> </ul>"},{"location":"hackmd/Computer%20Networking/#cisco-nexus-9000-series","title":"Cisco Nexus 9000 Series","text":"<ul> <li>Cisco Nexus 9000 Series NX-OS Troubleshooting Guide, Release 7.x - Overview [Cisco Nexus 9000 Series Switches] - Cisco<ul> <li>Cisco Nexus 9000 Series NX-OS Troubleshooting Guide, Release 7.x - Troubleshooting Ports [Cisco Nexus 9000 Series Switches] - Cisco</li> </ul> </li> </ul>"},{"location":"hackmd/Computer%20Networking/#proxy","title":"Proxy","text":"<ul> <li>Does Red Hat provide any SOCKS proxy server package? - Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/Computer%20Networking/#squid-system-proxy-config","title":"Squid + System Proxy config","text":"<ul> <li>\u5b89\u88dd Squid Proxy - Yowko's Notes</li> <li>Chapter\u00a08.\u00a0Configuring the Squid caching proxy server Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>Squid\u6b63\u5411\u4ee3\u7406\u670d\u52a1\u5668\u7684\u642d\u5efa\u548c\u914d\u7f6e \u2013 Jimmy's Blog</li> </ul> <pre><code>export http_proxy=\"\nhttp://10.199.19.1:3128\"\nexport https_proxy=\"\nhttp://10.199.19.1:3128\"\n</code></pre> <pre><code>/etc/squid/conf.d\n/etc/squid/conf.d/debian.conf\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#apt","title":"apt","text":"<p>/etc/apt/apt.conf.d/99proxy <pre><code>Acquire::http::Proxy \"http://10.199.19.1:3128\";\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#ssh-tunnelsocks-proxy-broser-proxy-config","title":"SSH Tunnel(SOCKS Proxy) + Broser Proxy config","text":"<ul> <li>SSH Tunneling (Port Forwarding) \u8a73\u89e3 \u00b7 John Engineering Stuff<ul> <li>Dynamic port forwarding with SSH and SOCKS5 - Blog, Antonio Gioia</li> <li>SSH Tunnel: Dynamic Port Forwarding</li> <li>\u5229\u7528\u9060\u7aef SSH \u4f3a\u670d\u5668\u67b6\u8a2d SOCKS \u4ee3\u7406\u4f3a\u670d\u5668(Proxy Server)\u4fdd\u8b77\u7db2\u8def\u50b3\u8f38\u5167\u5bb9 - MyApollo</li> <li>How to Set up SSH SOCKS Tunnel for Private Browsing | Linuxize</li> </ul> </li> <li>How to set up SSH dynamic port forwarding on Linux | Enable Sysadmin</li> <li>SOCKS vs HTTP Proxy - Choosing the Right One</li> <li>HTTP(s) Proxy vs SOCKS Proxy: What\u2019s the difference | by BrowserScan | Medium</li> </ul> <pre><code>ssh -N -D 9090 {user}@{bastion server}\n</code></pre> <p>run in the background <pre><code>ssh -D 9090 -q -C -N -f {user}@{bastion server}\n\n# in linux\nps aux | grep 'ssh -D'\nkill {pid}\n\n# in windows\ntasklist | findstr ssh\ntaskkill /F /pid {pid}\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#windows-chrome","title":"windows chrome","text":"<p>\u547d\u4ee4\u63d0\u793a\u5b57\u5143 <pre><code>cd C:\\Program Files\\Google\\Chrome\\Application\nchrome.exe --user-data-dir=\"%USERPROFILE%\\proxy-profile\" --proxy-server=\"socks4://localhost:9090\"\n</code></pre></p> <p></p>"},{"location":"hackmd/Computer%20Networking/#windows-edge","title":"windows edge","text":"<p>\u547d\u4ee4\u63d0\u793a\u5b57\u5143 <pre><code>cd \"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\"\nmsedge.exe  --user-data-dir=\"%USERPROFILE%\\edge-proxy-profile\" --proxy-server=\"socks4://localhost:9090\"\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#windows-firefox","title":"windows firefox","text":""},{"location":"hackmd/Computer%20Networking/#apt_1","title":"apt","text":"<ul> <li>[ubuntu][socks5][proxy] Set proxy for apt \u00b7 GitHub</li> </ul> <p>in the machine which in the private subnet and without internet /etc/apt/apt.conf.d/99proxy <pre><code>Acquire::http::Proxy \"socks5h://127.0.0.1:9090\";\nAcquire::https::Proxy \"socks5h://127.0.0.1:9090\";\nAcquire::socks::proxy \"socks5h://127.0.0.1:9090\";\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#mtu","title":"MTU","text":"<ul> <li>\u6709\u5173 MTU \u548c MSS \u7684\u4e00\u5207 | \u5361\u74e6\u90a6\u5676\uff01</li> <li>how to set MTU, now that ifconfig is gone</li> </ul> <p>After trial and error, I found the MTU config will impact the bandwidth</p> <pre><code>Case 1-1:\nd23cn001 mtu: 9000\nd23is168 mtu: 9000\nd23en007-p38 mtu: 1500\nd23en007-p39 mtu: 1500\n\nr12 d23is168 =&gt; d23en007-p38 =&gt; d23en007-p39 =&gt; r12 d23cn001 Speed Weird 0 byte\n\n\nCase 1-2:\nd23cn001 mtu: 9000\nd23is010 mtu: 1500\nd23en007-p38 mtu: 1500\nd23en007-p39 mtu: 1500\n\nr1 d23is010 =&gt; d23en003-p10 =&gt; d23en007-p39 =&gt; r12 d23cn001 Speed OK\n\n\nCase 1-3:\nd23cn001 mtu: 1500\nd23is010 mtu: 1500\nd23en007-p35 mtu: 1500\nd23en007-p37 mtu: 1500\n\nr12 d23is165 =&gt; d23en007-p35 =&gt; d23en007-p37 =&gt; r12 d23is167 Speed OK\n\n\nCase 2-1:\nd23cn001 mtu: 9000\nd23is168 mtu: 9000\nd23en007-p38 mtu: 9000\nd23en007-p39 mtu: 9000\n\nr12 d23is168 =&gt; d23en007-p38 =&gt; d23en007-p39 =&gt; r12 d23cn001 Speed OK\n\n\nCase 2-2:\nd23cn001 mtu: 9000\nd23is168 mtu: 1500\nd23en007-p38 mtu: 9000\nd23en007-p39 mtu: 9000\n\nr12 d23is168 =&gt; d23en007-p38 =&gt; d23en007-p39 =&gt; r12 d23cn001 Speed OK\n\n\nCase 2-3:\nd23is165 mtu: 1500\nd23is167 mtu: 1500\nd23en007-p35 mtu: 9000\nd23en007-p37 mtu: 9000\n\nr12 d23is165 =&gt; d23en007-p35 =&gt; d23en007-p37 =&gt; r12 d23is167 Speed OK\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#localhost-and-127001","title":"localhost and 127.0.0.1","text":"<ul> <li>localhost\u548c127.0.0.1\u7684\u533a\u522b | plantegg</li> </ul>"},{"location":"hackmd/Computer%20Networking/#can-a-single-network-card-have-2-ip-addresses","title":"Can a single network card have 2 IP addresses","text":"<ul> <li>networking - What happen when I assign 2 IP on one NIC? - Server Fault</li> <li>nic - Can a single network card have 2 IP addresses? - Server Fault</li> </ul>"},{"location":"hackmd/Computer%20Networking/#firewall","title":"Firewall","text":"<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u4e03\u7ae0\u3001Linux \u9632\u706b\u7246\u8a2d\u5b9a</li> <li>\u7b2c 4 \u5802\u8ab2 - \u8a8d\u8b58\u8207\u5efa\u7f6e\u9632\u706b\u7246</li> <li>Linux \u7684\u9632\u706b\u7246 (iptables) \u521d\u63a2 - King Zone<ul> <li>2.8.9.\u00a0IPTables | Red Hat Product Documentation</li> </ul> </li> <li>Illustrated introduction to Linux iptables<ul> <li>How To List and Delete Iptables Firewall Rules | DigitalOcean</li> <li>Iptables Essentials: Common Firewall Rules and Commands | DigitalOcean</li> <li>Linux Firewall - iptables - HackMD</li> <li>\u521d\u63a2 IPTABLES \u6d41\u52d5\u4e4b\u8def - \u4ee5 Docker \u70ba\u7bc4\u4f8b | Hwchiu Learning Note</li> </ul> </li> </ul>"},{"location":"hackmd/Computer%20Networking/#pxe","title":"PXE","text":"<ul> <li>\u95dc\u65bcPXE install OS - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u5b89\u88dd\u4f3a\u670d\u5668\u8207 kickstart</li> <li>SLES 15 SP5 | \u90e8\u7f72\u6307\u5357 | \u6e96\u5099\u7db2\u8def\u958b\u6a5f\u74b0\u5883</li> <li>SLES 15 SP4 | \u90e8\u7f72\u6307\u5357 | \u8a2d\u5b9a UEFI HTTP \u958b\u6a5f\u4f3a\u670d\u5668</li> <li>Chapter\u00a015.\u00a0Preparing to install from the network using PXE Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> <li>Linux\u81ea\u52d5\u904b\u7dad\uff1a\u4f7f\u7528 PXE &amp; Kickstart \u81ea\u52d5\u5b89\u88dd CentOS - HackMD</li> <li>explain Exsi PXE config</li> </ul> <p>\u9054\u6210\u9019\u500b PXE \u5fc5\u9808\u8981\u6709\u5169\u500b\u74b0\u7bc0 - (1)\u4e00\u500b\u662f\u7528\u6236\u7aef\u7684\u7db2\u8def\u5361\u5fc5\u9808\u8981\u652f\u63f4 PXE \u7528\u6236\u7aef\u529f\u80fd\uff0c\u4e26\u4e14\u958b\u6a5f\u6642\u9078\u64c7\u7db2\u8def\u5361\u958b\u6a5f\uff0c\u9019\u6a23\u7cfb\u7d71\u624d\u6703\u4ee5\u7db2\u8def\u5361\u9032\u5165 PXE \u7528\u6236\u7aef\u7684\u7a0b\u5e8f - (2)\u4e00\u500b\u662f PXE \u4f3a\u670d\u5668\u5fc5\u9808\u8981\u63d0\u4f9b\u81f3\u5c11\u542b\u6709 DHCP \u4ee5\u53ca TFTP \u7684\u670d\u52d9\u624d\u884c     - DHCP \u670d\u52d9\u5fc5\u9808\u8981\u80fd\u5920\u63d0\u4f9b\u7528\u6236\u7aef\u7684\u7db2\u8def\u53c3\u6578\u4e4b\u5916\uff0c\u9084\u5f97\u8981\u544a\u77e5\u7528\u6236\u7aef TFTP \u6240\u5728\u7684\u4f4d\u7f6e\u70ba\u4f55\u624d\u884c     - TFTP \u5247\u662f\u63d0\u4f9b\u7528\u6236\u7aef boot loader \u53ca kernel file \u4e0b\u8f09\u9ede\u7684\u91cd\u8981\u670d\u52d9</p>"},{"location":"hackmd/Computer%20Networking/#interface-name","title":"Interface name","text":"<ul> <li>Consistent Network Device Naming - Wikipedia</li> <li>Chapter\u00a011.\u00a0Consistent Network Device Naming Red Hat Enterprise Linux 7 | Red Hat Customer Portal</li> <li>11.3.\u00a0Understanding the Predictable Network Interface Device Names Red Hat Enterprise Linux 7 | Red Hat Customer Portal</li> <li>networking - what is the difference between eth1 and eno1? - Super User</li> <li>linux - Why is my ethernet interface called enp0s10 instead of eth0? - Unix &amp; Linux Stack Exchange</li> </ul>"},{"location":"hackmd/Computer%20Networking/#tftp","title":"TFTP","text":"<pre><code>sudo apt-get install tftpd-hpa\n</code></pre> <p>/etc/default/tftpd-hpa <pre><code># /etc/default/tftpd-hpa\n\nTFTP_USERNAME=\"tftp\" \nTFTP_DIRECTORY=\"/tftpboot\" \nTFTP_ADDRESS=\":69\" \nTFTP_OPTIONS=\"--secure\" \n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#test-tftp","title":"Test TFTP","text":"<ul> <li>TFTP \"Transfer timed out\" with firewalld - Red Hat Customer Portal</li> </ul> <pre><code>[root@foo tmp]# tftp\ntftp&gt; connect 172.24.131.123\ntftp&gt; status\nConnected to 172.24.131.123.\nMode: netascii Verbose: off Tracing: off Literal: off\nRexmt-interval: 5 seconds, Max-timeout: 25 seconds\ntftp&gt; get pxelinux.0\ntftp&gt; q\n[root@foo tmp]# md5sum pxelinux.0\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#ipxe","title":"iPXE","text":"<ul> <li>iPXE - open source boot firmware [start]<ul> <li>iPXE - open source boot firmware [download]</li> <li>iPXE - open source boot firmware [howto:chainloading]</li> <li>iPXE - open source boot firmware [howto:dhcpd]</li> <li>iPXE - open source boot firmware [cmd]</li> </ul> </li> <li>How to Netboot with iPXE Part 1. The Basics | by Peter Bolch | Medium</li> <li>How to Netboot with iPXE Part 2. Booting Alpine | by Peter Bolch | Medium</li> <li>How to setup iPXE on Ubuntu</li> <li>Install Clear Linux OS Over the Network with iPXE \u2014 Documentation for Clear Linux* project</li> <li>\u670d\u52a1\u5668\u7f51\u7edc\u542f\u52a8\u65b9\u5f0f\u63a2\u7d22Part2\uff1aUEFI\u542f\u52a8\u7bc7 | C0reFast\u8bb0\u4e8b\u672c</li> <li>\u4f7f\u7528 iPXE \u548c HTTP \u5c07 ESXi \u5b89\u88dd\u7a0b\u5f0f\u958b\u6a5f<ul> <li>\u7bc4\u4f8b DHCP \u7d44\u614b</li> </ul> </li> <li>linuxserver/netbootxyz - Docker Image | Docker Hub</li> <li>Unable to PXE boot while Secure Boot is enabled : r/vmware</li> <li>By MAC<ul> <li>Transfer boot file base on client's MAC</li> <li>Bootstrapping full iPXE native menu with customizable default option with timeout (also includes working Ubuntu 12.04 preseed install) \u00b7 GitHub</li> </ul> </li> <li>Ubuntu<ul> <li>ubuntu 22.04 - jammy - autoinstall - pxe \u81ea\u52a8\u5b89\u88c5 - \u5218\u5bb6\u7684\u535a\u5ba2<ul> <li>Autoinstall quick start - Ubuntu installation documentation</li> <li>Moln\u00e1r P\u00e9ter's Professional Blog - Ubuntu 22.04 (Jammy) autoinstall over PXE</li> <li>cloud init \u4ecb\u7d39 - HackMD<ul> <li>Autoinstall configuration reference manual - Ubuntu installation documentation</li> </ul> </li> <li>offline<ul> <li>firefox - Autoinstall Ubuntu 22.04 in Air Gapped network - Ask Ubuntu</li> <li>Install UBUNTU 22.04 offline with PACKER and CLOUD-INIT -<ul> <li>Modules \u2014 Cloud-Init 17.1 documentation</li> </ul> </li> <li>Question #817737 \u201cUbuntu22.04/22.10 autoinstall crash\u201d : Questions : scala package : Ubuntu</li> </ul> </li> </ul> </li> <li>Ubuntu 22.04 PXE / UEFI netboot DESKTOP installation - Ubuntu Community Hub</li> </ul> </li> <li>Redhat<ul> <li>Configure PXE Boot Server for Rocky Linux 9/CentOS 9 Kickstart Installation | Lisenet.com :: Linux | Security | Networking<ul> <li>Appendix\u00a0F.\u00a0Boot options reference | Red Hat Product Documentation</li> <li>Chapter\u00a023.\u00a0Boot Options | Red Hat Product Documentation</li> <li>Kickstart File Template for Automating Installation of RHEL 8 - HackMD</li> </ul> </li> <li>Chapter\u00a08.\u00a0Performing an automated installation using Kickstart | Red Hat Product Documentation</li> <li>rhel - PXE Boot Kickstart - how to include installation tree - Unix &amp; Linux Stack Exchange</li> </ul> </li> <li>UEFI Secure Boot<ul> <li>iPXE &amp; HTTP(s) Secure Booting | John Hannan's Blog</li> </ul> </li> </ul> <pre><code>sequenceDiagram\n    participant TN as target node\n    participant DHCP\n    participant TFTP\n    participant HTTP\n\n    TN-&gt;&gt;+DHCP: -\n    DHCP--&gt;&gt;-TN: next server and get file \"ipxe.efi\"\n    TN-&gt;&gt;+TFTP: -\n    TFTP--&gt;&gt;-TN: network boot firmware: ipxe.efi\n    TN-&gt;&gt;+DHCP: user-class = \"iPXE\"\n    DHCP--&gt;&gt;-TN: next server and get file \"ipxe.script\"\n    TN-&gt;&gt;+TFTP: -\n    TFTP--&gt;&gt;-TN: ipxe.script\n\n    TN-&gt;&gt;+HTTP: get kernel\n    HTTP--&gt;&gt;-TN: vmlinuz\n    TN-&gt;&gt;+HTTP: get Initrd ramdisk\n    HTTP--&gt;&gt;-TN: initrd\n    TN-&gt;&gt;+TN: boot with kernel and initrd\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#ubuntu","title":"Ubuntu","text":""},{"location":"hackmd/Computer%20Networking/#nfs-boot","title":"nfs boot","text":"<pre><code>sudo apt-get update\nsudo apt-get install build-essential debootstrap isc-dhcp-server tftpd-hpa nfs-kernel-server\n\n# tftp root path\nsudo mkdir -p /tftpboot\nsudo mkdir -p /tftpboot/boot\n\n# nfs root path\nsudo mkdir -p /srv/nfsroot\nsudo echo \"/srv/nfsroot *(rw,sync,no_root_squash,no_subtree_check)\" &gt; /etc/exports\nsudo exportfs -a\nsudo systemctl restart nfs-kernel-server\n</code></pre> <p>shared nfs for all nodes <pre><code># setup the nfs root filesystem\nsudo debootstrap --arch amd64 jammy /srv/nfsroot http://archive.ubuntu.com/ubuntu/\n# customize the nfs root filesystem\nsudo chroot /srv/nfsroot\necho \"root:$(openssl passwd -6 bar@123)\" | chpasswd -e\nuseradd -m -d /home/foo -p $(openssl passwd -6 bar@123) foo\napt-get install -y openssh-server\nexit\n</code></pre></p> <pre><code># ipxe\nsudo cp /boot/vmlinuz-$(uname -r) /tftpboot/vmlinuz\nsudo cp /boot/initrd.img-$(uname -r) /tftpboot/initrd.img\n# sudo chmod 775 /tftpboot/vmlinuz\nsudo wget -O /tftpboot/ipxe.efi http://boot.ipxe.org/ipxe.efi\n# Define the content to append\ncontent=$(cat &lt;&lt;EOF\n\n#!ipxe\n\nset http-server 192.168.1.10:8000\nset nfs-server 192.168.1.10\nset nfs-root /srv/nfsroot\n\nkernel http://${http-server}/vmlinuz initrd=initrd.img root=/dev/nfs rw nfsroot=${nfs-server}:${nfs-root} ip=dhcp\ninitrd http://${http-server}/initrd.img\nboot\nEOF\n)\n\n# Append the content to the file\necho \"$content\" &gt;&gt; /tftpboot/ipxe.script\n</code></pre> <p>nfs by mac if mac is 00:0c:29:d5:8a:04 <pre><code># setup the nfs root filesystem\nsudo debootstrap --arch amd64 jammy /srv/nfsroot/000c29d58a04 http://archive.ubuntu.com/ubuntu/\n# customize the nfs root filesystem\nsudo chroot /srv/nfsroot/000c29d58a04\necho \"root:$(openssl passwd -6 bar@123)\" | chpasswd -e\nuseradd -m -d /home/foo -p $(openssl passwd -6 bar@123) foo\napt-get install -y openssh-server\nexit\n</code></pre></p> <pre><code># ipxe\nsudo cp /boot/vmlinuz-$(uname -r) /tftpboot/vmlinuz\nsudo cp /boot/initrd.img-$(uname -r) /tftpboot/initrd.img\n# sudo chmod 775 /tftpboot/vmlinuz\nsudo wget -O /tftpboot/ipxe.efi http://boot.ipxe.org/ipxe.efi\n# Define the content to append\ncontent=$(cat &lt;&lt;EOF\n\n#!ipxe\nchain --replace --autofree mac-${mac:hexraw}.ipxe\nEOF\n)\n\n# Append the content to the file\necho \"$content\" &gt;&gt; /tftpboot/ipxe.script\n\n# Define the content to append\ncontent=$(cat &lt;&lt;EOF\n\n#!ipxe\n\nset http-server 192.168.1.10:8000\nset nfs-server 192.168.1.10\nset nfs-root /srv/nfsroot\n\nkernel http://${http-server}/vmlinuz initrd=initrd.img root=/dev/nfs rw nfsroot=${nfs-server}:${nfs-root}/${mac:hexraw} ip=dhcp\ninitrd http://${http-server}/initrd.img\nboot\nEOF\n)\n\n# Append the content to the file\necho \"$content\" &gt;&gt; /tftpboot/mac-000c29d58a04.ipxe\n</code></pre>"},{"location":"hackmd/Computer%20Networking/#http-autoinstall-provision","title":"http autoinstall provision","text":"<p>Memory: at least 6GiB</p> <p>/tftpboot/ipxe.script format 1 <pre><code>#!ipxe\nset http-server 192.168.1.10:8000\nset nfs-server 192.168.1.10\nset nfs-root /srv/nfsroot\n\nkernel http://${http-server}/ubuntu/jammy/casper/vmlinuz\ninitrd http://${http-server}/ubuntu/jammy/casper/initrd\nimgargs vmlinuz initrd=initrd \\\n autoinstall \\\n ip=dhcp \\\n url=http://192.168.1.10:8000/ubuntu/jammy/ubuntu-22.04.4-live-server-amd64.iso \\\n ds=nocloud-net;s=http://192.168.1.10:8000/ubuntu/jammy/autoinstall/\nboot\n</code></pre></p> <p>/tftpboot/ipxe.script format 2 <pre><code>#!ipxe\nset http-server 192.168.1.10:8000\nset nfs-server 192.168.1.10\nset nfs-root /srv/nfsroot\n\nkernel http://${http-server}/ubuntu/jammy/casper/vmlinuz autoinstall url=http://${http-server}/ubuntu/jammy/ubuntu-22.04.4-live-server-amd64.iso ds=nocloud-net;s=http://${http-server}/ubuntu/jammy/autoinstall/ ip=dhcp\ninitrd http://${http-server}/ubuntu/jammy/casper/initrd\nboot\n</code></pre></p> <p>/etc/dhcp/dhcpd.conf <pre><code>lease-file-name \"/var/lib/dhcp/dhcpd.leases\";\noption client-architecture code 93 = unsigned integer 16;\n\n\nshared-network ens192 {\n    subnet 192.168.1.0 netmask 255.255.255.0 {\n        max-lease-time 43200;\n        min-lease-time 43200;\n        default-lease-time 43200;\n        range 192.168.1.100 192.168.1.200;\n        option routers 192.168.1.1;\n        option subnet-mask 255.255.255.0;\n        #option domain-name-servers 8.8.8.8;\n        option domain-name \"yourdomain.local\";\n\n        next-server 192.168.1.10;  # IP of your TFTP server\n\n        if exists user-class and option user-class = \"iPXE\" {\n            filename \"ipxe.script\";\n        } elsif option client-architecture = 00:00 {\n            filename \"undionly.kpxe\";\n        } else {\n            filename \"ipxe.efi\";\n        }\n    }\n}\n</code></pre></p> <pre><code>wget -O /tmp/ubuntu-22.04.4-live-server-amd64.iso http://172.31.48.191/ISO/ubuntu-22.04.4-live-server-amd64.iso\nmkdir -p /tmp/ubuntu-jammy\nsudo mount -o loop /tmp/ubuntu-22.04.4-live-server-amd64.iso /tmp/ubuntu-jammy\nsudo mkdir -p /tftpboot/boot/ubuntu/jammy/casper/\nsudo cp /tmp/ubuntu-jammy/casper/initrd /tftpboot/boot/ubuntu/jammy/casper/\nsudo cp /tmp/ubuntu-jammy/casper/vmlinuz /tftpboot/boot/ubuntu/jammy/casper/\numount /tmp/ubuntu-jammy\nsudo cp /tmp/ubuntu-22.04.4-live-server-amd64.iso /tftpboot/boot/ubuntu/jammy/\nsudo mkdir -p /tftpboot/boot/ubuntu/jammy/autoinstall\nsudo touch /tftpboot/boot/ubuntu/jammy/autoinstall/meta-data\n# disable_suites is for offline env\nsudo cat &gt; /tftpboot/boot/ubuntu/jammy/autoinstall/user-data &lt;&lt; 'EOF'\n#cloud-config\nautoinstall:\n  identity:\n    hostname: ipxe-target-from-http\n    password: $6$Br4k9eeV7CUn4yAh$XUSXOInFLjkgndlC.S9kdsS6LhOUoIhWprDSa.VKhvprmjSdMienG4b.4n5r3NrD.auc3SEjbseOn3td/FnYS/\n    username: foo\n  version: 1\n  apt:\n    disable_suites: [updates, backports, security, proposed, release, inversion, multiverse]\n  user-data:\n    users:\n      - name: foo\n        gecos: 'foo User'\n        sudo: ALL=(ALL) NOPASSWD:ALL\nEOF\n\nsudo wget -O /tftpboot/ipxe.efi http://boot.ipxe.org/ipxe.efi\n\n# Define the content to append\nsudo cat &gt; /tftpboot/ipxe.script &lt;&lt; 'EOF'\n\n#!ipxe\n\nset http-server 192.168.1.10:8000\nset nfs-server 192.168.1.10\n\nkernel http://${http-server}/ubuntu/jammy/casper/vmlinuz autoinstall url=http://${http-server}/ubuntu/jammy/ubuntu-22.04.4-live-server-amd64.iso ds=nocloud-net;s=http://${http-server}/ubuntu/jammy/autoinstall/ ip=dhcp\ninitrd http://${http-server}/ubuntu/jammy/casper/initrd\nboot\nEOF\n</code></pre> <p>if need to enable root account ssh login by password, use this user-data <pre><code>#cloud-config\nautoinstall:\n  identity:\n    hostname: ipxe-target-from-http\n    password: $6$Br4k9eeV7CUn4yAh$XUSXOInFLjkgndlC.S9kdsS6LhOUoIhWprDSa.VKhvprmjSdMienG4b.4n5r3NrD.auc3SEjbseOn3td/FnYS/\n    username: foo\n  version: 1\n  apt:\n    disable_suites: [updates, backports, security, proposed, release, inversion, multiverse]\n  user-data:\n    users:\n      - name: foo\n        gecos: 'foo User'\n        sudo: ALL=(ALL) NOPASSWD:ALL\n    chpasswd:\n      list: |\n        root:$6$Br4k9eeV7CUn4yAh$XUSXOInFLjkgndlC.S9kdsS6LhOUoIhWprDSa.VKhvprmjSdMienG4b.4n5r3NrD.auc3SEjbseOn3td/FnYS/\n      expire: false\n    ssh_pwauth: true\n    write_files:\n      - path: /etc/ssh/sshd_config.d/customized.conf\n        content: |\n          PermitRootLogin yes\n          PasswordAuthentication yes\n    runcmd:\n      - systemctl restart sshd\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#redhat","title":"Redhat","text":""},{"location":"hackmd/Computer%20Networking/#http-autoinstall-provision_1","title":"http autoinstall provision","text":"<p>/tftpboot/ipxe.script <pre><code>#!ipxe\n\nset http-server 192.168.1.10:8000\n\nkernel http://${http-server}/boot/rhel/8.9/raw/images/pxeboot/vmlinuz initrd=initramfs inst.stage2=http://${http-server}/boot/rhel/8.9/raw inst.ks=http://${http-server}/boot/rhel/8.9/raw/ks.cfg\ninitrd --name initramfs http://${http-server}/boot/rhel/8.9/raw/images/pxeboot/initrd.img\nboot\n</code></pre></p> <pre><code>mount -t iso9660 /tmp/rhel-8.9-x86_64-dvd.iso /tmp/rhel-8.9 -o loop,ro\nmkdir -p /home/foo/boot/rhel/8.9/raw\nrsync -avzh --progress /tmp/rhel-8.9/ /home/foo/boot/rhel/8.9/raw/\ntouch /home/foo/boot/rhel/8.9/raw/ks.cfg\ncat &gt; /home/foo/boot/rhel/8.9/raw/ks.cfg &lt;&lt; 'EOF'\n#version=RHEL8\ntext\n\nrepo --name=\"AppStream\" --baseurl=http://192.168.1.10:8000/boot/rhel/8.9/raw/AppStream\n\n%packages\n@^minimal-environment\nkexec-tools\n\n%end\n\n# Keyboard layouts\nkeyboard --xlayouts='us'\n# System language\nlang en_US.UTF-8\n\n# Network information\nnetwork  --bootproto=dhcp --device=ens160 --ipv6=auto --activate\nnetwork  --hostname=ipxe-target-from-http.localdomain\n\n# Use network installation\nurl --url=\"http://192.168.1.10:8000/boot/rhel/8.9/raw\"\n\n# Run the Setup Agent on first boot\nfirstboot --enable\n\nignoredisk --only-use=sda\nautopart\n# Partition clearing information\nclearpart --all --initlabel\n\n# System timezone\ntimezone America/New_York --isUtc\n\n# Root password\nrootpw --iscrypted $6$nhMYeGx62dqF2l7O$pxNdZ6urW0mvCoMAh8.PhUFtbssl3LopiRCa7iMk.4n/qGcyKgDR2jMhhlcTHNPSJm73qEzeamQXfv.WyEEbb/\nuser --groups=wheel --name=foo --password=$6$M6xOA4EgUKJtHEUK$czJSOAjKfE1zbvZlB2CVOSRkmnRxCc52bPALWIJpk.aOaHAPT6ZvYWa4ZZaZTa0Q1o0ORf1Wf1yyR2OWkeCbY0 --iscrypted --gecos=\"foo\"\n\n%addon com_redhat_kdump --enable --reserve-mb='auto'\n\n%end\n\nreboot\nEOF\n</code></pre> <p>ks.cfg for autopart <pre><code>#version=RHEL8\ntext\n\nrepo --name=\"AppStream\" --baseurl=http://192.168.1.10:8000/boot/rhel/8.9/raw/AppStream\n\n%packages\n@^minimal-environment\nkexec-tools\n\n%end\n\n# Keyboard layouts\nkeyboard --xlayouts='us'\n# System language\nlang en_US.UTF-8\n\n# Network information\nnetwork  --bootproto=dhcp --device=ens160 --ipv6=auto --activate\nnetwork  --hostname=ipxe-target-from-http.localdomain\n\n# Use network installation\nurl --url=\"http://192.168.1.10:8000/boot/rhel/8.9/raw\"\n\n# Run the Setup Agent on first boot\nfirstboot --enable\n\nignoredisk --only-use=sda\nautopart\n# Partition clearing information\nclearpart --all --initlabel\n\n# System timezone\ntimezone America/New_York --isUtc\n\n# Root password\nrootpw --iscrypted $6$nhMYeGx62dqF2l7O$pxNdZ6urW0mvCoMAh8.PhUFtbssl3LopiRCa7iMk.4n/qGcyKgDR2jMhhlcTHNPSJm73qEzeamQXfv.WyEEbb/\nuser --groups=wheel --name=foo --password=$6$M6xOA4EgUKJtHEUK$czJSOAjKfE1zbvZlB2CVOSRkmnRxCc52bPALWIJpk.aOaHAPT6ZvYWa4ZZaZTa0Q1o0ORf1Wf1yyR2OWkeCbY0 --iscrypted --gecos=\"foo\"\n\n%addon com_redhat_kdump --enable --reserve-mb='auto'\n\n%end\n\nreboot\n</code></pre></p> <p>ks.cfg for customized partition(80G) <pre><code>#version=RHEL9\ntext\n\nrepo --name=\"AppStream\" --baseurl=http://192.168.1.10:8000/boot/rhel/9.3/raw/AppStream\n\n%packages\n@^minimal-environment\nrsync\nkexec-tools\n\n%end\n\n# Keyboard layouts\nkeyboard --xlayouts='us'\n# System language\nlang en_US.UTF-8\n\n# Network information\nnetwork  --bootproto=dhcp --device=ens160 --ipv6=auto --activate\nnetwork  --hostname=ipxe-target-from-http.localdomain\n\n# Use network installation\nurl --url=\"http://192.168.1.10:8000/boot/rhel/9.3/raw\"\n\n# Run the Setup Agent on first boot\nfirstboot --enable\n\nignoredisk --only-use=sda\n# Disk partitioning information\npart /boot/efi --fstype=efi --size=600\npart /boot --fstype=xfs --size=1024\npart pv.01 --size=1 --grow\n\nvolgroup vg_root pv.01\nlogvol / --vgname=vg_root --size=10240 --grow --name=lv_root --fstype=xfs\nlogvol /home --vgname=vg_root --size=10240 --name=lv_home --fstype=xfs\nlogvol /tmp --vgname=vg_root --size=30720 --name=lv_tmp --fstype=xfs\nlogvol swap --vgname=vg_root --size=2048 --name=lv_swap --fstype=swap\n\n# Partition clearing information\nclearpart --all --initlabel\n\n# System timezone\ntimezone America/New_York --isUtc\n\n# Root password\nrootpw --iscrypted $6$nhMYeGx62dqF2l7O$pxNdZ6urW0mvCoMAh8.PhUFtbssl3LopiRCa7iMk.4n/qGcyKgDR2jMhhlcTHNPSJm73qEzeamQXfv.WyEEbb/\nuser --groups=wheel --name=foo --password=$6$M6xOA4EgUKJtHEUK$czJSOAjKfE1zbvZlB2CVOSRkmnRxCc52bPALWIJpk.aOaHAPT6ZvYWa4ZZaZTa0Q1o0ORf1Wf1yyR2OWkeCbY0 --iscrypted --gecos=\"foo\"\n\n%addon com_redhat_kdump --enable --reserve-mb='auto'\n\n%end\n\nreboot\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#ipxe-menu","title":"ipxe menu","text":"<p>combine http autoinstall provision for ubuntu and redhat</p> <p>/tftpboot/ipxe-menu.script <pre><code>#!ipxe\n\n# Set a timeout for the menu 20s\nset menu-timeout 20000\n\n# Set http server access point\nset http-server 192.168.1.10:8000\n\n# Define the menu\n:start\nmenu iPXE Boot Menu\nitem --key u ubuntu22 Autoinstall provision for Ubuntu 22\nitem --key r rhel93 Autoinstall provision for Redhat 9.3\nitem --gap -- --------------------------\nitem --key x exit Exit iPXE\n\n# Choose the default menu item\nchoose --default ubuntu22 --timeout ${menu-timeout} selected\ngoto ${selected}\n\n:ubuntu22\necho Autoinstall provision for Ubuntu 22...\nkernel http://${http-server}/boot/ubuntu/jammy/casper/vmlinuz autoinstall url=http://${http-server}/boot/ubuntu/jammy/ubuntu-22.04.4-live-server-amd64.iso ds=nocloud-net;s=http://${http-server}/boot/ubuntu/jammy/autoinstall/ ip=dhcp\ninitrd http://${http-server}/boot/ubuntu/jammy/casper/initrd\nboot\n\n:rhel93\necho Autoinstall provision for Redhat 9.3...\nkernel http://${http-server}/boot/rhel/9.3/pxeboot/vmlinuz initrd=initramfs inst.stage2=http://${http-server}/boot/rhel/9.3/raw inst.ks=http://${http-server}/boot/rhel/9.3/raw/ks.cfg\ninitrd --name initramfs http://${http-server}/boot/rhel/9.3/pxeboot/initrd.img\nboot\n\n:exit\necho Exiting iPXE...\n</code></pre></p>"},{"location":"hackmd/Computer%20Networking/#cloudflare-tunnel","title":"Cloudflare Tunnel","text":"<ul> <li>Cloudflare Tunnel\u6559\u5b78\uff0c\u5f9e\u5916\u7db2\u5b89\u5168\u5730\u5b58\u53d6\u5167\u7db2\u7684Linux\u4f3a\u670d\u5668 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/Deployment/","title":"Deployment","text":"<ul> <li>\u5728\u672c\u5730\u7aef\u57f7\u884c GitHub Actions \u8dd1 CI | Run your GitHub Actions locally</li> </ul>"},{"location":"hackmd/Development/","title":"Development","text":"<ul> <li>CQRS Software Architecture Pattern: The Good, the Bad, and the Ugly</li> <li>System Design \u2014 Design a Monitoring System</li> </ul>"},{"location":"hackmd/Development/#communication","title":"Communication","text":"<p>\u4f60\u53ef\u80fd\u4e0d\u77e5\u9053\u7684\u5373\u6642\u66f4\u65b0\u65b9\u6848:Polling Polling Long Polling WebSocket Server Push / Server Send Event multipart/x-mixed-replace</p> <ul> <li>Server Send Event<ul> <li>\u4f60\u53ef\u80fd\u4e0d\u77e5\u9053\u7684\u5373\u6642\u66f4\u65b0\u65b9\u6848:Server Send Event | \u53c8LAG\u96a8\u6027\u7b46\u8a18</li> <li>\u5728 ASP.NET \u7528 Server-Sent Events \u5be6\u73fe\u5373\u6642\u5ee3\u64ad-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u4f7f\u7528 server-sent \u4e8b\u4ef6 - Web APIs | MDN</li> </ul> </li> </ul>"},{"location":"hackmd/Docker/","title":"Docker","text":"<ul> <li>docker run | Docker Documentation<ul> <li>docker cheat sheet</li> </ul> </li> <li>(212) Docker Tutorial for Beginners [FULL COURSE in 3 Hours] - YouTube</li> <li>Docker Internals -- Docker Saigon<ul> <li>Lifecycle of Docker Container</li> </ul> </li> <li>Dockerfile reference | Docker Documentation<ul> <li>Best practices for writing Dockerfiles<ul> <li>How to write excellent Dockerfiles</li> </ul> </li> <li>Docker CMD \u8207 ENTRYPOINT \u8aaa\u660e\u8a73\u89e3</li> <li>Understand CMD and ENTRYPOINT Differences in Docker<ul> <li>the executable is defined with ENTRYPOINT, while CMD specifies the default parameter.<ul> <li>If you are using both instructions, make sure to keep them in exec form.</li> </ul> </li> </ul> </li> <li>dockerfile - Why should I use docker ONBUILD? - Stack Overflow</li> <li>[Docker] Health Check and Restart Unhealthy Container | wshs0713's blog</li> </ul> </li> <li>What is the difference between a process, a container, and a VM</li> <li>dockerd | Docker Docs</li> <li>\u7528\u7db2\u9801\u5716\u5f62\u5316\u754c\u9762\u7ba1\u7406Docker\u5bb9\u5668 \\~ Portainer\u5b89\u88dd\u6559\u5b78\uff0c\u4e00\u9375\u555f\u52d5docker-compose\u3001\u7ba1\u7406image \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>Docker \u547d\u4ee4\u884c\u5c0f\u6280\u5de7\uff1arunlike | \u5361\u74e6\u90a6\u5676\uff01</li> <li>Python \u65b0\u624b\u7b46\u8a18 - \u7528 Docker \u8dd1 Python \u7db2\u7ad9-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>HTTPS Nginx Docker \u4e4b\u61f6\u4eba\u5b89\u88dd\u6cd5-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>Labs<ul> <li>:star:\u90a3\u4e9b\u95dc\u65bc docker \u4f60\u77e5\u9053\u8207\u4e0d\u77e5\u9053\u7684\u4e8b :: 2022 iThome \u9435\u4eba\u8cfd<ul> <li>Docker (\u5bb9\u5668) \u7684\u539f\u7406 | \u5361\u74e6\u90a6\u5676\uff01</li> <li>:star:Docker \u955c\u50cf\u6784\u5efa\u7684\u4e00\u4e9b\u6280\u5de7 | \u5361\u74e6\u90a6\u5676\uff01<ul> <li>GitHub - wagoodman/dive: A tool for exploring each layer in a docker image</li> </ul> </li> </ul> </li> <li>Welcome to Docker Labs</li> <li>Play with Docker Classroom</li> <li>Docker Compose 101 Labs</li> </ul> </li> <li>error<ul> <li>docker.errors.DockerException: Error while fetching server API version</li> </ul> </li> <li>registry<ul> <li>\u900f\u904e Harbor \u5efa\u5236\u81ea\u5df1\u7684 Docker Registry + \u6c38\u4e45\u6191\u8b49\u66f4\u65b0</li> </ul> </li> <li>How to keep Docker container running after starting services</li> <li>Docker container will automatically stop after \"docker run -d\"</li> <li>Environment variables in Python &amp; Docker</li> <li>How to set up separate .env for development and production using Docker</li> <li>How to use the same dockerfile for dev and prod</li> <li>GitHub - wsargent/docker-cheat-sheet: Docker Cheat Sheet</li> <li>Docker Container \u57fa\u790e\u5165\u9580\u7bc7 1. \u7334\u5b50\u4e5f\u6703\u7684 Docker\uff0c\u4f46\u7334\u5b50\u4e26\u4e0d\u60f3\u6703\u3002 | by Azole (\u5c0f\u8cf4) | Medium</li> <li>Distrobox<ul> <li>\u6211\u5168\u90fd\u8981\uff01Distrobox\u4f7f\u7528\u6559\u5b78\uff0c\u900f\u904e\u5bb9\u5668\u5b89\u88dd\u5176\u4ed6Linux\u767c\u884c\u7248\u7684\u5957\u4ef6 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>\u900f\u904e Distrobox \u89e3\u6c7a Linux \u74b0\u5883\u4f9d\u8cf4\u554f\u984c | omegaatt</li> <li>Never Install Locally\uff1f\u8a66\u8a66 Dev Container | omegaatt</li> </ul> </li> <li>debug<ul> <li>5 ways to debug an exploding Docker container | by Tim Perry | Medium</li> <li>What does docker container exit status 255 mean? - Stack Overflow</li> <li>Running docker compose up -d (strconv.Atoi: parsing \"\": invalid syntax) \u00b7 Issue #1537 \u00b7 docker/compose-cli \u00b7 GitHub</li> </ul> </li> <li>systemctl<ul> <li>Systemd fails to run in a docker container when using cgroupv2 (--cgroupns=private) - Server Fault</li> <li>How to run systemd in a container | Red Hat Developer<ul> <li>Systemd vs. Docker [LWN.net]</li> </ul> </li> <li>Docker and systemd | The Startup</li> <li>docker\u4e2d\u5355\u5bb9\u5668\u5f00\u542f\u591a\u670d\u52a1\u65f6systemctl\u5f15\u53d1\u7684\u8840\u6848\u53ca\u7834\u6848\u8fc7\u7a0b - \u77e5\u4e4e</li> <li>centos - failed to get D-Bus connection: Operation not permitted - Server Fault</li> <li>Systemd integration</li> <li>\u6e21\u9d09\u4e4b\u4e18: \u5728 docker container \u88e1\u9762\u57f7\u884c systemd \u670d\u52d9\uff08\u6e2c\u8a66\u74b0\u5883\u7528\uff5e\uff09</li> <li>Docker\u5bb9\u5668\u51fa\u73b0\u4f7f\u7528systemctl\u95ee\u9898\uff1aFailed to get D-Bus connection: Operation not permitted \u00b7 \u6d69\u7ff0Redamancy\u7684\u535a\u5ba2</li> <li>Is it recommended to run systemd inside docker container? - Stack Overflow</li> <li>linux - Docker with systemd and systemctl - Super User</li> <li>systemd - Run systemctl inside docker container - Ask Ubuntu</li> <li>https://chatgpt.com/share/6814872e-1b40-8009-9e0f-f75edc8ad2ec</li> </ul> </li> <li>cap_add<ul> <li>mknod: /dev/net/tun: Operation not permitted \u00b7 Issue #498 \u00b7 kylemanna/docker-openvpn \u00b7 GitHub</li> <li>\u70ba\u4f55\u5728 Docker \u4e2d\u57f7\u884c\u7279\u6b0a\u5bb9\u5668\u4e0d\u662f\u500b\u597d\u4e3b\u610f? \u2013 \u8cc7\u5b89\u8da8\u52e2\u90e8\u843d\u683c</li> </ul> </li> <li>High Availability<ul> <li>Building a High Availability Cluster with HAProxy, Keepalived, and Docker: A Step-by-Step Guide | by Yahya sghiouri | Medium</li> </ul> </li> <li>firewall<ul> <li>Packet filtering and firewalls | Docker Docs</li> <li>How to configure your firewall<ul> <li>LXD and Docker Firewall Redux - How to deal with FORWARD policy set to drop - LXD - Linux Containers Forum</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Docker/#build","title":"build","text":"<ul> <li>Capture ouput of docker build into a log file? - General Discussions - Docker Community Forums</li> </ul> <pre><code>docker build --no-cache --progress=plain . 2&gt;&amp;1 | tee build.log\n</code></pre>"},{"location":"hackmd/Docker/#multi-stage-builds","title":"multi-stage builds","text":"<ul> <li>Docker multi-stage builds \u6559\u5b78 - MyApollo</li> <li>\u900f\u904e Multiple Stage Builds \u7de8\u8b6f\u51fa\u6700\u5c0f\u7684 Docker Image</li> <li>\u900f\u904e Multi-Stage Builds \u6539\u5584\u6301\u7e8c\u4ea4\u4ed8\u6d41\u7a0b</li> </ul>"},{"location":"hackmd/Docker/#container","title":"container","text":"<pre><code>docker container prune\n</code></pre>"},{"location":"hackmd/Docker/#_1","title":"\u5bb9\u5668\u8207\u8a0a\u865f","text":"<ul> <li>\u57f7\u884c Docker \u5bb9\u5668\u53ef\u4f7f\u7528 dumb-init \u6216 tini \u6539\u5584\u7a0b\u5e8f\u512a\u96c5\u7d50\u675f\u7684\u554f\u984c | The Will Will Web</li> </ul> <p>\u7576\u4f60\u5728\u57f7\u884c Docker \u5bb9\u5668\u6642\uff0c\u4e3b\u8981\u57f7\u884c\u7a0b\u5e8f(Process)\u7684 PID \u5c07\u6703\u662f 1\uff0c\u53ea\u8981\u9019\u500b\u7a0b\u5e8f\u505c\u6b62\uff0c\u5bb9\u5668\u5c31\u6703\u8ddf\u8457\u505c\u6b62\u3002</p> <p>\u4ee5 docker stop \u70ba\u4f8b\uff0c\u9019\u500b\u547d\u4ee4\u5be6\u8cea\u4e0a\u662f\u5c0d\u5bb9\u5668\u4e2d\u7684 PID 1 \u9001\u51fa\u4e00\u500b SIGTERM \u8a0a\u865f\uff0c\u5982\u679c\u7a0b\u5e8f\u672c\u8eab\u4e26\u6c92\u6709\u8655\u7406 Signal \u7684\u6a5f\u5236\uff0c\u5c31\u6703\u76f4\u63a5\u5ffd\u7565\u9019\u985e\u8a0a\u865f\uff0c\u9019\u5c31\u6703\u5c0e\u81f4 docker stop \u7b49\u4e86 10 \u79d2\u4e4b\u5f8c\u9084\u4e0d\u7d50\u675f\uff0c\u7136\u5f8c Docker Engine \u53c8\u6703\u5c0d PID 1 \u9001\u51fa\u53e6\u4e00\u500b SIGKILL \u8a0a\u865f\uff0c\u8a66\u5716\u5f37\u8feb\u780d\u6389\u9019\u500b\u7a0b\u5e8f\uff0c\u9019\u624d\u6703\u8b93\u5bb9\u5668\u5fb9\u5e95\u505c\u4e0b\u4f86\u3002</p>"},{"location":"hackmd/Docker/#mknod","title":"mknod","text":"<ul> <li>linux - Error running mknod within buildah - Server Fault</li> </ul>"},{"location":"hackmd/Docker/#systemd-inside-the-docker-container","title":"systemd inside the docker container","text":"<p>That being said, there are also lots of reasons not to run systemd in containers. The main one is that systemd/journald controls the output of containers, whereas tools like Kubernetes and OpenShift expect the containers to log directly to stdout and stderr. So, if you are going to manage your containers via Orchestrator like these, then you should think twice about using systemd-based containers. Additionally, the upstream community of Docker and Moby were often hostile to the use of systemd in a container.  How to run systemd in a container | Red Hat Developer</p> <p>It is generally recommended that you separate areas of concern by using one service per container.   That service may fork into multiple processes (for example, Apache web server starts multiple worker processes).   It\u2019s ok to have multiple processes - Run multiple services in a container | Docker Documentation</p> <p>If your process falls into this category, you can use the --init option when you run the container. The --init flag inserts a tiny init-process into the container as the main process, and handles reaping of all processes when the container exits.  Handling such processes this way is superior to using a full-fledged init process such as sysvinit, upstart, or systemd to handle process lifecycle within your container.</p> <p>for example nginx</p> <pre><code>root@2b8cf1261323:/# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   8932  5708 ?        Ss   08:55   0:00 nginx: master process nginx -g daemon off;\nnginx         29  0.0  0.0   9320  2668 ?        S    08:55   0:00 nginx: worker process\nnginx         30  0.0  0.0   9320  2668 ?        S    08:55   0:00 nginx: worker process\nnginx         31  0.0  0.0   9320  2668 ?        S    08:55   0:00 nginx: worker process\nnginx         32  0.0  0.0   9320  2668 ?        S    08:55   0:00 nginx: worker process\nroot          33  0.0  0.0   4164  3580 pts/0    Ss   08:56   0:00 bash\nroot         383  0.0  0.0   6760  3076 pts/0    R+   08:58   0:00 ps aux\n</code></pre> <p>for example ubuntu</p> <pre><code>upermicro@supermicro-Virtual-Machine:~/srccode/dockerize-xcat$ docker run ubuntu bash -c 'ps aux'\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   7060  1548 ?        Rs   09:03   0:00 ps aux\n</code></pre> <p>for example redis</p> <pre><code>root@dc49d0761c3f:/data# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nredis          1  0.1  0.1  53676 13532 ?        Ssl  09:05   0:00 redis-server *:6379\nroot          34  0.0  0.0   4156  3484 pts/0    Ss   09:05   0:00 bash\nroot         855  0.0  0.0   6760  3008 pts/0    R+   09:10   0:00 ps aux\nroot@dc49d0761c3f:/data# cat /etc/issue\nDebian GNU/Linux 11 \\n \\l\n</code></pre>"},{"location":"hackmd/Docker/#image","title":"image","text":"<pre><code>docker image prune\n</code></pre> <pre><code>docker image ls | awk 'NR&gt;1 {print $1\":\"$2}' | xargs -I {} sh -c 'echo \"Inspecting image: {}\"; docker image inspect {}\n</code></pre>"},{"location":"hackmd/Docker/#save-and-load","title":"save and load","text":"<ul> <li>docker image save | Docker Docs</li> <li>docker image load | Docker Docs</li> <li>\u628aimage\u53e6\u5916\u5132\u5b58\u6210\u6a94\u6848 \u00b7 Docker\u5b78\u7fd2\u7b46\u8a18</li> <li>\u4f7f\u7528 save / export \u5206\u4eab image - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul>"},{"location":"hackmd/Docker/#network","title":"network","text":"<ul> <li>From inside of a Docker container, how do I connect to the localhost of the machine?</li> <li>Docker Container \u57fa\u790e\u5165\u9580\u7bc7 2. \u4e0d\u7576\u908a\u7de3\u4eba\u7684 container | by Azole (\u5c0f\u8cf4) | Medium</li> <li>Docker networking is CRAZY!! (you NEED to learn it) - YouTube</li> <li>under the hood<ul> <li>Docker Network - \u7db2\u8def\u6a21\u578b | Hwchiu Learning Note</li> <li>Docker \u7db2\u8def\u5165\u9580\u7bc7(\u4e8c) - Bridge \u7db2\u8def\u6a21\u578b | Hwchiu Learning Note</li> <li>Docker \u7db2\u8def\u5165\u9580\u7bc7(\u4e09) - \u7db2\u8def\u5b58\u53d6\u5206\u6790 | Hwchiu Learning Note</li> <li>Docker \u7db2\u8def\u5165\u9580\u7bc7(\u56db) - \u5916\u754c\u4e3b\u52d5\u5b58\u53d6 | Hwchiu Learning Note</li> </ul> </li> <li>Ubuntu<ul> <li>networking - No network access from within Docker container - Ask Ubuntu<ul> <li>Favoring \"iptables-legacy\" on Debian Sid causes iptables rules inconsistency \u00b7 Issue #2331 \u00b7 moby/libnetwork</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Docker/#host","title":"host","text":"<ul> <li>Use host networking | Docker Documentation</li> <li>Networking using the host network | Docker Documentation if you use the host network mode for a container, that container\u2019s network stack is not isolated from the Docker host (the container shares the host\u2019s networking namespace), and the container does not get its own IP-address allocated. </li> </ul>"},{"location":"hackmd/Docker/#port","title":"port","text":"<ul> <li>port - What is the difference between \"expose\" and \"publish\" in Docker? - Stack Overflow</li> </ul>"},{"location":"hackmd/Docker/#env-arg","title":"env, arg","text":"<ul> <li>How to set up separate .env for development and production using Docker</li> <li>Pass argument to docker compose</li> <li>\u6d3b\u7528 ENV \u8207 ARG</li> <li>How to define build-args in docker-compose?</li> </ul>"},{"location":"hackmd/Docker/#permission","title":"permission","text":"<ul> <li>Fixing permissions issues with Docker Compose and PHP</li> </ul>"},{"location":"hackmd/Docker/#volume","title":"volume","text":"<ul> <li>Docker Compose: volumes without colon (:) - Stack Overflow<ul> <li>anonymous volume</li> </ul> </li> </ul> <pre><code>/var/lib/docker/volumes\n</code></pre> <pre><code>docker volume ls\n</code></pre> <p>volume propagation behavior <pre><code>#!/bin/bash\n\n\nsudo ls -la /var/lib/docker/volumes/ng-vol/_data\n\n\n# run a container which creates a new volume\ndocker volume rm ng-vol\ndocker run -d --name nginx1 --mount source=ng-vol,target=/usr/share/nginx/html nginx\ndocker exec nginx1 ls -la /usr/share/nginx/html\ndocker exec nginx1 ls -la /app\ndocker exec nginx1 touch /usr/share/nginx/html/abc.html\nsudo ls -la /var/lib/docker/volumes/ng-vol/_data\n\n\n# /app not exist\ndocker run -d --name nginx2 --mount source=ng-vol,target=/app nginx\ndocker exec nginx2 ls -la /app\nsudo ls -la /var/lib/docker/volumes/ng-vol/_data\n\n\n# mount a non-empty volume into a directory in the container in which some files or directories exist, \n# these files or directories are obscured by the mount\ndocker run -d --name nginx3 --mount source=ng-vol,target=/usr/share/nginx/html nginx\ndocker exec nginx3 ls -la /usr/share/nginx/html\nsudo ls -la /var/lib/docker/volumes/ng-vol/_data\n\n\n# A given volume can be mounted into multiple containers simultaneously\n\n\n# create file in a container and show in another container\ndocker exec nginx3 touch /usr/share/nginx/html/ng3-abc.html\ndocker exec nginx2 ls -la /app\nsudo ls -la /var/lib/docker/volumes/ng-vol/_data\n\n\ndocker stop nginx1 nginx2 nginx3\ndocker rm nginx1 nginx2 nginx3\ndocker volume rm ng-vol\n</code></pre></p>"},{"location":"hackmd/Docker/#docker-compose","title":"docker compose","text":"<ul> <li>Compose specification | Docker Documentation</li> <li>Compose V2 Overview | Docker Documentation<ul> <li>Announcing Compose V2 General Availability | Docker<ul> <li>&gt;=  v20.10.13</li> </ul> </li> </ul> </li> <li>Reuse image built by one service in another service</li> <li>How to view log output using docker-compose run?</li> <li>Environment variables in Compose</li> <li>How to tag docker image with docker-compose</li> <li>docker-compose up for only certain containers</li> <li>Docker-compose exclude service by default - Stack Overflow</li> <li>\u4f7f\u7528 Docker Compose \u5efa\u7acb\u4f60\u81ea\u5df1\u7684\u5f00\u53d1\u73af\u5883 - \u54b8\u7cd6 - \u81ea\u5f8b\u8005\u81ea\u7531</li> <li>3 \u500b\u4f7f\u7528 docker compose \u7684\u5fc5\u5099\u6307\u4ee4 - MyApollo</li> <li>\u8ac7 docker compose \u7684 depends_on \u8a2d\u5b9a\u600e\u9ebc\u4f7f\u7528 - MyApollo</li> <li>Why docker-compose down deletes my volume? how to avoid this action done by 'down'. (Postgresql) - Stack Overflow</li> </ul> <p>``` docker= version: \"3\" services:   redis:     container_name: \"project-name-redis\"     image: \"redis:3.2.4-alpine\"     ports:       - \"6379:6379\"   mariadb:     container_name: \"project-name-config-db\"     image: \"mariadb:10.4\"     ports:       - \"3306:3306\"     environment:       MYSQL_ROOT_PASSWORD: example       MYSQL_DATABASE: project_name_alpha_0706       MYSQL_USER: project       MYSQL_PASSWORD: project     volumes:       - ./mariadb:/docker-entrypoint-initdb.d     command: ['mysqld', '--character-set-server=utf8', '--collation-server=utf8_general_ci']   elasticsearch:     container_name: \"project-name-es\"     image: \"docker.elastic.co/elasticsearch/elasticsearch:6.8.18\"     ports:       - \"127.0.0.1:9200:9200\"       - \"127.0.0.1:9300:9300\"     environment:       discovery.type: single-node   kibana:     image: \"docker.elastic.co/kibana/kibana:6.8.18\"     container_name: \"project-name-kibana\"     environment:       SERVER_NAME: kibana-server       ELASTICSEARCH_URL: http://elasticsearch:9200     depends_on:       - elasticsearch     ports:       - \"127.0.0.1:5601:5601\" <pre><code>There is a file such as init.sql in mariadb directory\n``` sql=\nGRANT ALL PRIVILEGES ON *.* TO 'project'@'%';\nCREATE DATABASE  IF NOT EXISTS `project_name_alpha_0706`;\nUSE `project_name_alpha_0706`;\n</code></pre></p>"},{"location":"hackmd/Docker/#build_1","title":"build","text":"<p>Build subsection is present for a service, it is valid for a Compose file to miss an Image attribute for corresponding service, as Compose implementation can build image from source. Compose file build reference | Docker Documentation</p>"},{"location":"hackmd/Docker/#networks","title":"networks","text":"<ul> <li>docker compose network\u7c21\u4ecb\u548c\u8a2d\u5b9a\u56fa\u5b9aip - Hjoru's sharing - Medium</li> </ul>"},{"location":"hackmd/Docker/#multiple-compose-files","title":"multiple compose files","text":"<ul> <li>Use multiple Compose files | Docker Docs<ul> <li>Extend | Docker Docs</li> <li>Include | Docker Docs</li> </ul> </li> <li>Docker Compose Modularity with `include` | Docker</li> </ul>"},{"location":"hackmd/Docker/#healthcheck","title":"healthcheck","text":"<ul> <li>How To Perform A Health Check In Docker Compose | Warp</li> <li>Docker HEALTHCHECK\u5065\u5eb7\u68c0\u67e5\u53ca\u6ce8\u610f\u4e8b\u9879 | \u80e1\u6587\u5cf0\u7684\u535a\u5ba2</li> </ul>"},{"location":"hackmd/Docker/#mysql","title":"mysql","text":"<ul> <li>File in docker-entrypoint-initdb.d never get executed when using docker compose<ul> <li>docker-compose rm</li> </ul> </li> <li>[\u5be6\u4f5c\u7b46\u8a18] \u4f7f\u7528 Docker \u4e00\u9375\u751f\u6210 Sample \u8cc7\u6599\u5eab | Marsen's Blog</li> </ul>"},{"location":"hackmd/Docker/#awesome-image","title":"awesome image","text":""},{"location":"hackmd/Docker/#sameersbnbind-docker-image-docker-hub","title":"sameersbn/bind - Docker Image | Docker Hub","text":"<pre><code>version: '3.5'\n\nservices:\n  bind9:\n    image: sameersbn/bind:latest\n    ports:\n    - \"53:53/udp\"\n    - \"53:53/tcp\"\n    - \"10000:10000\"\n    volumes:\n    - ./docker_data:/data\n    restart: always\n</code></pre>"},{"location":"hackmd/Docker/#sonatypenexus3-docker-image-docker-hub","title":"sonatype/nexus3 - Docker Image | Docker Hub","text":"<ul> <li>\u4f7f\u7528 Docker \u5efa\u7acb Nexus3 \u7684 Image Registry - Yowko's Notes</li> </ul> <p>Use a docker volume <pre><code>services:\n  nexus:\n    image: sonatype/nexus3\n    container_name: nexus\n    ports:\n      - \"8081:8081\"\n      # https://blog.yowko.com/nexus-docker-image-rergistry/\n      - \"8082:8082\"\n    volumes:\n      - nexus-data:/nexus-data\n\nvolumes:\n  nexus-data:\n    name: nexus-data\n</code></pre></p> <p>Mount a host directory as the volume. <pre><code>version: \"3.9\"\nservices:\n  nexus:\n    image: sonatype/nexus3\n    ports:\n    - \"8081:8081\"\n    # https://blog.yowko.com/nexus-docker-image-rergistry/\n    - \"8082:8082\"\n    volumes:\n    - ./host-nexus-data:/nexus-data\n    restart: always\n</code></pre></p>"},{"location":"hackmd/Docker/#run-docker-container-dbeavercloudbeaver-wiki-github","title":"Run Docker Container \u00b7 dbeaver/cloudbeaver Wiki \u00b7 GitHub","text":"<p>for quick test and the volume will be removed after stop <pre><code>docker run --name cloudbeaver --rm -ti -p 9090:8978 -v /opt/cloudbeaver/workspace dbeaver/cloudbeaver:latest\n</code></pre></p> <pre><code>version: \"3.9\"\nservices:\n  cloudbeaver:\n    image: dbeaver/cloudbeaver:latest\n    ports:\n    - \"9527:8978\"\n    volumes:\n    - cloudbeaver-data:/opt/cloudbeaver/workspace\n    restart: always\nvolumes:\n  cloudbeaver-data:\n</code></pre>"},{"location":"hackmd/Docker/#github-mermaid-jsmermaid-live-editor-edit-preview-and-share-mermaid-chartsdiagrams-new-implementation-of-the-live-editor","title":"GitHub - mermaid-js/mermaid-live-editor: Edit, preview and share mermaid charts/diagrams. New implementation of the live editor.","text":"<p>quick test <pre><code>docker run --name mermaid-live-editor --platform linux/amd64 -d --rm --publish 3000:8080 ghcr.io/mermaid-js/mermaid-live-editor\n</code></pre></p> <pre><code>git clone https://github.com/mermaid-js/mermaid-live-editor.git\ncd mermaid-live-editor\ndocker compose up -d\n</code></pre>"},{"location":"hackmd/Docker/#dockermrbs-it","title":"docker\u5b89\u88dd\u8001\u724c\u300c\u6703\u8b70\u5ba4\u9810\u7d04\u7cfb\u7d71(MRBS)\u300d - \u5496\u5561\u5076-IT\u65e5\u5e38","text":""},{"location":"hackmd/Docker/#github-aquasecuritytrivy-find-vulnerabilities-misconfigurations-secrets-sbom-in-containers-kubernetes-code-repositories-clouds-and-more","title":"GitHub - aquasecurity/trivy: Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more","text":"<pre><code>docker run aquasec/trivy image 3x3cut0r/tftpd-hpa\n</code></pre>"},{"location":"hackmd/Docker/#tftp-and-dhcp-for-pxe","title":"TFTP and DHCP for PXE","text":"<pre><code>- [3x3cut0r/isc-dhcp-server - Docker Image | Docker Hub](https://hub.docker.com/r/3x3cut0r/isc-dhcp-server)\n- [3x3cut0r/tftpd-hpa - Docker Image | Docker Hub](https://hub.docker.com/r/3x3cut0r/tftpd-hpa)\n</code></pre> <pre><code>version: '3.9'\n\nservices:\n  tftpd-hpa:\n    image: 3x3cut0r/tftpd-hpa\n    environment:\n        CREATE: 1\n        VERBOSE: 1\n    volumes:\n      - /tftpboot:/tftpboot\n    ports:\n      - 69:69/udp\n\n  isc-dhcp-server:\n    image: 3x3cut0r/isc-dhcp-server:latest\n    environment:\n        IFACE: \"ens160 ens256\"\n        PROTOCOL: 4\n    volumes:\n        - /etc/dhcp/dhcpd.conf:/etc/dhcp/dhcpd.conf\n    network_mode: host\n</code></pre>"},{"location":"hackmd/Docker/#github-cturradocker-ntp-chrony-ntp-server-running-in-a-docker-container-without-the-priviledged-flag","title":"GitHub - cturra/docker-ntp: \ud83d\udd52 Chrony NTP Server running in a Docker container (without the priviledged flag)","text":""},{"location":"hackmd/Docker/#httpd","title":"httpd","text":"<ul> <li>https://hub.docker.com/_/httpd</li> <li>Apache 403 Forbidden Error and Solution - nixCraft<ul> <li>permission<ul> <li>directory: 755</li> <li>file: 644</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Docker/#basic","title":"basic","text":"<pre><code>docker run -dit --name my-apache-app -p 8080:80 -v \"$PWD\":/usr/local/apache2/htdocs/ httpd:2.4\n\n# alpine\ndocker run -dit --name my-apache-app -p 8080:80 -v \"$PWD\":/usr/local/apache2/htdocs/ httpd:alpine\n</code></pre>"},{"location":"hackmd/Docker/#ssl-enable","title":"SSL enable","text":"<pre><code>openssl req -x509 -newkey rsa:4096 -sha256 -nodes -keyout server.key -out server.crt -days 30\n\ndocker run --rm httpd:2.4 cat /usr/local/apache2/conf/httpd.conf &gt; my-httpd.conf\nsed -i \\\n        -e 's/^#\\(Include .*httpd-ssl.conf\\)/\\1/' \\\n        -e 's/^#\\(LoadModule .*mod_ssl.so\\)/\\1/' \\\n        -e 's/^#\\(LoadModule .*mod_socache_shmcb.so\\)/\\1/' \\\n        conf/my-httpd.conf\n</code></pre> <pre><code>docker run -dit --name my-apache-app \\\n-p 8080:80 -p 443:443 \\\n-v \"$PWD\":/usr/local/apache2/htdocs/ \\\n-v \"$PWD\"/config/server.key:/usr/local/apache2/conf/server.key \\\n-v \"$PWD\"/config/server.crt:/usr/local/apache2/conf/server.crt \\\n-v \"$PWD\"/config/my-httpd.conf:/usr/local/apache2/conf/httpd.conf \\\nhttpd:alpine\n</code></pre>"},{"location":"hackmd/Docker/#nginx","title":"nginx","text":"<ul> <li>\u4f7f\u7528 Docker \u7248 Nginx \u5efa\u7acb\u975c\u614b\u9801\u9762\u7db2\u7ad9 - Yowko's Notes</li> <li>Docker \u4e00\u5206\u9418\u5b8c\u6210\u81ea\u52d5\u66f4\u65b0 SSL \u8a3c\u66f8\u7684 nginx-proxy \u8a2d\u7f6e | by Edmond Y. | HKIT DOG | Medium</li> </ul>"},{"location":"hackmd/Docker/#basic_1","title":"basic","text":"<pre><code>docker run --name some-nginx -p 8088:80 -v \"$PWD\"/test_html:/usr/share/nginx/html:ro -d nginx\n\n# alpine\ndocker run --name some-nginx -p 8088:80 -v \"$PWD\"/test_html:/usr/share/nginx/html:ro -d nginx:stable-alpine-slim\n</code></pre>"},{"location":"hackmd/Docker/#auto-index","title":"auto index","text":"<ul> <li>Apache-like directory listing fallback in Nginx - Server Fault</li> </ul> <p>:::info autoindex on; :::</p> <p>nginx_auto_index.conf <pre><code>server {\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n\n    #access_log  /var/log/nginx/host.access.log  main;\n\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n        autoindex on;\n    }\n\n    #error_page  404              /404.html;\n\n    # redirect server error pages to the static page /50x.html\n    #\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n\n    # proxy the PHP scripts to Apache listening on 127.0.0.1:80\n    #\n    #location ~ \\.php$ {\n    #    proxy_pass   http://127.0.0.1;\n    #}\n\n    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n    #\n    #location ~ \\.php$ {\n    #    root           html;\n    #    fastcgi_pass   127.0.0.1:9000;\n    #    fastcgi_index  index.php;\n    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n    #    include        fastcgi_params;\n    #}\n\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    #location ~ /\\.ht {\n    #    deny  all;\n    #}\n}\n</code></pre></p> <pre><code>docker run --name some-nginx -p 8088:80 -v \"$PWD\"/test_html/config/nginx_auto_index.conf:/etc/nginx/conf.d/default.conf:ro -v \"$PWD\"/test_html:/usr/share/nginx/html:ro -d nginx:stable-alpine-slim\n</code></pre>"},{"location":"hackmd/Docker/#ssl-enable_1","title":"SSL enable","text":"<ul> <li>Day 11 \u5229\u7528 docker \u5b89\u88dd nginx \u4e26\u914d\u7f6e https - iT \u90a6\u5e6b\u5fd9</li> <li>HTTPS Nginx Docker \u4e4b\u61f6\u4eba\u5b89\u88dd\u6cd5-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u7528Nginx\u67b6\u8a2dlocal\u7aefhttps\u61c9\u7528 - HackMD</li> </ul> <p>:::info listen 443 ssl; :::</p> <p>:::info ssl_certificate cert/server.crt; ssl_certificate_key cert/server.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; :::</p> <p>nginx_ssl_enable.conf <pre><code>server {\n    listen       80;\n    listen  [::]:80;\n    listen 443 ssl;\n\n    ssl_certificate cert/server.crt;\n    ssl_certificate_key cert/server.key;\n    ssl_session_timeout 5m;\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;\n    ssl_prefer_server_ciphers on;\n\n    server_name  localhost;\n\n    #access_log  /var/log/nginx/host.access.log  main;\n\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n        autoindex on;\n    }\n\n    #error_page  404              /404.html;\n\n    # redirect server error pages to the static page /50x.html\n    #\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n\n    # proxy the PHP scripts to Apache listening on 127.0.0.1:80\n    #\n    #location ~ \\.php$ {\n    #    proxy_pass   http://127.0.0.1;\n    #}\n\n    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n    #\n    #location ~ \\.php$ {\n    #    root           html;\n    #    fastcgi_pass   127.0.0.1:9000;\n    #    fastcgi_index  index.php;\n    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n    #    include        fastcgi_params;\n    #}\n\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    #location ~ /\\.ht {\n    #    deny  all;\n    #}\n}\n</code></pre></p> <pre><code>docker run --name some-nginx -p 8088:80 -p 443:443 -v \"$PWD\"/test_html/config/nginx_ssl_enable.conf:/etc/nginx/conf.d/default.conf:ro -v \"$PWD\"/cert:/etc/nginx/cert:ro -v \"$PWD\"/test_html:/usr/share/nginx/html:ro -d nginx:stable-alpine-slim\n</code></pre>"},{"location":"hackmd/Docker/#github-semaphoreuisemaphore-modern-ui-and-powerful-api-for-ansible-terraform-opentofu-powershell-and-other-devops-tools","title":"GitHub - semaphoreui/semaphore: Modern UI and powerful API for Ansible, Terraform, OpenTofu, PowerShell and other DevOps tools.","text":""},{"location":"hackmd/Docker/#github-rundeckrundeck-enable-self-service-operations-give-specific-users-access-to-your-existing-tools-services-and-scripts","title":"GitHub - rundeck/rundeck: Enable Self-Service Operations: Give specific users access to your existing tools, services, and scripts","text":"<p>install <pre><code>docker run --name rundeck-demo -d \\\n  -p 4440:4440 \\\n  -v rundeck-data:/home/rundeck/server/data \\\n  -e RUNDECK_GRAILS_URL=http://172.19.57.10:4440 \\\n  rundeck/rundeck:5.11.1\n\n# access http://172.19.57.10:4440/ with admin/admin\n</code></pre></p> <p>install with Welcom project <pre><code>wget https://github.com/rundeck/welcome-project-community/archive/refs/heads/main.zip &amp;&amp; unzip main.zip\ncd welcome-project-community-main/\n# modify RUNDECK_GRAILS_URL and ciao port if 3000 is used\n# RUNDECK_GRAILS_URL: http://172.19.57.10:4440\n# ciao:\n#         container_name: ciao\n#         image: brotandgames/ciao\n#         ports:\n#           - '3001:3000'\ndocker compose up -d\n</code></pre></p>"},{"location":"hackmd/Docker/#offiline-install","title":"offiline install","text":"<ul> <li>Install Docker offline | Cyberwatch Documentation<ul> <li>`Index of linux/ubuntu/dists/jammy/pool/stable/amd64/</li> </ul> </li> <li>Linux Ubuntu\u96e2\u7dda\u5b89\u88ddDocker. \u6b65\u9a5f1\u20131\uff1a\u6e96\u5099Docker\u96e2\u7dda\u5b89\u88dd\u5305\u3002 | by Wilson Lee | Medium<ul> <li>Index of linux/static/stable/x86_64/`</li> </ul> </li> </ul> <pre><code># Ubuntu 22 offiline docker installation\nwget https://download.docker.com/linux/ubuntu/dists/jammy/pool/stable/amd64/docker-ce_26.1.1-1~ubuntu.22.04~jammy_amd64.deb\nwget https://download.docker.com/linux/ubuntu/dists/jammy/pool/stable/amd64/containerd.io_1.6.31-1_amd64.deb\nwget https://download.docker.com/linux/ubuntu/dists/jammy/pool/stable/amd64/docker-ce-cli_26.1.1-1~ubuntu.22.04~jammy_amd64.deb\nsudo dpkg -i *.deb\n</code></pre>"},{"location":"hackmd/Docker/#mtu","title":"MTU","text":"<ul> <li>Docker MTU issues and solutions - Matthias Lohr</li> <li>Fixing Docker's MTU Issues on Ubuntu - Civo.com</li> <li>How we spent a full day figuring out a MTU issue with docker | by Sylvain Witmeyer | Medium</li> <li>\u865a\u62df\u7f51\u7edc\u73af\u5883\u4e2d Docker MTU \u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u5f0f - ZengXu's BLOG</li> <li>Docker in Docker (DIND) MTU fix for docker-compose</li> </ul>"},{"location":"hackmd/Docker/#for-docker-default-bridge","title":"for docker default bridge","text":"<pre><code>/lib/systemd/system/docker.service\n/etc/docker/daemon.json\n\nsudo systemctl daemon-reload\nsudo systemctl restart docker.service\n</code></pre> <p>/etc/docker/daemon.json <pre><code>{ \"mtu\": 1400 }\n</code></pre></p>"},{"location":"hackmd/Docker/#for-docker-compose","title":"for docker compose","text":"<p>docker-compose.yml</p> <pre><code>networks:\n  default:\n    driver: bridge\n    driver_opts:\n      com.docker.network.driver.mtu: 1400\n</code></pre>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/","title":"DynamoDB Deep Dive Advence Design","text":"<ul> <li>[Zyxel] Amazon DynamoDB hands-on training</li> <li>Hands-on Labs for Amazon DynamoDB<ul> <li>Modeling Game Player Data with Amazon DynamoDB</li> </ul> </li> </ul> <p>from 2004 amazon.com outage</p>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#_1","title":"\u5be6\u969b\u4f7f\u7528\u6848\u4f8b","text":"<ul> <li>amazon.com</li> <li>disney+</li> <li>netflix</li> <li>dropbox</li> <li>pokemon company</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#under-the-hood","title":"Under the hood","text":"<ul> <li>partition 10GB\u505a\u4e00\u6b21\u5207\u5272</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#data-model","title":"data model","text":"<ul> <li>different concept from Relational DB</li> <li>NoSQL Workbench</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#features","title":"features","text":"<ul> <li>Dynamodb stream(item-level change log) for events</li> <li>TTL</li> <li>transcation</li> <li>Point-in-time recovery (PITR)</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#detail-description","title":"Detail Description","text":"<ul> <li>partion key best practice</li> <li>Secondary Index</li> <li>\u4e8b\u524d\u5c31\u60f3\u5230 =&gt; LSI</li> <li>\u4e8b\u5f8c\u624d\u60f3\u52a0Index =&gt; GSI</li> <li>Fine-Grain Access Control</li> <li>IAM</li> <li>horizontal</li> <li>vertical</li> <li>Memory Cache</li> <li>DAX</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#scenario","title":"Scenario","text":"<ul> <li>building and maintaing an S3 metadata</li> <li>users buy products in online retail shops</li> <li>aggration for raw records</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#amazon-dynamo-db-nosql-designs-and-best-praction","title":"Amazon Dynamo DB NoSQL Designs and Best Praction","text":"<ul> <li>\u91dd\u5c0dAnalytics(OLAP)\u5834\u666f\u8f03\u5f31</li> <li>\u5ba2\u6236\u9ad4\u9a57(OLTP) vs \u5f8c\u7aef\u7d71\u8a08(OLAP)(ex. \u904e\u53bb\u4e00\u5e74/\u4e00\u5b63/\u4e00\u500b\u6708\u7684\u8a02\u55ae\u91cf)</li> <li>SQL is good for OLAP; NoSQL for OLTP for scale</li> <li>\u53ef\u4ee5\u7528DynomaDB Stream\u5f37\u5316OLAP\u61c9\u7528</li> <li>Archive</li> <li>TTL + DynomaDB Stream</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#sql-vs-nosql","title":"SQL vs NoSQL","text":"<ul> <li>Data Modeling</li> <li>Data Access Pattern</li> <li>Data Query</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#partion-key","title":"partion key","text":"<ul> <li>AWS Blog: Choosing the right dynamodb partition key \u9ad8\u9451\u5225\u5ea6\u7684\u8cc7\u6599\uff0c\u6703\u5f71\u97ff\u5be6\u9ad4partion\u7684\u5b58\u653e</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#operation","title":"operation","text":"<p>\u5efa\u8b70Batch Write Operation for cost saving</p>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#qa","title":"QA","text":"<ul> <li>prefix use #? =&gt; \u4e0d\u6210\u6587\u898f\u5b9a</li> <li> </li> <li>update ok status \u4ee3\u8868 \u5df2\u7d93\u540c\u6b65\u81f33\u500bAZ\u5b8c\u6210\uff0c\u5305\u542bGSI?</li> <li>partition\u6709\u53ef\u80fd\u53ea\u6709\u4e00\u500bitem\u7684\u60c5\u6cc1\u55ce? =&gt; \u6709\u53ef\u80fd\uff0c\u770bAWS\u5f8c\u9762hash function\u7684\u8a2d\u8a08</li> <li>partition key\u662f\u5177\u6709\u552f\u4e00\u6027\u7684\u8cc7\u6599, ex. uuid, \u4ee3\u8868\u4e00\u5b9a\u6703\u5728\u4e0d\u540cpartition\u55ce? =&gt; \u4e0d\u4e00\u5b9a\uff0c\u770bAWS\u5f8c\u9762hash function\u7684\u8a2d\u8a08\u6216\u662f\u8a72item\u662f\u5426\u662f\u975e\u5e38\u71b1\u9580</li> <li>primary key(partion key+sort key)\u4e00\u5b9a\u5177\u6709\u552f\u4e00\u6027?</li> </ul>"},{"location":"hackmd/DynamoDB%20Deep%20Dive%20Advence%20Design/#profilealexdebrie-vs-orderabcsdf-profile-order","title":"PROFILE#alexdebrie vs ORDER#abcsdf =&gt; #PROFILE ORDER \u6c92\u6709\u7279\u5225\u610f\u601d","text":""},{"location":"hackmd/GPU/","title":"GPU","text":"<ul> <li>\u6dfa\u8ac7GPU\u5230\u5e95\u662f\u4ec0\u9ebc\uff08\u4e0a\uff09\uff1a\u4e0d\u540c\u7684\u904b\u7b97\u578b\u614b (133369) - Cool3c</li> <li>\u6dfa\u8ac7GPU\u5230\u5e95\u662f\u4ec0\u9ebc\uff08\u4e2d\uff09\uff1a\u517c\u5177SIMD\u8207MIMD\u512a\u9ede\u7684SIMT (133370) - Cool3c</li> <li>\u786c\u79d1\u6280\uff1a\u6dfa\u8ac7GPU\u5230\u5e95\u662f\u4ec0\u9ebc\uff08\u4e0b\uff09\uff1a\u8d70\u5411\u6c4e\u7528\u5316\u7684GPGPU (134057) - Cool3c</li> <li>\u786c\u79d1\u6280\uff1aGPU\u865b\u64ec\u5316\u70ba\u4f55\u8d85\u7d1a\u96e3\u641e(\u4e0a) #CPU (157525) - Cool3c</li> <li>\u786c\u79d1\u6280\uff1aGPU\u865b\u64ec\u5316\u70ba\u4f55\u8d85\u7d1a\u96e3\u641e(\u4e2d) #api (157526) - Cool3c</li> <li>\u786c\u79d1\u6280\uff1aGPU\u865b\u64ec\u5316\u70ba\u4f55\u8d85\u7d1a\u96e3\u641e(\u4e0b) #nvidia (157527) - Cool3c</li> <li>PCI devices</li> </ul> <p>is it PCIe GPU or HGX?</p> <pre><code>mst status -v\nnvidia-smi topo -m\n</code></pre>"},{"location":"hackmd/GPU/#flow","title":"flow","text":"<p>enable gpu direct gpu1 &lt;=&gt; ib card &lt;=&gt; ib card   &lt;=&gt; gpu2 \u6709\u4e86\u4e4b\u5f8c\u662f\u7da0\u7684</p> <p>disable gpu direct gpu1 &lt;=&gt; cpu &lt;=&gt; ib card &lt;=&gt; ib card  &lt;=&gt; cpu  &lt;=&gt; gpu2 \u6c92\u6709gpu direct\u662f\u7d2b\u8272</p> <p></p>"},{"location":"hackmd/GPU/#cpu-slot","title":"\u78ba\u8a8dCPU Slot\u4f4d\u7f6e","text":"<pre><code>lspci -tvv\nnvidia-smi topo -m\n</code></pre>"},{"location":"hackmd/GPU/#gpu-and-nic-mapping","title":"GPU and NIC mapping","text":"<p>look at the PIX</p> <p>GPU0 is mapping to NIC0 GPU6 is mapping to NIC5 GPU4 is mapping to NIC4</p> <pre><code>nvidia-smi topo -m\n        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    NIC0    NIC1    NIC2    NIC3    NIC4    NIC5    CPU Affinity    NUMA Affinity   GPU NUMA ID\nGPU0     X      NV18    NV18    NV18    NV18    NV18    NV18    NV18    PIX     SYS     SYS     SYS     SYS     SYS     0-31,64-95      0               N/A\nGPU1    NV18     X      NV18    NV18    NV18    NV18    NV18    NV18    SYS     SYS     SYS     SYS     SYS     SYS     0-31,64-95      0               N/A\nGPU2    NV18    NV18     X      NV18    NV18    NV18    NV18    NV18    SYS     PIX     SYS     SYS     SYS     SYS     0-31,64-95      0               N/A\nGPU3    NV18    NV18    NV18     X      NV18    NV18    NV18    NV18    SYS     SYS     SYS     SYS     SYS     SYS     0-31,64-95      0               N/A\nGPU4    NV18    NV18    NV18    NV18     X      NV18    NV18    NV18    SYS     SYS     SYS     SYS     PIX     SYS     32-63,96-127    1               N/A\nGPU5    NV18    NV18    NV18    NV18    NV18     X      NV18    NV18    SYS     SYS     SYS     SYS     SYS     SYS     32-63,96-127    1               N/A\nGPU6    NV18    NV18    NV18    NV18    NV18    NV18     X      NV18    SYS     SYS     SYS     SYS     SYS     PIX     32-63,96-127    1               N/A\nGPU7    NV18    NV18    NV18    NV18    NV18    NV18    NV18     X      SYS     SYS     SYS     SYS     SYS     SYS     32-63,96-127    1               N/A\nNIC0    PIX     SYS     SYS     SYS     SYS     SYS     SYS     SYS      X      SYS     SYS     SYS     SYS     SYS\nNIC1    SYS     SYS     PIX     SYS     SYS     SYS     SYS     SYS     SYS      X      SYS     SYS     SYS     SYS\nNIC2    SYS     SYS     SYS     SYS     SYS     SYS     SYS     SYS     SYS     SYS      X      PIX     SYS     SYS\nNIC3    SYS     SYS     SYS     SYS     SYS     SYS     SYS     SYS     SYS     SYS     PIX      X      SYS     SYS\nNIC4    SYS     SYS     SYS     SYS     PIX     SYS     SYS     SYS     SYS     SYS     SYS     SYS      X      SYS\nNIC5    SYS     SYS     SYS     SYS     SYS     SYS     PIX     SYS     SYS     SYS     SYS     SYS     SYS      X\n\nLegend:\n\n  X    = Self\n  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing at most a single PCIe bridge\n  NV#  = Connection traversing a bonded set of # NVLinks\n\nNIC Legend:\n\n  NIC0: mlx5_0\n  NIC1: mlx5_1\n  NIC2: mlx5_2\n  NIC3: mlx5_3\n  NIC4: mlx5_4\n  NIC5: mlx5_5\n\nroot@tester:~/tools/perftest-cuda/bin# mst status -v\nMST modules:\n------------\n    MST PCI module is not loaded\n    MST PCI configuration module is not loaded\nPCI devices:\n------------\nDEVICE_TYPE             MST      PCI       RDMA            NET                                     NUMA\nConnectX6(rev:0)        NA       5d:00.0   mlx5_2          net-ibp93s0f0                           0\n\nConnectX7(rev:0)        NA       c0:00.0   mlx5_5          net-ibp192s0                            1\n\nConnectX7(rev:0)        NA       9c:00.0   mlx5_4          net-ibp156s0                            1\n\nConnectX7(rev:0)        NA       40:00.0   mlx5_1          net-ibp64s0                             0\n\nConnectX7(rev:0)        NA       1a:00.0   mlx5_0          net-ibp26s0                             0\n\nConnectX6(rev:0)        NA       5d:00.1   mlx5_3          net-ibp93s0f1                           0\n</code></pre>"},{"location":"hackmd/GPU/#sharing-nvidia-gpu-resources","title":"sharing Nvidia GPU resources","text":""},{"location":"hackmd/GPU/#multi-instance-gpu-mig","title":"Multi-Instance GPU (MIG)","text":"<p>Multi-Instance GPU (MIG)\u985e\u4f3cmulti process</p> <p>single the GPU is partitioned into multiple instances of the same size.  For example, an NVIDIA A100 GPU can be divided into seven instances, each with equal resources.</p> <p>mixed the GPU is partitioned into instances of different sizes.  This allows for a more flexible allocation of resources based on the specific needs of each workload.</p>"},{"location":"hackmd/GPU/#time-slicing-gpus","title":"Time-Slicing GPUs","text":"<p>Time-Slicing GPUs\u985e\u4f3csingle thread with event loop</p> <p>GPU time-slicing can be used with bare-metal applications, virtual machines with GPU passthrough, and virtual machines with NVIDIA vGPU.</p>"},{"location":"hackmd/GPU/#nvidia-license-server","title":"Nvidia License Server","text":"<ul> <li>:star:License System User Guide - NVIDIA Docs<ul> <li>Creating a License Service for NVIDIA AI Enterprise or Virtual GPU - YouTube</li> </ul> </li> </ul>"},{"location":"hackmd/GPU/#nvidia-cuda","title":"Nvidia CUDA","text":"<ul> <li>CUDA Toolkit 12.4 Update 1 Downloads | NVIDIA Developer<ul> <li>CUDA Toolkit Archive | NVIDIA Developer</li> </ul> </li> <li>https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/</li> <li>1. Introduction \u2014 Installation Guide for Linux 12.3 documentation</li> <li>1. Introduction \u2014 Quick Start Guide 12.4 documentation</li> <li>CUDA Compatibility<ul> <li>1. Introduction \u2014 CUDA C Programming Guide</li> </ul> </li> <li>Driver and Runtime<ul> <li>CUDA Driver VS CUDA Runtime - Lei Mao's Log Book</li> <li>CUDA has two APIs: 1. The runtime api (libcudart.so) 2. The driver api (libcuda.... | Hacker News</li> <li>CUDA \u7684driver API \u3001runtime API\u3001Libraries - \u77e5\u4e4e</li> <li>CUDA C++ Programming Guide - 3.3. Versioning and Compatibility</li> <li>Cuda toolkit \u2014 Cuda driver. Before using Nvidia\u2019s profiling tools\u2026 | by Gia Huy ( CisMine) | Medium</li> <li>CUDA Installation Guide for Linux - 18. Removing CUDA Toolkit and Driver</li> </ul> </li> <li>Runfile<ul> <li>Runfile Installation</li> </ul> </li> </ul> <pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\nsudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.1-550.54.15-1_amd64.deb\nsudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit-12-4\n</code></pre> <p>runfile <pre><code>sudo apt-get install build-essential gcc-12\nsudo ln -s -f /usr/bin/gcc-12 /usr/bin/gcc\nsudo sh cuda_12.6.2_560.35.03_linux.run --silent --driver\n</code></pre></p>"},{"location":"hackmd/GPU/#nccl","title":"NCCL","text":"<ul> <li>GitHub - NVIDIA/cloud-native-stack: Run cloud native workloads on NVIDIA GPUs</li> <li>GitHub - NVIDIA/nccl: Optimized primitives for collective multi-GPU communication</li> </ul>"},{"location":"hackmd/GPU/#docker","title":"docker","text":"<ul> <li>Installing the NVIDIA Container Toolkit \u2014 NVIDIA Container Toolkit 1.15.0 documentation</li> <li>\u5be6\u4f5c\u5728 Docker \u74b0\u5883\u4e2d\u4f7f\u7528 GPU - IT Bunny Lee</li> </ul>"},{"location":"hackmd/GPU/#driver","title":"Driver","text":"<ul> <li>Official Drivers | NVIDIA</li> </ul>"},{"location":"hackmd/GPU/#debug","title":"Debug","text":"<ul> <li>NVIDIA GPU Debug Guidelines :: GPU Deployment and Management Documentation</li> <li>Bug #1915413 \u201cMilan Delta A100 GPU fails to detect on Ubuntu 18....\u201d : Bugs : Ubuntu</li> </ul>"},{"location":"hackmd/GPU/#nim","title":"NIM","text":"<p>NVIDIA Inference Microservice - NVIDIA \u9ec3\u4ec1\u52f3\u57f7\u884c\u9577\u5728 2024 Computex \u8aaa\u7684 NIM \u662f\u4ec0\u9ebc\uff1f - CAVEDU\u6559\u80b2\u5718\u968a\u6280\u8853\u90e8\u843d\u683c</p>"},{"location":"hackmd/GPU/#amd-rocm","title":"AMD ROCm","text":"<ul> <li>ROCm quick start install guide for Linux \u2014 ROCm installation (Linux)<ul> <li>Installing multiple ROCm versions \u2014 ROCm installation (Linux)</li> <li>Uninstalling ROCm</li> </ul> </li> <li>New ROCm Documentation Site : r/ROCm</li> <li>System requirements (Linux) \u2014 ROCm installation (Linux)</li> <li>Compatibility matrix \u2014 ROCm Documentation</li> <li>GPU-enabled Message Passing Interface \u2014 GPU cluster networking documentation</li> </ul>"},{"location":"hackmd/GPU/#rocm-validation-suitervs","title":"ROCm Validation Suite(RVS)","text":"<ul> <li>ROCm Validation Suite documentation \u2014 RVS 1.1.0 Documentation</li> <li>ROCmValidationSuite/docs/ug1main.md at master \u00b7 ROCm/ROCmValidationSuite \u00b7 GitHub<ul> <li>example: /opt/rocm/share/rocm-validation-suite/conf/</li> <li>example: https://github.com/ROCm/ROCmValidationSuite/tree/master/rvs/conf</li> </ul> </li> </ul>"},{"location":"hackmd/GRUB/","title":"GRUB","text":"<ul> <li>How to Use Grub Rescue to Fix Linux Boot Failure | phoenixNAP KB</li> <li>Introduction \u00b7 GRUB\u67b6\u69cb\u89e3\u6790</li> <li>Grub2 - Community Help Wiki</li> <li>Getting Symbol grub_file_filters not found error While instaling parrot os . Need help. : ParrotSecurity</li> </ul> <p>/etc/default/grub</p>"},{"location":"hackmd/GRUB/#suse","title":"SUSE","text":"<ul> <li>\u958b\u6a5f\u8f09\u5165\u7a0b\u5f0f GRUB\u00a02 | \u7ba1\u7406\u6307\u5357 | SUSE Linux Enterprise Server 15</li> </ul>"},{"location":"hackmd/GRUB/#ubuntu","title":"Ubuntu","text":""},{"location":"hackmd/Git/","title":"Git","text":"<ul> <li>Git \u7684\u6545\u4e8b\uff1a\u9019\u4e00\u6b21\u6c92\u9019\u9ebc\u597d\u73a9 | \u8edf\u9ad4\u8003\u53e4\u5b78\u5bb6</li> <li>A Visual Git Reference<ul> <li>Explain Git with D3</li> <li>Learn Git Branching</li> </ul> </li> <li>Modern Git Commands and Features You Should Be Using | Martin Heinz | Personal Website &amp; Blog</li> <li>How to Store Dotfiles - A Bare Git Repository | Atlassian Git Tutorial</li> <li>Git \u5c0f\u6280\u5de7 - \u5207\u63db\u70ba\u7279\u5b9a Github \u5e33\u865f\u7dad\u8b77\u5c08\u6848-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u65b0 Git \u6307\u4ee4\u4e4b\u4f60\u8a72\u8a66\u8a66\u770b\u4e86 | \u662f Ray \u4e0d\u662f Array</li> <li>Git: How to enable autocorrect - Adam Johnson</li> <li>:star:Git \u8edf\u9ad4\u958b\u767c\u6307\u5357\uff1a\u63d0\u9ad8\u5718\u968a\u5354\u4f5c\u7684\u95dc\u9375 - \u5c0f\u60e1\u9b54 - AppleBOY<ul> <li>Gitea \u8207 Jira \u8edf\u9ad4\u958b\u767c\u6d41\u7a0b\u6574\u5408 - \u5c0f\u60e1\u9b54 - AppleBOY</li> </ul> </li> <li>\u521d\u63a2\u8f15\u91cf\u7d1a DevOps \u5e73\u53f0: Gitea - \u53f0\u5317 DevOpsDay - \u5c0f\u60e1\u9b54 - AppleBOY</li> <li>\u4e3b\u5e79\u958b\u767c\u7c21\u4ecb - trunk based development</li> </ul> <p>~/.bashrc <pre><code># git branch in bash prompt\nparse_git_branch() {\n     git branch 2&gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1)/'\n}\nexport PS1=\"\\u@\\h \\[\\e[32m\\]\\w \\[\\e[91m\\]\\$(parse_git_branch)\\[\\e[00m\\]$ \"\n</code></pre></p>"},{"location":"hackmd/Git/#config","title":"config","text":"<ul> <li>How to show or change your Git username or email address | alvinalexander.com</li> <li>[Git] \u6a94\u6848\u6b0a\u9650\u6539\u8b8a\uff0c\u5c0e\u81f4\u6240\u6709\u7684\u6a94\u6848\u90fd\u88ab Git \u8996\u70ba\u5df2\u4fee\u6539\uff1f | EPH \u7684\u7a0b\u5f0f\u65e5\u8a18<ul> <li>git status shows all files as modified \u00b7 Issue #184 \u00b7 microsoft/WSL \u00b7 GitHub</li> </ul> </li> </ul> <pre><code># \u67e5\u770b\u8a2d\u5b9a\n$ git config --list\n\n# \u6aa2\u67e5username\n$ git config user.name\n\n# \u8a2d\u7f6euser name\n$ git config --global user.name \"Ted.Changchien\"\n\n# \u8a2d\u7f6eemail\n$ git config --global user.email \"Ted.Changchien@zyxel.com.tw\"\n\n# \u8a2d\u7f6ecommit log template\n$ git config --global commit.template /path/to/log-template-file\n\n# \u8a2d\u7f6ecommit\u7de8\u8f2f\u5668\n$ git config --global core.editor \"vim\"\n\n# git log show ^M\n$ git config --global core.whitespace cr-at-eol\n\n# alias\n$ git config --global alias.tree \"log --graph --decorate --pretty=oneline --abbrev-commit\"\n\n# filemode\n$ git config core.filemode false\n</code></pre> <p>unset ```bash= git config --global --unset user.name git config --global --unset user.email</p>"},{"location":"hackmd/Git/#edit-directly","title":"edit directly","text":"<p>git config --global --edit <pre><code>## remote\n- [Working with Git remotes and pushing to multiple Git repositories](https://jigarius.com/blog/multiple-git-remote-repositories)\n- [Delete remote branch](https://gitbook.tw/chapters/github/delete-remote-branch.html)\n- [git Local \u7aef\u8207 Remote \u7aef\u7684\u5206\u652f\u64cd\u4f5c. \u524d\u8a00 | by Kiwi lee | Medium](https://sean22492249.medium.com/git-local-%E7%AB%AF%E8%88%87-remote-%E7%AB%AF%E7%9A%84%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C-3dc360be3b5b)\n\n```bash=\n# \u8a2d\u7f6e\u9060\u7aef\u5009\u5eab\u7684URL\n$ git remote set-url origin https://github.com/USERNAME/OTHERREPOSITORY.git\n$ git remote set-url origin git@192.168.188.95:UploadPlatform.git\n\n# \u66f4\u6539\u9060\u7aef\u4e3b\u6a5f\u8cc7\u8a0a\n$ git remote -v\n$ git remote rm origin\n$ git remote add origin git@git-server:project_name\n\n# \u9023\u7d50 remote repository \u7684 branch \u5230\u65b0\u5efa\u7684 local branch\n$ git branch --set-upstream-to=origin/feature3 feature3\n\n# \u522a\u9664\u9060\u7aef\u5206\u652f\n$ git push origin :feature_a\n\n# clean up the reference to the deleted remote branch from your local repository\n$ git fetch origin --prune \n</code></pre></p>"},{"location":"hackmd/Git/#stash","title":"stash","text":"<p>\u66ab\u5b58working directory \u60f3\u8981\u62c9\u56de\u9060\u7aefrepo\u7684\u65b0commit\u4f46\u60f3\u66ab\u6642\u4fdd\u5b58\u76ee\u524d\u9084\u6c92\u6709\u505alocal commit\u4e14\u6b63\u5728\u4fee\u6539\u7684\u90e8\u5206</p> <pre><code>git stash\ngit stash apply\ngit stash drop\ngit stash pop\n</code></pre> <ul> <li>git - See what's in a stash without applying it - Stack Overflow</li> </ul> <pre><code>git stash show -p stash@{0}\n</code></pre>"},{"location":"hackmd/Git/#tags","title":"tags","text":"<ul> <li>\u4f7f\u7528\u6a19\u7c64 - \u70ba\u4f60\u81ea\u5df1\u5b78 Git | \u9ad8\u898b\u9f8d</li> </ul> <pre><code># show tags\ngit tag -l\n</code></pre> <pre><code>git tag -a v1.2.1b3\ngit push origin v1.2.1b3\n\n# \u5c0d\u904e\u53bb\u7684commit\u4e0a\u52a0\u5165\u6a19\u7c64\ngit tag -a v1.3.0b2s2 9fceb02\n\n# Delete the tag from the repository\ngit tag -d &lt;tag name&gt;\n\ngit fetch --tags\ngit push origin --tags\n</code></pre>"},{"location":"hackmd/Git/#log","title":"log","text":"<p><pre><code># search log by commit message\ngit log --grep='JIRA ID'\n\n# log filter by author\ngit log --author=\"Jon\"\n\n# \u986f\u793a\u6a94\u6848\u8cc7\u8a0a\ngit log --name-status\n\n# find commit by hash sha in git\ngit show a2c25061\ngit log a2c25061 -n 1\ngit show a2c25061 --stat\n\n# view the change history of a method/function\ngit log -L :function:path/to/file\n\n# find a deleted file in the project commit history\n# do not know the exact path\ngit log --all --full-history -- \"**/thefile.*\"\n#  know the path the file was at\ngit log --all --full-history -- &lt;path-to-file&gt;\n</code></pre> https://stackoverflow.com/questions/7124914/how-to-search-a-git-repository-by-commit-message how do I view the change history of a method/function git - How to find a deleted file in the project commit history? - Stack Overflow</p>"},{"location":"hackmd/Git/#patch","title":"patch","text":"<pre><code># \u88fd\u4f5c\u6700\u8fd1n\u500bcommit\u7684patch\ngit format-patch -n\n\n# \u88fd\u4f5c\u5f9e\u6307\u5b9a\u8d77\u59cbcommit\u5230\u7d50\u675fcommit\u7684patch\ngit format-patch 5e86795..f2b286a\n# \u8a2d\u5b9a\u8f38\u51fa\u7684\u8cc7\u6599\u593e\ngit format-patch 5e86795..f2b286a -o {Dir Name}\n\n# \u6aa2\u67e5\u5957\u7528patch\u662f\u5426\u6703\u6709\u554f\u984c\ngit apply --check {patch_file}\n\n# \u5be6\u969b\u5957\u7528patch\ngit am {patch_file}\nnotes: \u6709[]\u6703\u6d88\u5931\n</code></pre>"},{"location":"hackmd/Git/#push","title":"push","text":"<ul> <li>\u5be6\u7528\u6280\u5de7 \ud83d\udcbc git push -f \u6551\u56de\u7684\u65b9\u6cd5\uff01 - \u7a0b\u5f0f\u733f\u5403\u9999\u8549 - Medium</li> </ul>"},{"location":"hackmd/Git/#pull","title":"pull","text":"<ul> <li>\u89e3\u6c7a git pull \u932f\u8aa4\uff1aNeed to specify how to reconcile divergent branches. \u2013 JumpingCode \u8cc7\u6599\u79d1\u5b78\u624b\u8a18</li> </ul>"},{"location":"hackmd/Git/#add","title":"add","text":""},{"location":"hackmd/Git/#commit-only-part-of-a-file-in-git","title":"Commit only part of a file in Git","text":"<p>\u4f8b\u5982: refactory\u6642\u6539import, \u4f46\u5176\u4ed6\u90e8\u5206\u548crefactory\u7121\u95dc https://stackoverflow.com/questions/1085162/commit-only-part-of-a-file-in-git</p> <pre><code>git add -p &lt;filename&gt;\n\nStage this hunk [y,n,q,a,d,/,j,J,g,s,e,?]?\nHere is a description of each option:\n\ny stage this hunk for the next commit\nn do not stage this hunk for the next commit\nq quit; do not stage this hunk or any of the remaining hunks\na stage this hunk and all later hunks in the file\nd do not stage this hunk or any of the later hunks in the file\ng select a hunk to go to\n/ search for a hunk matching the given regex\nj leave this hunk undecided, see next undecided hunk\nJ leave this hunk undecided, see next hunk\nk leave this hunk undecided, see previous undecided hunk\nK leave this hunk undecided, see previous hunk\ns split the current hunk into smaller hunks\ne manually edit the current hunk\n? print hunk help\n</code></pre>"},{"location":"hackmd/Git/#bundle","title":"bundle","text":"<ul> <li>Git \u5c0f\u6280\u5de7 - \u5c07 Commit \u6253\u5305\u6210\u6a94\u6848\u9001\u5230\u7570\u5730\u540c\u6b65-\u9ed1\u6697\u57f7\u884c\u7dd2</li> </ul>"},{"location":"hackmd/Git/#commit","title":"Commit","text":"<ul> <li>Conventional Commits<ul> <li>conventional-changelog/standard-version</li> <li>Conventional Commits \u2013 Gea-Suan Lin's BLOG</li> </ul> </li> <li>\u81ea\u52d5\u7522\u751f semantic Versioning \u7248\u865f\u8207\u8cc7\u8a0a, \u4f7f\u7528 semantic-release \u6216 standard-version</li> <li>generating-changelog-standard-version</li> </ul>"},{"location":"hackmd/Git/#real-world-example","title":"real world example","text":"<ul> <li>Commits \u00b7 apache/superset \u00b7 GitHub</li> </ul>"},{"location":"hackmd/Git/#diff","title":"diff","text":"<p>what changes between two commits and only the filename Git: How to show only filenames for a diff - makandra dev</p> <pre><code>git diff [commit a]..[commmit b] --stat\n\ngit diff [commit a]..[commmit b] --name-only\n</code></pre>"},{"location":"hackmd/Git/#flow","title":"Flow","text":"<ul> <li>Gitlab merge request \u6559\u5b78 - HackMD</li> </ul> <p>\u6301\u7e8c\u767c\u5e03 \u7248\u672c\u767c\u5e03</p>"},{"location":"hackmd/Git/#_1","title":"\u53c3\u8003","text":"<ul> <li>\u4e09\u7a2e\u7248\u63a7\u6d41\u7a0b</li> <li>\u8207\u5176\u5b83\u958b\u767c\u8005\u7684\u4e92\u52d5 - \u4f7f\u7528 Pull Request(PR)</li> <li> Chaser324/GitHub-Forking</li> <li>How can I tell a local branch to track a remote branch</li> </ul>"},{"location":"hackmd/Git/#rebase","title":"Rebase","text":"<ul> <li>Git-rebase \u5c0f\u7b46\u8a18 - Yu-Cheng Chuang\u2019s Blog</li> <li>Git \u7248\u672c\u63a7\u5236\u6559\u5b78 - \u7528\u7bc4\u4f8b\u5b78 rebase - MyApollo</li> <li>\u9001 PR \u524d\uff0c\u4f7f\u7528 Git rebase \u4f86\u6574\u7406\u4f60\u7684 commit \u5427\uff01</li> <li>\u4f7f\u7528 git rebase --onto \u7121\u75db\u66f4\u65b0\u5206\u652f | Summer\u3002\u6851\u83ab\u3002\u590f\u5929</li> </ul>"},{"location":"hackmd/Git/#conflict","title":"Conflict","text":"<ul> <li>\u4e00\u6b21Git\u8e29\u5751\u8bb0\u5f55\uff1aCONFLICT (modify/delete) - \u7c21\u66f8</li> </ul>"},{"location":"hackmd/Git/#revert","title":"Revert","text":"<p>\u67d0\u500b Commit \u53cd\u5411\u7684\u64cd\u4f5c - eset\u3001Revert \u8ddf Rebase \u6307\u4ee4\u6709\u4ec0\u9ebc\u5dee\u5225</p>"},{"location":"hackmd/Git/#discard-change","title":"Discard change","text":"<pre><code># discard unstaged changes\ngit checkout -- .\ngit checkout -- path/to/file/to/revert\n</code></pre> <pre><code># restore all changes\ngit restore .\n</code></pre>"},{"location":"hackmd/Git/#cherry-pick","title":"cherry pick","text":"<p>```bash=</p>"},{"location":"hackmd/Git/#to-cherry-pick-all-the-commits-from-commit-a-to-commit-b-where-a-is-older-than-b","title":"To cherry-pick all the commits from commit A to commit B (where A is older than B)","text":"<p>git cherry-pick A^..B</p>"},{"location":"hackmd/Git/#if-you-want-to-ignore-a","title":"If you want to ignore A","text":"<p>git cherry-pick A..B <pre><code>- [How to cherry-pick multiple commits](https://stackoverflow.com/questions/1670970/how-to-cherry-pick-multiple-commits)\n\n\n## sparse checkout\n- [\u5982\u4f55\u5728 Monorepo \u900f\u904e Git \u7684 Sparse Checkout \u53d6\u5f97\u90e8\u5206 Repo \u5167\u5bb9 | The Will Will Web](https://blog.miniasp.com/post/2022/05/17/Down-size-your-Monorepo-with-Git-Sparse-checkouts)\n\n## bisect\n- [\u4f7f\u7528 Git Bisect \u5feb\u901f\u627e\u5230\u7b2c\u4e00\u500b\u6709\u554f\u984c\u7684 Commit | Puck's Blog](https://blog.puckwang.com/posts/2021/use-git-bisect-debug/)\n\n## submodule\n- [Git \u7248\u672c\u63a7\u5236\u6559\u5b78 - submodule - MyApollo](https://myapollo.com.tw/blog/git-tutorial-submodule/)\n- [Git - submodule \u4f7f\u7528\u6559\u5b78 | Kenny's Blog](https://blog.kennycoder.io/2020/06/14/Git-submodule-%E4%BD%BF%E7%94%A8%E6%95%99%E5%AD%B8/)\n- [Git \u9032\u968e\u61c9\u7528 Submodule \u8207 Subtree\uff0c\u4f7f\u7528\u5b83\u5011\u4f86\u62c6\u5206\u5c08\u6848 | Puck's Blog](https://blog.puckwang.com/posts/2020/git-submodule-vs-subtree/)\n    - \u66f4\u65b0 Submodule\n- [git - How do I remove a submodule? - Stack Overflow](https://stackoverflow.com/questions/1260748/how-do-i-remove-a-submodule)\n- [[Git] \u66f4\u65b0 Git submodule \u6642\u51fa\u73fe not our ref \u7684\u932f\u8aa4\u8a0a\u606f\uff1f | EPH \u7684\u7a0b\u5f0f\u65e5\u8a18](https://ephrain.net/git-%e6%9b%b4%e6%96%b0-git-submodule-%e6%99%82%e5%87%ba%e7%8f%be-not-our-ref-%e7%9a%84%e9%8c%af%e8%aa%a4%e8%a8%8a%e6%81%af%ef%bc%9f/)\n- [How can I authenticate my information with a submo...](https://community.atlassian.com/t5/Sourcetree-questions/How-can-I-authenticate-my-information-with-a-submodule/qaq-p/2122821)\n    - [\u5982\u4f55\u900f\u904e Git Credential \u7ba1\u7406\u900f\u904e HTTP \u901a\u8a0a\u5354\u5b9a\u5b58\u53d6\u5132\u5b58\u5eab\u7684\u5e33\u865f\u5bc6\u78bc | The Will Will Web](https://blog.miniasp.com/post/2018/05/28/Git-Credential-Howto)\n        - [Git - git-credential-cache Documentation](https://git-scm.com/docs/git-credential-cache)\n    - [\u5982\u4f55\u4f7f\u7528 Git Credential Manager \u5feb\u901f\u6e05\u9664 Azure Repos \u4f7f\u7528\u8005\u8a8d\u8b49\u5feb\u53d6 | The Will Will Web](https://blog.miniasp.com/post/2022/05/18/Clear-Azure-Repos-Authority-Cache-using-Git-Credential-Manager)\n\n``` bash\n# \u91dd\u5c0d \u55ae\u4e00\u500b submodule \u505a remote update\ngit submodule update --remote path/to/submodule\n</code></pre></p> <p>fix corrupt submodule - git submodules - could not get a repository handle for submodule - Stack Overflow</p> <pre><code>rm -rf .git/modules/the_submodule/ the_submodule/\ngit submodule init \"the_submodule\"\ngit submodule update\n</code></pre>"},{"location":"hackmd/Git/#lfs","title":"LFS","text":"<ul> <li>\u4f7f\u7528 Git LFS \u4e0a\u50b3\u5927\u578b\u6a94\u6848 \u2014 1010Code</li> </ul>"},{"location":"hackmd/Git/#protect-secret-leak","title":"protect secret leak","text":"<ul> <li>Gitleaks \u2014 \u5e6b\u4f60\u5075\u6e2c/\u9632\u6b62\u91d1\u9470\u3001\u5bc6\u78bc\u88ab\u4e0d\u5c0f\u5fc3 commit \u7684\u60c5\u6cc1 - MyApollo<ul> <li>GitHub - gitleaks/gitleaks: Find secrets with Gitleaks \ud83d\udd11</li> </ul> </li> <li>GitHub - newren/git-filter-repo: Quickly rewrite git repository history (filter-branch replacement)</li> </ul>"},{"location":"hackmd/Git/#_2","title":"\u5de5\u4f5c\u539f\u7406","text":"<ul> <li>Git\u5185\u90e8\u5b58\u50a8\u539f\u7406-\u8d75\u5316\u51b0\u7684\u535a\u5ba2 | Zhaohuabing Blog</li> <li>In a git repository, where do your files live?</li> <li>Write yourself a Git!</li> </ul>"},{"location":"hackmd/Git/#hook","title":"hook","text":"<p>post-commit</p> <pre><code>#! /bin/bash\n\n\npython -m venv /tmp/doc\nsource /tmp/doc/bin/activate\npip install grip\n\ncd doc &amp;&amp; grip user_guide.md --export index.html\n</code></pre>"},{"location":"hackmd/Google%20docs%20api/","title":"Google docs api","text":"<p>api key oauth client</p> <ul> <li>https://www.maxlist.xyz/2018/09/25/python_googlesheet_crud/</li> <li>https://hackmd.io/@Yun-Cheng/GoogleSheets</li> <li>https://stackoverflow.com/questions/44899425/read-a-google-sheet-with-python-using-api-key-instead-of-oauth-client-id-python</li> <li>https://github.com/googleapis/google-api-python-client</li> <li>https://cloud.google.com/docs/authentication/api-keys?visit_id=637583046296973962-2610661765&amp;rd=1</li> <li>https://developers.google.com/sheets/api/quickstart/python</li> </ul>"},{"location":"hackmd/HTTP/","title":"HTTP","text":""},{"location":"hackmd/HTTP/#multipartform-data","title":"multipart/form-data","text":"<ul> <li>cURL\u548cmultipart/form-data | Bing</li> <li>linux - Curl post with multipart/form-data and JSON - Stack Overflow</li> </ul>"},{"location":"hackmd/HYCOM/","title":"HYCOM","text":"<ul> <li>official<ul> <li>GLBt0.72 \u00b7 HYCOM/HYCOM-examples Wiki \u00b7 GitHub</li> <li>Home \u00b7 HYCOM/HYCOM-src Wiki \u00b7 GitHub</li> <li>Compilation (Make) \u00b7 HYCOM/HYCOM-src Wiki \u00b7 GitHub</li> <li>Compilation (config) \u00b7 HYCOM/HYCOM-src Wiki \u00b7 GitHub</li> <li>HYCOM.org Forum - Google \u7db2\u8def\u8ad6\u58c7</li> </ul> </li> <li>AMD<ul> <li>AMD-EPYC-with-HYCOM<ul> <li>\"GLB\" stands for Global HYCOM Benchmark</li> <li>GLBT0.72, is smaller and easily runs on a single compute node</li> <li>GLBT0.08, is a more challenging workload and is equivalent to a true production run.</li> </ul> </li> <li>Guide-To-Running-HYCOM-on-EPYC</li> </ul> </li> <li>Ocean Modeling with HYCOM on AWS Graviton2 - High Performance Computing (HPC) blog - Arm Community blogs - Arm Community</li> <li>:star:HYCOM \u00b7 Wiki \u00b7 Arm HPC Resources / packages \u00b7 GitLab</li> <li>compiler<ul> <li>Compiler Commands</li> </ul> </li> </ul> <p>The script Make_global.csh is just Make.csh configured for the typical global tripole case.</p> <p>The Makefile sources ./config/\\$(ARCH)_\\$(TYPE) where ARCH defines exactly what machine architecture to target and TYPE is the parallelization strategy and precision (one, omp, mpi, ompi, mpisr, shmem).</p> <p>If some problems occur, read the error messages, correct the errors and be sure to remove the .o and .mod files before running the Make.com again.</p> <p>all the input/ouput files of HYCOM are presented as a couple of .a and .b files. The .a file actually contains the binary data and the .b file describes what is in the .a file and how it is stored.</p>"},{"location":"hackmd/HYCOM/#how-to-run-source-code-2301","title":"how to run source code 2.3.01","text":"<p>experiment executable(hycom tool, pre/post processing tool)</p> <p></p>"},{"location":"hackmd/HYCOM/#prepare-basic-environment","title":"Prepare basic environment","text":"<p>``` bash=</p>"},{"location":"hackmd/HYCOM/#basic-env","title":"basic env","text":"<p>sudo yum group install \"Development Tools\"  sudo yum install -y curl findutils gcc-c++ gcc gcc-gfortran git gnupg2 hostname iproute redhat-lsb-core make patch python3 python3-pip python3-setuptools unzip</p>"},{"location":"hackmd/HYCOM/#for-runing-makecsh","title":"for runing Make.csh","text":"<p>sudo yum install -y csh make environment-modules </p>"},{"location":"hackmd/HYCOM/#spack","title":"spack","text":"<p>git clone -c feature.manyFiles=true https://github.com/spack/spack.git . spack/share/spack/setup-env.sh spack install intel-oneapi-compilers@2023.0.0 spack compiler add <code>spack location -i intel-oneapi-compilers</code>/compiler/latest/linux/bin/intel64 spack compiler add <code>spack location -i intel-oneapi-compilers</code>/compiler/latest/linux/bin spack compilers</p>"},{"location":"hackmd/HYCOM/#spack-install-openmpi415-gcc","title":"spack install openmpi@4.1.5 %gcc","text":"<p>spack install openmpi@4.1.5 %intel@2021.8.0</p>"},{"location":"hackmd/HYCOM/#spack-install-intel-oneapi-mpi-gcc","title":"spack install intel-oneapi-mpi %gcc","text":""},{"location":"hackmd/HYCOM/#spack-install-intel-oneapi-mpi-intel202180","title":"spack install intel-oneapi-mpi %intel@2021.8.0","text":""},{"location":"hackmd/HYCOM/#spack-install-netcdf-c-openmpi-gcc","title":"spack install netcdf-c ^openmpi %gcc","text":""},{"location":"hackmd/HYCOM/#spack-install-netcdf-fortran-openmpi-gcc","title":"spack install netcdf-fortran ^openmpi %gcc","text":"<p>spack install netcdf-c ^openmpi %intel@2021.8.0 spack install netcdf-fortran ^openmpi %intel@2021.8.0</p>"},{"location":"hackmd/HYCOM/#for-environment-modules-files","title":"for environment-modules files","text":"<p>spack module tcl refresh spack load openmpi@4.1.5 spack load intel-oneapi-compilers@2023.0.0</p>"},{"location":"hackmd/HYCOM/#ansbile","title":"ansbile","text":"<p>sudo yum install ansible-core.x86_64</p>"},{"location":"hackmd/HYCOM/#add-fortune-compiler-path-bingfortran","title":"add fortune compiler path /bin/gfortran","text":"<p>vim /home/smci/.spack/linux/compilers.yaml</p> <p>compilers: - compiler:     spec: gcc@8.5.0     paths:       cc: /usr/bin/gcc       cxx: /usr/bin/g++       f77: /bin/gfortran       fc: /bin/gfortran     flags: {}     operating_system: rhel8     target: x86_64     modules: []     environment: {}     extra_rpaths: []</p>"},{"location":"hackmd/HYCOM/#hycom-examples-example-source-from-github","title":"HYCOM-examples example source from github","text":"<p>wget -O HYCOM-examples.zip https://github.com/HYCOM/HYCOM-examples/archive/refs/heads/master.zip &amp;&amp; unzip HYCOM-examples.zip &amp;&amp; mv HYCOM-examples-master HYCOM-examples cd HYCOM-examples/datasets/ vim get_datasets.csh</p>"},{"location":"hackmd/HYCOM/#long-time-because-large-size4213g","title":"long time because large size(42.13G)","text":""},{"location":"hackmd/HYCOM/#18g-cfsr_gomtargz","title":"18G     CFSR_GOM.tar.gz","text":""},{"location":"hackmd/HYCOM/#16g-cfsv2_gomtargz","title":"16G     CFSv2_GOM.tar.gz","text":""},{"location":"hackmd/HYCOM/#802m-core2_nyftargz","title":"802M    CORE2_NYF.tar.gz","text":""},{"location":"hackmd/HYCOM/#139m-phc3_hycomtargz","title":"139M    PHC3_HYCOM.tar.gz","text":""},{"location":"hackmd/HYCOM/#36g-woa13_hycomtargz","title":"3.6G    WOA13_HYCOM.tar.gz","text":""},{"location":"hackmd/HYCOM/#36g-woa18_hycomtargz","title":"3.6G    WOA18_HYCOM.tar.gz","text":"<p>csh get_datasets.csh</p>"},{"location":"hackmd/HYCOM/#hycom-tools","title":"HYCOM-tools","text":""},{"location":"hackmd/HYCOM/#git-clone-recursive-httpsgithubcomhycomhycom-toolsgit","title":"git clone --recursive https://github.com/HYCOM/HYCOM-tools.git","text":"<p>wget -O HYCOM-tools.zip https://github.com/HYCOM/HYCOM-tools/archive/refs/heads/master.zip &amp;&amp; unzip HYCOM-tools.zip &amp;&amp; mv HYCOM-tools-master HYCOM-tools</p>"},{"location":"hackmd/HYCOM/#make_allcsh-this-creates-all-executables-in-all-source-directories-except-plot-and-those-that-depend-on-the-netcdf-library","title":"Make_all.csh. This creates all executables in all source directories, except plot and those that depend on the NetCDF library","text":""},{"location":"hackmd/HYCOM/#running-make_ncdfcsh-in-the-hycom-tools-root-directory-creates-all-netcdf-executables-in-all-source-directories-including-hycom-toolsbin","title":"Running Make_ncdf.csh in the HYCOM-tools root directory creates all netCDF executables in all source directories, including HYCOM-tools/bin","text":"<p>cd HYCOM-tools csh Make_clean.csh vim Make_all.src</p>"},{"location":"hackmd/HYCOM/#setenv-arch-amdif","title":"setenv ARCH amdIF","text":""},{"location":"hackmd/HYCOM/#vim-binmake_allcsh","title":"vim bin/Make_all.csh","text":"<p>if ($OS == \"Linux\") then  setenv OS LinuxAIF</p> <p>csh Make_all.csh &gt;&amp; Make_all.log module avail vim Make_ncdf.src</p> <p>--- intel compiler module unload netcdf-fortran-4.6.0-intel-2021.8.0-5hpf7gh module unload netcdf-c-4.9.0-intel-2021.8.0-etqveet module   load netcdf-c-4.9.0-intel-2021.8.0-etqveet module   load netcdf-fortran-4.6.0-intel-2021.8.0-5hpf7gh module   list setenv NCDFC     /home/smci/spack/opt/spack/linux-rhel8-zen2/intel-2021.8.0/netcdf-c-4.9.0-etqveetgf6tzouaveywcqkxgnqb6ef47 setenv NCDF      /home/smci/spack/opt/spack/linux-rhel8-zen2/intel-2021.8.0/netcdf-fortran-4.6.0-5hpf7gh76cytq6q7ob5rymcay3gj6qu3 setenv EXTRANCDF \"-L${NCDFC}/lib -L${NCDF}/lib -lnetcdf -lnetcdff\" </p> <p>--- gcc</p>"},{"location":"hackmd/HYCOM/#module-load-costinit","title":"module   load costinit","text":"<p>module unload netcdf-fortran-4.6.0-gcc-8.5.0-inxalsx module unload netcdf-c-4.9.0-gcc-8.5.0-2qwncum module   load netcdf-c-4.9.0-gcc-8.5.0-2qwncum module   load netcdf-fortran-4.6.0-gcc-8.5.0-inxalsx module   list setenv NCDFC     /home/smci/spack/opt/spack/linux-rhel8-zen/gcc-8.5.0/netcdf-c-4.9.0-2qwncumfartt3qrjqpixzxgipxs3hgrq setenv NCDF      /home/smci/spack/opt/spack/linux-rhel8-zen/gcc-8.5.0/netcdf-fortran-4.6.0-inxalsxzrfxb4q4nposghyu44gpw4vuy setenv EXTRANCDF \"-L${NCDFC}/lib -L${NCDF}/lib -lnetcdf -lnetcdff\" </p>"},{"location":"hackmd/HYCOM/#vim-binmake_ncdfcsh","title":"vim bin/Make_ncdf.csh","text":"<p>if ($OS == \"Linux\") then  setenv OS LinuxAIF</p> <p>cat config/amdIF_setup csh Make_ncdf.csh &gt;&amp; Make_ncdf.log <pre><code>### run GLBt0.72\n\n#### data preparation\n``` bash=\nsed -i 's|setenv S  /p/work1/${user}|setenv S  /home/smci|g' /home/smci/HYCOM-examples/GLBt0.72/datasets/get_datasets.csh\ncsh get_datasets.csh\n# All the input files for the GLBt0.72 configuration can be downloaded from the HYCOM.org website through the GLBt0.72/datasets/get_datasets.csh script.\n\n# Maybe option\n# https://github.com/HYCOM/HYCOM-examples/wiki/GLBt0.72#how-to-create-forcing-and-relax-files-for-glbt072\nexport PATH=$PATH:/home/smci/HYCOM-tools/bin\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(spack location -i netcdf-c@4.9.0%intel)/lib:$(spack location -i netcdf-fortran@4.6.0%intel)/lib\ncd /home/smci/HYCOM-examples/GLBt0.72/topo &amp;&amp; sed -i 's|setenv SP  /p/work1/${user}|setenv SP  /home/smci|g' *.csh\nfind /home/smci/HYCOM-examples/GLBt0.72/topo/ -type f -name \"regional.grid.csh\" -execdir csh {} \\;\ncd /home/smci/HYCOM-examples/GLBt0.72/force &amp;&amp; sed -i 's|setenv SP  /p/work1/${user}|setenv SP  /home/smci|g' *.csh\nfind /home/smci/HYCOM-examples/GLBt0.72/force/ -type f -name \"*.csh\" -execdir csh {} \\;\ncd /home/smci/HYCOM-examples/GLBt0.72/relax &amp;&amp; sed -i 's|setenv SP  /p/work1/${user}|setenv SP  /home/smci|g' EXPT.src\nfind /home/smci/HYCOM-examples/GLBt0.72/relax/ -type f -name \"iso_sigma*\" -execdir csh {} \\;\nfind /home/smci/HYCOM-examples/GLBt0.72/relax/ -type f -name \"z_*\" -execdir csh {} \\;\nfind /home/smci/HYCOM-examples/GLBt0.72/relax/ -type f -name \"relax*\" -execdir csh {} \\;\nfind /home/smci/HYCOM-examples/GLBt0.72/relax/ -type f \\( -name \"sefold*\" -o -name \"tbaric*\" -o -name \"thkdf4*\" \\)\n# in addition for mpi\ncd /home/smci/HYCOM-examples/GLBt0.72/topo/partit/15 &amp;&amp; sed -i 's|setenv DS /p/work1/${user}|setenv DS  /home/smci|g' *.csh\ncsh depth_2d_Ssq.csh\ncsh size_S.csh\ncsh ppm1.csh\ncsh resize8.csh\n</code></pre></p>"},{"location":"hackmd/HYCOM/#run-the-experiment","title":"run the experiment","text":"<p>``` bash=</p>"},{"location":"hackmd/HYCOM/#new-experiment-directory","title":"new experiment directory","text":"<p>cd /home/smci/HYCOM-examples/GLBt0.72 mkdir expt_02.0 cp expt_01.2/new_expt.csh expt_02.0 cd expt_02.0 sed -i 's|setenv  O 011|setenv  O 012|g' new_expt.csh sed -i 's|setenv  N 012|setenv  N 020|g' new_expt.csh sed -i 's|setenv OS   HPE|setenv OS   Linux|g' new_expt.csh sed -i 's|setenv SCRN /p/work1/${user}|setenv SCRN /home/smci|g' new_expt.csh</p>"},{"location":"hackmd/HYCOM/#build-hycom-binary-by-type","title":"build hycom binary by type","text":""},{"location":"hackmd/HYCOM/#_1","title":"...","text":""},{"location":"hackmd/HYCOM/#_2","title":"...","text":""},{"location":"hackmd/HYCOM/#set-up-and-ready-to-run","title":"set up and ready to run","text":"<p>csh new_expt.csh sed -i 's|setenv QSUBMIT ~wallcraf/bin/q_navo|setenv QSUBMIT /bin/csh|g' EXPT.src vim GLBt0.72/expt_02.0/blkdat.input ===    5.0    'hybthn' = HYBGEN: ratio of layer thicknesses to select the thiner    3      'hybmap' = HYBGEN: remapper  flag (0=PCM, 1=PLM,  2=PPM, 3=WENO-like) ===</p> <p>vim EXPT.src vim 020.csh</p>"},{"location":"hackmd/HYCOM/#type-one","title":"type one","text":"<p>=== C --- Set parallel configuration, see ../README/README.expt_parallel. C --- NOMP = number of OpenMP threads, 0 for no OpenMP, 1 for inactive OpenMP C --- NMPI = number of MPI    tasks,   0 for no MPI C switch ($OS) case 'Linux':   setenv NOMP 0   setenv NMPI 0   breaksw</p> <p>setenv A \"a\" setenv B \"b\" setenv Y01 \"011\" setenv YXX \"011\"</p> <p>if ($NOMP == 0) then   setenv NOMP 0 endif ===</p>"},{"location":"hackmd/HYCOM/#type-mpi","title":"type mpi","text":"<p>=== C --- Set parallel configuration, see ../README/README.expt_parallel. C --- NOMP = number of OpenMP threads, 0 for no OpenMP, 1 for inactive OpenMP C --- NMPI = number of MPI    tasks,   0 for no MPI C switch ($OS) case 'Linux':   setenv NOMP 0   setenv NMPI 16   breaksw</p> <p>setenv A \"a\" setenv B \"b\" setenv Y01 \"011\" setenv YXX \"011\" ===</p> <p>spack load openmpi@4.1.5 %intel export PATH=$PATH:/home/smci/HYCOM-tools/bin nohup csh 020.csh &gt;&amp; results.log &amp;</p>"},{"location":"hackmd/HYCOM/#check-if-run-successfully","title":"check if run successfully","text":"<p>grep \"^normal stop\" data/summary_out <pre><code>#### build hycom binary by type\ntype is one\n``` bash=\ngit clone --recursive https://github.com/HYCOM/HYCOM-src.git /home/smci/HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_one\n\ncd /home/smci/HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_one\nmodule avail\nvim Make.csh\n# ARCH xc40-intel-relo_one is from config/xc40-intel-relo_one\n--- HPE\nunset echo\nmodule purge\n#module load compiler/intel/2017.4.196\n#module load compiler/intel/2023.0.0\n#module load mpt/2.16\nmodule load intel-oneapi-compilers-2023.0.0-gcc-8.5.0-7ccmh6l\nmodule list\nset echo\nsetenv ARCH xc40-intel-relo_one\n---\n\nrm *.o *.mod *.log hycom\ncsh Make.csh &gt;&amp; Make_hycom.log\nls -la hycom\n</code></pre></p> <p>type is mpi ``` bash= git clone --recursive https://github.com/HYCOM/HYCOM-src.git /home/smci/HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_mpi cd /home/smci/HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_mpi module avail vim Make.csh</p>"},{"location":"hackmd/HYCOM/#arch-intelsse-impi-sm-relo-is-from-configintelsse-impi-sm-relo","title":"ARCH intelsse-impi-sm-relo is from config/intelsse-impi-sm-relo","text":"<p>setenv OCN_EOS -DEOS_9T  ## EOS  9-term</p>"},{"location":"hackmd/HYCOM/#setenv-ocn_eos-deos_17t-eos-17-term","title":"setenv OCN_EOS -DEOS_17T ## EOS 17-term","text":"<p>setenv OCN_GLB -DARCTIC ## global tripolar simulation</p>"},{"location":"hackmd/HYCOM/#setenv-ocn_glb","title":"setenv OCN_GLB \"\"","text":"<p>--- OPENMPI unset echo module purge module load intel-oneapi-compilers-2023.0.0-gcc-8.5.0-7ccmh6l module load openmpi-4.1.5-intel-2021.8.0-v2iv375 module list set echo setenv ARCH intelsse-impi-sm-relo</p> <p>rm .o .mod *.log hycom csh Make.csh &gt;&amp; Make_hycom.log ls -la hycom <pre><code>config/intelsse-impi-sm-relo_mpi\n</code></pre> FC            = mpifort</p>"},{"location":"hackmd/HYCOM/#fcfflags-traceback-xsse42-o3-fp-model-source-r8-warn-nogeneral-mcmodelsmall","title":"FCFFLAGS      =        -traceback -xSSE4.2 -O3 -fp-model source -r8 -warn nogeneral -mcmodel=small","text":"<p>FCFFLAGS      = -traceback  -O3 -fp-model source -r8 -warn nogeneral -mcmodel=small CC            = icc</p>"},{"location":"hackmd/HYCOM/#ccflags-traceback-xsse42-o-mcmodelsmall","title":"CCFLAGS       =        -traceback -xSSE4.2 -O -mcmodel=small","text":"<p>CCFLAGS       = -traceback -O -mcmodel=small CPP           = cpp -P CPPFLAGS      = -DREAL8 -DMPI -DSERIAL_IO -DENDIAN_IO -DNAN2003 -DTIMER -DRELO $(CPP_EXTRAS) LD            = $(FC) LDFLAGS       = -V $(FCFFLAGS) -static-intel EXTRALIBS     =</p>"},{"location":"hackmd/HYCOM/#_3","title":"HYCOM","text":""},{"location":"hackmd/HYCOM/#-generic-make-definitions","title":"--- generic make definitions","text":""},{"location":"hackmd/HYCOM/#_4","title":"HYCOM","text":"<p>SHELL         = /bin/sh RM            = \\rm -f</p>"},{"location":"hackmd/HYCOM/#_5","title":"HYCOM","text":""},{"location":"hackmd/HYCOM/#rules","title":"rules.","text":""},{"location":"hackmd/HYCOM/#_6","title":"HYCOM","text":"<p>.c.o:         $(CC) $(CPPFLAGS) $(CCFLAGS)  -c $*.c</p> <p>.F90.o:         $(FC) $(CPPFLAGS) $(FCFFLAGS) -c $*.F90 <pre><code>### run GOMb0.08\n\n#### data preparation\n``` bash=\nsed -i 's|setenv S  /p/work1/${user}|setenv S  /home/${user}|g' /home/smci/HYCOM-examples/GLBt0.72/datasets/get_datasets.csh\ncsh get_datasets.csh\n</code></pre></p>"},{"location":"hackmd/HYCOM/#run-the-experiment_1","title":"run the experiment","text":"<pre><code>cd /home/smci/HYCOM-examples/GOMb0.08\nmkdir expt_02.0\ncp expt_01.0/new_expt.csh expt_02.0\ncd expt_02.0\nsed -i 's|setenv  O 011|setenv  O 012|g' new_expt.csh\nsed -i 's|setenv  N 012|setenv  N 020|g' new_expt.csh\nsed -i 's|setenv OS   HPE|setenv OS   Linux|g' new_expt.csh\nsed -i 's|setenv SCRN /p/work1/${user}|setenv SCRN /home/${user}|g' new_expt.csh\nsed -i 's|setenv W  /p/work1/abozec|setenv SCRN /home/${user}|g'\n\n# build hycom binary\ngit clone --recursive https://github.com/HYCOM/HYCOM-src.git /home/smci/HYCOM-examples/GOMb0.08/src_2.3.01_relo_mpi\nvim Make.csh\n\n---\n#setenv OCN_EOS -DEOS_9T  ## EOS  9-term\nsetenv OCN_EOS -DEOS_17T ## EOS 17-term\n#setenv OCN_GLB -DARCTIC ## global tripolar simulation\nsetenv OCN_GLB \"\"\n---\n\n--- OPENMPI\nunset echo\nmodule purge\nmodule load intel-oneapi-compilers-2023.0.0-gcc-8.5.0-7ccmh6l\nmodule load openmpi-4.1.5-intel-2021.8.0-v2iv375\nmodule list\nset echo\n# ARCH smci-intel-sm-relo is from config/smci-intel-sm-relo\nsetenv ARCH smci-intel-sm-relo\n---\n\n\nrm *.o *.mod *.log hycom\ncsh Make.csh &gt;&amp; Make_hycom.log\nls -la hycom\n\n# set up and ready to run\ncd ../expt_02.0\ncsh new_expt.csh\nsed -i 's|setenv QSUBMIT ~wallcraf/bin/q_navo|setenv QSUBMIT /bin/csh|g' EXPT.src\nvim GOMb0.08/expt_02.0/blkdat.input\n---\n   1.0    'hybthn' = HYBGEN: ratio of layer thicknesses to select the thiner\n   3      'hybmap' = HYBGEN: remapper  flag (0=PCM, 1=PLM,  2=PPM, 3=WENO-like)\n   ...\n   0      'sshflg' = diagnostic SSH flag (0=SSH,1=SSH&amp;stericSSH,2=SSH&amp;stericMONTG)\n---\n\nvim 020.csh\n# type mpi\n===\nC --- Set parallel configuration, see ../README/README.expt_parallel.\nC --- NOMP = number of OpenMP threads, 0 for no OpenMP, 1 for inactive OpenMP\nC --- NMPI = number of MPI    tasks,   0 for no MPI\nC\nswitch ($OS)\ncase 'Linux':\n  setenv NOMP 0\n  setenv NMPI 16\n  breaksw\n\nsetenv A \"a\"\nsetenv B \"b\"\nsetenv Y01 \"011\"\nsetenv YXX \"011\"\n===\n\ncd expt_02.0 &amp;&amp; touch 020y011a.limits &amp;&amp; echo \"-3653.00000  3684.00000\" &gt; 020y011a.limits\n\n# begin to run\nspack load openmpi@4.1.5 %intel\nexport PATH=$PATH:/home/smci/HYCOM-tools/bin\nnohup csh 020.csh &gt;&amp; results.log &amp;\n\n# check if run successfully\ngrep \"^normal stop\" data/summary_out\n</code></pre> <p>config/smci-intel-sm-relo_mpi <pre><code>#\n# ---------------------------------------------------------------------------\n# common definitions for Intel Fortran and MPI, small memory, real*8\n# -fp-model source to maintain bit for bit equality for all NMPI values\n# On IBM iDATAPlex, use the mpi/intel/impi module\n# Emulate SGI Altix ICE on IBM iDataPlex using -xSSE4.2\n# version that uses Serial I/O for HYCOM\n# relocatable version\n# ---------------------------------------------------------------------------\n#\n# MACROS      DESCRIPTIONS:\n#\n# FC:         Fortran 90 compiler.\n# FCFFLAGS:   Fortran 90 compilation flags.\n# CC:         C compiler.\n# CCFLAGS:    C compilation flags.\n# CPP:        cpp preprocessor (may be implied by FC).\n# CPPFLAGS:   cpp -D macro flags.\n# LD:         Loader.\n# LDFLAGS:    Loader flags.\n# EXTRALIBS:  Extra local libraries (if any).\n#\nFC            = mpifort\n#FCFFLAGS      =        -traceback -xSSE4.2 -O3 -fp-model source -r8 -warn nogeneral -mcmodel=small\nFCFFLAGS      = -traceback  -O3 -fp-model source -r8 -warn nogeneral -mcmodel=small\nCC            = icc\n#CCFLAGS       =        -traceback -xSSE4.2 -O -mcmodel=small\nCCFLAGS       = -traceback -O -mcmodel=small\nCPP           = cpp -P\nCPPFLAGS      = -DREAL8 -DMPI -DSERIAL_IO -DENDIAN_IO -DNAN2003 -DTIMER -DRELO $(CPP_EXTRAS)\nLD            = $(FC)\nLDFLAGS       = -V $(FCFFLAGS) -static-intel\nEXTRALIBS     =\n\n#\n# --- generic make definitions\n#\nSHELL         = /bin/sh\nRM            = \\rm -f\n\n#\n# rules.\n#\n\n.c.o:\n        $(CC) $(CPPFLAGS) $(CCFLAGS)  -c $*.c\n\n.F90.o:\n        $(FC) $(CPPFLAGS) $(FCFFLAGS) -c $*.F90\n</code></pre></p>"},{"location":"hackmd/HYCOM/#error","title":"error","text":""},{"location":"hackmd/HYCOM/#run-type-one","title":"run type one","text":""},{"location":"hackmd/HYCOM/#error-in-blkinr-input-hybmap-but-should-be-hybthn","title":"error in blkinr - input hybmap but should be hybthn","text":"<p>https://github.com/HYCOM/HYCOM-src/commit/8d247021484c5cb7f8ded897c1e2020c028ef7e9 edit GLBt0.72/expt_02.0/blkdat.input</p> <pre><code>1.0    'hybthn' = HYBGEN: ratio of layer thicknesses to select the thiner\n3      'hybmap' = HYBGEN: remapper  flag (0=PCM, 1=PLM,  2=PPM, 3=WENO-like)\n</code></pre>"},{"location":"hackmd/HYCOM/#error-neg-depm-1000","title":"error: neg. dep(m) &lt; -10.00","text":"<ul> <li>error: neg. dep(m) &lt; -10.00</li> <li>Error running GLBt0.72</li> </ul> <p>method 1: add dp00x in GLBt0.72/expt_02.0/blkdat.input 100.00   'dp00x ' = deep z-level spacing maximum thickness (m) =&gt; error in blkinr - input dp00x  but should be isotop</p> <p>method 2: change isotop in GLBt0.72/expt_02.0/blkdat.input 83.0    'isotop' = shallowest depth for isopycnal layers (m), &lt;0 from file =&gt; 100.0    'isotop' = shallowest depth for isopycnal layers (m), &lt;0 from file  =&gt; error: neg. dep(m) &lt; -10.00</p> <p>method 3: change sefold in GLBt0.72/expt_02.0/blkdat.input -365.0  'sefold' = e-folding time                  for SSS relaxation (days) =&gt; 0.3  'sefold' = e-folding time                  for SSS relaxation (days) =&gt; error: neg. dp (m) &lt;    -10.00</p> <p>method 4: build hycom with amd-intel-relo_one(copy FCFFLAGS, CCFLAGS, CPPFLAGS from HYCON-tools/config/amdIF_setup) =&gt; error: neg. dp (m) &lt;    -10.00</p>"},{"location":"hackmd/HYCOM/#run-type-mpi","title":"run type mpi","text":""},{"location":"hackmd/HYCOM/#xcspmd-patchinput-for-wrong-nreg","title":"xcspmd: patch.input for wrong nreg","text":"<ul> <li>ATTN: Alan Wallcraft</li> </ul> <p>change the src_2.3.01-17tsig2_relo_mpi/Make.csh <pre><code>setenv OCN_EOS -DEOS_9T  ## EOS  9-term\n#setenv OCN_EOS -DEOS_17T ## EOS 17-term\nsetenv OCN_GLB -DARCTIC ## global tripolar simulation\n#setenv OCN_GLB \"\"\n</code></pre> =&gt; xcspmd: patch.input for wrong nreg</p>"},{"location":"hackmd/HYCOM/#error-in-rdmonth-hit-end-of-input","title":"error in rdmonth - hit end of input","text":"<ul> <li>https://groups.google.com/a/hycom.org/g/forum/c/KWAPIMZFk7U/m/T8ahkU1fEQAJ</li> </ul> <p>blkdat.input <pre><code>0      'sshflg' = diagnostic SSH flag (0=SSH,1=SSH&amp;stericSSH,2=SSH&amp;stericMONTG)\n</code></pre></p>"},{"location":"hackmd/HYCOM/#xcspmd-patchinput-must-be-for-arctic","title":"xcspmd: patch.input must be for arctic,","text":"<p>https://groups.google.com/a/hycom.org/g/forum/c/ywUlB7pSalE/m/2OsN9j5JBQAJ</p>"},{"location":"hackmd/HYCOM/#forrtl-severe-24-end-of-file-during-read-unit-2911-file-homesanyahycomscsp008expt_010datascratchrelaxtempb","title":"forrtl: severe (24): end-of-file during read, unit 2911, file /home/sanya/hycom/SCSp0.08/expt_01.0/data/SCRATCH/./relax.temp.b.","text":"<p>https://groups.google.com/a/hycom.org/g/forum/c/KWA19-48uHg/m/_MYGMGImBAAJ check the datasets/relax if correct soft link</p> <pre><code>cd datasets/relax/ &amp;&amp; unlink 020 &amp;&amp; ln -s 010 020\n</code></pre>"},{"location":"hackmd/HYCOM/#error-in-zaiopf-cant-open-unit-11-for-array-io-cfile-restart_ina","title":"error in zaiopf -  can't open unit  11, for array I/O. cfile = restart_in.a","text":"<p>https://groups.google.com/a/hycom.org/g/forum/c/ccOVIBW2LnM/m/J7S41TCWBgAJ Is this the first month of the run?  If so, the limits file should have a negative (or zero) 1st entry and it is typically from a file like 011y011a.limits. This signals that the initial state is from climatology, not from a restart file.</p> <pre><code>C\nC --- local input files.\nC\nif ( -e /home/smci/HYCOM-examples/GLBt0.72/expt_02.0/data/../020y011a.limits ) then\n/bin/cp /home/smci/HYCOM-examples/GLBt0.72/expt_02.0/data/../020y011a.limits limits\nelse\n\ncat GLBt0.72/expt_02.0/data/limits\n-3653.00000  3684.00000\n\nC\nC --- local input files.\nC\nif ( -e /home/smci/HYCOM-examples/GOMb0.08/expt_02.0/data/../020y011a.limits ) then\necho LIMITS\nawk -f /home/smci/HYCOM-examples/GOMb0.08/expt_02.0/data/../020.awk y01=011 ab=a\nendif\n\ncat GOMb0.08/expt_02.0/data/limits\n     3653.00000     3684.00000\nC\n</code></pre> <pre><code>cd GOMb0.08/expt_02.0 &amp;&amp; touch 020y011a.limits &amp;&amp; echo \"-3653.00000  3684.00000\" &gt; 020y011a.limits\n</code></pre>"},{"location":"hackmd/HYCOM/#amd-cpu-with-intel-compiler","title":"AMD CPU with intel compiler","text":"<p>HYCOM-tools/Make_all.src <pre><code>setenv ARCH amdIF\n</code></pre></p> <p>HYCOM-tools/Make_ncdf.src <pre><code>module unload netcdf-fortran-4.6.0-intel-2021.8.0-5hpf7gh\nmodule unload netcdf-c-4.9.0-intel-2021.8.0-etqveet\nmodule   load netcdf-c-4.9.0-intel-2021.8.0-etqveet\nmodule   load netcdf-fortran-4.6.0-intel-2021.8.0-5hpf7gh\nsetenv NCDFC     /home/smci/spack/opt/spack/linux-rhel8-zen2/intel-2021.8.0/netcdf-c-4.9.0-etqveetgf6tzouaveywcqkxgnqb6ef47\nsetenv NCDF      /home/smci/spack/opt/spack/linux-rhel8-zen2/intel-2021.8.0/netcdf-fortran-4.6.0-5hpf7gh76cytq6q7ob5rymcay3gj6qu3\n</code></pre></p> <p>HYCOM-tools/bin/Make_all.csh HYCOM-tools/bin/Make_ncdf.csh <pre><code>if ($OS == \"Linux\") then\n setenv OS LinuxAIF\n</code></pre></p>"},{"location":"hackmd/HYCOM/#hycom-binary-from-openmpi","title":"hycom binary from openmpi","text":"<p>HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_mpi/Make.csh <pre><code>unset echo\nmodule purge\nmodule load intel-oneapi-compilers-2023.0.0-gcc-8.5.0-7ccmh6l\nmodule load openmpi-4.1.5-intel-2021.8.0-v2iv375\nmodule list\nset echo\nsetenv ARCH intelsse-impi-sm-relo\n</code></pre></p> <p>HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_mpi/config/intelsse-impi-sm-relo_mpi <pre><code>FC            = mpifort\n#FCFFLAGS      =        -traceback -xSSE4.2 -O3 -fp-model source -r8 -warn nogeneral -mcmodel=small\nFCFFLAGS      = -traceback  -O3 -fp-model source -r8 -warn nogeneral -mcmodel=small\nCC            = icc\n#CCFLAGS       =        -traceback -xSSE4.2 -O -mcmodel=small\nCCFLAGS       = -traceback -O -mcmodel=small\nCPP           = cpp -P\nCPPFLAGS      = -DREAL8 -DMPI -DSERIAL_IO -DENDIAN_IO -DNAN2003 -DTIMER -DRELO $(CPP_EXTRAS)\nLD            = $(FC)\nLDFLAGS       = -V $(FCFFLAGS) -static-intel\nEXTRALIBS     =\n\n#\n# --- generic make definitions\n#\nSHELL         = /bin/sh\nRM            = \\rm -f\n\n#\n# rules.\n#\n\n.c.o:\n        $(CC) $(CPPFLAGS) $(CCFLAGS)  -c $*.c\n\n.F90.o:\n        $(FC) $(CPPFLAGS) $(FCFFLAGS) -c $*.F90\n</code></pre></p>"},{"location":"hackmd/HYCOM/#amd-cpu-with-gnu-compiler","title":"AMD CPU with GNU compiler","text":"<p>HYCOM-tools/Make_all.src <pre><code>setenv ARCH amdIF\n</code></pre></p> <p>HYCOM-tools/Make_ncdf.src <pre><code>module unload netcdf-fortran-4.6.0-gcc-8.5.0-inxalsx\nmodule unload netcdf-c-4.9.0-gcc-8.5.0-2qwncum\nmodule   load netcdf-c-4.9.0-gcc-8.5.0-2qwncum\nmodule   load netcdf-fortran-4.6.0-gcc-8.5.0-inxalsx\nsetenv NCDFC     /home/smci/spack/opt/spack/linux-rhel8-zen/gcc-8.5.0/netcdf-c-4.9.0-2qwncumfartt3qrjqpixzxgipxs3hgrq\nsetenv NCDF      /home/smci/spack/opt/spack/linux-rhel8-zen/gcc-8.5.0/netcdf-fortran-4.6.0-inxalsxzrfxb4q4nposghyu44gpw4vuy\n</code></pre></p> <p>HYCOM-tools/bin/Make_all.csh HYCOM-tools/bin/Make_ncdf.csh <pre><code>if ($OS == \"Linux\") then\n setenv OS LinuxGF\n</code></pre></p>"},{"location":"hackmd/HYCOM/#hycom-binary-from-openmpi_1","title":"hycom binary from openmpi","text":"<p>HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_mpi/Make.csh <pre><code>unset echo\nmodule purge\nmodule load openmpi-4.1.5-gcc-8.5.0-uqgr6vy\nmodule list\nset echo\nsetenv ARCH aepyc-gnu-relo\n</code></pre></p> <p>HYCOM-examples/GLBt0.72/src_2.3.01-17tsig2_relo_mpi/config/aepyc-gnu-relo_mpi <pre><code>FC            = mpif90\nFCFFLAGS      = -fPIC -fno-second-underscore -O2 -mavx -m64 -fdefault-real-8 -fdefault-double-8\nCC            = mpicc\nCCFLAGS       = -O -m64\nCPP           = cpp -P\nCPPFLAGS      = -DREAL8 -DMPI -DSERIAL_IO -DENDIAN_IO -DNAN2003 -DTIMER -DRELO $(CPP_EXTRAS)\nLD            = $(FC)\nLDFLAGS       = $(FCFFLAGS)\nEXTRALIBS     =\n\n#\n# --- generic make definitions\n#\nSHELL         = /bin/sh\nRM            = \\rm -f\n\n#\n# rules.\n#\n\n.c.o:\n        $(CC) $(CPPFLAGS) $(CCFLAGS)  -c $*.c\n\n.F90.o:\n        $(FC) $(CPPFLAGS) $(FCFFLAGS) -c $*.F90\n</code></pre></p>"},{"location":"hackmd/HYCOM/#results","title":"results","text":"<p>Note: The following floating-point exceptions are signalling: IEEE_INVALID_FLAG IEEE_UNDERFLOW_FLAG IEEE_DENORMAL STOP (xcstop)</p>"},{"location":"hackmd/InfiniBand/","title":"InfiniBand","text":"<ul> <li>Infiniband</li> <li>\u95dc\u65bcinfiniband \u8ddf\u4e00\u822c\u7db2\u5361\u7684\u5dee\u5225 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>NVIDIA \u767c\u5e03 400G InfiniBand \u7db2\u8def\u5361\uff0c\u524d\u8eab\u70ba Mellanox | XFastest News</li> <li>\u5bb6\u7528\u4e07\u5146\u7f51\u7edc\u6307\u5357 1 - \u4e0d\u5982\u5148\u6765\u4e2a\u6700\u7b80\u5355\u7684100G\u7f51\u7edc - \u77e5\u4e4e</li> <li>users@lists.openhpc.community | Infiniband over slurm</li> <li>Infiniband - HackMD</li> <li>InfiniBand Command Examples</li> <li>openibd and opensm<ul> <li>linux - Ethernet connection is dropped when restarting openibd ( Infiniband ) service - Server Fault</li> </ul> </li> <li>Red Hat Enterprise Linux 8 Configuring InfiniBand and RDMA networks<ul> <li>Chapter\u00a01.\u00a0Understanding InfiniBand and RDMA Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>Chapter\u00a07.\u00a0Testing InfiniBand networks Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> </ul> </li> <li>Commands for InfiniBand Diagnostics - UFM-SDN Appliance UM v4.4.0 - NVIDIA Networking Docs<ul> <li>Diagnostic Tools - UFM-SDN Appliance UM v4.4.0 - NVIDIA Networking Docs</li> <li>InfiniBand Fabric Utilities - MLNX_OFED v5.0-2.1.8.0 - NVIDIA Networking Docs</li> <li>GitHub - linux-rdma/perftest: Infiniband Verbs Performance Tests</li> <li>ib_send_bw (perftest) get ERROR: Couldn't allocate MR failed to create mr \u00b7 Issue #23 \u00b7 zrlio/softiwarp \u00b7 GitHub</li> </ul> </li> <li>Driver<ul> <li>Linux InfiniBand Drivers</li> </ul> </li> <li>Firmware<ul> <li>HowTo Update Firmware for NVIDIA ConnectX-5 or ConnectX-6 Adapter on VMware ESXi 6.5 and above - Solutions - NVIDIA Networking Docs</li> <li>NVIDIA Networking Firmware Downloads</li> </ul> </li> <li>performance<ul> <li>Performance Tuning for Mellanox Adapters</li> </ul> </li> <li>switch<ul> <li>GitHub - stanford-rc/ibswinfo: Command-line tool to retrieve information and monitor Mellanox un-managed Infiniband switches</li> </ul> </li> </ul> <p>InfiniBand refers to two distinct things - The physical link-layer protocol for InfiniBand networks - The InfiniBand Verbs API, an implementation of the remote direct memory access (RDMA) technology     - [Day25] Device Plugin - RDMA</p> <p>RDMA provides access between the main memory of two computers without involving an operating system, cache, or storage. Using RDMA, data transfers with high-throughput, low-latency, and low CPU utilization.</p>"},{"location":"hackmd/InfiniBand/#troubleshoot","title":"Troubleshoot","text":"<ul> <li>ibqueryerrors(8) - Linux man page</li> <li>perfquery(8): query InfiniBand port counters - Linux man page</li> <li>Overview of Error Counters - OpenFabrics Alliance Wiki</li> </ul> <p>To troubleshoot InfiniBand network issues using Mellanox, you can follow these steps and use specific commands:</p> <ol> <li>Verify the Mellanox InfiniBand Network Configuration:</li> <li>Run the command <code>ibstatus</code> to check the overall status of the InfiniBand fabric and the connected nodes.</li> <li>Use <code>ibhosts</code> to view the list of hosts and their corresponding GUIDs (Globally Unique Identifier) in the InfiniBand fabric.</li> <li> <p>Run <code>ibnetdiscover</code> to discover the topology of the InfiniBand fabric and identify any connectivity issues.</p> </li> <li> <p>Check the Link Status and Performance:</p> </li> <li>Use <code>ibstatus</code> to check the link status of the InfiniBand adapters.</li> <li>Run <code>ibcheckstate -l</code> to check the state of the links in the fabric.</li> <li>Use <code>iblinkinfo</code> to gather information about the state and quality of the links in the InfiniBand fabric.</li> <li> <p>Run <code>ibdiagnet</code> to perform a comprehensive diagnostic test on the InfiniBand fabric, including link and cable testing.</p> </li> <li> <p>Analyze Performance and Latency:</p> </li> <li>Use <code>ibperf</code> to measure the throughput and latency of the InfiniBand fabric.</li> <li>Run <code>ib_read_bw</code> and <code>ib_write_bw</code> to measure the read and write bandwidth respectively.</li> <li>Use <code>ib_read_lat</code> and <code>ib_write_lat</code> to measure the read and write latency respectively.</li> <li> <p>Run <code>perfquery</code> to obtain performance counters from the InfiniBand adapters.</p> </li> <li> <p>Diagnose Errors and Issues:</p> </li> <li>Use <code>ibcheckerrors</code> to check for any InfiniBand-specific errors and correctable errors.</li> <li>Run <code>ibdiagnet</code> to perform a comprehensive diagnostic test and identify potential issues within the fabric.</li> <li>Use <code>ibstat</code> and <code>iblinkinfo</code> to check for any link errors or problems with the InfiniBand adapters.</li> </ol> <pre><code>ibstat\nsudo ibnodes\nsudo ibswitches\nsudo ibnetdiscover\nsudo iblinkinfo\nsudo perfquery -a 14\nsudo ibqueryerrors --report-port --data\nsudo ibqueryerrors --counters\n</code></pre> <pre><code>sudo sminfo\nibv_devices\nibv_devinfo -d mlx5_0\nibstatus\nibstat\nibstat mlx5_0\nsudo ibqueryerrors\nsudo ibqueryerrors --counters\nsudo ibnetdiscover\nsudo ibnodes\nsudo perfquery -a 14\nsudo smpquery nodeinfo 14\nsudo smpquery portinfo 14 1\nibportstate\nsudo ibswitches\n</code></pre> <p>command not found  <pre><code>ibcheckstate\nibdiagnet\nibperf\nibcheckerrors\n</code></pre></p> <p>test bandwidth \u7b2c\u4e00\u500b\u662fserver \u7b2c\u4e8c\u500b\u662fclient, \u5728client\u6307\u5b9aserver <pre><code>ib_read_bw -a -R -z -d mlx5_0 \nib_read_bw -a -R -z -d mlx5_0 167.123.200.1\n</code></pre></p> <p>check current NIC driver version and firmware version ``` bash= interface_name=ib0 driver_version=$(ethtool -i ${interface_name} | grep version | head -n 1 | awk '{print $2}') firmware_version=$(ethtool -i ${interface_name} | grep firmware-version | awk '{print $2}') <pre><code>install the nic driver\n``` bash\n# install the nic driver\nos=LINUX\nvendor=MLNX_OFED\ninstall_driver_version=5.4-3.6.8.1\ninstall_driver_version_full=${vendor}_${os}-${install_driver_version}\ndistribution_name=$(cat /etc/os-release | grep ID= | head -n 1 | awk -F = '{print $2}' | tr -d '\"')\ndistribution_version=$(cat /etc/os-release | grep VERSION_ID= | awk -F = '{print $2}' | tr -d '\"')\ndistribution=${distribution_name}${distribution_version}\nplatform=$(uname -m)\n\nwget https://content.mellanox.com/ofed/${vendor}-${install_driver_version}/${install_driver_version_full}-${distribution}-${platform}.tgz\ntar zxvf ${install_driver_version_full}-${distribution}-${platform}.tgz &amp;&amp; cd ${install_driver_version_full}-${distribution}-${platform}/\nsudo ./mlnxofedinstall --force --with-nfsrdma --add-kernel-support\n# To load the new driver, run:\nsudo /etc/init.d/openibd restart\n</code></pre></p> <p>install the nic firmware <pre><code># install the nic firmware\npci_bus_id=81:00.0\ninstall_firmware_version=16_25_1020\nordering_part_numbers=MCX516A-CCA\nfirmware_name=fw-ConnectX5-rel-${install_firmware_version}-${ordering_part_numbers}_Ax-UEFI-14.18.19-FlexBoot-3.5.701.bin\nwget -Nq -O ${firmware_name}.zip http://www.mellanox.com/downloads/firmware/${firmware_name}.zip\nunzip -o ${firmware_name}.zip\nsudo mstflint -d ${pci_bus_id} -i ${firmware_name} -y b\n# reset fw\nsudo mstfwreset -d ${pci_bus_id} -y r\n</code></pre></p> <p>MTU Here are the instructions of changing the mtu for the InfiniBand network. Document: https://linux.die.net/man/8/opensm, https://docs.nvidia.com/networking/display/MLNXOFEDv461000/OpenSM</p> <p>Modified the OpenSM partitions configuration file. This operation only needs to be done on the node that has <code>opensm</code>. Changing the value of mtu from 4 to 5. </p> <pre><code>$ vim /etc/rdma/partitions.conf\n\n# mtu =\n#   1 = 256\n#   2 = 512\n#   3 = 1024\n#   4 = 2048\n#   5 = 4096\n#\n# rate =\n#   2  = 2.5   GBit/s (SDR 1x)\n#   3  =  10   GBit/s (SDR 4x/QDR 1x)\n#   4  =  30   GBit/s (SDR 12x)\n#   5  =   5   GBit/s (DDR 1x)\n#   6  =  20   GBit/s (DDR 4x)\n#   7  =  40   GBit/s (QDR 4x)\n#   8  =  60   GBit/s (DDR 12x)\n#   9  =  80   GBit/s (QDR 8x)\n#   10 = 120   GBit/s (QDR 12x)\n# If ExtendedLinkSpeeds are supported, then these rate values are valid too\n#   11 =  14   GBit/s (FDR 1x)\n#   12 =  56   GBit/s (FDR 4x)\n#   13 = 112   GBit/s (FDR 8x)\n#   14 = 168   GBit/s (FDR 12x)\n#   15 =  25   GBit/s (EDR 1x)\n#   16 = 100   GBit/s (EDR 4x)\n#   17 = 200   GBit/s (EDR 8x)\n#   18 = 300   GBit/s (EDR 12x)\n\nDefault=0x7fff, rate=3, mtu=5, scope=2, defmember=full:\n        ALL, ALL_SWITCHES=full;\nDefault=0x7fff, ipoib, rate=3, mtu=5, scope=2:\n</code></pre> <pre><code># restart the opensm\n$ sudo systemctl restart opensm\n\n# ensure the opensm is working\n$ sudo systemctl status opensm\n\n# ensure the mtu becomes 4096\n$ ip a\n</code></pre>"},{"location":"hackmd/InfiniBand/#unmanaged-switch","title":"Unmanaged Switch","text":"<ul> <li>NVIDIA Firmware Tools (MFT)<ul> <li>Firmware update on Mellonox adapter fails on SLES 15 SP3 using MLNX OFED 4.9-3 and later releases</li> </ul> </li> <li>SX6025 unmanaged switch firmware update - Switches and Gateways / InfiniBand/VPI Switch Systems - NVIDIA Developer Forums</li> <li>How to retrieve the PSID and firmware version of HCA or Unmanaged Switches</li> </ul> <pre><code>ibswitches\nflint -d lid-103 q\n</code></pre>"},{"location":"hackmd/KVM/","title":"KVM","text":"<ul> <li>\u7b2c 1 \u985e\u8207\u7b2c 2 \u985e Hypervisor - Hypervisor \u985e\u578b\u4e4b\u9593\u7684\u5340\u5225 - AWS</li> <li>GitHub - 0voice/kernel_awsome_feature: \u6df1\u5165\u7814\u7a76 kvm,ceph,fuse\u7279\u6027<ul> <li>kernel_awsome_feature/KVM</li> </ul> </li> <li>\u4ec0\u9ebc\u662f KVM\uff1f - \u8aaa\u660e Kernel \u865b\u64ec\u6a5f\u5668 - AWS</li> <li>KVM: Linux \u865b\u64ec\u5316\u57fa\u790e\u5efa\u8a2d - HackMD</li> <li>How to Create Virtual Machines in Linux Using KVM (Kernel-based Virtual Machine) - Part 1</li> <li>Ubuntu\u5b89\u88ddQEMU/KVM\u548cVirt Manager\u865b\u64ec\u6a5f\u7ba1\u7406\u54e1 \u00b7 Ivon\u7684\u90e8\u843d\u683c<ul> <li>CentOS 7 \u5b89\u88dd KVM/QEMU \u865b\u64ec\u6a5f\u5668\u6559\u5b78 \u2013 G. T. Wang</li> </ul> </li> <li>Linux KVM\u555f\u7528\u5de2\u72c0\u865b\u64ec\u5316\uff0c\u5728\u865b\u64ec\u6a5f\u88e1\u9762\u8dd1\u865b\u64ec\u6a5f \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>\u514dMac\u96fb\u8166\uff0cOSX-KVM\u8b93\u4f60\u5728Linux\u7cfb\u7d71\u5b89\u88ddmacOS\u7684QEMU\u865b\u64ec\u6a5f \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> <p>KVM QEMU virtio(para virtualization)</p> <p>KVM/QEMU KVM/virtio (para virtualization)</p> <p>Intel VT-x AMD AMD-V</p> <p>three mode - user - kernel - guest</p> <p>libvirt </p>"},{"location":"hackmd/KVM/#ubuntu","title":"Ubuntu","text":"<ul> <li>KVM hypervisor: a beginners\u2019 guide | Ubuntu</li> <li>Install KVM On Ubuntu 22.04 Server - OSTechNix</li> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u4e8c\u7ae0\u3001\u7b2c\u4e00\u500b\u865b\u64ec\u6a5f\u5668\u7684\u5b89\u88dd\u8207\u8abf\u6574</li> <li>\u5728 ubuntu \u5be6\u9ad4\u6a5f\u5b89\u88dd ubuntu VM \u7684\u6d41\u7a0b - HackMD</li> <li>Virtual Machine Manager | Ubuntu</li> <li>kvm virtualization - How to install Ubuntu 22.04 as GUEST in KVM - Ask Ubuntu</li> <li>Web or GUI<ul> <li>Web-based interface for KVM / QEMU VM management? : r/selfhosted</li> <li>How to Install a Desktop (GUI) on an Ubuntu Server<ul> <li>Virt Manager SSH\u9023\u7dda\u5230\u9060\u7aefQEMU/KVM\u865b\u64ec\u6a5f\u7684\u684c\u9762 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> <li>Managing KVM Virtual Machines with Cockpit Web Console in Linux<ul> <li>How to manage virtual machines in Cockpit | Enable Sysadmin</li> <li>Cockpit\u6559\u5b78\uff1a\u7528\u7db2\u9801\u700f\u89bd\u5668\u7ba1\u7406QEMU/KVM\u865b\u64ec\u6a5f\uff0c\u66ff\u4ee3Virt Manager \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> <li>Proxmox VE<ul> <li>How To Install Proxmox on Ubuntu (The only way\u2026) \u2013 RaspberryTips</li> <li>Self Host with IPv6rs - IPv6 Provider - How to Install Proxmox VE on Ubuntu Server Latest</li> <li>Using netboot.xyz to boot to (and install) Proxmox : r/homelab<ul> <li>GitHub - cjlittle/netboot.xyz-proxmox: Configuration scripts and procedure for adding Proxmox VE to netboot.xyz.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>if the node is the vmware vm, enable \"\u5411\u5ba2\u9ad4\u4f5c\u696d\u7cfb\u7d71\u516c\u958b\u786c\u9ad4\u5354\u52a9\u865b\u64ec\u5316\" in \"\u786c\u9ad4\u865b\u64ec\u5316\"</p> <pre><code>sudo apt-get -y install bridge-utils cpu-checker libvirt-clients libvirt-daemon qemu qemu-kvm\nsudo kvm-ok\nlsmod | grep kvm\nmodinfo kvm\nmodinfo kvm_amd\nsystemctl status libvirtd\n</code></pre> <pre><code>virsh list --all\nsudo apt-get -y install virt-manager\n</code></pre> <p>GUI <pre><code>sudo apt-get install slim ubuntu-desktop\nsudo reboot\nsystemctl status slim.service\n</code></pre></p> <p>Web Console <pre><code>sudo apt-get install cockpit cockpit-machines\n# for error \"sscg: command not found\"\nsudo apt-get install libgnutls-openssl27\n\nsudo systemctl start cockpit\nsudo systemctl status cockpit\nsudo ufw allow 9090/tcp\nsudo ufw reload\n</code></pre></p> <p>For Ubuntu guest <pre><code>wget https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img\ncp jammy-server-cloudimg-amd64.img /var/lib/libvirt/images/\nqemu-img create -F qcow2 -b jammy-server-cloudimg-amd64.img -f qcow2 my-ubuntu-vm.img 10G\ncp my-ubuntu-vm.img /var/lib/libvirt/images/\n\nvirt-install --name my-first-vm --ram 6144 --vcpus 2 --import --disk path=/var/lib/libvirt/images/my-ubuntu-vm.img,format=qcow2 --cloud-init root-password-generate=on,disable=on,meta-data=/root/meta-data,user-data=/root/user-data --os-variant ubuntu22.04 --network bridge=virbr0 --graphics vnc,listen=0.0.0.0 --console pty,target_type=serial --noautoconsole\n\nvirsh net-dhcp-leases default\n</code></pre></p> <p>meta-data <pre><code># meta-data\ninstance-id: my-ubuntu-vm\nlocal-hostname: my-ubuntu-vm\n</code></pre></p> <p>user-data - https://bugs.launchpad.net/cloud-images/+bug/2049860/comments/15 <pre><code>#cloud-config\nssh_pwauth: true\nusers:\n  - name: root\n    lock_passwd: false\n    hashed_passwd: $6$P2LlhzIYWXC4XyCa$JzSWM6UBQ3BNLtQXO2jKTIhkBQyNl8DuhJ6tx8kovCtiick0mXMWE6z12HGBhTzAPW0EpDglWn7j.W9XZoaBl0\n  - name: ubuntu\n    lock_passwd: false\n    hashed_passwd: $6$P2LlhzIYWXC4XyCa$JzSWM6UBQ3BNLtQXO2jKTIhkBQyNl8DuhJ6tx8kovCtiick0mXMWE6z12HGBhTzAPW0EpDglWn7j.W9XZoaBl0\n    shell: /bin/bash\n    sudo: ALL=(ALL) NOPASSWD:ALL\n</code></pre> :::info \\$6\\$P2LlhzIYWXC4XyCa$JzSWM6UBQ3BNLtQXO2jKTIhkBQyNl8DuhJ6tx8kovCtiick0mXMWE6z12HGBhTzAPW0EpDglWn7j.W9XZoaBl0 =&gt;  foo@123</p> <p>from openssl passwd -6 foo@123 :::</p>"},{"location":"hackmd/KVM/#redhat","title":"Redhat","text":"<ul> <li>Chapter\u00a08.\u00a0Preparing and deploying a KVM Guest Image by using RHEL image builder | Red Hat Product Documentation<ul> <li>Composing a customized RHEL system image | Red Hat Product Documentation</li> <li>3.2.\u00a0Creating Guests with virt-install | Red Hat Product Documentation</li> </ul> </li> <li>\ud83d\udc27Linux_RH134_09_\u5b89\u88ddRHEL - HackMD</li> </ul>"},{"location":"hackmd/KVM/#for-redhat-guest","title":"For redhat guest","text":"<ol> <li>fetch Red Hat Enterprise Linux x.x KVM Guest Image<ul> <li>example: <code>rhel-8.8-x86_64-kvm.qcow2</code></li> </ul> </li> <li>Creating a virtual machine from a KVM guest image</li> </ol> <pre><code>mkdir cloudinitiso\ncd cloudinitiso\n</code></pre> <p>meta-data <pre><code>instance-id: citest\nlocal-hostname: vm-rhel\n</code></pre></p> <p>user-data <pre><code>#cloud-config\nssh_pwauth: true\nusers:\n  - name: root\n    lock_passwd: false\n    hashed_passwd: $6$P2LlhzIYWXC4XyCa$JzSWM6UBQ3BNLtQXO2jKTIhkBQyNl8DuhJ6tx8kovCtiick0mXMWE6z12HGBhTzAPW0EpDglWn7j.W9XZoaBl0\n  - name: rhel\n    lock_passwd: false\n    hashed_passwd: $6$P2LlhzIYWXC4XyCa$JzSWM6UBQ3BNLtQXO2jKTIhkBQyNl8DuhJ6tx8kovCtiick0mXMWE6z12HGBhTzAPW0EpDglWn7j.W9XZoaBl0\n    shell: /bin/bash\n    sudo: ALL=(ALL) NOPASSWD:ALL\n</code></pre></p> <pre><code>cp rhel-8.8-x86_64-kvm.qcow2 /var/lib/libvirt/images/\nqemu-img create -F qcow2 -b rhel-8.8-x86_64-kvm.qcow2 -f qcow2 my-rhel-vm.img 20G\nmv my-rhel-vm.img /var/lib/libvirt/images/\n</code></pre> <p>method 1: use cloud-init.iso <pre><code>genisoimage -output cloud-init.iso -volid cidata -joliet -rock user-data meta-data\ncp cloudinitiso/cloud-init.iso /var/lib/libvirt/images/\nvirt-install \\\n    --memory 4096 \\\n    --vcpus 4 \\\n    --name myvm \\\n    --disk /var/lib/libvirt/images/my-rhel-vm.img,device=disk,bus=virtio,format=qcow2 \\\n    --disk /var/lib/libvirt/images/cloud-init.iso,device=cdrom \\\n    --os-variant rhel8.8 \\\n    --virt-type kvm \\\n    --graphics vnc,listen=0.0.0.0 \\\n    --console pty,target_type=serial \\\n    --noautoconsole \\\n    --import\n</code></pre></p> <p>method 2: use --cloud-init argument <pre><code>virt-install  \\\n    --memory 4096  \\\n    --vcpus 4  \\\n    --name myvm2  \\\n    --disk /var/lib/libvirt/images/my-rhel-vm.img,device=disk,bus=virtio,format=qcow2  \\\n    --cloud-init root-password-generate=on,disable=on,meta-data=/root/cloudinitiso/meta-data,user-data=/root/cloudinitiso/user-data  \\\n    --os-variant rhel8.8  \\\n    --virt-type kvm  \\\n    --graphics vnc,listen=0.0.0.0  \\\n    --console pty,target_type=serial  \\\n    --noautoconsole  \\\n    --import\n</code></pre></p>"},{"location":"hackmd/KVM/#command","title":"command","text":"<ul> <li>Ubuntu Cloud Images - the official Ubuntu images for public clouds, Openstack, KVM and LXD</li> <li>\u7b2c\u00a04\u00a0\u7ae0\u00a0\u914d\u7f6e cloud-init | Red Hat Product Documentation</li> <li>Creating a VM using Libvirt, Cloud Image and Cloud-Init | Sumit\u2019s Space<ul> <li>Headless KVM install is not working - Installation - Home Assistant Community</li> </ul> </li> <li>Use Ubuntu Server Cloud Image to Create a KVM Virtual Machine with Fixed Network Properties | by Yu Ping | Medium</li> <li>Cloud Images with KVM (cloud-init) | \u5922\u60f3\u5bb6</li> <li>How to Install Ubuntu 22.04 Virtual Machine on KVM</li> <li>virt-install --cloud-init support | Cole Robinson<ul> <li>virt-manager/man/virt-install.rst at main \u00b7 virt-manager/virt-manager \u00b7 GitHub</li> <li>virt-install with cloud-init \u2022 Amit Agarwals Linux Blog</li> <li>15 virt-install examples | KVM virtualization commands cheatsheet | GoLinuxCloud</li> <li>3.2.\u00a0Creating Guests with virt-install | Red Hat Product Documentation</li> </ul> </li> </ul>"},{"location":"hackmd/KVM/#network","title":"network","text":"<ul> <li>libvirt: Virtual Networking<ul> <li>16.04 - port unreachable on pings from guest VM to internet. (KVM Virt-Manager default NAT network) - Ask Ubuntu</li> </ul> </li> <li>kernel_awsome_feature/KVM\u865a\u62df\u673a\u7f51\u7edc\u7ba1\u7406\u5b9e\u6218.md</li> <li>Bridged network \u2014 libvirt Networking Handbook \u2014 Jamie Nguyen</li> <li>How to set up a network bridge for virtual machine communication | Enable Sysadmin</li> <li>\u8a2d\u5b9a Ubuntu \u4e0b KVM \u7684 Bridge Networking \u00bb j7 \u788e\u5538\u4eba\u751f</li> <li>Set up Network Bridge on Ubuntu 22.04 - Full Guide - OrcaCore</li> <li>\u5c07Linux\u7684QEMU/KVM\u7db2\u8def\u8a2d\u5b9a\u70ba\u6a4b\u63a5\u6a21\u5f0f\uff0c\u8b93\u5916\u7db2\u53ef\u4ee5\u9023\u7dda\u5230\u865b\u64ec\u6a5f \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>How to Connect KVM VM to Host Network? \u2013 GetLabsDone</li> <li>Setting up UEFI HTTP boot with libvirt | Enable Sysadmin</li> </ul> <pre><code>virsh net-list --all\n</code></pre>"},{"location":"hackmd/Kubernetes/","title":"Kubernetes","text":"<ul> <li>\u597d\u6587\u5171\u8cde - How Kubernetes And Kafka Will Get You Fired - MyApollo</li> <li>CNCF Certified Kubernetes Administrator (CKA) \u8b49\u7167\u5fc3\u5f97 - Jasper Sui | Home</li> <li>\u5f9e\u984c\u76ee\u4e2d\u5b78\u7fd2k8s :: \u7b2c 12 \u5c46 iThome \u9435\u4eba\u8cfd</li> <li>Head-first k8s</li> <li>Kubernetes \u7c21\u4ecb - Huan-Lin \u5b78\u7fd2\u7b46\u8a18</li> <li>Ivan on Containers, Kubernetes, and Backend Development<ul> <li>Kubernetes Basics: Understanding Pods, Deployments, and Services</li> <li>Service Discovery in Kubernetes: Combining the Best of Two Worlds</li> </ul> </li> <li>\u6539\u9032\u5bb9\u5668\u5316\u90e8\u7f72 - \u6210\u529f\u5c0e\u5165 K8S \u7684\u7d93\u9a57\u8207\u6311\u6230.pdf - Google \u96f2\u7aef\u786c\u789f</li> <li>GitHub - Mozart4242/kubernetes-real-world: This is your kubernetes dream that WILL come true, a Real-World Kubernetes cluster with needed production enterprise services.</li> <li>\u89e3\u6c7aK8s\u7db2\u8def\u5b9a\u5740\u7f3a\u9677\u3000Antrea Egress\u5f9e\u982d\u5b78(\u4e00) | \u7db2\u7ba1\u4eba</li> <li>Kubernetes \u90e8\u7f72\u5728\u865b\u6a5f\u597d\u9084\u662f\u88f8\u6a5f\u597d? - \u9b42\u7cfb\u67b6\u69cb Phil's Workspace</li> <li>Kubernetes \u6982\u89c0 - iT \u90a6\u5e6b\u5fd9</li> <li>Automate All the Boring Kubernetes Operations with Python | Martin Heinz | Personal Website &amp; Blog</li> <li>\u4ece Helm \u5230 Operator\uff1aKubernetes\u5e94\u7528\u7ba1\u7406\u7684\u8fdb\u5316 | crossoverJie's Blog</li> <li>\u5982\u4f55 Debug Kubernetes Pod - Yowko's Notes</li> <li>The Containerization Tech Stack | Medium</li> <li>Day 20- Kubernetes \u4e2d\u7684\u547d\u540d\u7a7a\u9593\u8207\u8cc7\u6e90\u9694\u96e2 - iT \u90a6\u5e6b\u5fd9</li> <li>Test<ul> <li>\u5982\u4f55\u5bf9 kubernetes \u5e94\u7528\u505a e2e(\u7aef\u5230\u7aef) \u6d4b\u8bd5 | crossoverJie's Blog</li> </ul> </li> <li>log<ul> <li>\u5728 kubernetes \u73af\u5883\u4e0b\u5982\u4f55\u91c7\u96c6\u65e5\u5fd7 | crossoverJie's Blog</li> </ul> </li> <li>Lens<ul> <li>[\u63a8\u85a6] Kubernetes (k8s) GUI \u7ba1\u7406\u5de5\u5177 \u2013 Lens | \u8f9b\u6bd4\u8a8c</li> </ul> </li> <li>VMWare Tanzu<ul> <li>\u5168\u529f\u80fdTanzu\u793e\u7fa4\u7248\u958b\u7bb1\u3000\u6f14\u7df4K8s\u53e2\u96c6\u90e8\u7f72\u7ba1\u7406 | \u7db2\u7ba1\u4eba</li> <li>\u4eca\u5929\u4e0d\u8ac7\u6280\u8853\uff1a\u8ac7\u65b0\u540d\u5b57. \u8a71\u8aaa\u6700\u8fd1VMware\u91cb\u51fa\u4e86\u4e00\u5927\u5806\u7684\u65b0\u540d\u7a31\uff0c\u4f30\u8a08\u5927\u5bb6\u61c9\u8a72\u90fd\u660f\u982d\u4e86\u5427\uff1f\u7528\u9019\u500b\u6a5f\u6703\uff0c\u6211\u2026 | by Shawn Ho | \u8f15\u9b06\u5c0f\u54c1-k8s\u7684\u9ede\u6ef4 | Medium</li> </ul> </li> <li>monitor<ul> <li>k8s \u4e91\u539f\u751f\u5e94\u7528\u5982\u4f55\u63a5\u5165\u76d1\u63a7 | crossoverJie's Blog</li> </ul> </li> <li>HPC<ul> <li>Orchestrating Kubernetes Clusters on HPC Infrastructure - Elia Oggian - YouTube</li> <li>The Pros and Cons of Kubernetes for HPC - HPCwire</li> <li>The Convergence of HPC, AI and Cloud</li> <li>Kubernetes and Batch</li> <li>Is there anything like SLURM for k8s/eks (machine learning GPU workloads) : r/kubernetes</li> <li>Introducing SUNK: A Slurm on Kubernetes Implementation for HPC and Large Scale AI \u2014 CoreWeave<ul> <li>SUNK: Slurm on Kubernetes (Presented by Navarre Pratt at Supercomputing) - YouTube</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Kubernetes/#awesome-ref","title":"Awesome Ref","text":"<ul> <li>:star:\u5f9eSoftware Developer\u7684\u89d2\u5ea6\u4e00\u8d77\u8a8d\u8b58 Kubernetes :: 2023 iThome \u9435\u4eba\u8cfd<ul> <li>Day-20-Kubernetes_\u77e5\u8b58\u56de\u9867 \u8207 \u5e38\u7528\u5de5\u5177\u5206\u4eab - iT \u90a6\u5e6b\u5fd9</li> <li>Kubernetes Resource Map (Resource \uae30\ub2a5 \uc601\uc5ed\ubcc4)</li> <li>Day-19-Kubernetes_\u9664\u932f\u601d\u8def\u5206\u4eab - iT \u90a6\u5e6b\u5fd9</li> </ul> </li> <li>:star:\u5f9eSoftware Developer\u7684\u89d2\u5ea6\u4e00\u8d77\u8a8d\u8b58 Kubernetes (\u4e8c) :: 2024 iThome \u9435\u4eba\u8cfd</li> <li>Albert Weng for K8S</li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e00\uff09\u539f\u7406\u4ecb\u7d39 | Cheng-Wei Hu<ul> <li>The Containerization Tech Stack | Medium</li> </ul> </li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e8c\uff09\u5be6\u4f5c\u7bc4\u4f8b\uff1aPod\u3001Service\u3001Deployment\u3001Ingress | Cheng-Wei Hu</li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e09\uff09Helm \u4ecb\u7d39\u8207\u5efa\u7acb Chart | Cheng-Wei Hu</li> <li>CKA<ul> <li>:star:\u5165\u9580 Kubernetes \u5230\u8003\u53d6 CKA \u8b49\u7167 :: 2024 iThome \u9435\u4eba\u8cfd<ul> <li>GitHub - michaelchen1225/CKA-note</li> <li>CKA-note/\u9644\u9304/CKA \u5e38\u7528\u7684\u5b98\u65b9\u6587\u4ef6</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Kubernetes/#network","title":"Network","text":"<ul> <li>ClusterIP vs NodePort vs LoadBalancer: Key Differences &amp; When to Use</li> </ul>"},{"location":"hackmd/Kubernetes/#cpu-limit","title":"CPU limit","text":"<ul> <li>Kubernetes CPU limits are not intuitive at all</li> </ul>"},{"location":"hackmd/Kubernetes/#volume-pv-pvc-storageclass","title":"Volume, PV, PVC, StorageClass","text":"<ul> <li>Day 13 -\u3010Storage\u3011\uff1aVolume \u7684\u4e09\u7a2e\u57fa\u672c\u61c9\u7528 --- emptyDir\u3001hostPath\u3001configMap &amp; secret<ul> <li>Day 14 -\u3010Storage\u3011\uff1a PV\u3001PVC &amp; StorageClass</li> </ul> </li> <li>Day26 \u4e86\u89e3 K8S \u7684 Volumes &amp; StorageClass</li> </ul>"},{"location":"hackmd/Kubernetes/#cloud-native-storage-orchestrator","title":"cloud-native storage orchestrator","text":"<ul> <li>Quickstart - Rook Ceph Documentation<ul> <li>Block Storage Overview</li> <li>Filesystem Storage Overview</li> <li>Object Storage Overview</li> <li>Install storage in your application cluster using Rook | Red Hat Developer</li> </ul> </li> <li>Longhorn Overview | Rancher<ul> <li>Longhorn \u2014 \u96f2\u539f\u751f\u5132\u5b58\u7cfb\u7d71\u8a66\u73a9\uff08\u4e0a\uff09 | Cloud Solutions</li> <li>Longhorn \u2014 \u96f2\u539f\u751f\u5132\u5b58\u7cfb\u7d71\u8a66\u73a9\uff08\u4e2d\uff09 | Cloud Solutions</li> <li>Longhorn \u2014 \u96f2\u539f\u751f\u5132\u5b58\u7cfb\u7d71\u8a66\u73a9\uff08\u4e0b\uff09 | Cloud Solutions</li> </ul> </li> </ul>"},{"location":"hackmd/Kubernetes/#rbac","title":"RBAC","text":"<ul> <li>Using RBAC Authorization | Kubernetes</li> <li>Kubernetes RBAC Overview\uff1a\u8ce6\u4e88\u5b89\u5168\u8207\u5f48\u6027\u7684\u7ba1\u7406\uff5c\u65b9\u683c\u5b50 vocus</li> <li>Day 19 - \u8001\u95c6\uff01\u6211\u53ef\u4ee5\u505a\u4ec0\u9ebc\uff1aRBAC - iT \u90a6\u5e6b\u5fd9</li> <li>\u3010\u5f9e\u984c\u76ee\u4e2d\u5b78\u7fd2k8s\u3011-\u3010Day20\u3011\u7b2c\u5341\u4e8c\u984c - RBAC - iT \u90a6\u5e6b\u5fd9</li> <li>How to bind a Kubernetes Role to a user or group | LabEx</li> <li>Limiting access to Kubernetes resources with RBAC</li> </ul> <p>Role \u662f\u7528\u4f86\u5b9a\u7fa9\u5728\u67d0\u500b\u547d\u540d\u7a7a\u9593\u5e95\u4e0b\u7684\u89d2\u8272\uff0c\u800c ClusterRole \u5247\u662f\u5c6c\u65bc\u53e2\u96c6\u901a\u7528\u7684\u89d2\u8272 ClusterRole \u9664\u4e86\u53ef\u4ee5\u914d\u7f6e Role \u7684\u6b0a\u9650\u5167\u5bb9\u5916\uff0c\u7531\u65bc\u662f Cluster \u7bc4\u570d\u7684\u89d2\u8272\uff0c\u56e0\u6b64\u9084\u80fd\u5920\u914d\u7f6e</p> <ul> <li>\u53e2\u96c6\u7bc4\u570d\u7684\u8cc7\u6e90\uff0c\u4f8b\u5982 Nodes</li> <li>\u975e\u8cc7\u6e90\u985e\u578b\u7684 endpoints\uff0c\u4f8b\u5982 /healthz</li> <li>\u8de8\u547d\u540d\u7a7a\u9593\u7684\u8cc7\u6e90\uff0c\u4f8b\u5982 kubectl get pods --all-namespace</li> </ul>"},{"location":"hackmd/Kubernetes/#resource-quota","title":"Resource Quota","text":"<ul> <li>Kubernetes: Limit GPU resource usage for a namespace | Bright Cluster Manager Knowledge Base</li> </ul>"},{"location":"hackmd/Kubernetes/#minikube","title":"minikube","text":"<ul> <li>minikube start | minikube</li> </ul>"},{"location":"hackmd/Kubernetes/#kind","title":"kind","text":"<ul> <li>[DAY6]\u5f9e0\u958b\u59cb\u88ddk8s(1)-kind - iT \u90a6\u5e6b\u5fd9</li> </ul>"},{"location":"hackmd/Kubernetes/#rancher","title":"Rancher","text":"<ul> <li>Day 2 - \u4f55\u8b02 Rancher | hwchiu learning note</li> <li>How to use Rancher in Kubernetes</li> <li>(55) [Rancher] \u7528\u7db2\u9801\u5efa\u7acb\u4e26\u7ba1\u7406K8s Cluster - YouTube</li> </ul>"},{"location":"hackmd/Kubernetes/#helm","title":"Helm","text":"<ul> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e09\uff09Helm \u4ecb\u7d39\u8207\u5efa\u7acb Chart | Cheng-Wei Hu</li> <li>Day20 - \u4f7f\u7528 Helm \u7ba1\u7406 Kubernetes \u7684\u61c9\u7528\u4f48\u7f72 - iT \u90a6\u5e6b\u5fd9</li> <li>Kubernetes \u9047\u898b Helm charts - iT \u90a6\u5e6b\u5fd9</li> <li>\u53ef\u89c0\u6e2c\u6027\u5b87\u5b99\u7684\u7b2c\u4e5d\u5929 - Helm \u5b89\u88dd\u5305\u7ba1\u7406\u5668\u4ecb\u7d39 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>Day 21- Kubernetes \u7684\u5957\u4ef6\u7ba1\u7406\u5de5\u5177 Helm - iT \u90a6\u5e6b\u5fd9<ul> <li>example: Kubernetes Dashboard<ul> <li>Day 29- \u4f7f\u7528 Kubernetes Dashboard \u5716\u5f62\u4ecb\u9762\u7ba1\u7406 Cluster - iT \u90a6\u5e6b\u5fd9</li> </ul> </li> <li>example: mysql<ul> <li>Day 24 Package Manager for Kubernetes - Helm &amp; \u7528 Helm \u5b89\u88dd MySQL Cluster - iT \u90a6\u5e6b\u5fd9</li> </ul> </li> </ul> </li> <li>Day 3 - Helm \u4ecb\u7d39 - iT \u90a6\u5e6b\u5fd9</li> <li>kubernetes - HELM vs K8s Operators - Stack Overflow</li> <li>Operator vs. Helm: Finding the Best Fit for Your Kubernetes Applications | Datadog</li> <li>Helm | Cheat Sheet</li> <li>https://artifacthub.io/<ul> <li>Bitnami</li> </ul> </li> <li>repository<ul> <li>https://charts.helm.sh/stable</li> <li>https://helm.ngc.nvidia.com/nvidia</li> <li>https://prometheus-community.github.io/helm-charts</li> </ul> </li> </ul> <pre><code>helm version\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo list\nhelm install my-nginx bitnami/nginx\n# helm upgrade -n poc-scope --install  my-nginx bitnami/nginx\nhelm list -A\nhelm list -n poc-scope\nhelm status my-nginx\nhelm history my-nginx\nhelm uninstall my-nginx\n</code></pre> <p>\u5982\u679c\u8981\u8986\u5beb\uff0cvalues.yaml \u7684\u8a2d\u5b9a\u53ef\u4ee5\u900f\u904e <code>-f</code> \u65b9\u5f0f\u6307\u5b9a\u8986\u84cb\u9810\u8a2d values.yaml \u914d\u7f6e\u6216\u662f\u4f7f\u7528 <code>--set</code> \u8986\u5beb</p>"},{"location":"hackmd/Kubernetes/#kubevirt","title":"KubeVirt","text":"<ul> <li>\u5728 K8S \u4e0a\u4e5f\u80fd\u8dd1 VM\uff01KubeVirt \u7c21\u4ecb\u8207\u5efa\u7acb\uff08\u4ecb\u7d39\u7bc7\uff09 | Gemini Open Cloud \u96d9\u5b50\u661f\u96f2\u7aef\u904b\u7b97\u80a1\u4efd\u6709\u9650\u516c\u53f8<ul> <li>\u5728 K8S \u4e0a\u4e5f\u80fd\u8dd1 VM\uff01KubeVirt \u7c21\u4ecb\u8207\u5efa\u7acb\uff08\u90e8\u7f72\u7bc7\uff09 | Gemini Open Cloud \u96d9\u5b50\u661f\u96f2\u7aef\u904b\u7b97\u80a1\u4efd\u6709\u9650\u516c\u53f8</li> </ul> </li> <li>Re-Imagining Virtualization with Kubernetes and KubeVirt<ul> <li>Re-Imagining Virtualization with Kubernetes and KubeVirt - Part II</li> </ul> </li> </ul>"},{"location":"hackmd/Kubernetes/#kubeflow","title":"Kubeflow","text":"<ul> <li>Kubeflow | CNCF</li> <li>Kubeflow 101 - YouTube</li> <li>ML training</li> <li>MPI Training (MPIJob) | Kubeflow<ul> <li>How to use\u00a0Kubeflow and the MPI Operator on OpenShift</li> </ul> </li> </ul>"},{"location":"hackmd/Kubernetes/#kuberay","title":"KubeRay","text":"<ul> <li>High Performance Computing (HPC) on Kubernetes</li> <li>Day19 - Ray Cluster \u5b89\u88dd\u4e4b\u4e00: \u57fa\u790e\u74b0\u5883\u6e96\u5099 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul>"},{"location":"hackmd/Kubernetes/#kueue","title":"kueue","text":"<ul> <li>Introducing Kueue | Kubernetes<ul> <li>Run a MPIJob | Kueue</li> </ul> </li> </ul>"},{"location":"hackmd/Kubernetes/#yunikorn","title":"Yunikorn","text":"<ul> <li>Run MPI Jobs | Apache YuniKorn</li> </ul>"},{"location":"hackmd/Kubernetes/#volcano","title":"Volcano","text":"<ul> <li>Volcano | CNCF</li> <li>\u8f6c\u89d2\u9047\u4e0aVolcano\uff0c\u770bHPC\u5982\u4f55\u5e94\u7528\u5728\u6c14\u8c61\u884c\u4e1a-\u4e91\u793e\u533a-\u534e\u4e3a\u4e91</li> </ul>"},{"location":"hackmd/Kubernetes/#hkube","title":"hkube","text":"<ul> <li>Hkube 101 | Hkube</li> <li>HKube - Dashboard \ud83d\udc21</li> <li>Hkube | PPT</li> </ul>"},{"location":"hackmd/LDAP/","title":"LDAP","text":"<ul> <li>Explore LDAP Alternatives for IT Professionals</li> <li>LDAP \u7c21\u4ecb</li> <li>LDAP \u7c21\u4ecb</li> <li>LDAP \u5165\u9580</li> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u5341\u4e00\u7ae0\u3001\u4f7f\u7528 LDAP \u7d71\u4e00\u7ba1\u7406\u5e33\u865f</li> <li>\u5b89\u5168 LDAP \u7d50\u69cb\u5b9a\u7fa9 - Cloud Identity\u8aaa\u660e</li> <li>LDAP \u5e33\u865f\u7ba1\u7406</li> <li>FreeIPA\u8a2d\u5b9a\u8207\u5ba2\u6236\u7aef\u5b89\u88dd\u904e\u7a0b - Zen's Blog</li> <li>Active Directory(AD)<ul> <li>AD Security - [Day2] \u4e00\u8d77\u4f86\u5b78 AD \u5b89\u5168\u5427\uff01\uff1a\u4ec0\u9ebc\u662f AD(1)</li> <li>AD Security - [Day4] \u4e00\u8d77\u4f86\u5b78 AD \u5b89\u5168\u5427\uff01\uff1a\u4ec0\u9ebc\u662f AD(2) AD \u7684\u7269\u4ef6\u662f\u4ec0\u9ebc?\u662f\u5426\u80fd\u8b8a\u6210\u4e2d\u6587\u7248\u7684 AD</li> <li>AD Security - [Day10] \u4e00\u8d77\u4f86\u5b78 AD \u5b89\u5168\u5427\uff01\uff1aLDAP(1)</li> <li>AD Security - [Day16] \u4e00\u8d77\u4f86\u5b78 AD \u5b89\u5168\u5427\uff01\uff1a \u4f01\u696d\u62ff AD \u505a\u4ec0\u9ebc</li> </ul> </li> </ul> <p>LDAP \u76ee\u9304\u7d50\u69cb\u7d44\u6210 DN\uff0cDistinguished Name\uff1a\u8b58\u5225\u540d\u7a31\uff0cLDAP \u4e2d\u4e00\u7b46\u8a18\u9304\u7684\u4f4d\u7f6e RDN\uff0cRelative Distinguished Name\uff1a\u76f8\u5c0d\u8b58\u5225\u540d\u7a31\uff0cCN \u53ca CN \u7684\u503c\u3002\u4f8b\u5982\uff1acn=deyu \u7368\u4e00\u7121\u4e8c\u7684\u5c6c\u6027\u3002 CN\uff0cCommon Name/uid\uff1a\u986f\u793a\u540d\u7a31\uff0c\u4e00\u7b46 LDAP \u8a18\u9304\u7684\u540d\u5b57/ID OU\uff0cOrganizational Unit\uff1a\u7d44\u7e54\uff0c\u4e00\u7b46 LDAP \u8a18\u9304\u6240\u5c6c\u7d44\u7e54 DC\uff0cDomain Componet\uff1a\u7db2\u57df\u5143\u4ef6\uff0c\u4e00\u7b46 LDAP \u8a18\u9304\u6240\u5c6c\u5340\u57df LDAP DN\u4f8b\u5b50\uff1a\u5728 deyu.wang \u7db2\u57df\u5167 people \u7d44\u7e54\u4e2d\u4f7f\u7528\u8005 dywtest\u3002  dn: cn=dywtest,ou=people,dc=deyu,dc=wang</p>"},{"location":"hackmd/LDAP/#redhat-389-directory-server","title":"Redhat 389 Directory Server","text":"<ul> <li>8.5.\u00a0Managing Organizational Units | Red Hat Product Documentation</li> <li>389 Directory Server - Howto: Users and Groups</li> <li>GitHub - slominskir/keycloak_ldap: Docker Compose with Keycloak and 389 LDAP Directory Server<ul> <li>use the \"Users\" page directly in <code>test-realm</code> will fail <ul> <li>workaround: after log in keycloak, need to change the \"User federation\" test-realm-ldap-provider<ul> <li>Users DN from <code>ou=people,dc=example,dc=com</code> into <code>ou=People,dc=example,dc=com</code></li> </ul> </li> </ul> </li> </ul> </li> </ul> <pre><code>dsidm localhost -b \"dc=example,dc=com\" account list\ndsidm localhost -b \"dc=example,dc=com\" organizationalunit list\ndsidm localhost -b \"dc=example,dc=com\" organizationalunit create --ou Groups\ndsidm localhost -b \"dc=example,dc=com\" group create\ndsidm localhost -b \"dc=example,dc=com\" user list\n# (option 1)create user\n# not working in slominskir/keycloak_ldap container\ndsidm localhost -b \"dc=example,dc=com\" user create\n\n# (option 2)create user\n# works in this slominskir/keycloak_ldap container\nldapadd -D \"cn=Directory Manager\" -w password -H ldap://ldap:3389 -x &lt;&lt;EOF\ndn: uid=william,ou=People,dc=example,dc=com\nuid: william\ngivenName: William \nobjectClass: top\nobjectClass: person\nobjectClass: organizationalPerson\nobjectClass: inetorgperson\nsn: Brown\ncn: William\nEOF\n\ndsidm localhost group add_member my_awesome_group uid=william,ou=People,dc=example,dc=com\ndsidm localhost user get william\n</code></pre> <pre><code>dsidm localhost account reset_password uid=jdoe,ou=People,dc=example,dc=com\n</code></pre>"},{"location":"hackmd/LLM/","title":"LLM","text":"<ul> <li>microsoft/generative-ai-for-beginners: 21 Lessons, Get Started Building with Generative AI \ud83d\udd17 https://microsoft.github.io/generative-ai-for-beginners/</li> <li>GitHub - microsoft/ai-agents-for-beginners: 10 Lessons to Get Started Building AI Agents</li> <li>RAG \u548c Prompt \u539f\u7406\u8d85\u7c21\u55ae\u89e3\u8aaa\uff01\u60f3\u77e5\u9053 AI \u600e\u9ebc\u627e\u7b54\u6848\u770b\u9019\u7bc7<ul> <li>\u9032\u968e RAG \u6280\u5de7 - \u5230\u5e95 RAG \u662f\u4ec0\u9ebc\uff1f \u00b7 YWC \u79d1\u6280\u7b46\u8a18</li> </ul> </li> <li>GPT best practices - OpenAI API</li> <li>\u5c0d AI \u7684\u7c97\u6dfa\u8a8d\u8b58\u8207\u500b\u4eba\u898b\u89e3 | Thinking Today</li> <li>ChatGPT \u8ddf new Bing\u4e00\u4e9b\u4f7f\u7528\u6280\u5de7\u8207\u53c3\u8003\u7bc4\u4f8b/ Twitter</li> <li>\u5617\u8a66\u900f\u904e ChatGPT API \u6253\u9020\u4e86\u4e00\u500b\u300c\u9748\u611f\u5925\u4f34\u300d - Pin \u8d77\u4f86\uff01</li> <li>Google Bard \u958b\u653e\u652f\u63f4 AI \u4e2d\u6587\u554f\u7b54\uff0c6\u7a2e\u88fd\u4f5c\u4e2d\u6587\u8a66\u7b97\u8868\u8207\u5831\u544a\u6848\u4f8b</li> <li>ChatGPT \u8207 Quiz Wizard \u5e6b\u8001\u5e2b\u5bb6\u9577 AI \u751f\u6210\u9078\u64c7\u984c\u3001\u62bd\u8a8d\u5361\u6559\u5b78</li> <li>ChatGPT \u63d0\u793a\u8a9e\u8aaa\u660e\u66f8\uff1a\u901a\u7528\u4e09\u5c64\u7d50\u69cb\u8207 9 \u500b\u6280\u5de7\u63d0\u9ad8 AI \u751f\u7522\u529b</li> <li>\u5982\u4f55\u554f\u51fa\u66f4\u597d\u7684\u554f\u984c\uff1fAI\u4e16\u4ee3\u5e2b\u751f\u90fd\u5fc5\u9808\u9762\u5c0d\u7684\u6311\u6230 | Gamma</li> <li>\u5feb\u901f\u8f38\u5165 ChatGPT \u5e38\u7528\u63d0\u793a\u8a9e\uff0c\u6e1b\u5c11\u91cd\u8907\u6253\u5b57\uff0c\u9644\u5be6\u6230\u7bc4\u4f8b\u4e0b\u8f09</li> <li>\u4e00\u822c\u4eba\u6700\u597d\u4e0a\u624b\u4e14\u6709\u6548\u7684 ChatGPT \u63d0\u554f\u6cd5\uff0c\u4ee5\u751f\u6210\u82f1\u6587\u7df4\u7fd2\u984c\u70ba\u4f8b</li> <li>\u6211\u4e0eChatGPT\u7ed3\u5bf9\u7f16\u7a0b\u7684\u4f53\u9a8c \u00b7 BMPI</li> <li>\u73a9\u5177\u70cf\u6258\u90a6: ChatGPT\uff1a \u6b63\u78ba\u8207\u932f\u8aa4\u7684\u4f7f\u7528\u793a\u7bc4</li> <li>\u5927\u8a9e\u8a00\u6a21\u578b LLM \u61c9\u7528\u958b\u767c \u6295\u5f71\u7247 - ihower { blogging }</li> <li>[ChatGPT] \u4f7f\u7528 ChatGPT \u5efa\u7acb\u4e00\u500b\u4e2d\u82f1\u55ae\u5b57\u7ffb\u8b6f\u5668\uff0c\u540c\u6642\u63d0\u4f9b\u97f3\u6a19\u8207\u4f8b\u53e5 | EPH \u7684\u7a0b\u5f0f\u65e5\u8a18</li> <li>\u5927\u7832\u6253\u5c0f\u9ce5\u4e4b ChatGPT \u7ffb\u8b6f\u9cf3\u68a8\u9165 LINE Bot-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u4f7f\u7528 ChatGPT \u5b78\u7fd2 Git \u7248\u672c\u63a7\u7ba1 | The Will Will Web</li> <li>\u4ecb\u7d39\u597d\u7528\u5de5\u5177\uff1aCodeGPT (\u4f7f\u7528 GPT \u81ea\u52d5\u5316\u7522\u751f Git \u7684 Commit Log \u8a0a\u606f) | The Will Will Web</li> <li>.NET Walker: \u4f7f\u7528LINE Bot\u642d\u914dOpenAI API\u5efa\u7acb\u51fa\u65b0\u4e00\u4ee3\u7684AI\u6a5f\u5668\u4eba</li> <li>How To Use Midjourney for Web Design</li> <li>\u66ff\u4f60\u7684\u61c9\u7528\u7a0b\u5f0f\u52a0\u4e0a\u667a\u6167! \u8ac7 LLM \u7684\u61c9\u7528\u7a0b\u5f0f\u958b\u767c \u2014 \u5b89\u5fb7\u9b6f\u7684\u90e8\u843d\u683c</li> <li>\u751f\u6210\u5f0f AI \u5e74\u6703\u5927\u79ae\u5305</li> <li>Perplexity AI \u641c\u5c0b\u670d\u52d9\u7684\u958b\u6e90\u66ff\u4ee3\u54c1 \u2014 Perplexica - MyApollo</li> <li>\u63d0\u793a\u5de5\u7a0b\u6307\u5357 | Prompt Engineering Guide</li> <li>Python \u65b0\u624b\u7684 AI \u4e4b\u65c5\uff1a\u5f9e\u96f6\u958b\u59cb\u6253\u9020\u5c6c\u65bc\u4f60\u7684 AI / LLM \u61c9\u7528 :: 2024 iThome \u9435\u4eba\u8cfd</li> <li>\u5b78\u7fd2\u7528\u751f\u6210\u5f0f AI \u5beb\u7a0b\u5f0f \u2014 Coursera \u8ab2\u7a0b\u5fc3\u5f97 \u2022 \u597d\u8c6a\u7b46\u8a18</li> <li>\u7121\u9700\u7a0b\u5f0f\u78bc\uff01\u7528 tldraw computer \u756b\u5f35\u6d41\u7a0b\u5716\u8f15\u9b06\u6253\u9020 AI \u81ea\u52d5\u5316\u7cfb\u7d71</li> <li>\u597d\u6587\u63a8\u85a6 \u2014 My LLM codegen workflow atm - MyApollo</li> <li>:star:ihower-agents-202412 - ihower-agents-202412.pdf<ul> <li>\u5982\u4f55\u8a2d\u8a08\u81ea\u5df1\u7684 AI Agent \u6846\u67b6 | \u5f26\u800c\u6642\u7fd2\u4e4b</li> <li>\u5c0f\u578b\u4ee3\u7406\u4eba\u5927\u9769\u547d\uff1aSmolagents\u3001\u7db2\u9801\u722c\u87f2\u8207DeepSeek V3\u7684\u8d85\u5f37\u7d44\u5408 | \u6280\u8853\u8996\u91ce\u6d1e\u5bdf - Dennis\u7684\u5c08\u696d\u8996\u89d2</li> </ul> </li> <li>edd - ihower-edd-202409.pdf</li> <li>AI \u7576\u9053\uff0c\u70ba\u4ec0\u9ebc\u6211\u9084\u662f\u63a8\u85a6\u5beb\u90e8\u843d\u683c\uff1f | \u662f Ray \u4e0d\u662f Array</li> <li>BBC 6 Minute English\uff1a\u63d0\u5347\u82f1\u6587\u807d\u529b\u7684\u597d\u5925\u4f34 - Code and Me</li> <li>400\u5c0f\u6642Cursor\u7d93\u9a57\u5206\u4eab\uff1aAI\u8f14\u52a9\u958b\u767c\u7684\u7d42\u6975\u6307\u5357 | \u6280\u8853\u8996\u91ce\u6d1e\u5bdf - Dennis\u7684\u5c08\u696d\u8996\u89d2</li> <li>\u611b\u597d AI Engineer \u96fb\u5b50\u5831 \ud83d\ude80 AI \u61c9\u7528\u958b\u767c\u7684\u5e38\u898b\u932f\u8aa4 #22 \u2013 ihower { blogging }</li> <li>\u611b\u597d AI Engineer \u96fb\u5b50\u5831 \ud83d\ude80 \u5c31\u662f\u6709\u6df1\u5ea6 DeepSeek R1 \u548c OpenAI Deep Research #23 \u2013 ihower { blogging }</li> <li>\u611b\u597d AI Engineer \u96fb\u5b50\u5831 \ud83d\ude80 \u6069\u5c3c\u683c\u746a\u8a55\u4f30 #24 \u2013 ihower { blogging }<ul> <li>AI \u5927\u795e\u514d\u8cbb\u6559\u4f60\u751f\u6d3b\u7528 AI\uff0c\u5165\u9580\u5be6\u4f8b\u89e3\u6790\u4e92\u52d5\u6280\u5de7\u3001\u5de5\u5177\u4f7f\u7528\u3001\u6a94\u6848\u8655\u7406\uff0c\u5e36\u4f60\u5feb\u901f\u638c\u63e1LLM\u61c9\u7528\uff01\uff01OpenAI \u5171\u540c\u5275\u8fa6\u4eba\u3001\u7279\u65af\u62c9\u4eba\u5de5\u667a\u6167\u7e3d\u76e3 Andrej Karpathy - YouTube<ul> <li>Leaderboard<ul> <li>Chatbot Arena (formerly LMSYS): Free AI Chat to Compare &amp; Test Best AI Chatbots</li> <li>SEAL LLM Leaderboards: Expert-Driven Private Evaluations</li> </ul> </li> <li>Tiktokenizer<ul> <li>Tiktokenizer</li> </ul> </li> <li>Don't fully trust it, \u53ef\u80fd\u6703\u6709\u865b\u69cb\u7684\u5167\u5bb9</li> <li>model<ul> <li>\u82b1\u9322\u7684pre training<ul> <li>\u7279\u6027: \u4e0d\u6703\u6709\u6700\u65b0\u7684\u8cc7\u6599\uff0c\u6703\u505c\u5728\u67d0\u4e00\u500b\u6642\u9593\u9ede</li> <li>\u4e00\u822c\u6a21\u578b<ul> <li>\u5beb\u8a69\u3001\u5c65\u6b77\u3001\u90f5\u4ef6</li> <li>knowledge-based query</li> <li>\u8a62\u554f\u65c5\u904a\u5efa\u8b70</li> </ul> </li> </ul> </li> <li>\u6253\u78e8\u6027\u683c\u7684post training<ul> <li>\u52a0\u4e0a\u5f37\u5316\u5f0f\u5b78\u7fd2(reinforcement learning)\u7684\u6a21\u578b =&gt; \u601d\u7dad\u6a21\u578b(thinking model)</li> <li>\u4f7f\u7528\u6642\u6a5f\u70ba\u9700\u8981\u7372\u53d6\u54c1\u8cea\u8f03\u597d\u7684\u56de\u7b54</li> </ul> </li> </ul> </li> <li>tool use<ul> <li>internet search<ul> <li>\u4f7f\u7528\u6642\u6a5f: <ul> <li>\u66ff\u63db\u6389google search\u7684\u52d5\u4f5c</li> <li>\u89ba\u5f97\u53ef\u80fd\u662f\u8f03\u65b0\u7684\u8cc7\u8a0a</li> <li>\u6703\u96a8\u8457\u6642\u9593\u6539\u8b8a\u7684\u8cc7\u8a0a</li> </ul> </li> </ul> </li> <li>deep research<ul> <li>multiple internet search + \u601d\u7dad\u6a21\u578b(thinking model)</li> </ul> </li> <li>file upload<ul> <li>\u4f7f\u7528\u6642\u6a5f: \u4e00\u8d77\u8b80\u6587\u4ef6\u3001\u4e00\u8d77\u8b80\u66f8</li> </ul> </li> <li>python interpreter</li> </ul> </li> <li>\u4f7f\u7528\u5834\u666f<ul> <li>flash card<ul> <li>\u4e00\u6bb5\u6587\u5b57\uff0c\u8acbLLM\u751f\u6210flash card</li> <li>Claude Artifacts Showcase | Share Your AI Creations</li> </ul> </li> <li>\u4e00\u6bb5\u6587\u5b57\uff0c\u8acbLLM\u751f\u6210diagram\uff0c\u8996\u89ba\u5316</li> <li>cursor<ul> <li>composer</li> </ul> </li> </ul> </li> <li>\u8f38\u5165/\u8f38\u51fa<ul> <li>\u6587\u5b57</li> <li>\u97f3\u8a0a<ul> <li>\u9032\u968e\u8a9e\u97f3\u6a21\u5f0f\uff0c\u5373\u6a21\u578b\u5167\u90e8\u7684\u771f\u5be6\u97f3\u8a0a</li> </ul> </li> <li>\u5f71\u7247</li> <li>\u5716\u7247</li> </ul> </li> </ul> </li> </ul> </li> <li>\u3010\u751f\u6210\u5f0fAI\u5c0e\u8ad6 2024\u3011 - YouTube</li> </ul>"},{"location":"hackmd/LLM/#prompt","title":"Prompt","text":"<pre><code>\u4f7f\u7528\u9019\u4e9b\u4f86\u6e90:https://www.cna.com.tw/, https://www.dcard.tw\n\n\u7522\u751f\u548c\u8001\u5a46\u804a\u5929\u768410\u7d44\u6709\u8da3\u8a71\u984c\n</code></pre>"},{"location":"hackmd/LLM/#mcp","title":"MCP","text":"<ul> <li>\u5f9e\u958b\u767c\u8005\u89d2\u5ea6\u7406\u89e3 Model Context Protocol (MCP) - MyApollo</li> <li>\u8aaa\u660eMCP</li> <li>MCP \u662f\u4ec0\u9ebc\uff1f\u53ef\u4ee5\u5403\u55ce\uff1f</li> </ul>"},{"location":"hackmd/LLM/#_1","title":"\u6a5f\u5668\u5b78\u7fd2","text":"<ul> <li>\u5168\u6c11\u760bAI\u7cfb\u5217 [\u7d93\u5178\u6a5f\u5668\u5b78\u7fd2]</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/","title":"Linux\u6280\u5de7","text":"<p>find, grep awk, sed tar</p> <pre><code># network\nhostname\nhostnamectl set-hostname server1.example.com\nip a s\nnmcli connection show\ncat /etc/sysconfig/network-scripts/ifcfg-enp66s0f0\n# restart the network.\n#systemctl restart NetworkManager\nsudo nmcli connection reload &amp;&amp; sudo nmcli connection down enp68s0f0 &amp;&amp; sudo nmcli connection up enp68s0f0\n# restart the network.\n# sudo nmcli networking off\n# sudo nmcli networking on\nsudo ip link set enp66s0f0 down\nsudo ip link set enp66s0f0 up\n\n# mtu\nifconfig enp66s0f0 mtu 1500\n\nnmap 172.17.30.108 -p 22 -Pn\n\n# storage\ndf -hT\nlsblk -f\nsudo blkid\n\n# mount\n## Assuming you have made changes to the /etc/fstab file, you can use the following command to remount the file system\nsudo mount -av\n\n# lvm\nvgs\nvgdisplay\nlvs\nlvdisplay\n\n# process\nps -ef\npstree -p &lt;pid&gt;\nfree -m\n\n# find\nfind /home/ -type f -name \"*.sh\" | xargs chmod +x\n\n# systemctl\nsystemctl list-units --all\nsystemctl --type=service --state=active\nsystemctl --type=service --state=running\n# looking for the service file of a specific service\nsystemctl cat isc-dhcp-server\n# reload all daemon and include Automatically generated by systemd-sysv-generator\nsystemctl daemon-reload\n\n# rsync\nrsync --dry-run -avzh --progress {source} {target}\nrsync -avzh --progress {source} {target}\n\n\n# sed\nsed -i 's/172.19.30.157/172.31.56.32/g' *\n\n# ss\nss -tulnp\nss -tulnp | grep :80\n# netstat\nnetstat -tulnp\n\n# curl\ncurl -v telnet://test:53\n\n# network interface monitor\niftop -i ens192 -B\nnetstat -I ens192 -w 2\n</code></pre> <ul> <li>Linux \u4e0a\u7684\u5b57\u4e32\u4ee5\u53ca\u547d\u4ee4\u8f38\u51fa\u8655\u7406 grep\u3001awk\u3001xargs\u3001sed - Bingdoal's Note<ul> <li>UNIX \u5e38\u7528\u6307\u4ee4 - find - \u5927\u985e\u7684\u6280\u8853\u624b\u8a18</li> <li>UNIX \u5e38\u7528\u6307\u4ee4 - grep - \u5927\u985e\u7684\u6280\u8853\u624b\u8a18</li> </ul> </li> <li>explainshell</li> <li>shell.how</li> <li>Practical Shell Patterns I Actually Use</li> <li>\u4f60\u4e00\u5b9a\u7528\u904e htop\uff0c\u4f46\u4f60\u6709\u770b\u61c2\u6bcf\u500b\u6b04\u4f4d\u55ce</li> <li>Best Linux Commands For Advanced Hardware and System Info</li> <li>16.04 - Difference between systemctl init.d and service - Ask Ubuntu</li> <li>Bash Cheat Sheet | Just for noting</li> <li>\u6700\u725bB\u7684Linux Shell\u547d\u4ee4 | plantegg</li> <li>Cheat sheet: Old Linux commands and their modern replacements | Opensource.com</li> <li>System monitoring utilities | System Analysis and Tuning Guide | openSUSE Leap 15.5</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#debug","title":"debug","text":"<ul> <li>Linux \u6548\u80fd\u5de5\u5177</li> <li>Linux \u6548\u80fd\u5de5\u5177 - Intermediate</li> <li>\u662f\u8c01\u6740\u4e86\u6211\uff1f | \u5361\u74e6\u90a6\u5676\uff01</li> <li>System becomes unresponsive with message \"INFO: task {process}:{pid} blocked for more than 120 seconds\". - Red Hat Customer Portal</li> <li>Why is space not being freed from disk after deleting a file in Red Hat Enterprise Linux? - Red Hat Customer Portal</li> <li>[Linux] \u6b0a\u9650\u4e2d\u9ecf\u6eef\u4f4d\uff08sticky bit\uff09\u7684\u89e3\u91cb\uff08chmod 1777\uff09 - Clay-Technology World</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#apt","title":"apt","text":"<ul> <li>apt key - Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead - Stack Overflow<ul> <li>repository - How can I remove gpg key that I added using apt-key add -? - Ask Ubuntu</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#show-kernal-verion","title":"show kernal verion","text":"<p>How To Find Which Linux Kernel Version Is Installed On My System uname -r : Find Linux kernel version cat /proc/version : Show Linux kernel version with help of a special file hostnamectl | grep Kernel : For systemd based Linux distro you can use hotnamectl to display hostname and running Linux kernel version</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#memory","title":"memory","text":"<p>ps aux pmap gdb strace</p> <pre><code>ubuntu@ip-172-31-15-167:/var/log$ sudo pmap -d 26264 | sort -g -k 2 | tail\n00007f23bb0bd000   15628 ----- 0000000000000000 000:00000   [ anon ]\n00007f2405f8c000   25304 r-x-- 0000000000000000 103:00001 libicudata.so.55.1\n00007f23b8000000   49908 rw--- 0000000000000000 000:00000   [ anon ]\n00007f23cc000000   65232 rw--- 0000000000000000 000:00000   [ anon ]\n00007f23c0000000   65524 rw--- 0000000000000000 000:00000   [ anon ]\n00007f23e4000000   65536 rw--- 0000000000000000 000:00000   [ anon ]\n00007f23d4000000  131072 rw--- 0000000000000000 000:00000   [ anon ]\n00007f23dc000000  131072 rw--- 0000000000000000 000:00000   [ anon ]\n0000000000ad1000 2446724 rw--- 0000000000000000 000:00000   [ anon ]\nmapped: 3279696K    writeable/private: 3085236K    shared: 28K\n\n\nubuntu@ip-172-31-15-167:/var/log$ sudo cat /proc/26264/smaps | grep -A 18 0ad1000\n00ad1000-96032000 rw-p 00000000 00:00 0                                  [heap]\nSize:            2446724 kB\nRss:             2446600 kB\nPss:             2446600 kB\nShared_Clean:          0 kB\nShared_Dirty:          0 kB\nPrivate_Clean:         0 kB\nPrivate_Dirty:   2446600 kB\nReferenced:      2446356 kB\nAnonymous:       2446600 kB\nAnonHugePages:   2445312 kB\nShared_Hugetlb:        0 kB\nPrivate_Hugetlb:       0 kB\nSwap:                  0 kB\nSwapPss:               0 kB\nKernelPageSize:        4 kB\nMMUPageSize:           4 kB\nLocked:                0 kB\nVmFlags: rd wr mr mw me ac sd\n</code></pre> <ul> <li>pmap high memory usage by python script</li> <li>[Python] Debug \u4e00\u652f daemon \u72c2\u5403\u8a18\u61b6\u9ad4\u7684\u554f\u984c\u2026 \u539f\u4f86\u662f lxml \u641e\u7684\u9b3c</li> <li>How to Check Memory Usage Per Process on Linux</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#character-device-file","title":"character device file","text":"<ul> <li>Creating a character device file - Unix &amp; Linux Stack Exchange</li> <li>files - What are exactly mknod command parameters? - Unix &amp; Linux Stack Exchange</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#grep","title":"grep","text":"<ul> <li>how do I use the grep --include option for multiple file types?</li> <li>\u4f7f\u7528 grep \u641c\u5c0b\u591a\u500b\u503c</li> </ul> <p>remove sparse row <pre><code>cat package_list | grep -E '^[a-zA-Z0-9]'\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#by-specific-extensions","title":"by specific extensions","text":"<pre><code>grep --include=*.{py,yml} -irn 'abc' folder\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#_1","title":"\u7d44\u5408\u6280","text":"<p>\u8907\u88fdPE\u6a94\u6848\u81f3\u67d0\u500b\u76ee\u9304 malicious_pe/md5_fb9d3acc7d067fcea343d3c48d35f887_55296:   PE32 executable (console) Intel 80386, for MS Windows <pre><code>file malicious/* | grep -i 'exe' | awk {'print $1'} | awk -F ':' {'print $1'} | xargs cp -t malicious_pe\n</code></pre></p> <p>\u627e\u51fapdf\u6a94\u6848\u4e26\u5728\u53e6\u4e00\u500bmetadata\u6a94\u6848\u904e\u6ffe <pre><code>file malicious/* | grep -i 'pdf' | awk -F ':' '{print $1}' | awk -F '_' '{print $2}' | grep -f - malicious/csv/meta.csv\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#find","title":"find","text":""},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#delete-files-older-than-specific-date","title":"delete files older than specific date","text":"<pre><code>find /path ! -newermt \"YYYY-MM-DD HH:MM:SS\" | xargs rm -rf\n\nfind ./GeoIP_Lite/Release/ -type d ! -newermt \"2020-07-01\" | xargs rm -rf\n\nfind ./GeoIP_Lite/download -mindepth 2 -type d ! -newermt \"2020-07-01\"\n</code></pre> <ul> <li>How do you delete files older than specific date in Linux? </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#find-a-or-b","title":"find a or b","text":"<pre><code>find . -type f \\( -name \"sefold*\" -o -name \"iso_sigma*\" -o -name \"tbaric*\" \\)\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#rsync","title":"rsync","text":"<ul> <li>:star:Continuously Sync Files One-Way on Linux | Baeldung on Linux</li> <li>How To Use Rsync to Sync Local and Remote Directories | DigitalOcean</li> <li>Linux \u4f7f\u7528 rsync \u9060\u7aef\u6a94\u6848\u540c\u6b65\u8207\u5099\u4efd\u5de5\u5177\u6559\u5b78\u8207\u7bc4\u4f8b - G. T. Wang</li> <li>How To Use Rsync to Sync Local and Remote Directories</li> <li>Rsync over SSH with key authentication</li> <li>How to Exclude Files and Directories with Rsync<ul> <li>How to exclude subdirectory from rsync<ul> <li>anywhere or not anywhere in the tree</li> </ul> </li> </ul> </li> <li>shell script - rsync / mv how to skip empty files - Unix &amp; Linux Stack Exchange</li> </ul> <p>\u5c07\u9060\u7aef\u7684\u6a94\u6848\u5099\u4efd\u81f3\u672c\u5730\u7aef <pre><code>rsync -avzh pi@192.168.1.12:/mypath/myfile.gz /mybackup/\n\nrsync -avzh --progress pi@192.168.1.12:/mypath/myfile.gz /mybackup/\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#sed","title":"sed","text":"<ul> <li>sed &amp; awk<ul> <li>[Appendix A] A.3 Command Summary for sed</li> </ul> </li> <li>Linux \u6307\u4ee4 SED \u7528\u6cd5\u6559\u5b78\u3001\u53d6\u4ee3\u7bc4\u4f8b\u3001\u8a73\u89e3</li> <li>How can I replace a string in a file(s)?</li> </ul> <p>shell - How to delete from a text file, all lines that contain a specific string? - Stack Overflow <pre><code>sed -i '/\\/tmp/d' /etc/fstab\n</code></pre></p> <p>SED: insert text after the last line? - Unix &amp; Linux Stack Exchange <pre><code>sed -i -e '$a/dev/mapper/rhel-tmp    /tmp                    xfs     defaults        0 0' /etc/fstab\n</code></pre></p> <p>unix - How to use variables in a command in sed? - Stack Overflow <pre><code>sed -i \"s|\\$ROOT|${HOME}|\" abc.sh\n</code></pre></p> <p>regular expression - How can I use sed to replace a multi-line string? - Unix &amp; Linux Stack Exchange To handle newline characters, you need to read multiple lines into the pattern space. This is why the command sed ':a;N;$!ba;s/\\n/\\n/g' works\u2014it reads the entire input into the pattern space before performing the substitution.</p> <p>sed reads and processes one line at a time. When you use sed 's/\\n/\\n/g', it doesn't see the newline characters within the lines because it processes each line separately. <pre><code>#!/bin/bash\n\n# Define the certificate content\nCERTIFICATE=\"-----BEGIN CERTIFICATE-----\nMIID0DCCArigAwIBAgIUf0rrp7kWJf1eYRqyBRQzZLBsmkwwDQYJKoZIhvcNAQEL\nBQAwaDELMAkGA1UEBhMCVVMxCzAJBgNVBAgMAlZBMREwDwYDVQQHDAhOZXcgWW9y\nazENMAsGA1UECgwEUXVheTERMA8GA1UECwwIRGl2aXNpb24xFzAVBgNVBAMMDnF1\nYXkucG9sYWIuY29tMB4XDTI0MTExMDA3MTIwNloXDTI3MDgzMTA3MTIwNlowaDEL\nMAkGA1UEBhMCVVMxCzAJBgNVBAgMAlZBMREwDwYDVQQHDAhOZXcgWW9yazENMAsG\nA1UECgwEUXVheTERMA8GA1UECwwIRGl2aXNpb24xFzAVBgNVBAMMDnF1YXkucG9s\nYWIuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAu+iNCLjyMnB3\n0AS4twt9BIqgNaifTCHi/u0bOilwpIWT2vVW92MGqNkHujBoKJFJhRQaaijtFSE1\niRpt8YyEUTXJJbW1nE9iolRJbJ3orkYfyHremQjsVxpKrAzIqEa9cgjmgMLJIj+b\nfxqoLR3Hof4+TbNGo8x2wFU1iV/rJgrf/3G10NZXumng4rf0RW1c6wR9y/pnXFML\ng8xQuuJSX8DTkw+kLBEQ3EnITQOUDu+25q3YOzhwzD9JIDD1O3/W/arZCc5ffQuS\nEwrqahkGDcvVIruuclpBFe5lit6vP5wFexknIQcQFZqe+NfKSO/8Mu4lQ9pRQS5b\nim4+APntmQIDAQABo3IwcDALBgNVHQ8EBAMCAuQwEwYDVR0lBAwwCgYIKwYBBQUH\nAwEwGQYDVR0RBBIwEIIOcXVheS5wb2xhYi5jb20wEgYDVR0TAQH/BAgwBgEB/wIB\nATAdBgNVHQ4EFgQUfcKOlnOLCwrOtX0Gs7/Th763eyswDQYJKoZIhvcNAQELBQAD\nggEBAAdvOWkajk4NG0ataHEWXDt/EIS9Fqa8GN/hmz6kcFN5Ad56WsW/WvicMNE5\nB/2iyeQM39Dx7pgBY25ZQ33evhZU4eeJqwx7mnCs5IvauoOanOkmGPeP7UdyCMGV\nKhDoavfVf8gEdqS+IHkqUR9rfm2gms+y/BwNB/Qbn2bKG6JOz2c3WoyBajQqsJU9\nDM3aSNcFJu9acAeTWpcC2CHXAs5qBHND/38YLd+/Wug4rH48xtGc16QiQElIJLE8\nWqZzTb2dZH1MkFO4B98lYsBNrUO4s6ulQPvtem85hX+RQmopOXUzrsToycM7W4a+\nnz8PCkHirBNL9g7LfRtDCgi11rI=\n-----END CERTIFICATE-----\"\n\n# Replace end of line with \\n\nCERTIFICATE=$(echo \"$CERTIFICATE\" | sed ':a;N;$!ba;s/\\n/\\\\n/g')\n\n# Output the certificate content\necho \"$CERTIFICATE\"\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#awk","title":"awk","text":"<p>show specific line in large file</p> <pre><code>awk 'FNR==10' file_name\n\n# lines 20 to 40\nawk 'FNR&gt;=20 &amp;&amp; FNR&lt;=40' file_name\n</code></pre> <p>How to escape a single quote inside awk</p> <pre><code>ls -la | awk {'print $9'} | awk -F '_' {'print \"\\x27\"$2\"\\x27,\"'}\n</code></pre> <p>remove duplicate row  <pre><code>awk '!seen[$0]++' file.txt &gt; deduplicated_removed_file.txt\n</code></pre></p> <p>filter speficif time <pre><code>sudo awk -v n_times_ago=\"10 minutes\" -v now=\"$(date +%H:%M:%S)\" \"\\$3 &gt;= n_times_ago &amp;&amp; \\$3 &lt;= now {print} {next}\" /var/log/messages\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#tar","title":"tar","text":"<p>https://terryl.in/zh/linux-tar-command/ https://stackoverflow.com/questions/18681595/tar-a-directory-but-dont-store-full-absolute-paths-in-the-archive</p> <p>soft link -h https://superuser.com/questions/137388/how-can-i-tar-ball-a-directory-hierarchy-with-soft-links-in-linux</p> <p>exlcude/include - How do I use tar to exclude all files of a certain directory? - Ask Ubuntu - Using tar to only backup specific folders - Ask Ubuntu</p> <p>\u251c\u2500\u2500 foo \u2502\u00a0\u00a0 \u251c\u2500\u2500 shared_repo \u2502\u00a0\u00a0 \u251c\u2500\u2500 bar <pre><code># exlude the shared_repo\ntar zcvf foo_1.0.0_20230829_src.tar.gz --exclude=\"shared_repo/*\"  foo\n\n# include the shared_repo only\ntar zcvf foo_1.0.0_20230829_repo.tar.gz  foo/shared_repo\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#zipunzip","title":"zip/unzip","text":"<pre><code>unzip -P &lt;pwd&gt; test.zip\nzip -r --encrypt 202208.zip 202208\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#user","title":"user","text":"<ul> <li>How To Create a New Sudo-enabled User on Ubuntu 20.04 [Quickstart] <pre><code>adduser {user name}\nusermod -aG sudo {user name}\n</code></pre></li> </ul> <p>-m: Creates the home directory for the user. -g users: Sets the initial login group to \"users\". -s /bin/bash: Sets the login shell to Bash. -c \"bar\": Adds a comment or description for the user. <pre><code>groupadd foo\nuseradd -m -g foo -s /bin/bash -c \"bar\" foo\npasswd foo\necho 'foo ALL=(ALL:ALL) NOPASSWD: ALL' | sudo tee -a /etc/sudoers\n</code></pre></p> <pre><code>sudo useradd -s /bin/bash -d /home/foo/ -m -G sudo foo; echo -e \"bar@2025\\bar@2025\" | passwd foo\n</code></pre> <ul> <li>Linux Delete / Remove User Account Using userdel Command</li> </ul> <pre><code>id {user_name}\n\n# lock user account\npasswd -l {user_name}\n\n#  set the date on which the user account will be disabled\nusermod --expiredate YYYY-MM-DD {user_name}\n</code></pre> <p>switch user How To Change User on Linux \u2013 devconnected</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#crontab","title":"crontab","text":"<pre><code># Remove cron jobs\ncrontab -r -u \n</code></pre> <ul> <li>education about cron</li> <li>How can I set the timezone for Crontabs</li> <li>Is <code>*/1 * * * *</code> and <code>* * * * *</code> equivalent in CRON</li> <li><code>/bin/sh: 1: python: not found</code> when run via cron in docker<ul> <li>Cron doesn't set up the PATH environment variable the same as a normal login shell so python can't be found.</li> </ul> </li> <li>Cron job delayed by \\~1 second - Ask Ubuntu<ul> <li>crontab\u4e0d\u4fdd\u8b49\u7cbe\u78ba\u5230\u79d2</li> </ul> </li> <li>linux - When does `cron.daily` run? - Server Fault</li> </ul> <p>cron date file name Append current date to the filename via Cron? - Stack Overflow <pre><code>* * * * * echo \"hello\" &gt; /tmp/helloFile_$(date +\\%Y\\%m\\%d\\%H\\%M\\%S).txt\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#update-crontab-by-command-automatically","title":"update crontab by command automatically","text":"<pre><code>#!/bin/bash\n\n(crontab -u ubuntu -l; echo \"SHELL=/bin/bash\") | crontab -u ubuntu -\n(crontab -u ubuntu -l; echo \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\") | crontab -u ubuntu -\n\n(crontab -u ubuntu -l; echo \"$(cat my_cron_job)\") | crontab -u ubuntu -\n\n# my_cron_job is a file which contains crontab config\n# */2 * * * *  cd /home/ubuntu &amp;&amp; ./check.sh\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#curl","title":"curl","text":"<ul> <li>Linux Curl Command \u6307\u4ee4\u8207\u57fa\u672c\u64cd\u4f5c\u5165\u9580\u6559\u5b78</li> <li>10 Examples Why cURL is an Awesome CLI Tool | Martin Heinz | Personal Website &amp; Blog<ul> <li>Introduction - everything curl</li> </ul> </li> <li>Ways to check for open ports on RHEL - Red Hat Customer Portal</li> </ul> <pre><code>curl -v telnet://test:5601\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ss","title":"ss","text":"<ul> <li>Socket listen() backlog</li> <li>How to get BACKLOG of listening socket</li> <li>\u53ef\u80fd\u662f\u6700\u5b8c\u6574\u7684 TCP \u8fde\u63a5\u5065\u5eb7\u6307\u6807\u5de5\u5177 ss \u7684\u8bf4\u660e \u2013 Mark Zhu \u7684\u535a\u5ba2</li> </ul> <p>Recv-Q        Established: The count of bytes not copied by the user program        connected to this socket.  Listening: Since Kernel 2.6.18 this        column contains the current syn backlog. Send-Q        Established: The count of bytes not acknowledged by the remote        host.  Listening: Since Kernel 2.6.18 this column contains the        maximum size of the syn backlog.</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#jq","title":"jq","text":"<ul> <li>\u4f7f\u7528 jq \u9054\u6210\u8986\u5beb\u76f8\u540c json key \u7684\u6548\u679c</li> <li>\u4f7f\u7528 jq \u5c07\u591a\u500b\u6a94\u6848\u5167\u5bb9\u7d44\u6210\u4e00\u4efd key/value json</li> <li>Analyzing multi-gigabyte JSON files locally | thenybble.de</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#diff","title":"diff","text":"<ul> <li>How to Compare Two Files in Linux</li> </ul> <p>diff colordiff vimdiff</p> <pre><code>diff -y -W 60 test_file_1.txt test_file_2.txt\n\n| \u2014 Line is different in the second file\n&gt; \u2014 Line is additional in the second file\n&lt; \u2014 Line has been deleted from the second file\n\ndiff -y -W 60 --suppress-common-lines test_file_1.txt test_file_2.txt\n\n# ignore case\ndiff -y -W 60 --suppress-common-lines -i test_file_1.txt test_file_2.txt\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#syn-flooding-log","title":"SYN flooding log","text":"<p>Symptom: HTTP ok and in the sametime HTTPS timeout</p> <p><pre><code>Feb 22 12:02:18 ip-172-31-15-116 kernel: [  164.209387] TCP: request_sock_TCP: Possible SYN flooding on port 443. Sending cookies.  Check SNMP counters.\n</code></pre> - Handle \"possible SYN flooding on port 443. Sending cookies.\"</p> <p>check <code>net.ipv4.tcp_max_syn_backlog</code> : Specifies the maximum number of connection requests that are not acknowledged by the peer end and that can be stored in the queue.  - SYN packet handling in the wild - How TCP backlog works in Linux - How can I monitor the length of the accept queue - TCP socket debugging on GNU/Linux using a handful of basic tools: lsof, awk and tail. - What is the difference between tcp_max_syn_backlog and somaxconn</p> <p>system setting <pre><code>sudo sysctl -a | grep 'net.ipv4.tcp_max_syn_backlog'\nsudo sysctl -a | grep 'net.core.somaxconn'\n</code></pre></p> <p>on the wild <pre><code>ss -n state syn-recv sport = :80 | wc -l\nss -n state syn-recv sport = :443 | wc -l\n</code></pre></p> <p>system setting and on the wild in one command <pre><code>ss -plnt sport = :443|cat\n\nubuntu@ip-172-31-15-116:/var/log$ ss -plnt sport = :443|cat\nState    Recv-Q   Send-Q     Local Address:Port     Peer Address:Port  Process\nLISTEN   512      511                    *:443                 *:*\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#sysctl","title":"sysctl","text":"<ul> <li>Linux set sysctl variables command</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#copy","title":"copy","text":"<pre><code>file foo/* | grep -i 'pdf' | awk '{split($1,a,\":\"); print a[1]}' | xargs cp -t foo_pdf\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#shuf","title":"shuf","text":"<ul> <li>Randomly copy certain amount of certain file type from one directory into another<ul> <li>\u4e82\u6578\u6216\u96a8\u6a5f\u53d6\u6a23\u7684\u5de5\u5177\uff1ashuf</li> </ul> </li> </ul> <pre><code>shuf -zn8 -e *.jpg | xargs -0 cp -vt target/\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#openssl","title":"openssl","text":"<ul> <li>Openssl Demo: Encrypting/Decrypting files using both Symmetric and Asymmetric Encryption</li> <li>How to encrypt a file with private key</li> <li>Openssl verification fails</li> <li>How to view a certificate fingerprint as SHA-256, SHA-1 or MD5 using OpenSSL for RSA Authentication ... - RSA Community - 4230</li> <li>\u5982\u4f55\u4f7f\u7528 OpenSSL \u5efa\u7acb\u958b\u767c\u6e2c\u8a66\u7528\u9014\u7684\u81ea\u7c3d\u6191\u8b49 (Self-Signed Certificate) | The Will Will Web<ul> <li>OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs | DigitalOcean</li> <li>Generating a self-signed certificate using OpenSSL - IBM Documentation</li> <li>Create a self-signed certificate using OpenSSL | by Allan Sun | \u96a8\u7b46\u96dc\u8a18</li> <li>\u90a3\u4e9b\u95dc\u65bcSSL/TLS\u7684\u4e8c\u4e09\u4e8b(\u5341\u4e00) \u2014 \u95dc\u65bc\u6191\u8b49\u7684\u7dad\u904b. \u524d\u9762\u5df2\u7d93\u5c0d SSL \u7684\u539f\u7406\u6709\u4e86\u6bd4\u8f03\u8a73\u7d30\u7684\u89e3\u8aaa, \u9019\u7bc7\u958b\u59cb\u8981\u8ac7\u7684\u662f\u5be6\u4f5c\u7684\u7d30\u7bc0\u2026 | by Carl | Medium</li> <li>How to Check Certificate with OpenSSL</li> </ul> </li> <li>Generate a full self-signed certificate chain (Root -&gt; Intermediate CA -&gt; Server) using keytool, that can be used for 'localhost' development \u00b7 GitHub</li> <li>Creating Fullchain SSL Certificate With Bash</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#openssl-111f","title":"OpenSSL 1.1.1f","text":"<p>Generate private key <pre><code>openssl genpkey -algorithm RSA -out private_key.pem -pkeyopt rsa_keygen_bits:2048\n</code></pre></p> <p>Generate public key by private key <pre><code>openssl rsa -pubout -in private_key.pem -out public_key.pem\n</code></pre></p> <p>Encrypt the input data using an RSA public key and Decrypt the input data using an RSA private key <pre><code>echo '{\"mac\":\"BC:CF:4F:CF:E0:C6\",\"sn\":\"S202L12345678\",\"product\":1}'| openssl rsautl -encrypt -pubin -inkey public_key.pem | base64 -w 0 &gt; enc\n\ncat enc | base64 --decode | openssl rsautl -decrypt -inkey private_key.pem\n</code></pre></p> <p>Sign/Verify the data with PKCS#1 v1.5 (the default) padding <pre><code>echo '{\"mac\":\"BC:CF:4F:CF:E0:C6\",\"sn\":\"S202L12345678\",\"product\":1}'| openssl rsautl -sign -inkey private_key.pem | base64 -w 0 &gt; enc\n\ncat enc | base64 -d | openssl rsautl -verify -pubin -inkey public_key.pem\n</code></pre></p> <p>Sign/Verify the data with RSASSA-PSS padding <pre><code>echo 'Hello world' &gt; message\nopenssl dgst -sha256 -sign private_key.pem -sigopt rsa_padding_mode:pss message | base64 -w 0 &gt; signature\ncat signature | base64 -d &gt; signature.bin\nopenssl dgst -sha256 -verify public_key.pem -sigopt rsa_padding_mode:pss -signature signature.bin message\n# Verified OK or Verification Failure\n</code></pre></p> <p>https://www.jianshu.com/p/64cc65f2d04f <pre><code>echo \"Hello world!\" &gt; foo.txt\n\n\n######################################################\n# \u65b9\u6cd5\u4e00: \u76f4\u63a5\u4f7f\u7528openssl dgst -sign\u548copenssl dgst -verify\u5b8c\u6210\n# \u4f7f\u7528RSA private key \u9032\u884c\u7c3d\u540d, \u5176\u4e2d: sigopt rsa_padding_mode:pss\u6307\u5b9apadding scheme\nopenssl dgst -sha256 -sign private_key.pem -sigopt rsa_padding_mode:pss -out sig.bin foo.txt\n\n# \u4f7f\u7528RSA public key verify\u521a\u624d\u7684\u7b7e\u540d\nopenssl dgst -sha256 -verify public_key.pem -sigopt rsa_padding_mode:pss -signature sig.bin foo.txt\n\n\u8f93\u51fa Verified OK \u4ee3\u8868verify\u6210\u529f\n\n\n################################################\n# \u65b9\u6cd52: \u5148\u4f7f\u7528 openssl dgst -binary \u8f93\u51fa\u54c8\u5e0c\u6821\u9a8c\u548c, \u518d\u4f7f\u7528 pkeyutl \u8fdb\u884c\u6570\u5b57\u7b7e\u540d\u548c\u6821\u9a8c\nopenssl dgst -sha256 -binary -out sha256sum.bin \u6587\u4ef6\u540d.txt\nopenssl pkeyutl \\\n        -inkey rsakeypair.pem -pkeyopt rsa_padding_mode:pss -pkeyopt digest:sha256 \\\n        -sign -in sha256sum.bin -out sig2.bin\n\nopenssl pkeyutl \\\n        -pkeyopt rsa_padding_mode:pss -pkeyopt digest:sha256 \\\n        -pubin -inkey pubkey.pem \\\n        -verify -in sha256sum.bin -sigfile sig2.bin\n\u5c4f\u5e55\u8f93\u51fa Signature Verified Successfully \u4ee3\u8868\u6570\u5b57\u7b7e\u540d\u6821\u9a8c\u6210\u529f\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#certificate","title":"certificate","text":"<p>How to view a certificate fingerprint as SHA-256, SHA-1 or MD5</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#create-a-hashed-password","title":"Create a hashed password","text":"<pre><code>openssl passwd -1 abc123\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#create-a-account-by-command","title":"Create a account by command","text":"<pre><code>#!/bin/bash\n\necho \"mypostbootscript begin !\" \nACCOUNT=foo\nACCOUNT_HOME=/home/${ACCOUNT}\ndf -hT\nuseradd -m ${ACCOUNT}\nusermod -p '$6$5ptqLocOXaqpsWlL$93Sy8bAos7xMsn4hOepfUWXgko2KkR3g9wFva1f0piWq9fWLHEHn8/srdiLuQcYI2z668dstZFi5vQZpUVKcK/' ${ACCOUNT}\nls -la /opt_shared\ndf -hT\ntest -d ${ACCOUNT_HOME}/.ssh || mkdir -p ${ACCOUNT_HOME}/.ssh\ncp /opt_shared/diskless/authorized_keys ${ACCOUNT_HOME}/.ssh/\nchown ${ACCOUNT}: ${ACCOUNT_HOME}/.ssh/authorized_keys\ntouch /etc/sudoers.d/${ACCOUNT} &amp;&amp; echo \"${ACCOUNT} ALL=(root) NOPASSWD:ALL\" &gt; /etc/sudoers.d/${ACCOUNT}\necho \"mypostbootscript end\" \n</code></pre> <p>$6$5ptqLocOXaqpsWlL$93Sy8bAos7xMsn4hOepfUWXgko2KkR3g9wFva1f0piWq9fWLHEHn8/srdiLuQcYI2z668dstZFi5vQZpUVKcK/ by the commnad <pre><code>openssl passwd -6 &lt;foo password&gt;\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#self-signed-certificate","title":"self-signed certificate","text":"<pre><code>openssl req -x509 -newkey rsa:4096 -sha256 -nodes -keyout /tmp/test.key -out /tmp/test.crt -days 30 -subj \"/C=TW/ST=Taiwan/L=Taoyuan City/O=Foo/OU=Bar/CN=foo.bar\"\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#checking-the-status-of-a-certificate","title":"Checking the Status of a Certificate","text":"<pre><code>openssl x509 -in mycert.pem -text -noout\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#jdk","title":"JDK","text":"<ul> <li>How to Install Oracle JAVA 8 on Ubuntu 20.04 LTS</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#resize-partition","title":"Resize partition","text":"<ul> <li>How to resize partition via command line</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#tmp-read-only-file-system","title":"/tmp Read-only file system","text":"<pre><code>$ crontab -e \n/tmp/crontab.Ul9dS1: Read-only file system\n\n$ touch /tmp/test\n... Read-only file system\n\n$ mount\n\ntmpfs\u90fd\u662frw\nex. tmpfs on /run/user/1004 type tmpfs (rw,nosuid,nodev,relatime,size=398492k,mode=700,uid=1004,gid=1004)\n/dev/nvme0n1p1 on / type ext4 (ro,relatime,data=ordered)\n\n$ sudo mount -o remount,rw /\nmount: / not mounted or bad option\n\n       In some cases useful info is found in syslog - try\n       dmesg | tail or so.\n\n$ dmesg | tail\n[  307.911010] EXT4-fs (nvme0n1p1): Couldn't remount RDWR because of unprocessed orphan inode list.  Please umount/remount instead\n\n$  sudo e2fsck -f /dev/nvme0n1p1\ne2fsck 1.42.13 (17-May-2015)\nPass 1: Checking inodes, blocks, and sizes\nInodes that were part of a corrupted orphan linked list found.  Fix&lt;y&gt;? yes\nInode 776 was part of the orphaned inode list.  FIXED.\nInode 396524 was part of the orphaned inode list.  FIXED.\n...\n</code></pre> <ul> <li>crontab -e read-only filesystem error</li> <li>How to clean up an unprocessed orphan inode list</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#recover","title":"Recover","text":"<ul> <li>How to Recover Deleted Files in Ubuntu through TestDisk</li> <li>[\u6578\u64da\u6062\u5fa9] \u53ef\u6551\u56deEXT3/ EXT4 \u6a94\u6848\u683c\u5f0f\u7684\u958b\u6e90\u5de5\u5177 - extundelete</li> <li>How To Recover Deleted Files In Linux [Beginner\u2019s Guide]</li> <li>How to recover deleted files?</li> <li>Can files/directories deleted with rm be restored</li> <li>Ubuntu Official<ul> <li>DataRecovery</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#backup","title":"Backup","text":"<ul> <li>VirtualBox-Backup</li> <li>Ubuntu Official<ul> <li>BackupYourSystem</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#dpkg-reconfigure","title":"dpkg-reconfigure","text":"<ul> <li>How to do dpkg-reconfigure dash as bash automatically<ul> <li>Feeding input values to dpkg-reconfigure in a non-interactive way</li> </ul> </li> </ul> <p>Dockerfile <pre><code># make /bin/sh symlink to bash instead of dash:\nRUN echo \"dash dash/sh boolean false\" | debconf-set-selections\nRUN DEBIAN_FRONTEND=noninteractive dpkg-reconfigure dash\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#run-32bits-on-64bits-machine","title":"Run 32bits on 64bits machine","text":"<ul> <li>\"No such file or directory\" error when executing a binary</li> </ul> <p>Dockerfile <pre><code>RUN dpkg --add-architecture i386 &amp;&amp; apt update &amp;&amp; apt install libc6:i386 libncurses5:i386 libstdc++6:i386 zlib1g:i386\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#show-variables","title":"show variables","text":"<p>only the environment variables <pre><code>declare -xp\n</code></pre></p> <p>onlu</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#sudoer","title":"sudoer","text":"<p>foo is not in the sudoers file.\u00a0 This incident will be reported.</p> <pre><code>echo 'foo ALL=(ALL:ALL) NOPASSWD: ALL' | sudo tee -a /etc/sudoers\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#dns","title":"DNS","text":"<ul> <li>DNS issues after upgrading to 20.04<ul> <li>Using degraded feature set TCP instead of UDP for DNS server</li> <li>Failed to send hostname reply: Invalid argument</li> </ul> </li> <li>Why does /etc/resolv.conf point at 127.0.0.53?</li> <li>How to persist \u201csystemd-resolve\u201d configuration for a particular network interface</li> <li>linux - Activation via systemd failed for unit 'dbus-org.freedesktop.resolve1.service': Unit dbus-org.freedesktop.resolve1.service not found - Super User</li> </ul> <p>In Ubuntu 20.04, the expected configuration of /etc/resolv.conf is to point to a local systemd-networkd resolver <pre><code>resolvectl status\nsystemd-resolve --status\nsudo systemd-resolve --interface wlp2s0 --set-dns 192.168.88.22 --set-domain yourdomain.local\n</code></pre></p> <pre><code>sudo systemd-resolve --interface enp0s3 --set-dns 8.8.8.8\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#snap","title":"snap","text":"<ul> <li>How to remove disabled (unused) snap packages with a single line of command</li> </ul> <pre><code>snap list --all | awk '/disabled/{print $1\" --revision \"$3}' | xargs -rn3 snap remove\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#md5sum","title":"md5sum","text":"<ul> <li>How can I recursively list Md5sum of all the files in a directory and its subdirectories?</li> </ul> <pre><code>find -type f -exec md5sum '{}' \\; &gt; md5sum.txt\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#watch","title":"watch","text":"<ul> <li>Bash script needed to run every second</li> <li>How To Repeat A Command Every X Seconds On Linux</li> <li>How to kill watch command after certain time or set timeout for a watch command in bash</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#tcpdump","title":"tcpdump","text":"<ul> <li>A tcpdump Tutorial with Examples \u2014 50 Ways to Isolate Traffic</li> </ul> <pre><code>tcpdump -A -i ens160 port 443 -w mtu_issue\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#markdown-to-pdf","title":"markdown to pdf","text":"<ul> <li>Markdown to PDF \u2013 quick howto for linux users (Ubuntu)</li> <li>How to convert a Markdown file to PDF - Stack Overflow</li> <li>How To Convert Markdown to PDF</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#xargs","title":"xargs","text":"<ul> <li>shell - Piping commands after a piped xargs - Unix &amp; Linux Stack Exchange</li> </ul> <pre><code>ls\nmd5_019633f975a7d7cfd1d388b8fb208223_9492    md5_3a4eb5ed075a3c6c8aeb14a982ebcb40_12441   md5_6d7c30ba02010a4cf331a512c80d8e8e_6029     md5_c328f07c2465a7153be141c539d1c5da_8236\nmd5_08bae41634d7ee7282b6f584b047cc97_536834  md5_3c8418fe3dc3d51f756433383b926a02_294060  md5_87af59d786edfac662d9ac0d0add1cb1_4561993  md5_e3ea049445d877a536755cb6ce926011_13865\nmd5_0c96aba202f3d2c31f467aff18878525_10348   md5_461b40bd273b7214c83e5ba450308da4_11372   md5_8845dea738dcbb55cf1552cdfb7be5f4_6961     md5_f249e9dd68edac76168b4d93d041d9fa_823084\nmd5_148a174bd0f7662a012d6207a946ef48_10465   md5_5f6f06a93f5b2aa6d3fff0112f8f8205_13820   md5_8f55ed591f7073a9063d64e006ebec75_7111\nmd5_33768c95f3cf0f93c1f1ea5daa056593_115010  md5_610beebe6bf2a9b189d6924d9d6a4ce4_8734    md5_9570bc6ec0bcc9e3ebf5f52a4436584d_22295\nmd5_34f5fcbc46f66c0fe352deceac2c3d9a_65536   md5_6b46685a1f7da37bc3b4f4708bc6cce7_8366    md5_bd2f633a8cddfc04a80d6f93d6ab5777_11103\nls | awk -F '_' '{print \"mv \"$1\"_\"$2\"_\"$3\" \"$2}' | xargs -I {} sh -c {}\nls\n019633f975a7d7cfd1d388b8fb208223  33768c95f3cf0f93c1f1ea5daa056593  461b40bd273b7214c83e5ba450308da4  6d7c30ba02010a4cf331a512c80d8e8e  9570bc6ec0bcc9e3ebf5f52a4436584d  f249e9dd68edac76168b4d93d041d9fa\n08bae41634d7ee7282b6f584b047cc97  34f5fcbc46f66c0fe352deceac2c3d9a  5f6f06a93f5b2aa6d3fff0112f8f8205  87af59d786edfac662d9ac0d0add1cb1  bd2f633a8cddfc04a80d6f93d6ab5777\n0c96aba202f3d2c31f467aff18878525  3a4eb5ed075a3c6c8aeb14a982ebcb40  610beebe6bf2a9b189d6924d9d6a4ce4  8845dea738dcbb55cf1552cdfb7be5f4  c328f07c2465a7153be141c539d1c5da\n148a174bd0f7662a012d6207a946ef48  3c8418fe3dc3d51f756433383b926a02  6b46685a1f7da37bc3b4f4708bc6cce7  8f55ed591f7073a9063d64e006ebec75  e3ea049445d877a536755cb6ce926011\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#iptables","title":"iptables","text":"<pre><code>sudo iptables -L -n\n</code></pre> <ul> <li>linux - Debugging iptables and common firewall pitfalls? - Server Fault</li> <li>Day 46: debugging an iptables problem</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#iperf","title":"iperf","text":"<ul> <li>iPerf3 \u7db2\u8def\u901f\u5ea6\u6e2c\u8a66\u6559\u5b78\uff0c\u983b\u5bec\u6aa2\u6e2c\u6307\u4ee4\u5de5\u5177 - G. T. Wang</li> <li>Measuring Internal Bandwidth with iperf :: BalanceNG Load Balancer</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ssh","title":"ssh","text":"<ul> <li>A Visual Guide to SSH Tunnels (with labs)</li> <li>SSH Tunneling (Port Forwarding) \u8a73\u89e3 \u00b7 John Engineering Stuff<ul> <li>\u5229\u7528\u9060\u7aef SSH \u4f3a\u670d\u5668\u67b6\u8a2d SOCKS \u4ee3\u7406\u4f3a\u670d\u5668(Proxy Server)\u4fdd\u8b77\u7db2\u8def\u50b3\u8f38\u5167\u5bb9 - MyApollo</li> </ul> </li> <li>Creating an SSH tunnel in Linux | The STAR experiment</li> <li>Port forwarding with SSH - Rufflewind's Scratchpad</li> <li>How to Set up SSH SOCKS Tunnel for Private Browsing | Linuxize</li> <li>\u5728 Ubuntu \u4e2d\u8a2d\u5b9a\u7279\u5b9a\u7528\u6236\u7684 SSH \u5bc6\u78bc\u767b\u5165\u65b9\u6cd5 - Clarence \u7684\u79d1\u6280\u5b78\u7fd2\u5be6\u6230\u7b46\u8a18</li> </ul> <pre><code>ssh-keygen -t ed25519 -C \"bar@foo.com.tw\"\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#port-forwarding-by-multiple-hosts","title":"port forwarding by multiple hosts","text":"<p>client =&gt; hostA =&gt; hostB(exist http server) =&gt; PDU(exist http server with 443)</p> <p>hostA: 172.27.23.103 hostB: 167.22.10.1 PDU: 167.222.17.1</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#single-hop","title":"single hop","text":"<pre><code>ssh -N -L 8080:167.22.10.1:80 foo@172.27.23.103\n# access https://127.0.0.1:8080\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#multiple-hops","title":"multiple hops","text":"<pre><code>ssh -L 8888:localhost:12345 foo@172.27.23.103\nssh -N -L 12345:167.222.17.1:443 foo@167.22.10.1 \n\n# combine above into one commnad\nssh -L 8888:localhost:12345 foo@172.27.23.103 'ssh -N -L 12345:167.222.17.1:443 foo@167.22.10.1'\n\n# if no passwordless\nssh -L 8888:localhost:12345 foo@172.27.23.103 'sshpass -p fakepwd ssh -N -L 12345:167.222.17.1:443 foo@167.22.10.1'\n\n# access https://127.0.0.1:8888\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#known_hosts","title":"known_hosts","text":"<ul> <li>\u7b2c12\u7ae0\uff1aSSH\u9060\u7aef\u9023\u7dda\u8a2d\u5b9a\u8207\u539f\u7406\u4ecb\u7d39\uff08\u4e00\uff09 - iT \u90a6\u5e6b\u5fd9</li> <li>What is known_hosts File in Linux [Everything to Know]</li> <li>SSH Fingerprint: Get Fingerprint of SSH RSA Key - ShellHacks</li> <li>Ubuntu Manpage: ssh-keyscan \u2014 gather ssh public keys</li> <li>ssh_known_hosts file format - IBM Documentation</li> <li>ssh - Check the fingerprint for the ECDSA key sent by the remote host - Server Fault</li> <li>linux - How use ssh-keygen to show either ECDSA or ecdsa-sha2-nistp256? - Super User</li> <li>ssh - How to view ECDSA host key of a server? - Server Fault</li> <li>Linux Commando: How to disable SSH host key checking</li> </ul> <p>current host which has known_hosts file <pre><code>ssh-keyscan &lt;remote host&gt;\nssh-keyscan -t ecdsa &lt;remote host&gt;\nssh-keyscan -t rsa,ecdsa,ed25519 &lt;remote host&gt;\nssh-keyscan -t rsa,ecdsa,ed25519 -H &lt;remote host&gt;\n\nssh-keyscan -t rsa,ecdsa,ed25519 -H &lt;remote host&gt; 2&gt;/dev/null &gt;&gt; .ssh/known_hosts\n\n# Remove an entry from the known_hosts\nssh-keygen -R &lt;remote host&gt;\n</code></pre></p> <p>remote host <pre><code># the content will be added into the known_host\ncat /etc/ssh/ssh_host_ecdsa_key.pub\n# Show fingerprint of specified SSH key file. \n# the output will be shown on the propmpt when access this host first time\nssh-keygen -lf /etc/ssh/ssh_host_ecdsa_key.pub\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ssh-copy-id","title":"ssh-copy-id","text":"<ul> <li>ssh-copy-id</li> <li>SSH \u91d1\u9470\uff1a\u514d\u5bc6\u78bc\u767b\u5165\u9060\u7aef\u4e3b\u6a5f\u3001\u50b3\u905e\u6a94\u6848<ul> <li>authentication - Unable to login with SSH-RSA key - Unix &amp; Linux Stack Exchange</li> <li>Why am I still getting a password prompt with ssh with public key authentication? - Unix &amp; Linux Stack Exchange</li> </ul> </li> <li>linux - How to ssh-copy-id through a jump-host? Something similar to the -J option with ssh command - Server Fault</li> </ul> <pre><code>ssh-copy-id foo@bar.tw\n\n# through bastion\nssh-copy-id -o ProxyJump=jumpuser@jumphost:2455 remoteuser@remotehost\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#authorized_keys","title":"authorized_keys","text":"<ul> <li>sshd(8) - Linux manual page<ul> <li>ssh authorized_keys file location and permissions - Super User</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ssh-serversshd","title":"ssh server(sshd)","text":"<p>if you changed the sshd server config file and before restart or reload OpenSSH server <pre><code>/usr/sbin/sshd -t\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ssh-agent","title":"ssh agent","text":"<ul> <li>Working with SSH key passphrases - GitHub Docs</li> <li>Using SSH agent forwarding - GitHub Docs</li> <li>5 SSH Agent Best Practices</li> <li>\u6dfa\u8ac7 SSH agent forwarding \u548c proxy command \u7684\u5b89\u5168\u98a8\u96aa\u8207\u61c9\u7528 \u00ab Nic Lin's Blog</li> <li>Ssh-agent single sign-on configuration, agent forwarding, the agent protocol.</li> </ul> <pre><code>env=~/.ssh/agent.env\n\nagent_load_env () { test -f \"$env\" &amp;&amp; . \"$env\" &gt;| /dev/null ; }\n\nagent_start () {\n    (umask 077; ssh-agent &gt;| \"$env\")\n    . \"$env\" &gt;| /dev/null ; }\n\nagent_load_env\n\n# agent_run_state: 0=agent running w/ key; 1=agent w/o key; 2=agent not running\nagent_run_state=$(ssh-add -l &gt;| /dev/null 2&gt;&amp;1; echo $?)\n\nif [ ! \"$SSH_AUTH_SOCK\" ] || [ $agent_run_state = 2 ]; then\n    agent_start\n    ssh-add\nelif [ \"$SSH_AUTH_SOCK\" ] &amp;&amp; [ $agent_run_state = 1 ]; then\n    ssh-add\nfi\n\nunset env\n</code></pre> <p>If you want ssh-agent to forget your key after some time, you can configure it to do so by running ssh-add -t {seconds}.</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#config-for-sshd","title":"config for sshd","text":"<p>premit root ssh login <pre><code>cat &lt;&lt;EOF &gt;&gt; /etc/ssh/sshd_config.d/customized.conf\nPermitRootLogin yes\nPasswordAuthentication yes\nEOF\n\nsystemctl restart sshd\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#firewalld","title":"firewalld","text":"<ul> <li>CentOS Linux 7 \u4ee5 firewalld \u6307\u4ee4\u8a2d\u5b9a\u9632\u706b\u7246\u898f\u5247\u6559\u5b78 - G. T. Wang<ul> <li>CentOS Linux 7 \u4ee5 firewalld \u6307\u4ee4\u8a2d\u5b9a\u9632\u706b\u7246\u898f\u5247\u6559\u5b78 - \u98012\uff0c\u51712 - G. T. Wang</li> </ul> </li> <li>firewalld from iptables - Documentation</li> <li>Secure your Linux network with firewall-cmd | Enable Sysadmin</li> <li>CentOS 7 \u8a2d\u5b9a\u9632\u706b\u7246\u5141\u8a31\u7279\u5b9a PORT \u9023\u7dda - Yowko's Notes</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#basic","title":"basic","text":"<ul> <li>How to Setup Linux Firewall Using Firewalld | Cherry Servers</li> </ul> <p>external - Used when you want to configure the firewall as a NAT gateway. The external zone is used for NAT masquerading such that your internal network stays private but reachable from external systems.</p> <p>internal - Used for internal networks when you trust other computers or servers on your LAN.</p> <p>each zone has its associated .xml file stored within the /usr/lib/firewalld/zones/ directory</p> <p>By default, all the network interfaces are bound to default zone</p> <pre><code># get a list of all the zones\nsudo firewall-cmd --get-zones\n\nsudo firewall-cmd --get-default-zone\nsudo firewall-cmd --get-active-zones\n\n# display all the services supported by Firewalld\nsudo firewall-cmd --get-services\nsudo firewall-cmd --list-services\nsudo firewall-cmd --list-services --zone=public \n\n# you can bind an interface to another zone\nsudo firewall-cmd --change-interface=ens160 --zone=internal \n\n# check out the configuration associated with the internal zone\nsudo firewall-cmd --list-all --zone=internal\n\n# add/remove Services on Firewalld\nsudo firewall-cmd --add-service=http --zone=public\nsudo firewall-cmd --remove-service=http --zone=public\n</code></pre> <p>The --permanent option makes the change persistent. For the change made to apply even after a reboot, reload the firewall.</p> <pre><code>sudo firewall-cmd --add-service=http --zone=public --permanent\nsudo firewall-cmd --reload\n\nsudo firewall-cmd --remove-service=http --zone=public --permanent\nsudo firewall-cmd --reload\n\nsudo firewall-cmd --zone=public --add-port=18443/tcp --permanent\nsudo firewall-cmd --reload\n\nsudo firewall-cmd --zone=public --remove-port=18443/tcp --permanent\nsudo firewall-cmd --reload\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nfs","title":"nfs","text":"<p>NFS behind firewall</p> <pre><code>sudo firewall-cmd --zone=public --list-all\nsudo firewall-cmd --zone=public --add-service=nfs --permanent\nsudo firewall-cmd --reload\nsudo systemctl restart nfs-server\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#cat","title":"cat","text":"<ul> <li>Linux Here Document \u8207 cat + EOF \u7684\u4f7f\u7528 | Peng Jie's Blog<ul> <li>shell script about \"cat &lt;&lt;- _EOF_\" - Stack Overflow</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#tee","title":"tee","text":"<ul> <li>[Linux] tee \u6307\u4ee4\uff1a\u5c07\u7d50\u679c\u540c\u6642\u8f38\u51fa\u5230\u87a2\u5e55\u548c\u6a94\u6848 \u2013 OneJar \u7684\u96a7\u9053</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#network","title":"network","text":"<ul> <li>Linux \u7db2\u8def\u8a2d\u5b9a</li> <li>Linux: How to find the device driver used for a device? - Unix &amp; Linux Stack Exchange<ul> <li><code>ethtool -i enp2s0</code></li> <li><code>sudo lspci -v | grep 'Ethernet controller'</code></li> </ul> </li> <li>How to find PCI address of an ethernet interface? - Ask Ubuntu<ul> <li><code>sudo lshw -c network -businfo</code></li> <li><code>grep PCI_SLOT_NAME /sys/class/net/*/device/uevent</code></li> </ul> </li> <li>ethtool \u547d\u4ee4\uff0cLinux ethtool \u547d\u4ee4\u8be6\u89e3\uff1a\u663e\u793a\u6216\u4fee\u6539\u4ee5\u592a\u7f51\u5361\u7684\u914d\u7f6e\u4fe1\u606f - Linux \u547d\u4ee4\u641c\u7d22\u5f15\u64ce</li> <li>36.2.\u00a0\u4f7f\u7528 NetworkManager \u914d\u7f6e ethtool offload \u529f\u80fd Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>Configuring Mellanox mlx5 cards in Red Hat Enterprise Linux - Red Hat Customer Portal</li> <li>Red Hat Enterprise Linux Network Performance Tuning Guide</li> <li>linux - Check if a DHCP server existing in my network using bash - Super User<ul> <li><code>nmap --script broadcast-dhcp-discover -e eth0</code></li> </ul> </li> <li>networking - I can ping a server, but I can not ssh to it - Super User<ul> <li><code>nmap 172.17.30.108 -p 22</code></li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#cpu","title":"cpu","text":"<ul> <li>Rivermax Linux Performance Tuning Guide [1]</li> <li>cpu - Understanding output of lscpu - Unix &amp; Linux Stack Exchange</li> <li>What is the correct way to view your CPU speed on Linux? - Unix &amp; Linux Stack Exchange</li> <li>How To Set CPU Scaling Governor to Max Performance (scaling_governor)</li> <li>\u5982\u4f55\u4f7f\u7528 cpufreq-set \u548c cpufreq-info \u9032\u884c CPU \u8abf\u6548\uff1a\u63d0\u5347\u7cfb\u7d71\u6027\u80fd\u7684\u6700\u4f73\u5be6\u8e10 - Clarence \u7684\u79d1\u6280\u5b78\u7fd2\u5be6\u6230\u7b46\u8a18</li> </ul> <pre><code>lscpu\n\ncpupower frequency-info\ncat /proc/cpuinfo | egrep 'cpu MHz|processor'\ncat /proc/cpuinfo | sed -n '/^processor\\|^cpu MHz/p'\n\ncat /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq\ncat /sys/devices/system/cpu/cpu0/cpufreq/scaling_min_freq\ncat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cur_freq\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#rpm","title":"rpm","text":"<ul> <li>RPM \u6253\u5305\ufe30\u7531\u4e00\u7ac5\u4e0d\u901a\u5230\u52d5\u624b\u6feb\u7528 (\u4e8c). \u6559\u4f60\u5982\u4f55\u95b1\u8b80\u3001\u7de8\u5beb\u6253\u5305\u7528\u7684 .spec \u6a94\u6848 | by Koala Yeung | Linux \u5165\u9580\u7b46\u8a18 | Medium</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#umask","title":"umask","text":"<ul> <li>unix - what is the difference between umask and chmod - Super User</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#mount","title":"mount","text":"<ul> <li>How to Mount and Unmount an ISO Image in Linux</li> <li>\u4f7f Amazon EBS \u78c1\u789f\u5340\u53ef\u5728 Linux \u4e0a\u4f7f\u7528 - Amazon Elastic Compute Cloud</li> <li> <p>mount(8) \u2014 mount \u2014 Debian testing \u2014 Debian Manpages</p> <ul> <li><code>--all</code>, in this case already mounted filesystems are ignored<ul> <li>Does `mount -a` cause already mounted filesystems to be remounted, or are they ignored? - Unix &amp; Linux Stack Exchange</li> </ul> </li> <li>mount(8): mount filesystem - Linux man page <pre><code>sudo blkid\n# Reload the changes after changing the /etc/fstab by executing the command\nsudo mount -a\n</code></pre></li> </ul> </li> <li> <p>What Is /dev/shm And Its Practical Usage - nixCraft</p> </li> </ul> <pre><code>mount -o remount,size=8G /dev/shm\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nmap","title":"nmap","text":""},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#arp","title":"arp","text":"<p>Ceasar's Free Life: Linux\u6e05\u9664ARP \u66ab\u5b58 <pre><code># clear specific ip\narp -d {IP}\n\n# clear all\narp -n|awk '/^[1-9]/ {print \"arp -d \"$1}' | sh\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#netstat","title":"netstat","text":"<p>netstat -tulnp</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#udevadm","title":"udevadm","text":"<p>a tool used to manage the udev device manager in Linux.</p> <p>The ID_WWN (World Wide Name) property in udev is a unique identifier for a device. It is often used to identify storage devices, such as hard drives and solid-state drives.</p> <p>The ID_WWN property is assigned by the manufacturer of the device and is usually stored on the device itself. It is a 64-bit value that is unique to each device.</p> <pre><code>udevadm info --query=property --name=nvme0n1\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#pstree","title":"pstree","text":"<ul> <li>Linux pstree \u4ee5\u6a39\u72c0\u5716\u986f\u793a\u884c\u7a0b\u76f8\u95dc\u6027\u6307\u4ee4\u6559\u5b78 - G. T. Wang</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nmcli","title":"nmcli","text":"<ul> <li>nmcli: NetworkManager Reference Manual</li> <li>3 ways to configure a network interface in Linux | Enable Sysadmin</li> <li>How to assign an additional/alias IP addresses to a network card (NIC)? - Red Hat Customer Portal</li> <li>Linux NetworkManager \u7528\u547d\u4ee4\u5217\u5de5\u5177\u6216\u7d44\u614b\u6a94\u8a2d\u5b9a\u7db2\u8def\u9023\u7dda - \u77f3\u982d\u9592\u8a9e</li> </ul> <p>config infiniband - 0000166: NetworkManager fails to configure IP over InfiniBand (IPoIB) connections - Rocky Linux BugTracker - NetworkManager restart fails with: device state change: prepare -&gt; failed (reason 'dependency-failed') - Red Hat Customer Portal - Infiniband Troubleshooting \u2013 Hasan Mansur</p> <pre><code># check the link status\nibdev2netdev\nibstatus\nibstat\niblinkinfo\n\nnmcli connection add type infiniband con-name ib0 ifname ib0\nnmcli connection modify ib0 ipv4.addresses 167.123.200.3/16\nnmcli connection modify ib0 ipv4.method manual\nnmcli connection modify ib0 ipv6.method ignore\n# If ifcfg-files have changed, those changes can be applied with\nnmcli connection reload\nnmcli connection up ib0\n</code></pre> <p>gateway <pre><code># add the gateway\nsudo nmcli connection modify enp68s0f0 ipv4.gateway \"167.23.10.3\"\n\n# remove the gateway\nsudo nmcli connection modify enp68s0f0 ipv4.gateway \"\"\n\nsudo nmcli connection reload &amp;&amp; sudo nmcli connection down enp68s0f0 &amp;&amp; sudo nmcli connection up enp68s0f0\n</code></pre></p> <p>dns <pre><code># add the dns\nsudo nmcli connection modify enp68s0f0 ipv4.dns \"167.23.10.3 8.8.8.8\"\n\n# change the dns priority\nsudo nmcli connection modify enp68s0f0 ipv4.dns-priority 50\n# The default DNS priority values in NetworkManager are:\n# 50 for VPN connections\n# 100 for other connections\n# A lower value indicates a higher priority. If you don't set a specific priority, these default values will be used.\n\n# remove the dns\nsudo nmcli connection modify enp68s0f0 ipv4.dns \"\"\n\nsudo nmcli connection reload &amp;&amp; sudo nmcli connection down enp68s0f0 &amp;&amp; sudo nmcli connection up enp68s0f0\n</code></pre></p> <p>auto or manual <pre><code># manual\nnmcli connection modify ens34 \\\nipv4.method manual \\\nipv4.address 192.168.10.11/24 \\\nipv4.gateway 192.168.10.1 \\\nipv4.dns 8.8.8.8\n\nip link set ens34 down &amp;&amp; ip link set ens34 up\ncat /etc/NetworkManager/system-connections/ens34.nmconnection\n\n# auto\nnmcli connection modify ens34 \\\nipv4.method auto \\\nipv4.address '' \\\nipv4.gateway ''\n\nip link set ens34 down &amp;&amp; ip link set ens34 up\ncat /etc/NetworkManager/system-connections/ens34.nmconnection\n</code></pre></p> <p>if device is disconnected <pre><code>systemctl restart NetworkManager\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#netplan","title":"netplan","text":"<ul> <li>Ubuntu 20.04 \u7db2\u8def\u8a2d\u5b9a | \u4e0d\u52d9\u6b63\u696d\u5de5\u7a0b\u5e2b\u7684\u5bb6<ul> <li>How to add static route with netplan on Ubuntu 22.04 Jammy Jellyfish Linux - Linux Tutorials - Learn Linux Configuration</li> </ul> </li> <li>Ubuntu 20.04 \u7db2\u8def\u7d81\u5b9a | \u4e0d\u52d9\u6b63\u696d\u5de5\u7a0b\u5e2b\u7684\u5bb6</li> <li>How to Configure Networking in Ubuntu 20.04 with NetPlan - Serverlab</li> <li>linux - Is \"netplan apply\" required if I reboot after changing /etc/netplan/xxx-config.yaml file - Server Fault</li> <li>networking - Netplan does not apply at startup - Ask Ubuntu</li> <li>networking - How do I stop netplan from binding a default gateway on every interface - Ask Ubuntu</li> <li>networking - What does \"routes\" mean? [Netplan, YAML file] - Ask Ubuntu</li> <li>ubuntu - netplan static and dynamic interfaces without default route for static? - Stack Overflow</li> </ul> <p>/etc/netplan</p> <pre><code>network:\n  ethernets:\n    ens160:\n      dhcp4: true\n    ens192:\n      addresses: [ 172.20.0.1/16]\n  version: 2\n</code></pre> <p>no default route <pre><code>network:\n  ethernets:\n    ens160:\n      dhcp4: true\n      dhcp4-overrides:\n         use-routes: false\n    ens192:\n      addresses: [ 172.20.0.1/16]\n  version: 2\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#dhcp","title":"dhcp","text":"<p>To release the current dynamic IP address, use the \"dhclient -r\" command followed by the name of the network interface.  <pre><code># release the dynamic IP address for the eth0 interface.\ndhclient -r eth0\n</code></pre></p> <p>To remove a specific dynamic IP address, use the \"ip addr del\" command followed by the IP address and the network interface.  <pre><code># remove the IP address 192.168.0.100 from the eth0 interface\nip addr del 192.168.0.100 dev eth0\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#in-box-driver","title":"In-box driver","text":"<p>You can also use the lsmod command to list the modules that are currently loaded in the kernel, which will include in-box drivers that are being used by the system.</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#xml","title":"xml","text":"<p>xmlstarlet <pre><code>yum install xmlstarlet\n\nxmlstarlet sel -t -v \"//comps/environment/name[not(@xml:lang)]\" -n my.xml\n\nxmlstarlet sel -t -v \"//comps/group[id='infiniband']/packagelist/packagereq\" -n my.xml\n\nxmlstarlet sel -t -v \"//comps/group[id='infiniband']/packagelist/packagereq[not(@type='optional')]\" -n my.xml\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ulimit","title":"ulimit","text":"<ul> <li>\u67e5\u8a62\u8207\u8a2d\u5b9a Linux \u4f7f\u7528\u8005\u53ef\u958b\u555f\u7684\u884c\u7a0b\u6578\u91cf\u4e0a\u9650\u503c\uff0c\u9650\u5236\u958b\u555f\u7a0b\u5f0f\u7684\u6578\u76ee - G. T. Wang</li> <li>\u89e3\u958bCentOs \u5229\u7528systemd \u8d77service \u7684 ulimit \u8cc7\u6e90\u9650\u5236 | by Yen-Ying Lee | Medium</li> <li>limit - ulimit vs file-max - Unix &amp; Linux Stack Exchange</li> <li>ulimit - do changes in /etc/security/limits.conf require a reboot? - Unix &amp; Linux Stack Exchange</li> <li>Linux\u4e0b\u7684resource limits(ulimit) | C0reFast\u8bb0\u4e8b\u672c</li> <li>Linux\u6700\u5927\u958b\u5553\u6a94\u6848\u6578- FineBI\u5e2e\u52a9\u6587\u6863 FineBI\u5e2e\u52a9\u6587\u6863</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#operation-not-permitted","title":"Operation not permitted","text":"<p>ulimit: open files: cannot modify limit: Operation... - Hewlett Packard Enterprise Community bash - ulimit PICKLE: \"Operation not permitted\" and \"Command not found\" - Unix &amp; Linux Stack Exchange A normal user can adjust the soft limit freely in the range of 0.... A normal user can adjust the hard limit too, but can only decrease it. You must be root to increase the hard limit from its default value.</p> <p>The limit values are inherited from the parent process to the child process: you could add the command to increase the hard limit to the sshd startup script, so that sshd and all sessions started through it will inherit the increased hard limit. After that, you should be able to increase the soft limit as a normal user. <pre><code>ulimit -a\nulimit -H -a\n</code></pre></p> <p>/etc/security/limits.conf <pre><code>* soft memlock unlimited\n* hard memlock unlimited\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nohup","title":"nohup","text":"<ul> <li>Linux \u7684 nohup \u6307\u4ee4\u4f7f\u7528\u6559\u5b78\u8207\u7bc4\u4f8b\uff0c\u767b\u51fa\u4e0d\u4e2d\u65b7\u7a0b\u5f0f\u57f7\u884c - G. T. Wang</li> <li>[Day3] Linux \u5077\u61f6\u5c0f\u5de5\u5177 nohup</li> <li>linux - What's the difference between nohup and ampersand - Stack Overflow</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#fill-whole-disk-space-in-linux","title":"fill whole disk space in Linux","text":"<ul> <li>Tip: How to quickly fill whole disk space in Linux with one command ? | New Generation Enterprise Linux</li> </ul> <pre><code>date; nohup yes; date\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#etcshadow","title":"/etc/shadow","text":"<pre><code># SHA512\nopenssl passwd -6 test\n# $6$MY7OCrv90dRsfxoP$Lq8Uo1gNddpOC1YIOabuadH9XO/QxUTfb6V9.xeF/Cq50CG2asUa9eL0gUG0cOShhfgeqA7lYIdVjiEDnCYoM.\nsudo usermod -p '$6$MY7OCrv90dRsfxoP$Lq8Uo1gNddpOC1YIOabuadH9XO/QxUTfb6V9.xeF/Cq50CG2asUa9eL0gUG0cOShhfgeqA7lYIdVjiEDnCYoM.' username\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#chrony","title":"chrony","text":"<ul> <li>Chapter\u00a029.\u00a0Using Chrony Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>13.2.\u00a0\u4f7f\u7528 Chrony | Red Hat Product Documentation</li> <li>chrony \u2013 chrony.conf(5)</li> </ul> <pre><code>chronyc sources -v\nchronyc tracking\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#systemd","title":"systemd","text":"<ul> <li>systemd - How to see full log from systemctl status service? - Unix &amp; Linux Stack Exchange</li> <li>SLES 15 SP1 | Administration Guide | The systemd daemon</li> <li>Linux systemd \u7cfb\u7d71\u670d\u52d9\u7ba1\u7406\u57fa\u790e\u6559\u5b78\u8207\u7bc4\u4f8b - G. T. Wang</li> <li>Linux \u5efa\u7acb\u81ea\u8a02 Systemd \u670d\u52d9\u6559\u5b78\u8207\u7bc4\u4f8b - G. T. Wang</li> <li>linux - Do you know how to make the system automatically restart daemon service? - Stack Overflow</li> <li>How to Control Systemd Services on Remote Linux Server</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#vim","title":"vim","text":"<ul> <li>\u8a18\u9304\u7528: 106.07.01 vim \u591a\u884c\u8a3b\u89e3\u8207\u53d6\u6d88</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#gpustat","title":"gpustat","text":"<ul> <li>Multi-server GPU status monitor | SSARCandy's Blog</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#lspci","title":"lspci","text":"<ul> <li>lspci\u547d\u4ee4\u8f93\u51fa\u7684\u4e00\u4e9b\u89e3\u91ca | C0reFast\u8bb0\u4e8b\u672c<ul> <li>/usr/share/hwdata/pci.ids.gz</li> <li>/usr/share/hwdata/pci.ids</li> <li>The PCI ID Repository</li> </ul> </li> </ul> <p>Bus Number:Device Number.Function Number</p> <pre><code>lspci\nlspci -D\nlspci -nn\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#gpu","title":"gpu","text":"<p>NVIDIA <pre><code>[foo@bar ~]$ lspci | grep NVIDIA\n01:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)\n81:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)\n[foo@bar ~]$\n</code></pre></p> <p>AMD <pre><code>foo@bar:~$ lspci | grep Display\n03:00.0 Display controller: Advanced Micro Devices, Inc. [AMD/ATI] Device 740f (rev 02)\nfoo@bar:~$ \n</code></pre></p> <pre><code>foo@mi325x:/tmp$ lspci | grep -i 'accelerators'\n05:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\n15:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\n65:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\n75:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\n85:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\n95:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\ne5:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\nf5:00.0 Processing accelerators: Advanced Micro Devices, Inc. [AMD/ATI] Device 74a5\nfoo@mi325x:/tmp$\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#logrotate","title":"logrotate","text":"<ul> <li>Setting up logrotate in Linux | Enable Sysadmin</li> <li>linux - How to make log-rotate change take effect - Unix &amp; Linux Stack Exchange</li> </ul> <pre><code>ls -la /etc/cron.daily/\n## debug output\nlogrotate -d /etc/logrotate.d/your-logrotate-config\n## execute it directly\nlogrotate /etc/logrotate.d/your-logrotate-config\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#environment-modules","title":"environment-modules","text":"<pre><code>dnf -y install environment-modules\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#alternatives","title":"alternatives","text":"<pre><code>alternatives --set python3 /usr/bin/python3.8\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#ip","title":"ip","text":"<ul> <li>rh_ip_command_cheatsheet_1214_jcs_print.pdf</li> <li>awesome-cheatsheets/tools/ip.txt at master \u00b7 skywind3000/awesome-cheatsheets</li> <li>linux - ip vs ifconfig commands pros and cons - Unix &amp; Linux Stack Exchange</li> <li>ip vs. ifconfig: Which do you use? | Enable Sysadmin</li> <li>Linux networking: ifconfig versus ip | Enable Sysadmin</li> <li>linux/ip---route---command.md at master \u00b7 wl-sre/linux \u00b7 GitHub</li> </ul> <pre><code>ip route del default\nip route add default via 172.19.50.1 dev enp3s0f1\nping -c 2 8.8.8.8; ping -c 2 www.google.com; curl www.google.com\n</code></pre> <p>static route <pre><code>ip route add 192.168.1.0/24 via 192.168.1.1 dev eth0\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nvidia-smi","title":"nvidia-smi","text":"<ul> <li>\u89e3\u6c7a NVIDIA Linux \u4f7f\u7528 nvidia-smi \u51fa\u73fe No devices were found \u554f\u984c - Clarence \u7684\u79d1\u6280\u5b78\u7fd2\u5be6\u6230\u7b46\u8a18</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#lsof","title":"lsof","text":"<pre><code>sudo lsof -i :53\n\n# sudo killall dnsmasq\n</code></pre> <pre><code>COMMAND   PID            USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nsystemd-r 254 systemd-resolve   12u  IPv4  23159      0t0  UDP 127.0.0.53:domain\nsystemd-r 254 systemd-resolve   13u  IPv4  23160      0t0  TCP 127.0.0.53:domain (LISTEN)\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#dnsmasq","title":"dnsmasq","text":"<ul> <li>linux - how to disable dnsmasq service in CentOS 8 - Stack Overflow</li> <li>How to configure DNS caching server with dnsmasq in RHEL - Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#yq","title":"yq","text":"<ul> <li>yq - yq</li> </ul> <p>Another tool named yq is at https://kislyuk.github.io/yq/. The two yq tools are not compatible; commands that are designed for one of them do not work with the other.</p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nmstate","title":"NMState","text":"<ul> <li>NMState All you need to know - Goglides Dev \ud83c\udf31</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#nfs_1","title":"NFS","text":"<p>/etc/exports</p> <p>specify which directories on a server should be available to NFS clients re-export all NFS shared directories specified in the /etc/exports file and provides verbose output <pre><code>exportfs -arv\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#journalctl","title":"journalctl","text":"<ul> <li>journalctl\u4f7f\u7528\u7b46\u8a18 - babygoat's blog</li> <li>systemd &amp; systemctl &amp; journalctl - HackMD</li> </ul> <pre><code>journalctl -r -u foo.service\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#vnc","title":"VNC","text":"<ul> <li>noVNC\uff0c\u7528\u4efb\u610f\u7db2\u9801\u700f\u89bd\u5668\u5b58\u53d6Linux VNC\u9060\u7aef\u684c\u9762 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#dnsmasq_1","title":"dnsmasq","text":"<ul> <li>\u4f7f\u7528 dnsmasq \u914d\u7f6e\u5185\u90e8 DNS server</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#rclone","title":"rclone","text":"<ul> <li>Rclone:\u73a9\u8f49Google Drive &amp; One Drive - \u6d88\u5931\u7684\u4e9e\u7279\u862d\u63d0\u65af</li> <li>\u624b\u52d5\u6253\u9020Google Drive\u540c\u6b65\u5de5\u5177\uff1aownCloud\u8207rclone\u7684\u7d44\u5408 / Build a File Sync Tool for Google Drive: ownCloud + rclone - \u5e03\u4e01\u5e03\u4e01\u5403\u4ec0\u9ebc\uff1f</li> <li>GUI</li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#timedatectl","title":"timedatectl","text":"<pre><code>timedatectl status\ntimedatectl list-timezones\ntimedatectl set-timezone \"Asia/Taipei\"\n\ntimedatectl timesync-status\n</code></pre> <pre><code>apt install systemd-timesyncd\ntimedatectl set-ntp true\nsystemctl start systemd-timesyncd\nsystemctl status systemd-timesyncd\n</code></pre> <p>/etc/systemd/timesyncd.conf <pre><code>[Time]\nNTP=ntp.server.you.want\n</code></pre></p>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#iftop","title":"iftop","text":"<ul> <li>Linux iftop \u547d\u4ee4 - Jamin Zhang</li> <li>\u3010\u7b46\u8a18\u6574\u7406\u3011Linux\u7db2\u8def\u6d41\u91cf\u5373\u6642\u76e3\u63a7\uff1aiftop | ghoseliang - \u9ede\u90e8\u843d</li> </ul> <pre><code>iftop -i ens192 -B\n</code></pre>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#build-iso","title":"build ISO","text":"<ul> <li>GNU xorriso - GNU Project - Free Software Foundation<ul> <li>linux - How to create bootable ISO from custom Ubuntu 22.04 Image? - Unix &amp; Linux Stack Exchange</li> <li>boot - Ubuntu 22.04 build ISO (Both: MBR and EFI ) - Ask Ubuntu</li> </ul> </li> <li>How to create a modified Red Hat Enterprise Linux ISO with kickstart file or modified installation media? - Red Hat Customer Portal<ul> <li>mkisofs</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E6%8A%80%E5%B7%A7/#dotfile","title":"dotfile","text":"<ul> <li>Chezmoi\uff1a\u512a\u96c5\u7ba1\u7406Linux\u7684dotfile\uff0c\u4f7f\u7528Git\u5132\u5b58\u5eab\u5099\u4efd\uff0c\u985e\u4f3cGNU Stow \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/","title":"Linux\u89c0\u5ff5","text":"<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c 11 \u5802\u8ab2\uff1a\u57fa\u790e\u8a2d\u5b9a\u3001\u5099\u4efd\u3001\u6a94\u6848\u58d3\u7e2e\u6253\u5305\u8207\u5de5\u4f5c\u6392\u7a0b</li> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c 13 \u5802\u8ab2\uff1a\u670d\u52d9\u7ba1\u7406\u8207\u958b\u6a5f\u6d41\u7a0b\u7ba1\u7406<ul> <li>\u5c08\u984c\u4e94 - \u5efa\u7acb rootfs \u7684\u7121\u78c1\u789f Linux \u7cfb\u7d71\u74b0\u5883<ul> <li>The kernel\u2019s command-line parameters \u2014 The Linux Kernel documentation</li> </ul> </li> <li>\u6df1\u5165\u7406\u89e3 Linux 2.6 \u7684 initramfs \u6a5f\u5236<ul> <li>Understanding the initrd and vmlinuz in Linux Boot Process - DEV Community</li> </ul> </li> <li>generate customized iso and explain the boot process by ChatGPT</li> <li>SQUASHFS-Linux\u58d3\u7e2e\u578b\u6a94\u6848\u7cfb\u7d71\u7684\u738b\u8005 - Day dreamer's blog</li> </ul> </li> <li>\u7b2c 2 \u5802\u8ab2 - SELinux \u521d\u63a2\u8207\u7db2\u8def\u57fa\u790e</li> <li>\u7b2c 3 \u5802\u8ab2 - LACP \u8207 bonding/team \u53ca IPv6 \u7c21\u6613\u8a2d\u5b9a</li> <li>\u7b2c 4 \u5802\u8ab2 - \u8a8d\u8b58\u8207\u5efa\u7f6e\u9632\u706b\u7246</li> <li>\u7b2c 5 \u5802\u8ab2 - \u5340\u57df\u7db2\u8def\u7684 DHCP server \u5efa\u7f6e<ul> <li>How can I give IP addresses to 1000 users via DHCP? - Super User</li> <li>PT-27- \u5be6\u4f5c3\u68df\u5927\u6a13DHCP Server\u8207DHCP Relay Agent\u7684\u8a2d\u5b9a\uff08CCNA\u5148\u5099\u6280\u80fd\uff09 - YouTube<ul> <li>Cisco DHCP Relay Agent (IP Helper) \u57fa\u672c\u8a2d\u5b9a - King Zone</li> </ul> </li> <li>Configuring a DHCP Relay Agent on Ubuntu 20.04 | Reintech media</li> <li>DHCP-DHCP Relay Agent - Ask Ubuntu</li> </ul> </li> <li>\u7b2c 7 \u5802\u8ab2 - \u8eab\u4efd\u8b58\u5225\u4f3a\u670d\u5668\u8207\u5167\u90e8\u6a94\u6848\u7cfb\u7d71\u4f3a\u670d\u5668<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u5341\u4e00\u7ae0\u3001\u4f7f\u7528 LDAP \u7d71\u4e00\u7ba1\u7406\u5e33\u865f</li> </ul> </li> <li>The \ud835\udc0b\ud835\udc22\ud835\udc27\ud835\udc2e\ud835\udc31 \ud835\udc12\ud835\udc2d\ud835\udc28\ud835\udc2b\ud835\udc1a\ud835\udc20\ud835\udc1e \ud835\udc12\ud835\udc2d\ud835\udc1a\ud835\udc1c\ud835\udc24 \ud835\udc03\ud835\udc22\ud835\udc1a\ud835\udc20\ud835\udc2b\ud835\udc1a\ud835\udc26 shows the layout of the the Linux storage stack. Diagram by Thomas-Krenn. </li> <li>\u95dc\u65bc \u00b7 \u6bcf\u4f4d\u7a0b\u5f0f\u958b\u767c\u8005\u90fd\u8a72\u6709\u7684\u8a18\u61b6\u9ad4\u77e5\u8b58</li> <li>Check if Computer Uses UEFI or Legacy BIOS [Linux &amp; Windows]</li> <li>Ventoy\u6559\u5b78\uff1a\u88fd\u4f5c\u80fd\u7576Linux\uff06Windows\u958b\u6a5f\u789f\u53c8\u7576\u8cc7\u6599\u789f\u7684USB\u96a8\u8eab\u789f \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>\u7d00\u9304\u4f7f\u7528Linux\u7cfb\u7d71\u4e8c\u5e74\u5f8c\u7684\u5fc3\u5f97 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>\u6211\u5168\u90fd\u8981\uff01Distrobox\u4f7f\u7528\u6559\u5b78\uff0c\u900f\u904e\u5bb9\u5668\u5b89\u88dd\u5176\u4ed6Linux\u767c\u884c\u7248\u7684\u5957\u4ef6 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>NCNU OpenSource - LSA \u8ab2\u7a0b\u4ecb\u7d39</li> <li>:star:LPIC<ul> <li>LPIC-1 Exam 101<ul> <li>Learning Materials: LPIC-1 (101) - LPI-Learning-Material-101-500-en.pdf</li> </ul> </li> <li>LPIC-1 Exam 102<ul> <li>Learning Materials: LPIC-1 (102) - LPI-Learning-Material-102-500-en.pdf</li> </ul> </li> <li>Security Essentials<ul> <li>Learning Materials: Security Essentials - LPI-Learning-Material-020-100-en.pdf</li> </ul> </li> <li>LPIC-2<ul> <li>The LPIC2 Exam Prep - lpic2book.pdf</li> </ul> </li> </ul> </li> <li>FHS<ul> <li>FHS Referenced Specifications</li> <li>FHS \u8b1b\u7fa9 - HackMD</li> </ul> </li> </ul>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#_1","title":"\u78c1\u789f\u5206\u5272\u8207\u6a94\u6848\u7cfb\u7d71","text":"<ul> <li>unix - How to get the number of physical disks in Linux? - Super User</li> <li>[Linux] Linux LVM \u78c1\u5340\u64f4\u589e disk extending (\u4ee5 Redhat \u70ba\u4f8b) - \u6e05\u65b0\u4e0b\u5348\u8336</li> <li>\u4e86\u89e3LVM\u4e26\u65bcUbuntu\u64f4\u5145\u4f3a\u670d\u5668\u78c1\u789f\u7a7a\u9593 \u00b7 GitHub</li> <li>\u7bc0\u7701\u5de5\u5177\u7bb1 Jason Tools: [\u6280\u8853\u6587\u7ae0] Proxmox VE \u5132\u5b58\u67b6\u69cb\u8868</li> <li>Linux \u786c\u789f\u7a7a\u9593\u4e0d\u8db3\u600e\u9ebc\u8fa6\uff1f\u6392\u67e5\u8207\u6e05\u7406\u7684\u5b8c\u6574\u6307\u5357 - Clarence \u7684\u79d1\u6280\u5b78\u7fd2\u5be6\u6230\u7b46\u8a18</li> </ul>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#_2","title":"\u78c1\u789f\u5206\u5272","text":"<p>\u63a5\u8fd1\u7269\u7406\u5c64\u7684\u786c\u9ad4\u4e0a\u505a\u7b2c\u4e00\u5c64\u7684\u62bd\u8c61\u5316 - \u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u4e8c\u7ae0\u3001\u4e3b\u6a5f\u898f\u5283\u8207\u78c1\u789f\u5206\u5272     - \u5728Linux\u7cfb\u7d71\u4e2d\uff0c\u6bcf\u500b\u88dd\u7f6e\u90fd\u88ab\u7576\u6210\u4e00\u500b\u6a94\u6848\u4f86\u5c0d\u5f85         - Linux\u6838\u5fc3\u652f\u63f4\u7684\u786c\u9ad4\u88dd\u7f6e\u8207\u6a94\u540d     - \u6574\u9846\u78c1\u789f\u7684\u7b2c\u4e00\u500b\u78c1\u5340\u7279\u5225\u7684\u91cd\u8981\uff0c\u56e0\u70ba\u4ed6\u8a18\u9304\u4e86\u6574\u9846\u78c1\u789f\u7684\u91cd\u8981\u8cc7\u8a0a         - MBR (Master Boot Record)             - \u7b2c\u4e00\u500b\u78c1\u5340 512bytes \u6703\u6709\u9019\u5169\u500b\u8cc7\u6599                 - \u4e3b\u8981\u958b\u6a5f\u8a18\u9304\u5340(Master Boot Record, MBR)\uff1a\u53ef\u4ee5\u5b89\u88dd\u958b\u6a5f\u7ba1\u7406\u7a0b\u5f0f\u7684\u5730\u65b9\uff0c\u6709446 bytes                 - \u5206\u5272\u8868(partition table)\uff1a\u8a18\u9304\u6574\u9846\u786c\u789f\u5206\u5272\u7684\u72c0\u614b\uff0c\u670964 bytes                     - \u6bcf\u7d44\u5206\u5272\u8868\u50c5\u6709 16bytes, \u6700\u591a4\u7d44                     - \u4e3b\u8981(Primary)\u6216\u5ef6\u4f38(Extended)\u5206\u5272\u69fd                     - \u5ef6\u4f38\u5206\u5272\u6700\u591a\u53ea\u80fd1\u7d44         - GPT (GUID partition table)             - \u5728\u78c1\u5340\u7684\u5b9a\u7fa9\u4e0a\u9762\uff0c \u5927\u591a\u6703\u4f7f\u7528\u6240\u8b02\u7684\u908f\u8f2f\u5340\u584a\u4f4d\u5740(Logical Block Address, LBA)\u4f86\u8655\u7406             - \u8207 MBR \u50c5\u4f7f\u7528\u7b2c\u4e00\u500b 512bytes \u5340\u584a\u4f86\u7d00\u9304\u4e0d\u540c\uff0c GPT \u4f7f\u7528\u4e86 34 \u500b LBA \u5340\u584a\u4f86\u7d00\u9304\u5206\u5272\u8cc7\u8a0a     - \u5982\u4f55\u7d50\u5408\u76ee\u9304\u6a39\u7684\u67b6\u69cb(\u908f\u8f2f\u4e0a)\u8207\u78c1\u789f\u5167(\u7269\u7406\u5c64\u9762)\u7684\u8cc7\u6599         - \u639b\u8f09: \u5229\u7528\u4e00\u500b\u76ee\u9304\u7576\u6210\u9032\u5165\u9ede\uff0c\u5c07\u78c1\u789f\u5206\u5272\u69fd\u7684\u8cc7\u6599\u653e\u7f6e\u5728\u8a72\u76ee\u9304\u4e0b\uff1b \u4e5f\u5c31\u662f\u8aaa\uff0c\u9032\u5165\u8a72\u76ee\u9304\u5c31\u53ef\u4ee5\u8b80\u53d6\u8a72\u5206\u5272\u69fd             - \u9032\u5165\u9ede\u7684\u76ee\u9304\u6211\u5011\u7a31\u70ba\u300e\u639b\u8f09\u9ede\u300f</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#_3","title":"\u6a94\u6848\u7cfb\u7d71","text":"<p>\u4e86\u89e3\u78c1\u789f\u5206\u5272\u5f8c\uff0c\u5f15\u5165\u4f5c\u696d\u7cfb\u7d71\u6982\u5ff5\uff0c\u505a\u7b2c\u4e8c\u5c64\u7684\u62bd\u8c61\u5316(\u6a94\u6848\u7cfb\u7d71) \u53ef\u4ee5\u5c07\u6a94\u6848\u7cfb\u7d71\u60f3\u6210\u4f5c\u696d\u7cfb\u7d71\u8981\u7ba1\u7406\u5be6\u969b\u6a94\u6848\u6642\u6240\u9700\u8981\u7684\u8cc7\u6599\u7d50\u69cb \u5206\u5272\u69fd\u548c\u6a94\u6848\u7cfb\u7d71\u7684\u70ba\u591a\u5c0d\u591a\u95dc\u4fc2</p> <p>``` bash= df -hT <pre><code>- [\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c\u4e03\u7ae0\u3001Linux \u78c1\u789f\u8207\u6a94\u6848\u7cfb\u7d71\u7ba1\u7406](https://linux.vbird.org/linux_basic/centos7/0230filesystem.php)\n    - \u78c1\u789f\u5206\u5272\u5b8c\u7562\u5f8c\u9084\u9700\u8981\u9032\u884c\u683c\u5f0f\u5316(format)\uff0c\u4e4b\u5f8c\u4f5c\u696d\u7cfb\u7d71\u624d\u80fd\u5920\u4f7f\u7528\u9019\u500b\u6a94\u6848\u7cfb\u7d71\u3002 \u70ba\u4ec0\u9ebc\u9700\u8981\u9032\u884c\u300e\u683c\u5f0f\u5316\u300f\u5462\uff1f\u9019\u662f\u56e0\u70ba\u6bcf\u7a2e\u4f5c\u696d\u7cfb\u7d71\u6240\u8a2d\u5b9a\u7684\u6a94\u6848\u5c6c\u6027/\u6b0a\u9650\u4e26\u4e0d\u76f8\u540c\uff0c \u70ba\u4e86\u5b58\u653e\u9019\u4e9b\u6a94\u6848\u6240\u9700\u7684\u8cc7\u6599\uff0c\u56e0\u6b64\u5c31\u9700\u8981\u5c07\u5206\u5272\u69fd\u9032\u884c\u683c\u5f0f\u5316\n    - \u5e38\u807d\u5230\u7684LVM\u8207\u8edf\u9ad4\u78c1\u789f\u9663\u5217(software raid)\uff0c \u9019\u4e9b\u6280\u8853\u53ef\u4ee5\u5c07\u4e00\u500b\u5206\u5272\u69fd\u683c\u5f0f\u5316\u70ba\u591a\u500b\u6a94\u6848\u7cfb\u7d71(\u4f8b\u5982LVM)\uff0c\u4e5f\u80fd\u5920\u5c07\u591a\u500b\u5206\u5272\u69fd\u5408\u6210\u4e00\u500b\u6a94\u6848\u7cfb\u7d71(LVM, RAID)\n    - \u76ee\u524d\u6211\u5011\u5728\u683c\u5f0f\u5316\u6642\u5df2\u7d93\u4e0d\u518d\u8aaa\u6210\u91dd\u5c0d partition \u4f86\u683c\u5f0f\u5316\u4e86\uff0c \u901a\u5e38\u6211\u5011\u53ef\u4ee5\u7a31\u547c\u4e00\u500b\u53ef\u88ab\u639b\u8f09\u7684\u8cc7\u6599\u70ba\u4e00\u500b\u6a94\u6848\u7cfb\u7d71\u800c\u4e0d\u662f\u4e00\u500b\u5206\u5272\u69fd\n        - \u5c07\u6a94\u6848\u7cfb\u7d71\u8207\u76ee\u9304\u6a39\u7d50\u5408\u7684\u52d5\u4f5c\u6211\u5011\u7a31\u70ba\u300e\u639b\u8f09\u300f\n    - \u8f03\u65b0\u7684\u4f5c\u696d\u7cfb\u7d71\u7684\u6a94\u6848\u8cc7\u6599\u9664\u4e86\u6a94\u6848\u5be6\u969b\u5167\u5bb9\u5916\uff0c \u901a\u5e38\u542b\u6709\u975e\u5e38\u591a\u7684\u5c6c\u6027\uff0c\u4f8b\u5982 Linux \u4f5c\u696d\u7cfb\u7d71\u7684\u6a94\u6848\u6b0a\u9650(rwx)\u8207\u6a94\u6848\u5c6c\u6027(\u64c1\u6709\u8005\u3001\u7fa4\u7d44\u3001\u6642\u9593\u53c3\u6578\u7b49)\u3002 \u6a94\u6848\u7cfb\u7d71\u901a\u5e38\u6703\u5c07\u9019\u5169\u90e8\u4efd\u7684\u8cc7\u6599\u5206\u5225\u5b58\u653e\u5728\u4e0d\u540c\u7684\u5340\u584a\uff0c\u6b0a\u9650\u8207\u5c6c\u6027\u653e\u7f6e\u5230 inode \u4e2d\uff0c\u81f3\u65bc\u5be6\u969b\u8cc7\u6599\u5247\u653e\u7f6e\u5230 data block \u5340\u584a\u4e2d\u3002 \u53e6\u5916\uff0c\u9084\u6709\u4e00\u500b\u8d85\u7d1a\u5340\u584a (superblock) \u6703\u8a18\u9304\u6574\u500b\u6a94\u6848\u7cfb\u7d71\u7684\u6574\u9ad4\u8cc7\u8a0a\uff0c\u5305\u62ec inode \u8207 block \u7684\u7e3d\u91cf\u3001\u4f7f\u7528\u91cf\u3001\u5269\u9918\u91cf\u7b49\u3002\n        - superblock\uff1a\u8a18\u9304\u6b64 filesystem \u7684\u6574\u9ad4\u8cc7\u8a0a\uff0c\u5305\u62ecinode/block\u7684\u7e3d\u91cf\u3001\u4f7f\u7528\u91cf\u3001\u5269\u9918\u91cf\uff0c \u4ee5\u53ca\u6a94\u6848\u7cfb\u7d71\u7684\u683c\u5f0f\u8207\u76f8\u95dc\u8cc7\u8a0a\u7b49\uff1b\n        - inode\uff1a\u8a18\u9304\u6a94\u6848\u7684\u5c6c\u6027\uff0c\u4e00\u500b\u6a94\u6848\u4f54\u7528\u4e00\u500binode\uff0c\u540c\u6642\u8a18\u9304\u6b64\u6a94\u6848\u7684\u8cc7\u6599\u6240\u5728\u7684 block \u865f\u78bc\uff1b\n        - block\uff1a\u5be6\u969b\u8a18\u9304\u6a94\u6848\u7684\u5167\u5bb9\uff0c\u82e5\u6a94\u6848\u592a\u5927\u6642\uff0c\u6703\u4f54\u7528\u591a\u500b block \u3002\n- [\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c 15 \u5802\u8ab2\uff1aLinux \u7cfb\u7d71\u7684\u6e96\u5099 (Optional)](https://linux.vbird.org/linux_basic_train/centos8/unit15.php)\n\nThe `tmpfs` and `devtmpfs` devices are file systems in system memory. \nAll files that are written to the tmpfs or devtmpfs file system disappear after a system reboot.\n\nhuman-readable options\n- The -h option reports in KiB (210), MiB (220), or GiB (230)\n- the -H option reports in SI units: KB (103), MB (106), or GB (109)\n\n#### /tmp\n- [linux - When does /tmp get cleared? - Server Fault](https://serverfault.com/questions/377348/when-does-tmp-get-cleared)\n- [How to use systemd-tmpfiles-clean to automatically remove the old logs in the directory - Red Hat Customer Portal](https://access.redhat.com/solutions/6964016)\n    - [Linux\u4e0b\u5173\u4e8e/tmp\u76ee\u5f55\u7684\u6e05\u7406\u89c4\u5219 - \u7231\u5403\u751c\u98df\u7684boy - \u535a\u5ba2\u56ed](https://www.cnblogs.com/samtech/p/9490166.html)\n    - /usr/lib/systemd/system/systemd-tmpfiles-clean.timer\n    - /usr/lib/systemd/system/systemd-tmpfiles-clean.service\n    - /usr/lib/tmpfiles.d/tmp.conf\n        - [tmpfiles.d](https://www.freedesktop.org/software/systemd/man/latest/tmpfiles.d.html)\n        - [Ubuntu Manpage: tmpfiles.d - Configuration for creation, deletion and cleaning of volatile and temporary](https://manpages.ubuntu.com/manpages/bionic/man5/tmpfiles.d.5.html)\n- [/tmp\u4e34\u65f6\u76ee\u5f55\u5b9a\u671f\u6e05\u7406\u673a\u5236 \u2014 Cloud Atlas 0.1 \u6587\u6863](https://cloud-atlas.readthedocs.io/zh_CN/latest/linux/redhat_linux/systemd/tmp_directory_cleanup_periodically.html)\n\n\n#### mount\nThe /mnt directory exists for use as a temporary mount point.\n\nIf a directory to use as a mount point is not empty, then the existing files are hidden and not accessible when a file system is mounted there. \nThe original files are accessible again after the mounted file system is unmounted.\n\nIt is recommended to use an unchanging device identifier to mount file systems consistently.\n\nOne stable identifier that is associated with a file system is its universally unique identifier (UUID). \nThis UUID is stored in the file system superblock and remains the same until the file system is re-created.\n\n``` bash=\n# lists the full path of the device, the UUIDs and mount points, and the partition's file-system type\nlsblk -fp\n</code></pre></p> <p>System shutdown and reboot procedures unmount all file systems automatically. </p> <p>Unmounting is not possible when the mounted file system is in use. - For the umount command to succeed, all processes must stop accessing data under the mount point.</p> <p>``` bash= mount UUID=\"efd314d0-b56e-45db-bbb3-3f32ae98f652\" /mnt/data cd /mnt/data umount /mnt/data</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#lists-all-open-files-and-the-processes-that-are-accessing-the-file-system","title":"lists all open files and the processes that are accessing the file system.","text":"<p>lsof /mnt/data cd umount /mnt/data <pre><code>### LVM\n- [4.3.7.\u00a0Activating and Deactivating Volume Groups Red Hat Enterprise Linux 4 | Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/4/html/cluster_logical_volume_manager/vg_activate)\n- [Chapter\u00a05.\u00a0LVM Configuration Examples Red Hat Enterprise Linux 7 | Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/logical_volume_manager_administration/lvm_examples#doc-wrapper)\n- [\u201cLogical volume vg/lv contains a filesystem in use\u201d \u2013 while removing LVM filesystem \u2013 The Geek Diary](https://www.thegeekdiary.com/logical-volume-vg-lv-contains-a-filesystem-in-use-while-removing-lvm-filesystem/)\n- [Can not remove Logical Volume, message \"Logical volume contains a filesystem in use\" returned - Red Hat Customer Portal](https://access.redhat.com/solutions/2961861)\n\n``` bash=\n# deactive\nvgchange -a n my_volume_group\n\n# activce\nvgchange -a y my_volume_group\n</code></pre></p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#raid-and-lvm","title":"RAID and LVM","text":"<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u7b2c 14 \u5802\u8ab2\uff1a\u9032\u968e\u6a94\u6848\u7cfb\u7d71\u7ba1\u7406</li> </ul> <p>RAID \u53ef\u4ee5\u5c07\u6a94\u6848\u7cfb\u7d71\u5bb9\u91cf\u589e\u52a0\uff0c\u4e5f\u6709\u6548\u80fd\u589e\u52a0\u8207\u5bb9\u932f\u7684\u6a5f\u5236\uff0c\u4f46\u662f\u5c31\u662f\u6c92\u6709\u8fa6\u6cd5\u5728\u65e2\u6709\u7684\u6a94\u6848\u7cfb\u7d71\u67b6\u69cb\u4e0b\uff0c\u76f4\u63a5\u5c07\u5bb9\u91cf\u653e\u5927\u7684\u6a5f\u5236\u3002 </p> <p>LVM \u6700\u91cd\u8981\u7684\u4efb\u52d9\u5c31\u662f\u9032\u884c\u88dd\u7f6e\u7684\u5bb9\u91cf\u653e\u5927\u8207\u7e2e\u5c0f\uff0c\u524d\u63d0\u662f\u5728\u8a72\u88dd\u7f6e\u4e0b\u7684\u6a94\u6848\u7cfb\u7d71\u80fd\u5920\u652f\u63f4\u653e\u5927\u8207\u7e2e\u5c0f\u624d\u884c\u3002 \u76ee\u524d\u5728 CentOS 8 \u4e0a\u9762\u4e3b\u8981\u7684\u5169\u6b3e\u6a94\u6848\u7cfb\u7d71\u4e2d\uff0c ext4 \u53ef\u4ee5\u653e\u5927\u8207\u7e2e\u5c0f\uff0c\u4f46\u662f xfs \u6a94\u6848\u7cfb\u7d71\u5247\u50c5\u80fd\u653e\u5927\u800c\u5df2\u3002\u56e0\u6b64\u4f7f\u7528\u4e0a\u9700\u8981\u7279\u5225\u6ce8\u610f\u3002</p> <p>RAID \u4e3b\u8981\u7684\u76ee\u7684\u5728\u6548\u80fd\u8207\u5bb9\u932f (\u5bb9\u91cf\u53ea\u662f\u9644\u52a0\u7684)\uff0c\u800c LVM \u91cd\u9ede\u5728\u5f48\u6027\u7ba1\u7406\u6a94\u6848\u7cfb\u7d71 (\u6700\u597d\u4e0d\u8981\u8003\u91cf LVM \u5167\u5efa\u7684\u5bb9\u932f\u6a5f\u5236)\u3002 \u82e5\u9700\u8981\u5169\u8005\u7684\u512a\u9ede\uff0c\u5247\u53ef\u4ee5\u5728 RAID \u4e0a\u9762\u5efa\u7f6e LVM\u3002</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#resize","title":"Resize","text":"<ul> <li>How to resize a logical volume with 5 simple LVM commands | Enable Sysadmin</li> <li>How to reduce XFS file system - Red Hat Customer Portal</li> <li>Chapter\u00a06.\u00a0Modifying the size of a logical volume Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> <li>How to Shrink/Reduce XFS partition size on LVM &gt; Blog-D without Nonsense</li> <li>How to Reduce / Shrink the Size of a LVM Partition Formatted with XFS Filesystem? - YallaLabs</li> <li>How To Resize LVM Software RAID1 Partitions (Shrink &amp; Grow)</li> <li>Shrinking LVM physical volume running on software RAID - KobelNET Blog</li> <li>Resize root partition (or how to remove the default /home partition) on CentOS 7 online \u00b7 GitHub</li> </ul> <pre><code>cat /proc/mdstat\nmdadm --detail /dev/md126\nlsof /dev/md126\n</code></pre>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#shrink-xfs-system-on-lvm-on-raid","title":"Shrink xfs system on LVM on RAID","text":"<ul> <li>ubuntu 18.04 - How to move mounted and mapped logical volume from one volume group/physical volume to another - Stack Overflow</li> <li>CentOS / RHEL 7 : How to boot into Rescue Mode or Emergency Mode \u2013 The Geek Diary</li> </ul> <p>/tmp ``` bash=</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#enter-into-resure-mode-after-reboot","title":"enter into Resure mode after reboot","text":"<p>umount /tmp</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#remove-mount-point-tmp-on-the-etcfstab","title":"remove mount point /tmp on the /etc/fstab","text":"<p>sed -i '/\\/tmp/d' /etc/fstab</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#deactive-and-remove-logic-volume","title":"deactive and remove logic volume","text":"<p>lvchange -an -v /dev/rhel/tmp lvremove -vf /dev/rhel/tmp reboot</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#normal-mode","title":"normal mode","text":"<p>lvcreate -L 600G -n tmp rhel mkfs.xfs -f /dev/rhel/tmp sed -i -e '$a/dev/mapper/rhel-tmp    /tmp                    xfs     defaults        0 0' /etc/fstab reboot <pre><code>### Ramdisk\n- [Create a RAM disk in Linux | JamesCoyle.net Limited](https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux)\n- [The Difference Between a tmpfs and ramfs RAM Disk | JamesCoyle.net Limited](https://www.jamescoyle.net/knowledge/951-the-difference-between-a-tmpfs-and-ramfs-ram-disk)\n- [\u5c08\u984c\u4e94 - \u5efa\u7acb rootfs \u7684\u7121\u78c1\u789f Linux \u7cfb\u7d71\u74b0\u5883](https://dic.vbird.tw/network_project/unit05.php)\n- [ramfs, tmpfs, rootfs, initramfs\u7684\u533a\u522b](https://flyflypeng.tech/%E5%86%85%E6%A0%B8/2017/06/14/ramfs-rootfs-initramfs%E7%9A%84%E5%8C%BA%E5%88%AB.html)\n    - [linux - What sets the size of tmpfs? What happens when its full? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/205174/what-sets-the-size-of-tmpfs-what-happens-when-its-full)\n        - The default is half of your physical RAM without swap\n\nramfs is the older file system type and is largely replaced in most scenarios by tmpfs\n- it creates an in memory file system which uses the same mechanism and storage space as Linux file system cache\n- it cannot be limited in size like a disk base file system which is limited by it\u2019s capacity.\n    - it will continue using memory storage until the system runs out of RAM and likely crashes or becomes unresponsive.\n- you cannot see the size of the file system in df and it can only be estimated by looking at the cached entry in free command\n\ntmpfs is a more recent RAM file system which overcomes many of the drawbacks with ramfs.\n- You can specify a size limit in tmpfs which will give a \u2018disk full\u2019 error when the limit is reached.\n    - This behaviour is exactly the same as a partition of a physical disk.\n- tmpfs may use SWAP space.\n\n## \u7db2\u8def\n- [networking - what is the difference between eth1 and eno1? - Super User](https://superuser.com/questions/1053003/what-is-the-difference-between-eth1-and-eno1)\n\n## NFS\n- [nfs(5) - Linux man page](https://linux.die.net/man/5/nfs)\n    - [Additional mounting considerations - Amazon Elastic File System](https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-mount-cmd-general.html)\n- [NFS vs CIFS - \u6a94\u6848\u7cfb\u7d71\u4e4b\u9593\u7684\u5340\u5225 - AWS](https://aws.amazon.com/tw/compare/the-difference-between-nfs-and-cifs/)\n- [Chapter\u00a03.\u00a0Mounting NFS shares Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal](https://access.redhat.com/documentation/zh-tw/red_hat_enterprise_linux/8/html/managing_file_systems/mounting-nfs-shares_managing-file-systems#common-nfs-mount-options_mounting-nfs-shares)\n- [An NFS client hangs on various operations, including \"df\". Hard vs Soft NFS mounts. | Support | SUSE](https://www.suse.com/support/kb/doc/?id=000020830)\n- [Where are NFS defaults specified? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/310178/where-are-nfs-defaults-specified)\n    - [fstab(5) - Linux manual page](https://man7.org/linux/man-pages/man5/fstab.5.html)\n- [Chapter\u00a0110.\u00a0Using Ansible to automount NFS shares for IdM users Red Hat Enterprise Linux 8 | Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_identity_management/using-ansible-to-automount-nfs-shares-for-idm-users_configuring-and-managing-idm)\n- [NFS \u6548\u80fd - IBM \u8aaa\u660e\u6587\u4ef6](https://www.ibm.com/docs/zh-tw/aix/7.3?topic=management-nfs-performance)\n    - [The nfsstat -s command - IBM Documentation](https://www.ibm.com/docs/en/aix/7.3?topic=server-nfsstat-s-command)\n    - [Causes of slow access times for NFS - IBM Documentation](https://www.ibm.com/docs/en/aix/7.2?topic=troubleshooting-causes-slow-access-times-nfs)\n    - [Using nfsstat and nfsiostat to troubleshoot NFS performance issues on Linux | Enable Sysadmin](https://www.redhat.com/sysadmin/using-nfsstat-nfsiostat)\n    - [RHEL NFS Client: slow NFS performance with \\`noac\\` NFS mount option - Red Hat Customer Portal](https://access.redhat.com/solutions/83723)\n- [1893329 \u2013 Mounting NFS home dirs at boot fails](https://bugzilla.redhat.com/show_bug.cgi?id=1893329)\n    - [Chapter\u00a028.\u00a0Mounting file systems on demand Red Hat Enterprise Linux 8 | Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/assembly_mounting-file-systems-on-demand_managing-file-systems#proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_assembly_mounting-file-systems-on-demand)\n        - [systemd.mount](https://www.freedesktop.org/software/systemd/man/systemd.mount.html)\n    - [networking - systemd: failed to mount NFS share: mount.nfs: Network is unreachable until later in boot process - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/459731/systemd-failed-to-mount-nfs-share-mount-nfs-network-is-unreachable-until-late)\n        - soft,retrans=5,timeo=30,retry=2\n    - [systemd - (Ubuntu 19.04) NFS share won't automount at boot: 'mount.nfs: Network is unreachable' - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/542925/ubuntu-19-04-nfs-share-wont-automount-at-boot-mount-nfs-network-is-unreach)\n    - [fstab\u4e0esystemd.mount\u81ea\u52a8\u6302\u8f7d\u7684\u4e00\u70b9\u7814\u7a76\u548c\u89c1\u89e3 \u00b7 zhangguanzhang's Blog](https://zhangguanzhang.github.io/2019/01/30/fstab/#/findmnt)\n    - [Reboot hangs when NFS share is mounted and lost connection to NFS server during I/O operation in Red Hat Enterprise Linux. - Red Hat Customer Portal](https://access.redhat.com/solutions/3339001)\n    - [NFS hard and soft mounts - IBM Documentation](https://www.ibm.com/docs/en/spectrum-protect/8.1.9?topic=considerations-nfs-hard-soft-mounts)\n- [How to log NFS related messages in \"/var/log/messages\"? - Red Hat Customer Portal](https://access.redhat.com/solutions/137313)\n- firewall\n    - [Configuring the NFS server to run behind a firewall](https://access.redhat.com/documentation/zh-tw/red_hat_enterprise_linux/8/html/deploying_different_types_of_servers/exporting-nfs-shares_deploying-different-types-of-servers#assembly_configuring-the-nfs-server-to-run-behind-a-firewall_exporting-nfs-shares)\n- server is gone\n    - [How to unmount NFS when server is gone? - Ask Ubuntu](https://askubuntu.com/questions/292043/how-to-unmount-nfs-when-server-is-gone)\n- server not responding\n    - [RHEL mount hangs: nfs: server [...] not responding, still trying - Red Hat Customer Portal](https://access.redhat.com/solutions/28211)\n        - [How to increase the number of threads created by the NFS daemon in RHEL 4, 5, 6, 7 and 8? - Red Hat Customer Portal](https://access.redhat.com/solutions/2216)\n    - [Correct nfs server not responding error in EFS | AWS re:Post](https://repost.aws/knowledge-center/efs-fix-nfs-server-not-responding)\n        - noresvport\n- NFS client hangs\n    - [NFS client hang problem analysis - IBM Documentation](https://www.ibm.com/docs/en/zos/2.4.0?topic=aids-nfs-client-hang-problem-analysis)\n    - [An NFS client hangs on various operations, including \"df\". Hard vs Soft NFS mounts. | Support | SUSE](https://www.suse.com/support/kb/doc/?id=000020830)\n    - [Dell Unity: ls command hung on RHEL 8.4 client when mounting Unity NFS export via NFSv4 (User Correctable) | Dell US](https://www.dell.com/support/kbdoc/en-us/000202521/dell-emc-unity-ls-command-hung-on-rhel-8-4-client-in-a-user-correctable)\n    - [Why does the command 'df' hang on a RHEL NFS client when the NFS server is unavailable? - Red Hat Customer Portal](https://access.redhat.com/solutions/23338)\n    - [linux - Mount nfs hangs client - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/404066/mount-nfs-hangs-client)\n\n\n``` bash=\n# on the server\nnfsstat -s\n\n# on the client\nnfsstat -m\nnfsstat -c\nnfsiostat\n</code></pre></p> <p>``` bash=</p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#on-the-server","title":"on the server","text":""},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#firewall","title":"firewall","text":"<p>sudo firewall-cmd --zone=public --list-all sudo firewall-cmd --add-service=nfs --permanent sudo firewall-cmd --reload sudo systemctl restart nfs-server <pre><code>Test\n``` bash=\n# on the client\nsudo systemctl stop opt_shared.mount\nsudo sed -i 's/167.22.10.1/167.22.10.2/g' /etc/fstab\nsudo systemctl daemon-reload\nsystemctl status opt_shared.mount\n</code></pre></p>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#tty","title":"TTY","text":"<ul> <li>\u7528 Python \u63a7\u5236\u5176\u4ed6\u884c\u7a0b\u7684 TTY \u7d42\u7aef\u88dd\u7f6e \u00b7 John Engineering Stuff</li> <li>Bash output \u8a0e\u8ad6 &gt;file 2&gt;&amp;1 \u8207 2&gt;&amp;1 &gt; file \u7684\u5dee\u7570 | hwchiu learning note</li> </ul>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#privilege-escalation","title":"Privilege Escalation","text":"<ul> <li>Privilege Escalation on Linux (With Examples)</li> </ul>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#cpu","title":"CPU","text":"<ul> <li>\u4e09\u5206\u949f\u901f\u89c8cpu,socket,core,thread\u7b49\u672f\u8bed\u4e4b\u95f4\u7684\u5173\u7cfb-\u817e\u8baf\u4e91\u5f00\u53d1\u8005\u793e\u533a-\u817e\u8baf\u4e91</li> <li>Socket vs. Core, CPU vs. Thread: The Evolution of x86 Architecture Terms - VMware Professional Services</li> <li>cluster computing - What is socket, core, threads, CPU? - Stack Overflow</li> <li>cpu - Any way to check the clock speed of my processor? - Ask Ubuntu</li> <li>What is the correct way to view your CPU speed on Linux? - Unix &amp; Linux Stack Exchange</li> <li>linux - How to determine ARMv8 CPU's frequency? - Stack Overflow</li> <li>Check CPU Temp on Linux {3 Methods} | phoenixNAP KB</li> <li>Cpu EDC is high - AMD Community</li> <li>\u88ab\u8bef\u89e3\u7684CPU\u5229\u7528\u7387\u3001\u8d85\u7ebf\u7a0b\u3001\u52a8\u6001\u8c03\u9891 \u2014\u2014 CPU \u6027\u80fd\u4e4b\u8ff7 Part 1 \u2013 Mark Zhu \u7684\u535a\u5ba2</li> <li>\u8c01\u52a8\u4e86\u6211\u7684 CPU \u9891\u7387 \u2014\u2014 CPU \u6027\u80fd\u4e4b\u8ff7 Part 2 \u2013 Mark Zhu \u7684\u535a\u5ba2</li> <li>Multi-core Processors: Does each 'core' run at the full clock speed or some fraction of the full clock frequency? - Quora</li> </ul> <pre><code>cat /proc/cpuinfo\ncat /proc/cpuinfo | egrep '^processor|^physical|^core id'\nnumactl --hardware\nlscpu\ncpupower frequency-info\ncpupower -c all frequency-info\nlshw  -c cpu\nlshw -json -c cpu\n</code></pre>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#tuning","title":"tuning","text":"<ul> <li>\u9ce5\u54e5\u79c1\u623f\u83dc - \u9ad8\u6548\u80fd\u96fb\u8166\u7684\u7a0b\u5e8f\u512a\u5316<ul> <li>NUMA<ul> <li>SLES 15 SP4 | System Analysis and Tuning Guide | Automatic Non-Uniform Memory Access (NUMA) balancing</li> <li>numatop</li> </ul> </li> </ul> </li> <li>SLES 15 SP5 | System Analysis and Tuning Guide | Power management<ul> <li>Balancing Power and Performance in the Linux Kernel</li> <li>kernel.org/doc/Documentation/cpu-freq/intel-pstate.txt</li> <li>intel_pstate CPU Performance Scaling Driver \u2014 The Linux Kernel documentation</li> <li>CPU Performance Scaling \u2014 The Linux Kernel documentation<ul> <li>For this reason, CPUFreq allows scaling drivers to bypass the governor layer and implement their own performance scaling algorithms. That is done by the intel_pstate scaling driver.</li> </ul> </li> <li>CPU frequency scaling - ArchWiki</li> </ul> </li> <li>HPC Cluster Tuning Guide on Intel\u00ae Xeon\u00ae processor platforms<ul> <li>For HPC clusters, the goal is to reduce workload runtimes for applications using MPI libraries and high-performance fabrics</li> </ul> </li> <li>linux - Cannot set CPU frequency - Unix &amp; Linux Stack Exchange</li> <li>18.04 - How to update CPU frequency policy? - Ask Ubuntu</li> <li>windows - Intel CPU using low clock for no reason - Super User</li> <li>\u518d\u8c08CPU\u7684\u7535\u6e90\u7ba1\u7406\uff08\u5982\u4f55\u505a\u5230\u7a33\u5b9a\u5168\u6838\u777f\u9891\uff1f\uff09 | C0reFast\u8bb0\u4e8b\u672c</li> <li>Maximum CPU frequency is not maintained on Intel CPUs - Red Hat Customer Portal</li> <li>Max CPU Frequency Reported by cpupower Differs Between intel_pstate and acpi_cpufreq drivers - Red Hat Customer Portal</li> <li>linux - How to set specific cpu frequency when using intel_pstate - Stack Overflow</li> <li>Maximum CPU frequency is not maintained on Intel CPUs - Red Hat Customer Portal<ul> <li>HWP uses hardware information (aperf/mperf counters) to determine the \"best\" frequency for the cpus.</li> <li>For example, if a user requested 800MHz, the hardware using system temperature information, states of other CPUs and other factors may determine that a better frequency for the workload is really 900MHz and will raise the frequencies temporarily to that value.</li> </ul> </li> <li>\u670d\u52a1\u5668\u7684\u80fd\u8017\u63a7\u5236\u4ee5\u53ca\u9ad8\u6027\u80fd\u6a21\u5f0f\u914d\u7f6e\uff08Dell\uff09 | C0reFast\u8bb0\u4e8b\u672c</li> <li>CPU frequency always at 200Mhz [Solved] / Kernel &amp; Hardware / Arch Linux Forums</li> <li>intel-pstate<ul> <li>\u66f4\u63dbCPU driver - HackMD</li> <li>linux - HOW TO FORCEFULLY DISABLE intel_pstate? intel_pstate is enabled on reboot even with intel_pstate=disable option in grub - Stack Overflow</li> <li>cpu - Permanently setting intel pstate driver to \"passive\" - Ask Ubuntu</li> <li>\u5f9eGrub\u8a2d\u5b9a\u4fee\u6539CPU\u6548\u80fd\u8abf\u6574\u9a45\u52d5\u53c3\u6578 \u2013 Musicha \uff3f\uff3f\uff3f\u97f3\u5275\u7b46\u96fb</li> <li>SLES 15 SP2 | \u7ba1\u7406\u6307\u5357 | \u958b\u6a5f\u8f09\u5165\u7a0b\u5f0f GRUB\u00a02<ul> <li>\u7de8\u8f2f /etc/default/grub \u5f8c\uff0c\u8acb\u4f7f\u7528 grub2-mkconfig -o /boot/grub2/grub.cfg \u66f4\u65b0\u4e3b\u8981\u7d44\u614b\u6a94\u6848</li> </ul> </li> </ul> </li> <li>Chapter\u00a017.\u00a0Tuning CPU frequency to optimize energy consumption Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>intel cpu<ul> <li>[SOLVED] CPU frequency stuck at 200MHz / Kernel &amp; Hardware / Arch Linux Forums<ul> <li>microcode<ul> <li>Loading Microcode from the OS<ul> <li>Intel-Linux-Processor-Microcode-Data-Files/intel-ucode at main \u00b7 intel/Intel-Linux-Processor-Microcode-Data-Files \u00b7 GitHub<ul> <li>SUSE: zypper install ucode-intel</li> </ul> </li> </ul> </li> <li>How to install/update Intel microcode firmware on Linux - nixCraft</li> </ul> </li> </ul> </li> <li>\u5df2\u89e3\u6c7a\uff1aIntel Xeon Platinum 8176 Max Frequency - Intel Community<ul> <li>Xeon Platinum 8176 - Intel - WikiChip</li> </ul> </li> </ul> </li> </ul> <pre><code>cpupower -c all frequency-set --governor performance\ncpupower frequency-set -g performance\n</code></pre> <pre><code>grep . /sys/devices/system/cpu/cpu*/cpufreq/scaling_driver \ngrep . /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor \ngrep . /sys/devices/system/cpu/cpu0/cpufreq/*\nturbostat\n</code></pre> <pre><code>watch -n 2 \"cpupower monitor -m Mperf\"\nwatch -n 1 cpupower frequency-info\n</code></pre> <p>driver - acpi-cpufreq - intel_pstate</p> <p>Hardware P-States (HWP)</p> <pre><code>cpuid | grep 'hardware P-State control'\n</code></pre>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#driver","title":"Driver","text":"<ul> <li>how to know what dirver can load in linux</li> </ul>"},{"location":"hackmd/Linux%E8%A7%80%E5%BF%B5/#init-system","title":"Init System","text":"<ul> <li>\u5f9e\u555f\u52d5\u5230\u4f11\u7720 systemd \u5982\u4f55\u638c\u63a7\u4f60\u7684 Linux \u7cfb\u7d71. \u5728\u73fe\u4ee3Linux\u7cfb\u7d71\u4e2d\uff0csystemd\u2026 | by \u9673\u9996\u5409 | Medium</li> </ul>"},{"location":"hackmd/Makefile/","title":"Makefile","text":"<ul> <li>\u5beb Web \u4e5f\u53ef\u4ee5\u7528 Makefile\uff1a\u597d\u597d\u7ba1\u7406\u4f60\u7684\u74b0\u5883\u6d41\u7a0b | \u5c0f\u514b's \u90e8\u843d\u683c</li> <li>Learn Makefiles With the tastiest examples</li> <li>How do I use shell variables in Makefile actions</li> <li>gnu make - read input variable in makefile and set variable upon it`s name - Stack Overflow</li> </ul>"},{"location":"hackmd/Message%20Passing%20Interface/","title":"Message Passing Interface","text":"<ul> <li>\u8a2d\u5b9a HPC \u7684\u8a0a\u606f\u50b3\u905e\u4ecb\u9762 \uff08MPI\uff09 - Azure \u865b\u64ec\u6a5f\u5668 - Azure Virtual Machines | Microsoft Learn<ul> <li>Unified Communication - X Framework Library - NVIDIA Docs<ul> <li> <ul> <li>\u3010\u8bba\u6587\u5206\u4eab\u3011\u6df1\u5165\u5206\u6790\u9ad8\u6027\u80fd\u4e92\u8fde\u70b9\u5bf9\u70b9\u901a\u4fe1\u5f00\u9500 - \u77e5\u4e4e</li> </ul> </li> </ul> </li> </ul> </li> <li>Tutorials \u00b7 MPI Tutorial</li> <li>Parallel Programming with MPI For Python - Research Computing in Earth Sciences</li> </ul> <p>A communicator defines a group of processes that have the ability to communicate with one another.  In this group of processes, each is assigned a unique rank, and they explicitly communicate with one another by their ranks.</p> <p>A process may send a message to another process by providing the rank of the process and a unique tag to identify the message. The receiver can then post a receive for a message with a given tag (or it may not even care about the tag), and then handle the data accordingly Communications such as this which involve one sender and receiver are known as point-to-point communications.</p> <p>There are many cases where processes may need to communicate with everyone else. For example, when a manager process needs to broadcast information to all of its worker processes. MPI can handle a wide variety of these types of collective communications that involve all processes.</p> <p>Mixtures of point-to-point and collective communications can be used to create highly complex parallel programs.</p> <p>MPI\u2019s send and receive calls operate in the following manner.  First, process A decides a message needs to be sent to process B. Process A then packs up all of its necessary data into a buffer for process B. These buffers are often referred to as envelopes since the data is being packed into a single message before transmission (similar to how letters are packed into envelopes before transmission to the post office).  After the data is packed into a buffer, the communication device (which is often a network) is responsible for routing the message to the proper location. The location of the message is defined by the process\u2019s rank.</p> <p>Even though the message is routed to B, process B still has to acknowledge that it wants to receive A\u2019s data. Once it does this, the data has been transmitted. Process A is acknowledged that the data has been transmitted and may go back to work.</p> <p>Sometimes there are cases when A might have to send many different types of messages to B. Instead of B having to go through extra measures to differentiate all these messages, MPI allows senders and receivers to also specify message IDs with the message (known as tags).</p> <p>One of the things to remember about collective communication is that it implies a synchronization point among processes.</p> <p>A broadcast is one of the standard collective communication techniques. During a broadcast, one process sends the same data to all processes in a communicator. </p> <p>The primary difference between MPI_Bcast and MPI_Scatter is small but important. MPI_Bcast sends the same piece of data to all processes while MPI_Scatter sends chunks of an array to different processes.</p> <p>MPI_Gather is the inverse of MPI_Scatter. Instead of spreading elements from one process to many processes, MPI_Gather takes elements from many processes and gathers them to one single process. </p> <p>we have covered two MPI routines that perform many-to-one or one-to-many communication patterns, which simply means that many processes send/receive to one process. Oftentimes it is useful to be able to send many elements to many processes (i.e. a many-to-many communication pattern). MPI_Allgather has this characteristic.</p>"},{"location":"hackmd/Nagios/","title":"Nagios","text":"<ul> <li>Table Of Contents \u00b7 Nagios Core Documentation<ul> <li>Nagios Core - Installing Nagios Core From Source</li> <li>Nagios Plugins - Installing Nagios Plugins From Source</li> </ul> </li> <li>Ansible playbooks for Nagios Installation on Ubuntu 18.04.4 LTS / 20.04 LTS \u2013 The Mythryll Log</li> <li>\u4f7f\u7528Grafana+InfluxDB\u5c55\u793aNagios\u76d1\u63a7\u6570\u636e | Wislay</li> <li>Nagios Core: \u0391 Beginner\u2019s Guide for 2023</li> <li>API<ul> <li>API for Querying the Data - Nagios Support Forum</li> <li>linux - Fetching host availability to external webpage in Nagios - Stack Overflow</li> </ul> </li> <li>permission<ul> <li>View FAQ - Nagios Support</li> <li>18.5.\u00a0Nagios Advanced Configuration Red Hat Gluster Storage 3.3 | Red Hat Customer Portal</li> </ul> </li> <li>default<ul> <li>check interval is 5 minutes</li> </ul> </li> </ul> <pre><code>/usr/local/nagios/etc/nagios.cfg\n/usr/local/nagios/etc/htpasswd.users\n/usr/local/nagios/etc/cgi.cfg\n\n/usr/local/nagios/var/nagios.log\n</code></pre>"},{"location":"hackmd/Nagios/#basic-config","title":"Basic config","text":"<ul> <li>Monitoring Publicly Available Services \u00b7 Nagios Core Documentation</li> <li>Object Configuration Overview \u00b7 Nagios Core Documentation</li> <li>Monitoring Linux/Unix Machines \u00b7 Nagios Core Documentation</li> <li>definition<ul> <li>Main Configuration File Options \u00b7 Nagios Core Documentation</li> <li>Object Definitions \u00b7 Nagios Core Documentation</li> <li>Time-Saving Tricks For Object Definitions \u00b7 Nagios Core Documentation</li> </ul> </li> <li>Main Configuration File Options \u00b7 Nagios Core Documentation</li> <li>Host and Service Check Scheduling \u00b7 Nagios Core Documentation <pre><code>grep 'cfg_file' /usr/local/nagios/etc/nagios.cfg\ngrep 'cfg_dir' /usr/local/nagios/etc/nagios.cfg\n</code></pre></li> </ul> <p>/usr/local/nagios/etc/ <pre><code>cfg_dir=/usr/local/nagios/etc/servers\n</code></pre></p> <p>/usr/local/nagios/etc/servers foo.cfg boo.cfg</p> <p>foo.cfg <pre><code>###############################################################################\n# LOCALHOST.CFG - SAMPLE OBJECT CONFIG FILE FOR MONITORING THIS MACHINE\n#\n#\n# NOTE: This config file is intended to serve as an *extremely* simple\n#       example of how you can create configuration entries to monitor\n#       the local (Linux) machine.\n#\n###############################################################################\n\n\n\n###############################################################################\n#\n# HOST DEFINITION\n#\n###############################################################################\n\n# Define a host for the local machine\n\ndefine host {\n\n    use                     linux-server            ; Name of host template to use\n                                                    ; This host definition will inherit all variables that are defined\n                                                    ; in (or inherited by) the linux-server host template definition.\n    host_name               foo\n    alias                   foo\n    address                 167.22.10.1\n}\n\n\n\n\n\n###############################################################################\n#\n# SERVICE DEFINITIONS\n#\n###############################################################################\n\n# Define a service to \"ping\" the local machine\n\ndefine service {\n\n    use                     generic-service           ; Name of service template to use\n    host_name               foo\n    service_description     PING\n    check_command           check_ping!100.0,20%!500.0,60%\n}\n\n\n\ndefine service {\n\n    use                     generic-service           ; Name of service template to use\n    host_name               foo\n    service_description     SSH\n    check_command           check_ssh\n    notifications_enabled   0\n}\n\n\n\n# Define a service to check HTTP on the local machine.\n# Disable notifications for this service by default, as not all users may have HTTP enabled.\n\ndefine service {\n\n    use                     generic-service           ; Name of service template to use\n    host_name               foo\n    service_description     HTTP\n    check_command           check_http\n    notifications_enabled   0\n}\n</code></pre></p>"},{"location":"hackmd/Nagios/#nrpe","title":"NRPE","text":"<ul> <li>NRPE - How To Install NRPE v4 From Source</li> <li>NRPE - How to install NRPE</li> <li>Perform Nagios configuration step by step | TechTarget</li> </ul> <pre><code>/usr/local/nagios/etc/nrpe.cfg\n</code></pre>"},{"location":"hackmd/Nexus%20Repository%20Manager/","title":"Nexus Repository Manager","text":"<ul> <li>https://www.sonatype.com/products/sonatype-nexus-repository<ul> <li>Sonatype Nexus Repository OSS vs. Pro Features</li> <li>Sonatype Nexus Repository System Requirements</li> <li>Sonatype Nexus Repository 3 Versions Status</li> <li>Install Nexus Repository with a PostgreSQL Database<ul> <li>Only available in Sonatype Nexus Repository Pro</li> </ul> </li> </ul> </li> <li>https://github.com/sonatype/nexus-public</li> <li>https://hub.docker.com/r/sonatype/nexus3/</li> <li>Nexus Repository Manager \u5957\u4ef6\u79c1\u670d\u7684\u5b89\u88dd\u8207\u4ecb\u7d39 - HackMD</li> <li>\u4f7f\u7528 Docker \u5efa\u7acb Nexus3 \u7684 Image Registry - Yowko's Notes</li> <li>Day 14: \u8208\u5efa\u6211\u7684\u6210\u54c1\u5009\u5eab!Nexus OSS! </li> <li>\u4f7f\u7528harbor\u548cnexus\u4f5c\u4e3adocker registry - \u6398\u91d1</li> <li>Docker Registry: Harbor or\u00a0Nexus? | Cloud Native Daily</li> <li>How to secure Sonatype Nexus using a self-signed certificate &amp; use it as a secure Docker Registry on macOS | by Shashank Srivastava | Medium</li> <li>Sonatype Nexus Usage 101 | Best Practices &amp; Example Use Cases</li> <li>https<ul> <li>Docker \u5bb9\u5668 Nexus \u914d\u7f6e SSL/https | GitLab/Kubernetes \u77e5\u8bc6\u5e93</li> <li>\u8a2d\u5b9a Nexus Repository OSS 3.X for Windows \u555f\u7528HTTPS(\u4f7f\u7528\u81ea\u6211\u7c3d\u7f72\u6191\u8b49) | by Eric Studio | Medium</li> <li>RHEL8 \u5e6bNexus\u88ddhttps(\u7cbe\u7c21\u6574\u7406). RHEL8 \u5e6bNexus\u88ddhttps(\u7cbe\u7c21\u6574\u7406,crt\u8207key\u8f49jks) | by ZONGRU Li | Medium</li> <li>Installing Sonatype Nexus With Nginx Reverse Proxy &amp; HTTPS</li> <li>Setting Up a Secure Private Docker Registry with Nexus and SSL Configuration | by Ramkrushna Maheshwar | Medium<ul> <li>Set Up NGINX Reverse Proxy with SSL Termination</li> </ul> </li> <li> Set Up NGINX Reverse Proxy with SSL Termination and backend server is Nexus</li> </ul> </li> </ul>"},{"location":"hackmd/Nexus%20Repository%20Manager/#apt","title":"apt","text":"<ul> <li>Nexus--Ubuntu apt\u4ed3\u5e93\u642d\u5efa_ubuntu\u5b89\u88c5nexus-CSDN\u535a\u5ba2</li> <li>\u4f7f\u7528nexus\u4ee3\u7406yum\u6e90\u548capt\u6e90 | \u9752\u86d9\u5c0f\u767d</li> </ul> <p>http://tw.archive.ubuntu.com/ubuntu</p> <pre><code>sed -i 's/tw.archive.ubuntu.com\\/ubuntu/10.184.27.20:8082\\/repository\\/ubuntu-focal/g' /etc/apt/sources.list\n</code></pre>"},{"location":"hackmd/Nexus%20Repository%20Manager/#docker","title":"docker","text":"<ul> <li>Setup Nexus OSS on Docker as Docker Registry for Learning | by tanut aran | CODEMONDAY | Medium</li> <li>\u4f7f\u7528 Nexus Repository \u5efa\u7acb Docker Registry - Yowko's Notes</li> <li>\u901a\u904e Sonatype Nexus \u5efa\u7acb\u79c1\u6709 Docker Image Registry | \u4f59\u5c0f\u7ae0 @ \u5927\u5167\u6bbf\u5802 - \u9ede\u90e8\u843d</li> <li>\u642d\u5efaNexus\u4f5c\u4e3aDocker\u7684\u4ee3\u7406\u7f13\u5b58 - Hazx\u5c0f\u5c4b</li> </ul>"},{"location":"hackmd/Nexus%20Repository%20Manager/#pypi","title":"pypi","text":"<ul> <li>\u4f7f\u7528nexus3\u914d\u7f6ePython\u79c1\u6709\u4ed3\u5e93 | \u4e8c\u4e2b\u8bb2\u68b5</li> </ul> <pre><code>python3 -m pip install lxml --trusted-host 172.19.50.105 -i http://172.19.50.105:8081/repository/proxy-pypi/simple\n</code></pre>"},{"location":"hackmd/OpenShift/","title":"OpenShift","text":"<ul> <li>redhat hybrid cloud console</li> <li>:star: Deploying a simple Python app to Kubernetes/OpenShift | JJ Asghar | Conf42 Python 2022<ul> <li>jjasghar (jjasghar) / Repositories \u00b7 GitHub</li> </ul> </li> <li>\u300e\u7d05\u5e3d\u300f\u7684 Cloud-Native \u5de5\u4f5c\u8853: \u5f9e Container \u5230 OpenShift \u3002 :: \u7b2c 12 \u5c46 iThome \u9435\u4eba\u8cfd<ul> <li>\u514d YAML \u90e8\u7f72 App \u5230 OpenShift: new-app \u8ddf Template \u6dfa\u8ac7 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li><code>oc get all -o NAME --no-headers | xargs oc delete</code></li> </ul> </li> <li>Docker\u7378 \u7a76\u6975\u9032\u5316 \uff5e\uff5e Kubernetes\u7378 :: \u7b2c 12 \u5c46 iThome \u9435\u4eba\u8cfd</li> <li>\u611b\u7684\u8d70\u99ac\u770b\u82b1 Red Hat CoreOS \u8207 Red Hat OpenShift Part 1 - \u9b42\u7cfb\u67b6\u69cb Phil's Workspace</li> <li>Machine configuration tasks | Post-installation configuration | OpenShift Container Platform 4.13</li> <li>How to Configure a Squid Proxy and SSH Tunnel on RHEL 8 to access OpenShift Console from your local machine - Goglides Dev \ud83c\udf31</li> <li>Configure access to a Red Hat OpenShift cluster on a private network in IBM Power Systems Virtual Server - IBM Developer</li> <li>Red Hat OpenStack Services on OpenShift: Rethinking storage design in pod-based architectures</li> <li>Course<ul> <li>:star: Red Hat OpenShift Administration I - Managing Containers and Kubernetes 1</li> <li>Red Hat OpenShift Administration I - Managing Containers and Kubernetes 2</li> <li>Red Hat OpenShift Developer II: Building and Deploying Cloud-native Applications(DO288) 1</li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#install","title":"install","text":"<ul> <li>Chapter\u00a02.\u00a0Selecting a cluster installation method and preparing it for users OpenShift Container Platform 4.11 | Red Hat Customer Portal</li> <li>OpenShift 4.10 \u5b89\u88dd\u6b65\u9a5f - HackMD<ul> <li>Meet The New Agent-Based OpenShift Installer</li> </ul> </li> <li>Day 0 \u5230\u5e95\u8a72\u5982\u4f55\u898f\u5283 Openshift Container Platform</li> <li>Day 1 \u5230\u5e95\u8a72\u5982\u4f55\u5b89\u88dd Openshift Container Platform (Part 1)</li> <li>Day 1 \u5230\u5e95\u8a72\u5982\u4f55\u5b89\u88dd Openshift Container Platform (Part 2)</li> <li>agent install<ul> <li>Preparing to install with Agent-based Installer - Installing an on-premise cluster with the Agent-based Installer | Installing | OpenShift Container Platform 4.14<ul> <li>Recommended resources for topologies</li> </ul> </li> <li>Installing a cluster with Agent-based Installer - Installing an on-premise cluster with the Agent-based Installer | Installing | OpenShift Container Platform 4.14<ul> <li>Gathering log data from a failed Agent-based installation<ul> <li>./openshift-install --dir  agent wait-for bootstrap-complete --log-level=debug <li>./openshift-install --dir  agent wait-for install-complete --log-level=debug <li>Better securing the future: Navigating Red Hat OpenShift disconnected installations with the agent-based installer</li> <li>OpenShift Agent install disconnected - HackMD</li> <li>What is the best practice for dealing with kubeadmin user in OpenShift 4? - Red Hat Customer Portal<ul> <li>Creating a cluster admin </li> </ul> </li> <li>Add worker to cluster built with Agent based installation<ul> <li>Add worker to cluster built with Agent based installation : r/openshift</li> <li>\u4f7f\u7528 agent based installer \u5b89\u88c5 3 \u8282\u70b9\u96c6\u7fa4 - OpenShift4 \u6162\u6162\u8d70</li> </ul> </li> <li>Troubleshooting installations - Troubleshooting | Support | OpenShift Container Platform 4.15<ul> <li>The initial kubeadmin password can be found in /auth/kubeadmin-password on the installation host. <p>which - installer-provisioned infrastructure installation - user-provisioned infrastructure installation</p>"},{"location":"hackmd/OpenShift/#openshift-417-build-woker-node-iso","title":"openshift 4.17 build woker node iso","text":"<pre><code>export REGISTRY_AUTH_FILE=/tmp/ocp/mirror-registry/pull-secret.json\noc adm node-image create nodes-config.yaml\noc adm node-image monitor --ip-addresses &lt;ip_addresses&gt;\noc get csr\noc adm certificate approve &lt;csr_name&gt;\n</code></pre> <p>nodes-config.yaml <pre><code>hosts:\n  - hostname: extra-worker-1\n    rootDeviceHints:\n      deviceName: /dev/nvme0n1\n    interfaces:\n      - macAddress: 90:5a:08:03:6a:30\n        name: enp23s0f0np0\n      - macAddress: 5E:09:6B:17:DE:F6\n        name: enp0s20f0u1u1c2\n      - macAddress: 90:5a:08:03:6a:31\n        name: enp23s0f1np1\n    networkConfig:\n      interfaces:\n        - name: enp23s0f0np0\n          type: ethernet\n          state: up\n          mac-address: 90:5a:08:03:6a:30\n          ipv4:\n            enabled: true\n            address:\n              - ip: 172.17.217.240\n                prefix-length: 24\n            dhcp: false\n            auto-dns: false\n          ipv6:\n            enabled: false\n        - name: enp0s20f0u1u1c2\n          type: ethernet\n          state: down\n          mac-address: 5E:09:6B:17:DE:F6\n          ipv4:\n            enabled: false\n          ipv6:\n            enabled: false\n        - name: enp23s0f1np1\n          type: ethernet\n          state: down\n          mac-address: 90:5a:08:03:6a:31\n          ipv4:\n            enabled: false\n          ipv6:\n            enabled: false\n      routes:\n        config:\n          - destination: 0.0.0.0/0\n            next-hop-address: 172.17.217.1\n            next-hop-interface: enp23s0f0np0\n            table-id: 254\n      dns-resolver:\n        config:\n          search:\n            - b3qportal.com\n          server:\n            - 172.17.217.241\n</code></pre></p>"},{"location":"hackmd/OpenShift/#cli","title":"CLI","text":"<ul> <li>CLI tools OpenShift Container Platform 4.14 | Red Hat Customer Portal<ul> <li>Deleting Operators from a cluster - Administrator tasks | Operators | OpenShift Container Platform 4.15</li> </ul> </li> </ul> <pre><code>oc cluster-info\noc project\noc login https://api.ocp4.example.com:6443\n# oc login https://172.24.131.126:6443 --username=kubeadmin --password=bar --insecure-skip-tls-verify\noc whoami -c\noc whoami --show-console\noc api-versions\noc status\n# view your current CLI configuration\noc config view\n#  list the total memory and CPU usage of all pods in the cluster, --sum option with the command to print the sum of the resource usage. The -A option shows pods from all namespaces.\noc adm top pods -A --sum\n# Use the --containers option to display the resource usage of containers within a pod.\noc adm top pods apiserver-75ff56786f-25rpd -n openshift-apiserver --containers\n\noc get clusteroperator\noc get operators\noc get operators nfd.openshift-nfd\noc get RESOURCE_TYPE\noc get RESOURCE_TYPE RESOURCE_NAME -o yaml\noc get RESOURCE_TYPE RESOURCE_NAME -o json\noc get all\noc get all -n openshift-apiserver --show-kind\noc get all -n openshift-monitoring --show-kind\n# execute commands in a different project, you must include the --namespace or -n options.\noc get pods -n openshift-apiserver\noc get pods -n openshift-apiserver -o yaml\noc get pods -n openshift-apiserver -o json\n# print the labels used by the pods.\noc get pods -n openshift-apiserver --show-labels\noc get pod --all-namespaces -o wide\n# shows additional fields.\noc get pods -o wide\n\n# this function is not available across all resources. \noc describe RESOURCE_TYPE RESOURCE_NAME\n\n# to print the documentation of a specific field of a resource. \n# Fields are identified via a JSONPath identifier.\n# Information about each field is retrieved from the server in OpenAPI format.\noc explain pods\noc explain pods.spec.containers.resources\n# display all fields of a resource without descriptions.\noc explain pods --recursive\n\n\n# create a RHOCP resource in the current project.\n# paired with the oc get RESOURCE_TYPE RESOURCE_NAME -o yaml command for editing definitions.\n# to indicate the file that contains the JSON or YAML representation of an RHOCP resource.\noc create -f pod.yaml\n\n# delete an existing RHOCP resource from the current project.\n# must specify the resource type and the resource name.\noc delete pod quotes-ui\n\n# RBAC\noc get clusterrole.rbac\n</code></pre> <p>monitor and log about the cluster <pre><code>oc logs alertmanager-main-0 -n openshift-monitoring\n# returns the output for a container within a pod\noc logs alertmanager-main-0 -n openshift-monitoring\noc get nodes master-0 -o json | jq '.status.conditions'\noc get nodes worker-0 -o json | jq '.status.conditions'\noc adm node-logs worker-0\noc adm node-logs worker-0 --tail 10\n## start a debug session on the node \noc debug node/worker-0\noc get pods alertmanager-main-0 -n openshift-monitoring -o jsonpath='{.spec.containers[*].name}'\noc logs alertmanager-main-0 -n openshift-monitoring -c alertmanager-proxy\noc exec -n openshift-monitoring alertmanager-main-0 -c alertmanager-proxy -it -- bash -il\n</code></pre></p>"},{"location":"hackmd/OpenShift/#tab-completion","title":"Tab completion","text":"<ul> <li>https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/cli_tools/index#cli-enabling-tab-completion <pre><code>oc completion bash &gt; oc_bash_completion\nsudo cp oc_bash_completion /etc/bash_completion.d/\n</code></pre> You can also save the file to a local directory and source it from your .bashrc file instead.</li> </ul> <p>Tab completion is enabled when you open a new terminal.</p>"},{"location":"hackmd/OpenShift/#authentication-with-oauth","title":"Authentication with OAuth","text":"<p>For users to interact with RHOCP, they must first authenticate to the cluster. The authentication layer identifies the user that is associated with requests to the RHOCP API. After authentication, the authorization layer then uses information about the requesting user to determine whether the request is allowed.</p> <p>A user in OpenShift is an entity that can make requests to the RHOCP API. </p> <p>An RHOCP User object represents an actor that can be granted permissions in the system by adding roles to the user or to the user's groups.</p> <ul> <li>Regular users<ul> <li>An RHOCP User object represents a regular user.</li> </ul> </li> <li>System users</li> <li>Service accounts<ul> <li>ServiceAccount objects represent service accounts. </li> <li>RHOCP creates service accounts automatically when a project is created</li> </ul> </li> </ul> <p>The RHOCP control plane includes a built-in OAuth server.</p> <p>To authenticate themselves to the API, users obtain OAuth access tokens. Token authentication is the only guaranteed method to work with any OpenShift cluster</p> <p>To retrieve an OAuth token by using the OpenShift web console, navigate to Help \u2192 Command line tools. </p> <pre><code>[user@host ~]$ oc login --token=sha256-BW...rA8 \\\n  --server=https://api.ocp4.example.com:6443\n</code></pre>"},{"location":"hackmd/OpenShift/#image","title":"image","text":"<ul> <li>Chapter\u00a09.\u00a0Image configuration resources OpenShift Container Platform 4.11 | Red Hat Customer Portal</li> <li>OpenShift External/Mirror Image registry\u662f\u600e\u9ebc\u904b\u4f5c\u7684? | by Albert Weng | Medium</li> <li>OpenShift 4 - \u914d\u7f6eOpenShift\u53ef\u4f7f\u7528\u7684\u5916\u90e8Image Registry\u548cMirror Registry_openshift\u914d\u7f6e\u5916\u90e8\u79c1\u6709registry-CSDN\u535a\u5ba2</li> <li>Openshift - Quay \u672c\u5730\u79c1\u6709 Registry \u5009\u5eab (standalone) - HowHow \u306e WebSite</li> </ul>"},{"location":"hackmd/OpenShift/#quay","title":"quay","text":"<ul> <li>Chapter\u00a02.\u00a0Creating a mirror registry with mirror registry for Red Hat OpenShift | Red Hat Product Documentation<ul> <li>Chapter\u00a03.\u00a0Mirroring images for a disconnected installation | Red Hat Product Documentation</li> </ul> </li> <li>GitHub - quay/mirror-registry: A standalone registry used to mirror images for Openshift installations.</li> <li>Installing OpenShift in a disconnected network, step-by-step - HackMD</li> <li>Chapter\u00a01.\u00a0SSL and TLS for Red Hat Quay | Red Hat Product Documentation</li> <li>OpenShift External/Mirror Image registry\u662f\u600e\u9ebc\u904b\u4f5c\u7684? | by Albert Weng | Medium</li> <li>Quay.io rate limiting - Red Hat Customer Portal</li> </ul> <p>with internet <pre><code>wget https://mirror.openshift.com/pub/cgw/mirror-registry/latest/mirror-registry-amd64.tar.gz\ntar -xvf mirror-registry-amd64.tar.gz\n./mirror-registry install --quayHostname $(hostname -f) --quayRoot /home/foo/quay --initUser foo --initPassword barbarbar\n\n# use different port\n# https://github.com/quay/mirror-registry/blob/e609475d2eba1825866909d5d5997b048da5bc88/ansible-runner/context/app/project/roles/mirror_appliance/templates/pod.service.j2#L15\n./mirror-registry install --quayHostname $(hostname -f):18443 --quayRoot /home/foo/quay --initUser foo --initPassword barbarbar\n</code></pre></p> <p>air-gapped https://github.com/quay/mirror-registry#installation <pre><code>wget https://github.com/quay/mirror-registry/releases/download/v2.0.3/mirror-registry-offline.tar.gz\ntar -zxvf mirror-registry-offline.tar.gz\n./mirror-registry install --quayHostname $(hostname -f) --quayRoot /home/foo/quay --initUser foo --initPassword barbarbar\n</code></pre></p>"},{"location":"hackmd/OpenShift/#pull-images","title":"pull images","text":"<p>with internet <pre><code>oc adm release mirror -a /tmp/ocp/mirror-registry/pull-secret.json \\\n--from=quay.io/openshift-release-dev/ocp-release:4.17.10-x86_64 \\\n--to=&lt;LOCAL_REGISTRY&gt;/&lt;LOCAL_REPOSITORY&gt; \\\n--to-release-image=&lt;LOCAL_REGISTRY&gt;/&lt;LOCAL_REPOSITORY&gt;:4.17.10-x86_64\n</code></pre></p> <p>air-gapped Mirror the images to a directory on the removable media <pre><code>oc adm release mirror -a /tmp/ocp/mirror-registry/pull-secret.json \\\n--to-dir=/tmp/mirror \\\nquay.io/openshift-release-dev/ocp-release:4.17.10-x86_64\n</code></pre></p> <p>:::info info: Mirroring completed in 30m21.7s (10.99MB/s)</p> <p>Success Update image:  openshift/release:4.17.10-x86_64</p> <p>To upload local images to a registry, run:</p> <pre><code>oc image mirror --from-dir=/tmp/mirror 'file://openshift/release:4.17.10-x86_64*' REGISTRY/REPOSITORY\n</code></pre> <p>Configmap signature file /tmp/mirror/config/signature-sha256-4c8cc149a8e4ef2f.json created :::</p> <pre><code>oc image mirror \\\n-a /tmp/ocp/mirror-registry/pull-secret.json \\\n--certificate-authority=/home/foo/quay/quay-rootCA/rootCA.pem \\\n--from-dir=/tmp/mirror \\\n'file://openshift/release:4.17.10-x86_64*' &lt;LOCAL_REGISTRY&gt;/&lt;LOCAL_REPOSITORY&gt;\n</code></pre>"},{"location":"hackmd/OpenShift/#uninstall","title":"uninstall","text":"<pre><code>./mirror-registry uninstall -v --autoApprove --quayRoot /home/foo/quay\n</code></pre>"},{"location":"hackmd/OpenShift/#debug","title":"debug","text":"<ul> <li>Failed to mirror-registry installation with WRONGPASS invalid username-password pair or user is disabled messages - Red Hat Customer Portal</li> </ul> <pre><code>podman secret ls\npodman secret rm redis_pass\n</code></pre>"},{"location":"hackmd/OpenShift/#nexus","title":"Nexus","text":"<ul> <li>Using Nexus as a proxy registry for a disconnected OpenShift install - Sonatype Nexus Repository - Sonatype Community<ul> <li>Using Nexus as a proxy registry for a disconnected OpenShift install \u00b7 Issue #475 \u00b7 sonatype/nexus-public</li> <li>small patch for disconnected OCP deploy with regular proxy registries (like Nexus) \u00b7 Issue #757 \u00b7 karmab/kcli \u00b7 GitHub</li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#api","title":"API","text":"<ul> <li>How to request and pass an oauth token for REST API access in OpenShift 4 - Red Hat Customer Portal</li> </ul> <pre><code># Get OAuth Route Hostname\noc get route -n openshift-authentication -o jsonpath='{.items[].spec.host}{\"\\n\"}'  \n\n# Oauth Bearer Token: Method 1\nTOKEN=$(curl -s -k -i -L -X GET --user USER:PASSWORD 'https://&lt;OAuth-route-hostname&gt;/oauth/authorize?response_type=token&amp;client_id=openshift-challenging-client' | grep -oP \"access_token=\\K[^&amp;]*\")\n\n# Oauth Bearer Token: Method 2\nTOKEN=$(curl -s -k -i -L -X GET --user USER:PASSWORD 'https://&lt;oauth-route-hostname&gt;/oauth/authorize?response_type=token&amp;client_id=openshift-challenging-client' | grep  \"access_token=\" | awk -F'=' '{print $2}' | awk -F'&amp;' '{print $1}')\n\n# Test\ncurl -s -k -H \"Authorization: Bearer $TOKEN\" -X GET https://&lt;API host&gt;:6443/apis/project.openshift.io/v1/projects\n</code></pre>"},{"location":"hackmd/OpenShift/#operators","title":"Operators","text":"<pre><code>curl -s -k -H \"Authorization: Bearer $TOKEN\" -X GET https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/subscriptions\n\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X GET https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/subscriptions/web-terminal\n\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X GET https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/redhat-ods-operator/subscriptions/rhods-operator\n</code></pre> <p>web-terminal <pre><code># remove\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X DELETE https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/subscriptions/web-terminal\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X DELETE https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/clusterserviceversions/web-terminal.v1.9.0-0.1708477317.p\n\n\n# install\ncurl -k -H \"Authorization: Bearer $TOKEN\" -H 'Content-Type: application/json' -X POST https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/subscriptions -d '{\"apiVersion\":\"operators.coreos.com/v1alpha1\",\"kind\":\"Subscription\",\"metadata\":{\"name\":\"web-terminal\",\"namespace\":\"openshift-operators\"},\"spec\":{\"channel\":\"fast\",\"name\":\"web-terminal\",\"source\":\"redhat-operators\",\"sourceNamespace\":\"openshift-marketplace\",\"startingCSV\":\"web-terminal.v1.9.0\"}}'\n</code></pre></p> <p>openshift AI <pre><code># get subscription\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X GET https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/redhat-ods-operator/subscriptions/rhods-operator\n\n# remove\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X DELETE https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/redhat-ods-operator/subscriptions/rhods-operator\ncurl -k -H \"Authorization: Bearer $TOKEN\" -X DELETE https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/redhat-ods-operator/clusterserviceversions/rhods-operator.2.8.0\n\n# install\ncurl -k -H \"Authorization: Bearer $TOKEN\" -H 'Content-Type: application/json' -X POST https://api.test.supershift.com:6443/apis/operators.coreos.com/v1alpha1/namespaces/redhat-ods-operator/subscriptions -d '{\"apiVersion\":\"operators.coreos.com/v1alpha1\",\"kind\":\"Subscription\",\"metadata\":{\"name\":\"rhods-operator\",\"namespace\":\"redhat-ods-operator\"},\"spec\":{\"channel\":\"stable\",\"name\":\"rhods-operator\",\"source\":\"redhat-operators\",\"sourceNamespace\":\"openshift-marketplace\", \"installPlanApproval\": \"Automatic\", \"startingCSV\":\"rhods-operator.2.8.0\"}}'\n</code></pre></p>"},{"location":"hackmd/OpenShift/#basic","title":"Basic","text":"<ul> <li>:star:How to deploy a web service on OpenShift | Enable Sysadmin</li> <li>Running a PostgreSQL app in Openshift &amp; connecting to it! | by Harshit Dawar | Medium<ul> <li>Facing permission issue when creating application using postgres image - Red Hat Customer Portal</li> </ul> </li> <li>Harness the Power of Python Microservices in OpenShift \u00b7 MeatyBytes</li> </ul>"},{"location":"hackmd/OpenShift/#template","title":"template","text":"<pre><code>oc process openshift//postgresql-persistent POSTGRESQL_USER=test POSTGRESQL_PASSWORD=test POSTGRESQL_DATABASE=test0328 | oc create -n tedchangchien-dev -f -\noc status\noc get pods\noc rsh &lt;pod name&gt;\n\npsql -U test -W test0328\n</code></pre>"},{"location":"hackmd/OpenShift/#network","title":"Network","text":"<ul> <li>OpenShift Networking - Full Walkthrough - Containers and Virtual Machines - YouTube</li> </ul>"},{"location":"hackmd/OpenShift/#machine-network","title":"Machine Network","text":"<p>This is the network at the infrastructure layer of an OpenShift cluster, typically used to connect physical or virtual nodes (e.g., masters, worker nodes). The IP range of the machine network is used for communication between nodes and for running management services like ETCD and the Kubernetes control plane.</p>"},{"location":"hackmd/OpenShift/#cluster-network","title":"Cluster Network","text":"<p>The internal Pod network within the cluster used for communication between Pods. </p> <p>Each Pod is typically assigned a unique IP address. OpenShift uses Software-Defined Networking (SDN) to manage the cluster network, ensuring seamless communication between Pods.</p>"},{"location":"hackmd/OpenShift/#service-network","title":"Service Network","text":"<p>This network manages the virtual IP range for Kubernetes Services. Each Service is assigned a Cluster IP to handle traffic from both internal and external sources. Service IPs usually do not communicate directly with the external world but instead use a Service Proxy or Load Balancer for traffic forwarding.</p>"},{"location":"hackmd/OpenShift/#service","title":"Service","text":"<ul> <li>https://www.youtube.com/watch?v=AObTrhIeK2U<ul> <li>internal<ul> <li>ClusterIP</li> </ul> </li> <li>external<ul> <li>NodePort</li> <li>LoadBalancer</li> </ul> </li> </ul> </li> <li>Kubernetes Service\uff1aOverview\uff5c\u65b9\u683c\u5b50 vocus</li> <li>[Day 9] \u5efa\u7acb\u5916\u90e8\u670d\u52d9\u8207Pods\u7684\u6e9d\u901a\u7ba1\u9053 - Services</li> <li>ClusterIP vs NodePort vs LoadBalancer vs Ingress - Red Hat Learning Community</li> </ul>"},{"location":"hackmd/OpenShift/#ingress","title":"Ingress","text":"<ul> <li>[Day 19] \u5728 Kubernetes \u4e2d\u5be6\u73fe\u8ca0\u8f09\u5e73\u8861 - Ingress Controller</li> <li>\u514d\u9664 Ingress Controller \u7169\u60f1\uff0c\u64c1\u62b1 OpenShift Route \u65b0\u4e16\u754c\u3002</li> <li>Kubernetes \u90a3\u4e9b\u4e8b \u2014 Ingress \u7bc7\uff08\u4e00\uff09. \u524d\u8a00 | by Andy Chen | Andy\u7684\u6280\u8853\u5206\u4eabblog | Medium</li> <li>Kubernetes \u90a3\u4e9b\u4e8b \u2014 Ingress \u7bc7\uff08\u4e8c\uff09. \u524d\u8a00 | by Andy Chen | Andy\u7684\u6280\u8853\u5206\u4eabblog | Medium</li> <li>Kubernetes Ingress vs OpenShift Route</li> </ul>"},{"location":"hackmd/OpenShift/#rbac","title":"RBAC","text":"<ul> <li>Red Hat OpenShift RBAC \u6700\u5c0f\u6b0a\u9650\u5be6\u8e10 - \u9b42\u7cfb\u67b6\u69cb Phil's Workspace</li> </ul>"},{"location":"hackmd/OpenShift/#console","title":"Console","text":"<ul> <li>Customizing the console route<ul> <li>How to customize console URL in OpenShift 4 under the same *.apps subdomain - Red Hat Customer Portal</li> <li>Customizing the OpenShift Console URL with TLS \u00b7 MeatyBytes<ul> <li>How to create a TLS/SSL certificate with a Cert-Manager Operator on OpenShift</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#storageclass","title":"StorageClass","text":"<ul> <li>:star:Chapter\u00a04.\u00a0Configuring persistent storage | Red Hat Product Documentation</li> <li>OpenShift External/Mirror Image registry\u662f\u600e\u9ebc\u904b\u4f5c\u7684? | by Albert Weng | Medium</li> </ul>"},{"location":"hackmd/OpenShift/#openshift-data-foundation","title":"OpenShift Data Foundation","text":"<ul> <li>Product Documentation for Red Hat OpenShift Data Foundation 4.15 | Red Hat Customer Portal<ul> <li>Chapter\u00a03.\u00a0Deploy using local storage devices Red Hat OpenShift Data Foundation 4.15 | Red Hat Customer Portal</li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#operators_1","title":"Operators","text":"<ul> <li>Adding Operators to a cluster - Administrator tasks | Operators | OpenShift Container Platform 4.15</li> <li>Deleting Operators from a cluster - Administrator tasks | Operators | OpenShift Container Platform 4.15</li> <li>3scale Operator on OpenShift4.2 | \u91ce\u751f\u7684\u5de5\u7a0b\u5e2b</li> </ul>"},{"location":"hackmd/OpenShift/#openshift-ai","title":"openshift AI","text":"<ul> <li>Red Hat OpenShift AI Overview | Red Hat Developer<ul> <li>Red Hat OpenShift AI Demo - YouTube</li> </ul> </li> <li>Chapter\u00a05.\u00a0Installing the Red\u00a0Hat OpenShift AI Operator Red Hat OpenShift AI Self-Managed 2.6 | Red Hat Customer Portal</li> <li>How to create a natural language processing (NLP) application using Red Hat OpenShift AI | Red Hat Developer</li> </ul>"},{"location":"hackmd/OpenShift/#nvidia-gpu","title":"NVIDIA GPU","text":"<ul> <li>NVIDIA GPU architecture | Hardware accelerators | OpenShift Container Platform 4.17<ul> <li>:star:Red Hat OpenShift on Bare Metal \u2014 NVIDIA AI Enterprise: OpenShift on Bare-metal Deployment Guide<ul> <li>:star:Installing the NVIDIA GPU Operator on OpenShift \u2014 NVIDIA GPU Operator on Red Hat OpenShift Container Platform</li> <li>Run Nvidia NIM microservice containers in Red Hat OpenShift on IBM Cloud</li> <li>Pulling and Running NVIDIA AI Enterprise Containers \u2014 NVIDIA AI Enterprise: Cloud Deployment Guide</li> </ul> </li> <li>Enabling the GPU Monitoring Dashboard \u2014 NVIDIA GPU Operator on Red Hat OpenShift Container Platform</li> </ul> </li> <li>NVIDIA AI Enterprise<ul> <li>Subscription Required for \"NVIDIA AI Enterprise Essentials\"</li> <li>Overview \u2014 NVIDIA AI Enterprise Licensing Guide</li> <li>NVIDIA AI Enterprise - NVIDIA Docs<ul> <li>Infrastructure Support Matrix \u2014 NVIDIA AI Enterprise</li> <li>NVIDIA-Certified Systems - NVIDIA Docs</li> <li>Quick Start Guide \u2014 NVIDIA AI Enterprise</li> </ul> </li> <li>Activate Your NVIDIA AI Enterprise License | NVIDIA<ul> <li>NVIDIA AI Enterprise Licensing \u2014 NVIDIA AI Enterprise Licensing Guide</li> <li>Activating your NVIDIA Software Subscription and Enterprise Support</li> <li>nvaie-instruction-document-the-serial-number-of-nvidiagpu-february-2023.pdf</li> </ul> </li> <li>Deploying NVIDIA AI Enterprise Containers \u2014 NVIDIA AI Enterprise: OpenShift on Bare-metal Deployment Guide<ul> <li>Generating NGC API Keys</li> <li>\u7533\u8acb NVIDIA NGC API key \u7528\u65bc TAO toolkit DLI \u8ab2\u7a0b - CAVEDU\u6559\u80b2\u5718\u968a\u6280\u8853\u90e8\u843d\u683c</li> <li>https://ngc.nvidia.com/signin</li> </ul> </li> <li>Pulling and Running NVIDIA AI Enterprise Containers \u2014 NVIDIA AI Enterprise: Cloud Deployment Guide</li> </ul> </li> <li>Demo: NVIDIA AI Enterprise with Red Hat OpenShift - YouTube</li> <li>pa-nvidia-steamline-gen-ai-development-brief-1468598-202410-en.pdf</li> <li>NVIDIA GPU Operator<ul> <li>About the NVIDIA GPU Operator \u2014 NVIDIA GPU Operator</li> <li>Installing the NVIDIA GPU Operator on OpenShift \u2014 NVIDIA GPU Operator on Red Hat OpenShift Container Platform</li> <li>NVIDIA AI Enterprise with OpenShift \u2014 NVIDIA GPU Operator on Red Hat OpenShift Container Platform</li> <li>Red Hat OpenShift on Bare Metal \u2014 NVIDIA AI Enterprise: OpenShift on Bare-metal Deployment Guide</li> </ul> </li> <li>NVIDIA NIM<ul> <li>Introduction \u2014 NVIDIA NIM for Large Language Models (LLMs)</li> <li>Deliver generative AI at scale with NVIDIA NIM on OpenShift AI | Red Hat Developer</li> <li>Installing NVIDIA NIM Operator on Red Hat OpenShift \u2014 NVIDIA NIM Operator</li> </ul> </li> <li>Others<ul> <li>GPU-powered Kubernetes clusters. A comprehensive and incremental\u2026 | by Gleb Vazhenin | Bumble Tech | Medium</li> <li>Sharing A Nvidia GPU Between Pods In Kubernetes - DEV Community</li> <li>Schedule GPUs | Kubernetes<ul> <li>GitHub - NVIDIA/k8s-device-plugin: NVIDIA device plugin for Kubernetes</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#gpus-and-bare-metal","title":"GPUs and bare metal","text":"<p>In addition, the worker nodes can host one or more GPUs, but they must be of the same type. For example, a node can have two NVIDIA A100 GPUs, but a node with one A100 GPU and one T4 GPU is not supported. The NVIDIA Device Plugin for Kubernetes does not support mixing different GPU models on the same node.</p>"},{"location":"hackmd/OpenShift/#multi-instance-gpu-mig-partitioning","title":"Multi-instance GPU (MIG) partitioning","text":"<ul> <li>Sharing is caring: How to make the most of your GPUs part 2 - Multi-instance GPU</li> </ul> <p>MIG is only supported with A30, A100, A100X, A800, AX800, H100, and H800.</p> <p>For instance, the NVIDIA A100 40GB, offers multiple partitioning options:</p> <ul> <li>1g.5gb: 1 Compute Instance (CI), 5GB memory</li> <li>2g.10gb: 2 CIs, 10GB memory</li> <li>3g.20gb: 3 CIs, 20GB memory</li> <li>4g.20gb: 4 CIs, 20GB memory</li> <li>7g.40gb: 7 CIs, 40GB memory</li> </ul> <p>Check the supported profiles <pre><code>oc rsh  -n nvidia-gpu-operator  $(oc get pods -n nvidia-gpu-operator | grep -E 'nvidia-dcgm-exporter.*' | awk '{print $1}') nvidia-smi mig -lgip\n\n# if not all gpu nodes support the MIG\noc get pods -n nvidia-gpu-operator | grep -E 'nvidia-dcgm-exporter.*' | awk '{print $1}\noc rsh  -n nvidia-gpu-operator nvidia-dcgm-exporter-dln49  nvidia-smi mig -lgip\n</code></pre></p> <pre><code>Defaulted container \"nvidia-dcgm-exporter\" out of: nvidia-dcgm-exporter, toolkit-validation (init), init-pod-nvidia-node-status-exporter (init)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   0  MIG 1g.5gb        19     7/7        4.75       No     14     0     0   |\n|                                                             1     0     0   |\n+-----------------------------------------------------------------------------+\n|   0  MIG 1g.5gb+me     20     1/1        4.75       No     14     1     0   |\n|                                                             1     1     1   |\n+-----------------------------------------------------------------------------+\n|   0  MIG 1g.10gb       15     4/4        9.75       No     14     1     0   |\n|                                                             1     0     0   |\n+-----------------------------------------------------------------------------+\n|   0  MIG 2g.10gb       14     3/3        9.75       No     28     1     0   |\n|                                                             2     0     0   |\n+-----------------------------------------------------------------------------+\n|   0  MIG 3g.20gb        9     2/2        19.62      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n|   0  MIG 4g.20gb        5     1/1        19.62      No     56     2     0   |\n|                                                             4     0     0   |\n+-----------------------------------------------------------------------------+\n|   0  MIG 7g.40gb        0     1/1        39.38      No     98     5     0   |\n|                                                             7     1     1   |\n+-----------------------------------------------------------------------------+\n</code></pre> <p>config MIG</p> <pre><code># config the mig to node/worker-1(has a GPU A100) which is based on your environment\noc label  node/worker-1 nvidia.com/mig.config=all-1g.10gb --overwrite=true\n# check the log\noc logs -n nvidia-gpu-operator $(oc get pods -n nvidia-gpu-operator -l app=nvidia-mig-manager -o jsonpath='{.items[0].metadata.name}')\n# check the node\noc describe node worker-1\noc describe nodes | grep -A 6 \"Capacity\"\noc get nodes -o=custom-columns='Node:metadata.name,GPU Product:metadata.labels.nvidia\\.com/gpu\\.product,GPU Capacity:status.capacity.nvidia\\.com/gpu'\n\n# show the mig\noc rsh -n nvidia-gpu-operator \\\n$(oc get pods -n nvidia-gpu-operator | grep -E 'nvidia-driver-daemonset.*' | awk '{print $1}') nvidia-smi mig -lgi\n\n# if not all gpu nodes support the MIG\noc get pods -n nvidia-gpu-operator | grep -E 'nvidia-driver-daemonset.*' | awk '{print $1}'\noc rsh  -n nvidia-gpu-operator nvidia-driver-daemonset-417.94.202412180008-0-rzp8x nvidia-smi mig -lgi\n</code></pre> <p>After config it into all-1g.10gb <pre><code>+-------------------------------------------------------+\n| GPU instances:                                        |\n| GPU   Name             Profile  Instance   Placement  |\n|                          ID       ID       Start:Size |\n|=======================================================|\n|   0  MIG 1g.10gb         15        3          4:2     |\n+-------------------------------------------------------+\n|   0  MIG 1g.10gb         15        4          6:2     |\n+-------------------------------------------------------+\n|   0  MIG 1g.10gb         15        5          0:2     |\n+-------------------------------------------------------+\n|   0  MIG 1g.10gb         15        6          2:2     |\n+-------------------------------------------------------+\n</code></pre></p> <p>After config it into all-1g.5gb <pre><code>+-------------------------------------------------------+\n| GPU instances:                                        |\n| GPU   Name             Profile  Instance   Placement  |\n|                          ID       ID       Start:Size |\n|=======================================================|\n|   0  MIG 1g.5gb          19        7          4:1     |\n+-------------------------------------------------------+\n|   0  MIG 1g.5gb          19        8          5:1     |\n+-------------------------------------------------------+\n|   0  MIG 1g.5gb          19        9          6:1     |\n+-------------------------------------------------------+\n|   0  MIG 1g.5gb          19       11          0:1     |\n+-------------------------------------------------------+\n|   0  MIG 1g.5gb          19       12          1:1     |\n+-------------------------------------------------------+\n|   0  MIG 1g.5gb          19       13          2:1     |\n+-------------------------------------------------------+\n|   0  MIG 1g.5gb          19       14          3:1     |\n+-------------------------------------------------------+\n</code></pre></p> <pre><code># run the gpu application\ncat &lt;&lt; EOF | oc create -f -\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: cuda-vectoradd\nspec:\n restartPolicy: OnFailure\n containers:\n - name: cuda-vectoradd\n   image: \"nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda12.5.0-ubi8\"\n   resources:\n     limits:\n       nvidia.com/gpu: 4\nEOF\n</code></pre> <p>Disalbe the MIG <pre><code># disalbe the mig on node/worker-1\noc label  node/worker-1 nvidia.com/mig.config=all-disabled --overwrite=true\n</code></pre></p>"},{"location":"hackmd/OpenShift/#deploying-nvidia-ai-enterprise-containers","title":"Deploying NVIDIA AI Enterprise Containers","text":"<ul> <li>Deploying NVIDIA AI Enterprise Containers \u2014 NVIDIA AI Enterprise: OpenShift on Bare-metal Deployment Guide</li> </ul> <p>prerequisite 1. apply for NGC_KEY</p> <ol> <li>create a secret for pulling images from NGC <pre><code>oc create secret docker-registry regcred --docker-server=nvcr.io --docker-username=\\$oauthtoken --docker-password=&lt;YOUR_NGC_KEY&gt; --docker-email=&lt;your_email_id&gt; -n default\n</code></pre></li> </ol>"},{"location":"hackmd/OpenShift/#jupyter","title":"jupyter","text":"<p>tensorflow-jupyter.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tensorflow-jupyter-notebook\n  labels:\n    app: tensorflow-jupyter-notebook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tensorflow-jupyter-notebook\n  template:\n    metadata:\n      labels:\n        app: tensorflow-jupyter-notebook\n    spec:\n      containers:\n      - name: tensorflow-container\n        image: nvcr.io/nvidia/tensorflow-pb24h2:24.08.07-tf2-py3\n        # image: nvcr.io/nvaie/tensorflow-2-3:22.09-tf2-nvaie-2.3-py3\n        ports:\n        - containerPort: 8888\n        command: [\"jupyter-notebook\"]\n        args: [\"--NotebookApp.token=''\"]\n        resources:\n          requests:\n            nvidia.com/gpu: 1\n          limits:\n            nvidia.com/gpu: 1\n      imagePullSecrets:\n      - name: regcred\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: tensorflow-jupyter-notebook\nspec:\n  type: NodePort\n  selector:\n    app: tensorflow-jupyter-notebook\n  ports:\n  - protocol: TCP\n    nodePort: 30040\n    port: 8888\n    targetPort: 8888\n</code></pre></p> <pre><code>oc apply -f tensorflow-jupyter.yaml\noc get pods\noc describe pod &lt;pod-name&gt;\n# Note the FQDN or IP of the node it is running on and construct the URL for accessing the notebook.\n# http://&lt;NODE_FQDN_OR_IP&gt;:30040\n</code></pre>"},{"location":"hackmd/OpenShift/#running-resnet-50-with-tensorflow","title":"Running ResNet-50 with TensorFlow","text":"<ul> <li>Running ResNet-50 with TensorFlow</li> </ul> <p>tensorflow-gpu.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tensorflow-gpu\n  labels:\n    app: tensorflow-gpu\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tensorflow-gpu\n  template:\n    metadata:\n      labels:\n        app: tensorflow-gpu\n    spec:\n      containers:\n      - name: tensorflow\n        image: nvcr.io/nvidia/tensorflow-pb24h2:24.08.07-tf2-py3\n        command: [\"/bin/bash\"]\n        args: [\"-c\", \"sleep infinity\"]\n        resources:\n          limits:\n            nvidia.com/gpu: 1\n      imagePullSecrets:\n      - name: regcred\n</code></pre></p> <pre><code>oc apply -f tensorflow-gpu.yaml\noc get pods\noc exec -it &lt;pod-name&gt; -- /bin/bash\ncd /workspace/nvidia-examples/cnn\n\npython resnet.py  -b 16 -i 200 -u batch --precision fp16\n# it works\npython resnet.py  -b 32 -i 200 -u batch --precision fp16\n# it works\n\n# mpiexec --allow-run-as-root --bind-to socket -np 7 python resnet.py  -b 32 -i 200 -u batch --precision fp16\n# it can not work\n# ncclCommInitRank failed: invalid usage (run with NCCL_DEBUG=WARN for details)\n</code></pre> <pre><code>Every 2.0s: nvidia-smi                                                                                                            tensorflow-gpu-56754d7d47-2lgjh: Tue Apr 22 10:00:38 2025\n\nTue Apr 22 10:00:38 2025\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:01:00.0 Off |                   On |\n| N/A   55C    P0            104W /  250W |                  N/A   |     N/A      Default |\n|                                         |                        |              Enabled |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| MIG devices:                                                                            |\n+------------------+----------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|        Shared         |\n|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC  DEC  OFA  JPG |\n|                  |                                  |        ECC|                       |\n|==================+==================================+===========+=======================|\n|  0    7   0   0  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n|  0    8   0   1  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n|  0    9   0   2  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n|  0   11   0   3  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n|  0   12   0   4  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n|  0   13   0   5  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n|  0   14   0   6  |             375MiB /  4864MiB    | 14      0 |  1   0    0    0    0 |\n|                  |                 2MiB /  8191MiB  |           |                       |\n+------------------+----------------------------------+-----------+-----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0    7    0            35027      C   python                                  332MiB |\n|    0    8    0            35002      C   python                                  332MiB |\n|    0    9    0            35014      C   python                                  332MiB |\n|    0   11    0            35001      C   python                                  332MiB |\n|    0   12    0            35009      C   python                                  332MiB |\n|    0   13    0            35008      C   python                                  332MiB |\n|    0   14    0            34993      C   python                                  332MiB |\n+-----------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"hackmd/OpenShift/#pytorch-mnist","title":"PyTorch MNIST","text":"<ul> <li>Pulling and Running NVIDIA AI Enterprise Containers \u2014 NVIDIA AI Enterprise: Cloud Deployment Guide</li> </ul> <p>pytorch.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pytorch-mnist\n  labels:\n    app: pytorch-mnist\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pytorch-mnist\n  template:\n    metadata:\n      labels:\n        app: pytorch-mnist\n    spec:\n      containers:\n      - name: pytorch\n        image: nvcr.io/nvidia/pytorch-ltsb2:23.08-lws2.1.0-py3\n        command: [\"/bin/bash\"]\n        args: [\"-c\", \"sleep infinity\"]\n        resources:\n          limits:\n            nvidia.com/gpu: 1\n      imagePullSecrets:\n      - name: regcred\n</code></pre></p> <pre><code>oc apply -f pytorch.yaml\noc get pods\noc exec -it &lt;pod-name&gt; -- /bin/bash\ncd /workspace/examples/upstream/mnist\n\npython main.py\n# it works\n</code></pre>"},{"location":"hackmd/OpenShift/#debug_1","title":"Debug","text":"<ul> <li>oauth - Lost my openshift console (\"Application is not available\") - Stack Overflow</li> <li>Troubleshooting Red Hat OpenShift Container Platform 4: DNS - Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/OpenShift/#image_1","title":"image","text":"<ul> <li>\"unable to sync: Operation cannot be fulfilled on configs.imageregistry.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again, requeuing\" in OpenShift 4.4.x - Red Hat Customer Portal</li> <li>OpenShift 4 Container Image Management - YouTube</li> <li>Image Registry operator is in degraded state with error \"Unable to apply resources: storage backend not configured\" - Red Hat Customer Portal<ul> <li>Configuring the registry for vSphere - Setting up and configuring the registry | Registry | OpenShift Container Platform 4.15</li> </ul> </li> <li>\u555f\u7528 OpenShift \u5167\u90e8\u6620\u50cf\u6a94\u767b\u9304 - IBM \u8aaa\u660e\u6587\u4ef6</li> </ul> <pre><code>oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{\"spec\":{\"managementState\":\"Managed\"}}'\noc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{\"spec\":{\"storage\":{\"emptyDir\":{}}}}'\n</code></pre>"},{"location":"hackmd/OpenShift/#agent-install","title":"agent install","text":"<ul> <li>Installing a cluster with Agent-based Installer - Installing an on-premise cluster with the Agent-based Installer | Installing | OpenShift Container Platform 4.14</li> <li>Troubleshooting installation issues | Installing | OpenShift Container Platform 4.15</li> <li>Troubleshooting installations - Troubleshooting | Support | OpenShift Container Platform 4.15</li> <li>How to recover install-config.yaml file from an installed OpenShift 4.x cluster - Red Hat Customer Portal</li> <li>Day-19-Kubernetes_\u9664\u932f\u601d\u8def\u5206\u4eab - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>[Kubernetes] Taints and Tolerations | \u5c0f\u4fe1\u8c6c\u7684\u539f\u59cb\u90e8\u843d</li> </ul>"},{"location":"hackmd/OpenShift/#some-cluster-operators-are-not-available","title":"some cluster operators are not available","text":"<p>ClusterVersion: Installing \"4.14.15\" for About an hour: Unable to apply 4.14.15: some cluster operators are not available</p> <p>DEBUG Still waiting for the cluster to initialize: Cluster operators authentication, console, ingress, machine-api, monitoring are not available - OCP 4.x Installation incomplete: cluster failed to initialize due to some cluster operators are still updating - Red Hat Customer Portal - openshift-install not creating the worker vm using IPI \u00b7 Issue #386 \u00b7 okd-project/okd \u00b7 GitHub - Crio and kubelet services are stuck in \"dead\" status and are unable to start in OCP 4 - Red Hat Customer Portal - Master kubelet gets Unauthorized and stuck when bootstrapping masters with 10 min gaps in OpenShift 4 - Red Hat Customer Portal</p> <pre><code>oc get nodes -o wide\noc get clusteroperators\noc get pod --all-namespaces -o wide\noc get po -n openshift-ingress\noc describe pod -n openshift-ingress router-default-66f58c7559-f2gqf\n</code></pre> <p>on Rendezvous node <pre><code>journalctl -u assisted-service.service\njournalctl -b -f -u release-image.service -u bootkube.service\n</code></pre></p> <pre><code>oc get pods -n openshift-ingress  router-default-66f58c7559\noc describe pod/router-default-66f58c7559-fmx72 -n openshift-ingress\noc get mcp\n</code></pre> <p>on faile node <pre><code>systemctl list-jobs\npodman login registry.redhat.io --authfile /var/lib/kubelet/config.json\ndig registry.redhat.io\nnslookup registry.redhat.io\n</code></pre></p> <p>log in the target core os node <pre><code>ssh core@&lt;target core os ip or FQDN&gt;\n</code></pre></p>"},{"location":"hackmd/OpenShift/#dns-issue","title":"DNS issue","text":"<p>172.20.0.1 is internal dns and if it can reach internet, it't ok</p> <p>otherwise, add the external dns into agent-config.yaml</p> <pre><code>dns-resolver:\n        config:\n          search:\n          - supershift.com\n          server:\n          - 172.20.0.1\n          - 8.8.8.8\n</code></pre>"},{"location":"hackmd/OpenShift/#vmware-virtual-machine","title":"vmware virtual machine","text":"<ul> <li>\u865b\u64ec\u6a5f\u5668\u9078\u9805 =&gt; \u958b\u6a5f\u9078\u9805 =&gt; \u555f\u7528 UEFI \u5b89\u5168\u958b\u6a5f</li> <li>\u865b\u64ec\u6a5f\u5668\u9078\u9805 =&gt; \u9032\u968e =&gt; \u7d44\u614b\u53c3\u6578<ul> <li>disk.EnableUUID: TRUE</li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#mirror-registry","title":"mirror registry","text":"<p>check the <code>/etc/containers/registries.conf</code></p>"},{"location":"hackmd/OpenShift/#deployment-failure","title":"deployment failure","text":"<pre><code>journalctl -u kubelet -n 100\njournalctl -u crio -n 100\n</code></pre>"},{"location":"hackmd/OpenShift/#integration","title":"Integration","text":""},{"location":"hackmd/OpenShift/#identity-provider","title":"Identity provider","text":"<ul> <li>Openshift Oauth use OpenID (Keycloak) as identity provider, oc login failed but can login successful with web console - Red Hat Customer Portal</li> <li>How to Integrate OpenShift with Keycloak - The New Stack</li> <li>Keycloak (as an Identity Provider) to secure Openshift | by Abhishek koserwal | Keycloak | Medium</li> <li>Keycloak - OpenShift Examples</li> <li>install keyclock in openshift<ul> <li>OpenShift - Keycloak</li> <li>OpenShift, SSO with KeyCloak &amp; Active Directory | DELL Technologies</li> </ul> </li> </ul>"},{"location":"hackmd/OpenShift/#ldap","title":"LDAP","text":"<ul> <li>389 Directory Server - Deploying 389 Directory Server on OpenShift</li> </ul>"},{"location":"hackmd/OpenShift/#subscription","title":"Subscription","text":"<ul> <li>Chapter\u00a03.\u00a0Cluster subscriptions and registration | Red Hat Product Documentation</li> <li>Red Hat OpenShift pricing</li> <li>Self-managed Red Hat OpenShift subscription guide</li> </ul>"},{"location":"hackmd/OpenShift/#hypershift","title":"HyperShift","text":"<ul> <li>GitHub - openshift/hypershift: Hyperscale OpenShift - clusters with hosted control planes</li> </ul>"},{"location":"hackmd/OpenShift/#support","title":"Support","text":"<p>OpenShift Lifecycle: https://access.redhat.com/support/policy/updates/openshift</p> <p>OpenShift AAA: https://docs.openshift.com/container-platform/4.17/authentication/index.html</p> <p>OpenShift Identity Providers: https://docs.openshift.com/container-platform/4.17/authentication/understanding-identity-provider.html</p> <p>Certificates: https://docs.openshift.com/container-platform/4.17/security/index.html</p> <p>Deploying ODF on Bare Metal: https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.17/html/deploying_openshift_data_foundation_using_bare_metal_infrastructure/index</p> <p>ODF Architecture (Internal/External approach): https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.17/html/planning_your_deployment/odf-architecture_rhodf#odf-architecture_rhodf</p> <p>Mirror Registry: https://docs.openshift.com/container-platform/4.17/disconnected/mirroring/installing-mirroring-creating-registry.html</p> <p>OpenShift Web Console customizations: https://docs.openshift.com/container-platform/4.17/web_console/customizing-the-web-console.html</p> <p>Add Worker Node to an OpenShift cluster: https://docs.openshift.com/container-platform/4.17/nodes/nodes/nodes-nodes-adding-node-iso.html</p>"},{"location":"hackmd/Openstack/","title":"Openstack","text":"<ul> <li>OpenStack \u4ecb\u7d39 1 - iT \u90a6\u5e6b\u5fd9</li> <li>OpenStack Basics - An overview for the Absolute Beginner - YouTube</li> <li>Public vs Private, Amazon compared to OpenStack</li> <li>guide<ul> <li>OpenStack Installation Guide \u2014 Installation Guide documentation<ul> <li>Logical architecture \u2014 Installation Guide documentation</li> <li>Overview \u2014 Installation Guide documentation</li> </ul> </li> <li>OpenStack Architecture Design Guide \u2014 arch-design 0.0.1.dev15 documentation</li> <li>Operations Guide \u2014 openstack-ansible 25.2.1.dev1 documentation</li> </ul> </li> <li>deploy by ansible<ul> <li>Quick Start \u2014 kolla-ansible 14.5.1.dev2 documentation</li> <li>Overview \u2014 openstack-ansible 25.1.2.dev3 documentation<ul> <li>Quickstart: AIO \u2014 openstack-ansible 25.2.1.dev1 documentation </li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Openstack/#basic","title":"basic","text":""},{"location":"hackmd/Openstack/#infra","title":"infra","text":""},{"location":"hackmd/Openstack/#deployment","title":"deployment","text":""},{"location":"hackmd/Openstack/#microstack","title":"MicroStack","text":"<ul> <li>OpenStack for the edge, micro clouds and developers</li> <li>OpenStack tutorials on Ubuntu | OpenStack | Ubuntu</li> <li>Navigate through the OpenStack dashboard menu | Ubuntu</li> <li> Interact with the SQL database service</li> <li>Tear down your OpenStack lab environment | Ubuntu</li> </ul> <p>deploy for poc or test</p> <pre><code>foo@ted-1-ubuntu:~$ sudo snap install microstack --beta\n[sudo] password for foo:\nmicrostack (beta) ussuri from Canonical\u2713 installed\nfoo@ted-1-ubuntu:~$ sudo microstack init --auto --control\n2022-12-01 00:15:01,868 - microstack_init - INFO - Configuring clustering ...\n2022-12-01 00:15:01,989 - microstack_init - INFO - Setting up as a control node.\n2022-12-01 00:15:04,856 - microstack_init - INFO - Generating TLS Certificate and Key\n2022-12-01 00:15:05,706 - microstack_init - INFO - Configuring networking ...\n2022-12-01 00:15:11,083 - microstack_init - INFO - Opening horizon dashboard up to *\n2022-12-01 00:15:12,015 - microstack_init - INFO - Waiting for RabbitMQ to start ...\nWaiting for 172.17.43.61:5672\n2022-12-01 00:15:18,322 - microstack_init - INFO - RabbitMQ started!\n2022-12-01 00:15:18,322 - microstack_init - INFO - Configuring RabbitMQ ...\n2022-12-01 00:15:19,211 - microstack_init - INFO - RabbitMQ Configured!\n2022-12-01 00:15:19,231 - microstack_init - INFO - Waiting for MySQL server to start ...\nWaiting for 172.17.43.61:3306\n2022-12-01 00:15:24,538 - microstack_init - INFO - Mysql server started! Creating databases ...\n2022-12-01 00:15:25,933 - microstack_init - INFO - Configuring Keystone Fernet Keys ...\n2022-12-01 00:15:36,216 - microstack_init - INFO - Bootstrapping Keystone ...\n2022-12-01 00:15:48,198 - microstack_init - INFO - Creating service project ...\n2022-12-01 00:15:54,069 - microstack_init - INFO - Keystone configured!\n2022-12-01 00:15:54,088 - microstack_init - INFO - Configuring the Placement service...\n2022-12-01 00:16:15,858 - microstack_init - INFO - Running Placement DB migrations...\n2022-12-01 00:16:19,203 - microstack_init - INFO - Configuring nova control plane services ...\n2022-12-01 00:16:31,690 - microstack_init - INFO - Running Nova API DB migrations (this may take a lot of time)...\n2022-12-01 00:16:54,551 - microstack_init - INFO - Running Nova DB migrations (this may take a lot of time)...\nWaiting for 172.17.43.61:8774\n2022-12-01 00:17:37,624 - microstack_init - INFO - Creating default flavors...\n2022-12-01 00:18:06,057 - microstack_init - INFO - Configuring nova compute hypervisor ...\n2022-12-01 00:18:06,057 - microstack_init - INFO - Checking virtualization extensions presence on the host\n2022-12-01 00:18:06,072 - microstack_init - WARNING - Unable to determine hardware virtualization support by CPU vendor id \"GenuineIntel\": assuming it is not supported.\n2022-12-01 00:18:06,073 - microstack_init - WARNING - Hardware virtualization is not supported - software emulation will be used for Nova instances\n2022-12-01 00:18:08,069 - microstack_init - INFO - Configuring the Spice HTML5 console service...\n2022-12-01 00:18:08,551 - microstack_init - INFO - Configuring Neutron\nWaiting for 172.17.43.61:9696\n2022-12-01 00:19:27,731 - microstack_init - INFO - Configuring Glance ...\nWaiting for 172.17.43.61:9292\n2022-12-01 00:20:04,534 - microstack_init - INFO - Adding cirros image ...\n2022-12-01 00:20:07,237 - microstack_init - INFO - Creating security group rules ...\n2022-12-01 00:20:17,787 - microstack_init - INFO - Configuring the Cinder services...\n2022-12-01 00:21:22,413 - microstack_init - INFO - Running Cinder DB migrations...\n2022-12-01 00:21:30,160 - microstack_init - INFO - restarting libvirt and virtlogd ...\n2022-12-01 00:21:53,115 - microstack_init - INFO - Complete. Marked microstack as initialized!\n</code></pre>"},{"location":"hackmd/Operation/","title":"Operation","text":"<ul> <li>GitHub - Vrashabh-Sontakke/Complete_DevOps_Roadmap_2022</li> <li>OpenTelemetry, the standardized observability framework for everyone</li> <li>\u63ed\u958b 17LIVE SRE \u795e\u79d8\u9762\u7d17. \u524d\u8a00 | by Sammy Lin | 17LIVE Tech Insight | Medium</li> <li>91APP Way: 91APP \u5728 AWS \u4e0a\u7684 SRE \u5be6\u8e10\u4e4b\u8def - YouTube</li> <li>\u5bc6\u78bc\u90fd\u653e Vault \u88e1\u4e86\uff0c\u7136\u5f8c\u5462\uff1f\uff01. \u7576\u7136\u8981\u4f86\u8ac7\u8ac7\u600e\u9ebc\u7ba1\u7406 Vault \uff3e\uff3e | by smalltown | Starbugs Weekly \u661f\u5df4\u54e5\u6280\u8853\u5c08\u6b04 | Medium</li> <li>\u81ea\u67b6\u670d\u52d9(Self-hosting)\u9700\u8981\u7684\u786c\u9ad4\u8207\u5e38\u7528\u5de5\u5177 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>Docker \u6548\u80fd\u76e3\u63a7\u8c6a\u83ef\u5957\u9910 - cAdvisor Prometheus \u4f50 Grafana-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>How To Monitor Server and Docker Resources:CPU,Memory...</li> <li>Grafana Zero to Hero :: 2024 iThome \u9435\u4eba\u8cfd</li> <li>\u5f8c Grafana \u6642\u4ee3\u7684\u81ea\u6211\u4fee\u990a :: 2024 iThome \u9435\u4eba\u8cfd</li> </ul>"},{"location":"hackmd/Operation/#sre","title":"SRE","text":"<ul> <li>\u4e00\u7abaSRE\u521d\u5fc3\u8005\u7684\u751f\u6d3b\uff1a\u8b93\u8b66\u5831\u70ba\u60a8\u7684\u4eba\u751f\u756b\u4e0b\u5982\u4ea4\u97ff\u6a02\u4e00\u822c\u7684\u65b0\u7bc7\u7ae0 :: 2023 iThome \u9435\u4eba\u8cfd<ul> <li>SRE\u5de5\u4f5c\u73fe\u5834\u76f4\u64ca!\uff1a\u7dad\u904b\u8d77\u9edex\u5be6\u6230\u7d93\u9a57x\u8077\u6daf\u898f\u5283\u9762\u9762\u89c0\uff08iThome\u9435\u4eba\u8cfd\u7cfb\u5217\u66f8\uff09</li> </ul> </li> <li>Site Reliability Engineering (SRE, \u7db2\u7ad9\u53ef\u9760\u6027\u5de5\u7a0b) | Complete Think<ul> <li>SRE \u5be6\u8e10\u8207\u958b\u767c\u5e73\u53f0\u6307\u5357</li> </ul> </li> </ul>"},{"location":"hackmd/Operation/#k8s","title":"k8s","text":"<ul> <li>Kubernetes - \u5169\u5927\u985e\u96a8\u624b\u8a18</li> <li>Kubernetes 101\uff1a\u91d0\u6e05 kubectl create \u8207 kubectl apply \u7684\u5dee\u7570 | The Will Will Web</li> </ul>"},{"location":"hackmd/Operation/#fluentd","title":"fluentd","text":"<p>curl -L https://toolbelt.treasuredata.com/sh/install-ubuntu-xenial-td-agent4.sh | sh</p> <p>/etc/td-agent/td-agent.conf /var/log/td-agent/td-agent.log</p> <p>sudo systemctl status td-agent.service sudo systemctl restart td-agent.service</p>"},{"location":"hackmd/Operation/#dashborad","title":"dashborad","text":"<ul> <li>Dashboard \u5229\u5668: Metabase - \u5c0f\u6d77\u56b4\u5beb<ul> <li>Metabase\u6559\u5b78 \u2013 IT \u7a7a\u9593</li> <li>[Metabase \u7cfb\u5217] Metabase \u7c21\u4ecb\u8207\u5b89\u88dd\u6559\u5b78\uff0cBI \u5de5\u5177\u63a8\u85a6 \u2013 IT \u7a7a\u9593</li> </ul> </li> <li>\u958b\u653e\u539f\u59cb\u78bc\u7684\u6578\u64da\u53ef\u8996\u5316\u5de5\u5177 Superset vs Redash vs Metabase (\u4e00) - \u884c\u92b7\u5ba2\u793e\u7fa4 - Inboundnow</li> </ul>"},{"location":"hackmd/Operation/#librenms","title":"LibreNMS","text":"<ul> <li>[\u6559\u5b78] \u7528 Docker \u4f86\u67b6\u8a2d LibreNMS \u67b6\u8a2d\u7db2\u8def\u670d\u52d9\u76e3\u63a7\u7cfb\u7d71 - \u6e05\u65b0\u4e0b\u5348\u8336</li> <li>\u958b\u6e90\u7db2\u8def\u88dd\u7f6e\u670d\u52d9\u76e3\u63a7\u7cfb\u7d71\uff1aLibreNMS (\u4e00) - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul>"},{"location":"hackmd/Operation/#cicd","title":"CI/CD","text":"<ul> <li>\u4e0d\u60f3\u5403\u571f\u55ce\uff1f\u5c31\u5229\u7528\u958b\u6e90\u8edf\u9ad4\u6253\u9020CICD Pipeline\u5427\uff01 :: 2022 iThome \u9435\u4eba\u8cfd</li> <li>\u770b\u597d\u4e86 GitHub Action\uff0c\u6211\u53ea\u793a\u7bc4\u4e00\u6b21\u3002 :: 2024 iThome \u9435\u4eba\u8cfd</li> </ul> <p>\u6301\u7e8c\u6574\u5408\u5de5\u5177\u6703\u5b9a\u7fa9\u4e86\u6574\u5408\u7684\u89f8\u767c\u6642\u6a5f\u3002\u4f8b\u5982\u7576\u67d0\u4e00\u500b\u5206\u652f\u6709\u5408\u4f75\u767c\u751f\u3001\u6216\u662f\u65b0\u589e\u4e86\u4e00\u500b\u65b0\u7684\u767c\u4f48\u6a19\u7c64\u6642\uff0c\u6301\u7e8c\u6574\u5408\u5de5\u5177\u5c31\u6703\u5f9e\u7248\u672c\u7ba1\u7406\u7cfb\u7d71\u53d6\u5f97\u76f8\u95dc\u7684\u7a0b\u5f0f\u78bc\u9032\u884c\u4e0b\u4e00\u500b\u52d5\u4f5c</p> <p>\u76f8\u95dc\u7684\u7a0b\u5f0f\u78bc\u6703\u9032\u884c\u4e00\u4e9b\u57fa\u672c\u7684\u6e2c\u8a66\u3002\u4f8b\u5982\u6aa2\u67e5\u767c\u7684\u7a0b\u5f0f\u662f\u5426\u5408\u4e4e\u76f8\u95dc\u958b\u767c\u8a9e\u8a00\u7684\u6a19\u6e96(Coding Standard)\uff0c\u53c8\u6216\u8005\u662f\u7a0b\u5f0f\u4e2d\u662f\u5426\u6709\u6f0f\u6d1e(Vulnerabilities)\u3002\u5982\u679c\u6aa2\u67e5\u6642\u767c\u73fe\u7a0b\u5f0f\u672a\u80fd\u5408\u7b26\u767c\u4f48\u7684\u8981\u6c42\u6642\uff0c\u6574\u5408\u5de5\u5177\u53ef\u4ee5\u4e2d\u6b62\u76f8\u95dc\u7684\u767c\u4f48\u52d5\u4f5c</p> <p>\u6210\u529f\u901a\u904e\u4e86\u81ea\u52d5\u5316\u7684\u6e2c\u8a66\u5f8c\uff0c\u76f8\u95dc\u7684\u7a0b\u5f0f\u6703\u88ab\u6253\u5305\u6210\u70ba\u53ef\u4ee5\u88ab\u5f15\u7528\u7684\u5957\u4ef6\uff0c\u6216\u8005\u662f\u53ef\u904b\u884c\u7684Docker Image\u7b49\uff0c\u4e26\u4e0a\u8f09\u5230\u5132\u5b58\u5009\u5eab\u4e2d\uff0c\u4ee5\u4fbf\u65e5\u5f8c\u5229\u7528</p> <p>\u7248\u672c\u7ba1\u7406\u5de5\u5177\u4f8b\u5982GitLab\u7b49\uff0c\u4ea6\u662f\u5e02\u9762\u4e0a\u6bd4\u8f03\u591a\u4eba\u4f7f\u7528\u7684\u6574\u5408\u5de5\u5177\u4e4b\u4e00\u3002\u5b83\u7684\u597d\u8655\u662f\u628a\u6574\u5408\u5de5\u5177\u8ddf\u7248\u672c\u7ba1\u7406\u653e\u5230\u540c\u4e00\u5957\u5de5\u5177\u4e2d\uff0c\u5728\u7ba1\u7406\u4e0a\u6703\u66f4\u52a0\u65b9\u4fbf\u3002\u800c\u7f3a\u9ede\u4ea6\u56e0\u70ba\u6574\u5408\u4e86\u7248\u672c\u7ba1\u7406\u7cfb\u7d71\u7684\u95dc\u4fc2\uff0c\u5982\u679c\u6709\u9700\u8981\u4f7f\u7528\u591a\u5957\u7248\u672c\u7ba1\u7406\u7cfb\u7d71\u6642\uff0c\u53ef\u80fd\u5728\u6574\u5408\u4e0a\u6703\u589e\u52a0\u4e86\u64cd\u4f5c\u53ca\u6574\u5408\u4e0a\u7684\u7e41\u8907\u6027</p>"},{"location":"hackmd/Operation/#jenkins","title":"Jenkins","text":"<ul> <li>\u4f7f\u7528 docker \u5efa\u7acb jenkins \u57f7\u884c\u74b0\u5883\u8207\u8a2d\u5b9a agent - HackMD</li> <li>You must define the following mandatory properties for 'Unknown': sonar.projectKey - SonarQube Server / Community Build - Sonar Community</li> </ul> <p>docker-compose.yml</p> <p>``` yml= services:   jenkins:     image: jenkins/jenkins     container_name: jenkins     restart: always     ports:       - \"8080:8080\"       - \"50000:50000\"     volumes:       - jenkins_data:/var/jenkins_home       - /var/run/docker.sock:/var/run/docker.sock</p> <p>volumes:   jenkins_data: <pre><code>``` bash=\ndocker compose exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword\n</code></pre></p>"},{"location":"hackmd/Operation/#plugins","title":"plugins","text":"<ul> <li>Pipeline: Stage View | Jenkins plugin</li> <li>SonarQube Scanner | Jenkins plugin</li> </ul>"},{"location":"hackmd/Operation/#sonarqube","title":"SonarQube","text":"<ul> <li>docker-sonarqube/example-compose-files/sq-with-postgres/docker-compose.yml at master \u00b7 SonarSource/docker-sonarqube \u00b7 GitHub<ul> <li>\u5982\u4f55\u5728 Ubuntu 20.04 \u4f7f\u7528 Docker Image \u5b89\u88dd SonarQube | by Ivan Cheng | Medium<ul> <li>\u6ce8\u610felastic search\u9650\u5236</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Operation/#dependency-track","title":"Dependency Track","text":"<ul> <li>Deploying Docker Container | Dependency-Track<ul> <li>dependencytrack.org/docker-compose.yml</li> </ul> </li> </ul>"},{"location":"hackmd/RedHat/","title":"RedHat","text":"<ul> <li>Red Hat Universal Base Images for Docker users | Red Hat Developer</li> <li>Chapter\u00a03.\u00a0Downloading a RHEL installation ISO image Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> <li>Product Life Cycles | Red Hat Customer Portal<ul> <li>Understanding the various RHEL .iso files - Red Hat Customer Portal</li> </ul> </li> <li>Red Hat Enterprise Linux Getting Started | Red Hat Developer</li> <li>Modular Perl in Red Hat Enterprise Linux 8 | Red Hat Developer</li> <li>desktop gui<ul> <li>How to Install GUI on RHEL 8? - Red Hat Customer Portal</li> <li>RHEL 8 not booting into GUI mode - Red Hat Customer Portal</li> </ul> </li> <li>os start<ul> <li>Failed to start Switch Root in RHEL 8 - Red Hat Customer Portal</li> <li>System fails to boot printing \"systemd[1]: Freezing execution\" after applying security patches on RHEL 8.2 or upgrading to RHEL 8.3 - Red Hat Customer Portal</li> <li>RHEL 8.2 Boot Failing - Red Hat Customer Portal<ul> <li>Using rescue mode<ul> <li>Appendix\u00a0G.\u00a0Troubleshooting Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> <li>How to boot a system into rescue mode - Red Hat Customer Portal</li> </ul> </li> </ul> </li> </ul> </li> <li>partition<ul> <li>Appendix\u00a0E.\u00a0Partitioning reference Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> <li>Can /boot/efi be formatted using a filesystem type other than VFAT? - Red Hat Customer Portal</li> </ul> </li> <li>htop<ul> <li>How To enable the EPEL Repository on RHEL 8 / CentOS 8 Linux - Linux Tutorials - Learn Linux Configuration</li> <li>sudo yum install htop</li> </ul> </li> <li>20150325_network_performance_tuning.pdf</li> <li>subscriptions<ul> <li>Free Red Hat Enterprise Linux subscription | Red Hat Developer</li> <li>Simple Content Access - Red Hat Customer Portal</li> <li>How to register and subscribe a RHEL system to the Red Hat Customer Portal using Red Hat Subscription-Manager? - Red Hat Customer Portal</li> <li>Red Hat \u66f4\u65b0\u51fa\u73fe This system is registered to Red Hat Subscription Management, but is not receiving updates. You can use subscription-manager to assign subscriptions. \u89e3\u6c7a\u65b9\u6cd5 - Clarence</li> <li>SUBSCRIPTION-MANAGER COMMAND CHEAT SHEET</li> <li>How to register and subscribe a system offline to the Red Hat Customer Portal? - Red Hat Customer Portal</li> <li>renew<ul> <li>Red Hat Developer Subscription : Renewal - Best Practice - Red Hat Customer Portal<ul> <li>Subscription page</li> </ul> </li> <li>How to renew your Red Hat Developer Subscription for Individuals | Red Hat Developer</li> <li>No-cost Red Hat Enterprise Linux Individual Developer Subscription: FAQs | Red Hat Developer<ul> <li>login into https://developers.redhat.com/ if renew is not allowed</li> </ul> </li> </ul> </li> </ul> </li> <li>auto upgrade kernel<ul> <li>Red Hat Enterprise Linux Release Dates - Red Hat Customer Portal</li> <li>How to update Red Hat Enterprise Linux via minor releases and Extended Update Support</li> <li>How do I exclude kernel or other packages from getting updated in Red Hat Enterprise Linux while updating system via yum? - Red Hat Customer Portal<ul> <li>1891603 \u2013 dnf system upgrade error: kernel-srpm-macros-1.0-3.fc33 not allowing redhat-rpm-config install</li> </ul> </li> <li>Prevent Kernel Upgrades - Red Hat Customer Portal<ul> <li>Restricting a Package to a Fixed Version Number with yum - Red Hat Customer Portal</li> <li>How to tie a system to a specific update of Red Hat Enterprise Linux? - Red Hat Customer Portal</li> </ul> </li> </ul> </li> <li>downgrade kernel<ul> <li>How to use yum/dnf to downgrade or rollback some package updates? - Red Hat Customer Portal</li> <li>Chapter\u00a07.\u00a0Managing software packages Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> </ul> </li> <li>GRUB<ul> <li>Chapter\u00a07.\u00a0Making persistent changes to the GRUB boot loader Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> </ul> </li> <li>Rescue mode<ul> <li>How to boot a system into rescue mode - Red Hat Customer Portal</li> <li>How to Boot into Rescue Mode or Emergency Mode Through Systemd in CentOS/RHEL 7 and 8 \u2013 The Geek Diary</li> </ul> </li> <li>NFS<ul> <li>nfsd: too many open connections, consider increasing the number of threads - Red Hat Customer Portal</li> <li>How to increase the number of threads created by the NFS daemon in RHEL 4, 5, 6, 7 and 8? - Red Hat Customer Portal</li> <li>When nfs server is stopped how long does the client retry ? - Red Hat Customer Portal</li> <li>firewall<ul> <li>Configuring the NFS server to run behind a firewall</li> </ul> </li> </ul> </li> <li>High Availablity<ul> <li>Chapter\u00a02.\u00a0Getting started with Pacemaker Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>\u5728 Azure \u4e2d\u7684 RHEL \u4e0a\u8a2d\u5b9a Pacemaker | Microsoft Learn</li> </ul> </li> <li>hostname<ul> <li>How to configure a hostname on a Linux system | Enable Sysadmin</li> </ul> </li> <li>perl<ul> <li>Modular Perl in Red Hat Enterprise Linux 8 | Red Hat Developer</li> </ul> </li> <li>password<ul> <li>bcrypt support for passwords in /etc/shadow - Red Hat Customer Portal</li> </ul> </li> <li>log<ul> <li>How to enable persistent logging for the systemd journal - Red Hat Customer Portal</li> <li>How to configure your system to preserve system logs after a reboot | Enable Sysadmin</li> </ul> </li> </ul>"},{"location":"hackmd/RedHat/#training","title":"Training","text":"<ul> <li>Red Hat System Administration 1 (RH124) v9</li> <li>Red Hat System Administration 2-1 (RH124) v9</li> <li>Red Hat System Administration 2-2 (RH124) v9</li> </ul>"},{"location":"hackmd/RedHat/#red-hat-api-tokens","title":"Red Hat API Tokens","text":"<p>https://access.redhat.com/management/api eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJhZDUyMjdhMy1iY2ZkLTRjZjAtYTdiNi0zOTk4MzVhMDg1NjYifQ.eyJpYXQiOjE2ODExODQxNjcsImp0aSI6IjliODk0MGE4LWY5MTItNGEwOC1hYzJjLTZkNGQyN2YzNWJiMSIsImlzcyI6Imh0dHBzOi8vc3NvLnJlZGhhdC5jb20vYXV0aC9yZWFsbXMvcmVkaGF0LWV4dGVybmFsIiwiYXVkIjoiaHR0cHM6Ly9zc28ucmVkaGF0LmNvbS9hdXRoL3JlYWxtcy9yZWRoYXQtZXh0ZXJuYWwiLCJzdWIiOiJmOjUyOGQ3NmZmLWY3MDgtNDNlZC04Y2Q1LWZlMTZmNGZlMGNlNjp0ZWRjaGFuZ2NoaWVuQHN1cGVybWljcm8uY29tLnR3IiwidHlwIjoiT2ZmbGluZSIsImF6cCI6InJoc20tYXBpIiwic2Vzc2lvbl9zdGF0ZSI6ImI3MGNhMjMxLThhZjctNDg2Yi1hNzczLWI4MTYwYzIwZThiMyIsInNjb3BlIjoib2ZmbGluZV9hY2Nlc3MiLCJzaWQiOiJiNzBjYTIzMS04YWY3LTQ4NmItYTc3My1iODE2MGMyMGU4YjMifQ.t55UUlk1dIzEZ8I6fFqBuLJxpQH3iNwv1oPpH6k8BHA</p>"},{"location":"hackmd/RedHat/#downloading-an-iso-image-using-curl","title":"Downloading an ISO image using curl","text":"<ul> <li>https://web.archive.org/web/20240422004454/https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/performing_a_standard_rhel_8_installation/downloading-beta-installation-images_installing-rhel#downloading-an-iso-image-with-curl_downloading-beta-installation-images<ul> <li>You have an offline token generated from Red Hat API Tokens.</li> <li>You have a checksum of the file you want to download from Product Downloads.  ``` bash=</li> </ul> </li> </ul>"},{"location":"hackmd/RedHat/#binbash","title":"!/bin/bash","text":""},{"location":"hackmd/RedHat/#set-the-offline-token-and-checksum-parameters","title":"set the offline token and checksum parameters","text":"<p>offline_token=\"\" checksum="},{"location":"hackmd/RedHat/#get-an-access-token","title":"get an access token","text":"<p>access_token=$(curl https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token -d grant_type=refresh_token -d client_id=rhsm-api -d refresh_token=$offline_token | jq -r '.access_token')</p>"},{"location":"hackmd/RedHat/#get-the-filename-and-download-url","title":"get the filename and download url","text":"<p>image=$(curl -H \"Authorization: Bearer $access_token\" \"https://api.access.redhat.com/management/v1/images/$checksum/download\") filename=$(echo $image | jq -r .body.filename) url=$(echo $image | jq -r .body.href)</p>"},{"location":"hackmd/RedHat/#download-the-file","title":"download the file","text":"<p>curl $url -o $filename <pre><code>## Red Hat Subscription Management\n- [How to register and subscribe a system offline to the Red Hat Customer Portal? - Red Hat Customer Portal](https://access.redhat.com/solutions/3121571)\n- [Why subscription-manager is showing Overall Status: Disabled? - Red Hat Customer Portal](https://access.redhat.com/solutions/7080864)\n- [Simple Content Access - Red Hat Customer Portal](https://access.redhat.com/articles/simple-content-access)\n    - [How to register and subscribe a system offline to the Red Hat Customer Portal? - Red Hat Customer Portal](https://access.redhat.com/solutions/7065718)\n\nRegister a system by using the credentials of the Red Hat Customer Portal as the root user\n</code></pre> [root@host ~]# subscription-manager register --username  Registering to: subscription.rhsm.redhat.com:443/subscription Password: yourpassword The system has been registered with ID: 1457f7e9-f37e-4e93-960a-c94fe08e1b4f The registered system name is: host.example.com <pre><code>\n</code></pre> [root@host ~]# subscription-manager register --username foo@bar.com --password foobar --auto-attach <pre><code>View available subscriptions for your Red Hat account\n</code></pre> [root@host ~]# subscription-manager list --available <pre><code>Auto-attach a subscription\n</code></pre> [root@host ~]# subscription-manager attach --auto <pre><code>Alternatively, attach a subscription from a specific pool from the list of available subscriptions\n</code></pre> [root@host ~]# subscription-manager attach --pool=poolID <pre><code>View consumed subscriptions\n</code></pre> [root@host ~]# subscription-manager list --consumed <pre><code>did this system get properly registered?\n</code></pre> subscription-manager identity <pre><code>Unregister a system\n</code></pre> [root@host ~]# subscription-manager unregister <pre><code>## RPM Software Packages\nRPM package file names consist of four elements (plus the .rpm suffix): name-version-release.architecture\n\nARCH is the processor architecture that the package is compiled to run on. The x86_64 value indicates that this package is built for the 64-bit version of the x86 instruction set (as opposed to aarch64 for 64-bit ARM, and so on).\n\nRPM packages are often downloaded from repositories. \n- A repository is a central location for storing and maintaining RPM software packages.\n\nEach RPM package is an archive with the following components\n- The files that the package installs in your system.\n- Information about the package (metadata), such as the name, version, release, and architecture; a summary and description of the package; whether it requires other packages to be installed; licensing; a package change log; and other details.\n- Scripts that might run when you install, update, or remove the package. These scripts might also run when you install, update, or remove other packages.\n\nTypically, software providers digitally sign RPM packages with GPG (GNU Privacy Guard) keys. (Red Hat digitally signs all packages that it releases.) \n- The RPM system verifies package integrity by confirming that the package is signed with the appropriate GPG key. \n- The RPM system fails to install a package if the GPG signature does not match.\n\nTypically, only one version of a package is installed at a time. \nIf a package is built with non-conflicting file names, then you might install multiple versions. \n- The kernel package is a an example of installing multiple package versions.\n\n``` bash=\n# List all installed packages\nrpm -qa\n# Determine which package provides FILENAME\nrpm -qf /etc/yum.repos.d\n# List the currently installed package version\nrpm -q dnf\n# Get detailed package information\nrpm -qi wget\n#  List the files that the package installs\nrpm -ql wget\n# List only the configuration files that the package installs\nrpm -qc wget\n# List only the documentation files that the package installs.\nrpm -qd openssh-clients\n# List the shell scripts that run before or after you install or remove the package.\nrpm -q --scripts openssh-server\n# List the change log information for the package\nrpm -q --changelog openssh-server\n\n# install an RPM package that you downloaded to your local directory\nrpm -ivh podman-4.0.0-6.el9.x86_64.rpm\n\n# Use the rpm2cpio command to extract files from an RPM package file without installing the package.\n# The rpm2cpio command converts an RPM package to a cpio archive. After the RPM package is converted to a cpio archive, the cpio command can extract a list of files.\n[user@host tmp-extract]$ rpm2cpio httpd-2.4.51-7.el9_0.x86_64.rpm | cpio -idv\n\n# Extract individual files by specifying the path of the file\nrpm2cpio httpd-2.4.51-7.el9_0.x86_64.rpm | cpio -id \"*/etc/httpd/conf/httpd.conf\"\n\n# list the files in an RPM package\nrpm2cpio httpd-2.4.51-7.el9_0.x86_64.rpm | cpio -tv\n</code></pre>"},{"location":"hackmd/RedHat/#manage-software-packages-with-dnf","title":"Manage Software Packages with DNF","text":"<p>The low-level rpm command can be used to install packages, but it is not designed to work with package repositories or to resolve dependencies from multiple sources automatically.</p> <p>DNF improves RPM-based software installation and updates. With the dnf command, you can install, update, remove, and get information about software packages and their dependencies. </p> <p>``` bash=</p>"},{"location":"hackmd/RedHat/#displays-installed-packages-from-which-repo-name","title":"displays installed packages from which repo name","text":"<p>dnf list installed | grep fping  dnf list installed | grep perl-Net-SNMP</p>"},{"location":"hackmd/RedHat/#displays-installed-and-available-packages","title":"displays installed and available packages","text":"<p>dnf list 'http*'</p>"},{"location":"hackmd/RedHat/#lists-packages-by-keywords-that-are-in-the-name-and-summary-fields-only","title":"lists packages by keywords that are in the name and summary fields only","text":"<p>dnf search 'web server'</p>"},{"location":"hackmd/RedHat/#lists-packages-by-keywords-that-are-in-the-name-summary-and-description-fields","title":"lists packages by keywords that are in the name, summary, and description fields","text":"<p>dnf search all 'web server'</p>"},{"location":"hackmd/RedHat/#detailed-information-about-a-package","title":"detailed information about a package","text":"<p>dnf info httpd</p>"},{"location":"hackmd/RedHat/#displays-packages-that-match-the-specified-path-name","title":"displays packages that match the specified path name","text":"<p>dnf provides /var/www/html</p>"},{"location":"hackmd/RedHat/#obtains-and-installs-a-software-package-including-any-dependencies","title":"obtains and installs a software package, including any dependencies","text":"<p>dnf install httpd</p>"},{"location":"hackmd/RedHat/#obtains-and-installs-a-later-version-of-the-specified-package-including-any-dependencies","title":"obtains and installs a later version of the specified package, including any dependencies.","text":""},{"location":"hackmd/RedHat/#generally-the-process-tries-to-preserve-configuration-files-in-place-but-in-some-cases-those-files-might-be-renamed-if-the-packager-considers-that-the-earlier-name-will-not-work-after-the-update","title":"Generally, the process tries to preserve configuration files in place, but in some cases, those files might be renamed if the packager considers that the earlier name will not work after the update.","text":"<pre><code>:::danger\nThe dnf remove command removes the listed packages and any package that requires the packages to be removed (and packages which require those packages, and so on). This command can lead to unexpected removal of packages\n:::\n\nBecause a new kernel can be tested only by booting to that kernel, the package specifically supports the installation of multiple versions at once. If the new kernel fails to boot, then the earlier kernel is still available. \n\n``` bash=\n# list all installed and available kernels\ndnf list kernel\n\n# view the currently running kernel\nuname -r\nuname -a\n\n# installs the new kernel\ndnf update kernel\n</code></pre>"},{"location":"hackmd/RedHat/#groups-of-software-with-dnf","title":"Groups of Software with DNF","text":"<p>concept of groups, which are collections of related software that are installed together</p> <p>two kinds of package groups.  - Regular groups are collections of packages. - Environment groups are collections of regular groups. </p> <p>``` bash=</p>"},{"location":"hackmd/RedHat/#shows-the-names-of-installed-and-available-groups","title":"shows the names of installed and available groups","text":"<p>dnf group list</p>"},{"location":"hackmd/RedHat/#some-groups-are-normally-installed-through-environment-groups-and-are-hidden-by-default","title":"Some groups are normally installed through environment groups and are hidden by default.","text":""},{"location":"hackmd/RedHat/#list-these-hidden-groups","title":"List these hidden groups","text":"<p>dnf group list hidden</p>"},{"location":"hackmd/RedHat/#displays-information-about-a-group-it-includes-a-list-of-mandatory-default-and-optional-package-names","title":"displays information about a group. It includes a list of mandatory, default, and optional package names.","text":"<p>dnf group info \"RPM Development Tools\"</p>"},{"location":"hackmd/RedHat/#installs-a-group-that-installs-its-mandatory-and-default-packages-and-their-dependent-packages","title":"installs a group that installs its mandatory and default packages and their dependent packages.","text":"<p>dnf group install \"RPM Development Tools\" <pre><code>All installation and removal transactions are logged in the /var/log/dnf.rpm.log file.\n\nThe `dnf history` command displays a summary of installation and removal transactions.\n\nThe `dnf history undo` command reverses a transaction.\n\n#### BaseOS and Application Stream\nFor developers who wanted the latest version of an application and administrators who wanted the most stable version of the application, the resulting situation was tedious to manage.\n\nWith modularity, a single repository can host multiple versions of an application's package and its dependencies.\n\nRed Hat Enterprise Linux 9 distributes the content through two main software repositories: BaseOS and Application Stream (AppStream).\n- The BaseOS repository provides the core operating system content for Red Hat Enterprise Linux as RPM packages. \n- The Application Stream repository provides content with varying lifecycles as both modules and traditional packages.\n    - The Application Stream repository contains two types of content: modules and traditional RPM packages. \n        - A module describes a set of RPM packages that belong together. \n        - Modules can contain several streams to make multiple versions of applications available for installation. \n\nRed Hat Enterprise Linux 9 supports modular features of Application Stream. \n\nEach module has one or more module streams, which hold different versions of the content\nEach module can have one or more profiles. \n- A profile is a list of packages that you can install together for a particular use case, such as for a server, client, development, minimal installation, or other.\n\n### DNF Software Repositories\nSystems often have access to many Red Hat repositories.\n\n``` bash=\n# lists all available repositories and their statuses\ndnf repolist all\n\n# enable and disable repositories\ndnf config-manager --enable rhel-9-server-debug-rpms\n</code></pre></p> <p>Non-Red Hat sources provide software through third-party repositories.  For example, Adobe provides some of its software for Linux through DNF repositories.</p> <p>The dnf command can access repositories from a website, an FTP server, or the local file system.</p> <p>You can add a third-party repository in one of two ways.  - create a .repo file in the /etc/yum.repos.d/ directory - add a [repository] section to the /etc/dnf/dnf.conf file</p> <p>Red Hat recommends using .repo files, and reserving the dnf.conf file for additional repository configurations. </p> <p>``` bash=</p>"},{"location":"hackmd/RedHat/#add-repositories-to-the-machine","title":"add repositories to the machine","text":"<p>[user@host ~]$ dnf config-manager \\ --add-repo=\"https://dl.fedoraproject.org/pub/epel/9/Everything/x86_64/\"</p>"},{"location":"hackmd/RedHat/#imports-the-rpm-gpg-key-epel-9-epel-gpg-public-key-and-installs-the-rhel9-extra-packages-for-enterprise-linux-epel-repository-rpm","title":"imports the RPM-GPG-KEY-EPEL-9 (EPEL) GPG public key and installs the RHEL9 Extra Packages for Enterprise Linux (EPEL) repository RPM","text":"<p>[user@host ~]$ rpm --import \\ https://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-9 [user@host ~]$ dnf install \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm  dnf config-manager --add-repo=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo <pre><code>## GUI\n\n``` bash=\ndnf groupinstall \"Server with GUI\"\ndnf group list hidden\nsystemctl set-default graphical.target\nsystemctl isolate graphical.target\n</code></pre></p> <p><code>`` bash= systemctl status gdm.service systemctl restart gdm.service <pre><code>## Kickstart\n- [Appendix\u00a0B.\u00a0Kickstart commands and options reference | Red Hat Product Documentation](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8/html/automatically_installing_rhel/kickstart-commands-and-options-reference_rhel-installer)\n- [23.3. Kickstart \u8a9e\u6cd5\u53c3\u7167 Red Hat Enterprise Linux 7 | Red Hat Customer Portal](https://access.redhat.com/documentation/zh-tw/red_hat_enterprise_linux/7/html/installation_guide/sect-kickstart-syntax#doc-wrapper)\n- [23.4. Kickstart \u914d\u7f6e\u7684\u7bc4\u4f8b Red Hat Enterprise Linux 7 | Red Hat Customer Portal](https://access.redhat.com/documentation/zh-tw/red_hat_enterprise_linux/7/html/installation_guide/sect-kickstart-examples)\n- [Performing an advanced RHEL 8 installation Red Hat Enterprise Linux 8 | Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/performing_an_advanced_rhel_8_installation/index#creating-kickstart-files_installing-rhel-as-an-experienced-user)\n- [Chapter\u00a04.\u00a0Creating Kickstart files Red Hat Enterprise Linux 8 | Red Hat Customer Portal](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/performing_an_advanced_rhel_8_installation/creating-kickstart-files_installing-rhel-as-an-experienced-user#creating-a-kickstart-file-with-the-kickstart-configuration-tool_creating-kickstart-files)\n    - /root/anaconda-ks.cfg\n- tool\n    - [Kickstart Generator | Red Hat Customer Portal Labs](https://access.redhat.com/labs/kickstartconfig/)\n- partition\n    - [centos - How do I calculate Linux physical volume and volume group metadata overhead? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/410288/how-do-i-calculate-linux-physical-volume-and-volume-group-metadata-overhead)\n    - [linux - How is the size of an LVM volume calculated? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/393898/how-is-the-size-of-an-lvm-volume-calculated)\n    - [linux - Use a dynamic value in a kickstart file - Server Fault](https://serverfault.com/questions/843773/use-a-dynamic-value-in-a-kickstart-file)\n    - [how size of partition is defined for kickstart installation - Red Hat Customer Portal](https://access.redhat.com/discussions/737553)\n    - [linux - CentOS/RHEL 7 LVM Partitioning in Kickstart? - Server Fault](https://serverfault.com/questions/826006/centos-rhel-7-lvm-partitioning-in-kickstart)\n- [How do I set the root password in a kickstart file? - Red Hat Customer Portal](https://access.redhat.com/solutions/44662)\n    - [How to generate a SHA-2 (sha256 or sha512) hashed password compatible with /etc/shadow - Red Hat Customer Portal](https://access.redhat.com/solutions/221403)\n        - openssl passwd -6 \"your passphrase\"\n\n\n### RAID + LVM\n- [Configuring an LVM logical volume by Install GUI](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/performing_a_standard_rhel_8_installation/graphical-installation_graphical-installation#configuring-lvm-logical-volume_manual-partitioning)\n\n\n#### sample 1\n</code></pre> bootloader --append=\"crashkernel=auto\" --location=mbr --boot-drive=sda part raid.2025 --fstype=\"mdmember\" --ondisk=sdb --size=3813822 part /boot --fstype=\"xfs\" --size=1024 part /boot/efi --fstype=\"efi\" --size=600 --fsoptions=\"umask=0077,shortname=winnt\" part raid.2018 --fstype=\"mdmember\" --ondisk=sda --size=3813822 raid pv.2032 --device=pv00 --fstype=\"lvmpv\" --level=RAID0 --chunksize=512 raid.2018 raid.2025 volgroup rhel --pesize=4096 pv.2032 logvol / --fstype=\"xfs\" --grow --size=1024 --name=root --vgname=rhel logvol /home --fstype=\"xfs\" --size=7551608 --name=home --vgname=rhel logvol swap --fstype=\"swap\" --size=4096 --name=swap --vgname=rhel <pre><code>\n</code></pre> [anaconda root@s8is001 ~]# lsblk NAME            MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT loop0             7:0    0 674.5M  1 loop loop1             7:1    0     3G  1 loop |-live-rw       253:0    0     3G  0 dm    /</code>-live-base     253:1    0     3G  1 dm loop2             7:2    0    32G  0 loop <code>-live-rw       253:0    0     3G  0 dm    / sda               8:0    1   3.7T  0 disk |-sda1            8:1    1   600M  0 part  /mnt/sysroot/boot/efi |-sda2            8:2    1     1G  0 part  /mnt/sysroot/boot</code>-sda3            8:3    1   3.7T  0 part   <code>-md127         9:127  0   7.3T  0 raid0     |-rhel-swap 253:2    0     4G  0 lvm   [SWAP]     |-rhel-home 253:3    0   7.2T  0 lvm   /mnt/sysroot/home</code>-rhel-root 253:4    0    70G  0 lvm   /mnt/sysroot sdb               8:16   1   3.7T  0 disk <code>-sdb1            8:17   1   3.7T  0 part</code>-md127         9:127  0   7.3T  0 raid0     |-rhel-swap 253:2    0     4G  0 lvm   [SWAP]     |-rhel-home 253:3    0   7.2T  0 lvm   /mnt/sysroot/home     `-rhel-root 253:4    0    70G  0 lvm   /mnt/sysroot sdc               8:32   1   3.7T  0 disk nvme0n1         259:0    0 894.3G  0 disk <pre><code>#### sample 2\n</code></pre> ignoredisk --only-use=nvme0n1,nvme1n1</p>"},{"location":"hackmd/RedHat/#partition-clearing-information","title":"Partition clearing information","text":"<p>clearpart --none --initlabel</p>"},{"location":"hackmd/RedHat/#disk-partitioning-information","title":"Disk partitioning information","text":"<p>part raid.1186 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=1026 part raid.3290 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=12816 part raid.2703 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=10256 part raid.1658 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=12816 part raid.389 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=5128 part raid.4558 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=1625420 part raid.1179 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=1026 part raid.3283 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=12816 part raid.4551 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=1625420 part /boot/efi --fstype=\"efi\" --size=2048 --fsoptions=\"umask=0077,shortname=winnt\" part raid.2159 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=131200 part raid.1651 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=12816 part raid.3899 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=12816 part raid.3906 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=12816 part /boot --fstype=\"xfs\" --size=2048 part raid.2166 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=131200 part raid.396 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=5128 part raid.2710 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=10256 raid swap --device=swap --fstype=\"swap\" --level=RAID0 --chunksize=512 raid.2159 raid.2166 raid /home --device=home --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.1179 raid.1186 raid /var/log/audit --device=var_log_audit --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.3899 raid.3906 raid /usr --device=usr --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.2703 raid.2710 raid /tmp --device=tmp --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.4551 raid.4558 raid /var/log --device=var_log --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.3283 raid.3290 raid /var --device=var --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.1651 raid.1658 raid / --device=root --fstype=\"xfs\" --level=RAID0 --chunksize=512 raid.389 raid.396  nvme1n1      259:0    0   1.8T  0 disk \u251c\u2500nvme1n1p1  259:2    0 128.1G  0 part \u2502 \u2514\u2500md127      9:127  0   256G  0 raid0 [SWAP] \u251c\u2500nvme1n1p2  259:3    0  12.5G  0 part \u2502 \u2514\u2500md123      9:123  0    25G  0 raid0 /var \u251c\u2500nvme1n1p3  259:4    0  12.5G  0 part \u2502 \u2514\u2500md120      9:120  0    25G  0 raid0 /var/log \u251c\u2500nvme1n1p4  259:5    0  12.5G  0 part \u2502 \u2514\u2500md121      9:121  0    25G  0 raid0 /var/log/audit \u251c\u2500nvme1n1p5  259:7    0    10G  0 part \u2502 \u2514\u2500md126      9:126  0    20G  0 raid0 /usr \u251c\u2500nvme1n1p6  259:8    0     5G  0 part \u2502 \u2514\u2500md125      9:125  0    10G  0 raid0 / \u251c\u2500nvme1n1p7  259:11   0     1G  0 part \u2502 \u2514\u2500md122      9:122  0     2G  0 raid0 /home \u2514\u2500nvme1n1p8  259:13   0   1.6T  0 part   \u2514\u2500md124      9:124  0   3.1T  0 raid0 /tmp nvme0n1      259:1    0   1.8T  0 disk \u251c\u2500nvme0n1p1  259:6    0     2G  0 part  /boot/efi \u251c\u2500nvme0n1p2  259:9    0     2G  0 part  /boot \u251c\u2500nvme0n1p3  259:10   0 128.1G  0 part \u2502 \u2514\u2500md127      9:127  0   256G  0 raid0 [SWAP] \u251c\u2500nvme0n1p4  259:12   0  12.5G  0 part \u2502 \u2514\u2500md123      9:123  0    25G  0 raid0 /var \u251c\u2500nvme0n1p5  259:14   0  12.5G  0 part \u2502 \u2514\u2500md120      9:120  0    25G  0 raid0 /var/log \u251c\u2500nvme0n1p6  259:15   0  12.5G  0 part \u2502 \u2514\u2500md121      9:121  0    25G  0 raid0 /var/log/audit \u251c\u2500nvme0n1p7  259:16   0    10G  0 part \u2502 \u2514\u2500md126      9:126  0    20G  0 raid0 /usr \u251c\u2500nvme0n1p8  259:17   0     5G  0 part \u2502 \u2514\u2500md125      9:125  0    10G  0 raid0 / \u251c\u2500nvme0n1p9  259:18   0     1G  0 part \u2502 \u2514\u2500md122      9:122  0     2G  0 raid0 /home \u2514\u2500nvme0n1p10 259:19   0   1.6T  0 part   \u2514\u2500md124      9:124  0   3.1T  0 raid0 /tmp <pre><code>if re-install the disk which has configured with raid\n``` bash\n########################################################################\n# create the partition scheme file /tmp/partitionfile\n########################################################################\n\n# disabling md RAID resync during installation\n# this speeds up the installation process significantly\necho \"[$0] disabling md RAID resync during installation\"\necho 0 &gt; /proc/sys/dev/raid/speed_limit_max\necho 0 &gt; /proc/sys/dev/raid/speed_limit_min\n# get all disks md raid\nmdraid=$(grep -E \"^md[0-9]+\" /proc/mdstat | awk '{print $1}')\n# erase all existing md RAIDs\nmdadm --stop /dev/${mdraid}\n# Remove the Superblocks from the disks\nmdadm --zero-superblock /dev/nvme0n1\nmdadm --zero-superblock /dev/nvme1n1\n\n# ignoredisk --only-use=nvme1n1,nvme0n1\n# System bootloader configuration\necho 'bootloader --append=\"crashkernel=auto\" --location=mbr --boot-drive=nvme0n1' &gt;&gt; /tmp/partitionfile\n# Partition clearing information\nclearpart --none --initlabel\n# Disk partitioning information\necho 'part raid.2203 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=2050' &gt;&gt; /tmp/partitionfile\necho 'part raid.995 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=1827319' &gt;&gt; /tmp/partitionfile\necho 'part raid.1581 --fstype=\"mdmember\" --ondisk=nvme1n1 --size=2050' &gt;&gt; /tmp/partitionfile\necho 'part raid.2196 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=2050' &gt;&gt; /tmp/partitionfile\necho 'part raid.988 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=1827319' &gt;&gt; /tmp/partitionfile\necho 'part raid.1574 --fstype=\"mdmember\" --ondisk=nvme0n1 --size=2050' &gt;&gt; /tmp/partitionfile\necho 'raid /boot --device=boot --fstype=\"xfs\" --level=RAID1 raid.1574 raid.1581' &gt;&gt; /tmp/partitionfile\necho 'raid pv.1002 --device=pv00 --fstype=\"lvmpv\" --level=RAID0 --chunksize=512 raid.988 raid.995' &gt;&gt; /tmp/partitionfile\necho 'raid /boot/efi --device=boot_efi --fstype=\"efi\" --level=RAID1 --fsoptions=\"umask=0077,shortname=winnt\" raid.2196 raid.2203' &gt;&gt; /tmp/partitionfile\necho 'volgroup rhel --pesize=4096 pv.1002' &gt;&gt; /tmp/partitionfile\necho 'logvol /tmp --fstype=\"xfs\" --size=3282664 --name=tmp --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol /var/log/audit --fstype=\"xfs\" --size=25600 --name=var_log_audit --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol /var --fstype=\"xfs\" --size=25600 --name=var --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol /usr --fstype=\"xfs\" --size=20480 --name=usr --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol /var/log --fstype=\"xfs\" --size=25600 --name=var_log --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol swap --fstype=\"swap\" --size=262144 --name=swap --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol / --fstype=\"xfs\" --size=10240 --name=root --vgname=rhel' &gt;&gt; /tmp/partitionfile\necho 'logvol /home --fstype=\"xfs\" --size=2048 --name=home --vgname=rhel' &gt;&gt; /tmp/partitionfile\n</code></pre></p>"},{"location":"hackmd/RedHat/#yum","title":"yum","text":"<ul> <li>Chapter\u00a012.\u00a0Managing software packages Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> <li>linux - How to know from which yum repository a package has been installed? - Server Fault</li> <li>How to instruct yum to install a specific package (rpm) from a specific repo - Stack Overflow</li> <li>How do I get a list of package groups used by kickstart and the anaconda installer? - Red Hat Customer Portal</li> <li>yum or dnf fails with \"Error: Unable to find a match\" when a package is missing - Red Hat Customer Portal</li> <li>gpg<ul> <li>RPM and GPG: How to verify Linux packages before installing them | Enable Sysadmin <pre><code>yum repolist\nyum info --installed\n\nyum group list --hidden\nyum grouplist hidden\nyum groupinstall '&lt;group name&gt;'\n\n# install from file\nyum -y install $(cat package_list)\n</code></pre></li> </ul> </li> </ul>"},{"location":"hackmd/RedHat/#offline-install-package","title":"offline install package","text":"<ul> <li>How to create a local mirror of the latest update for Red Hat Enterprise Linux 5, 6, 7, 8 and 9 without using Satellite server? - Red Hat Customer Portal</li> <li>Creating a Local Repository and Sharing With Disconnected/Offline/Air-gapped Systems - Red Hat Customer Portal</li> <li>How to create local repository distributed through apache of Red Hat Enterprise Linux 5/6/7/8/9 using DVD iso for update or installation? - Red Hat Customer Portal</li> <li>Share a local repository using NFS - Red Hat Customer Portal</li> <li>linux - Install packages without internet Red Hat - Stack Overflow</li> <li>Installing RHEL packages without network connection - Clever Net Systems</li> </ul>"},{"location":"hackmd/RedHat/#iso","title":"ISO","text":""},{"location":"hackmd/RedHat/#on-the-local-repo-node","title":"on the local repo node","text":"<p>``` bash= sudo mount -o loop  ISO/rhel-8.5-x86_64-dvd.iso /mnt shopt -s dotglob cp -avRpf /mnt/* /var/www/html/8.5 <pre><code>##### on the target node\n/etc/yum.repos.d/BaseOS.repo\n</code></pre> [BaseOS] name=Red Hat Enterprise Linux 8.5 BaseOS enabled=1 gpgcheck=1 baseurl=http://192.168.89.29/8.5/BaseOS/ <pre><code>/etc/yum.repos.d/AppStream.repo\n</code></pre> [AppStream] name=Red Hat Enterprise Linux 8.5 AppStream enabled=1 gpgcheck=1 baseurl=http://192.168.89.29/8.5/AppStream/ <pre><code>``` bash=\nyum clean all\nrm -rf /var/cache/yum/*\nyum makecache\nyum repolist\n</code></pre></p>"},{"location":"hackmd/RedHat/#reposync","title":"reposync","text":""},{"location":"hackmd/RedHat/#on-the-node-which-can-access-internet","title":"on the node which can access internet","text":"<ol> <li>use reposync to /var/www/html/8.5</li> <li>dump the /var/www/html/8.5 to the another local repo server which has no internet access</li> </ol> <p>``` bash= subscription-manager release --set=8.5 &amp;&amp; rm -rf /var/cache/dnf</p>"},{"location":"hackmd/RedHat/#check-the-repo-id-this-example-is-rhel-8-for-x86_64-baseos-rpms-and-rhel-8-for-x86_64-appstream-rpms","title":"check the repo id, this example is rhel-8-for-x86_64-baseos-rpms and rhel-8-for-x86_64-appstream-rpms","text":"<p>subscription-manager repos --list-enabled reposync -n -p /var/www/html/8.5 --download-metadata --repo=rhel-8-for-x86_64-baseos-rpms reposync -n -p /var/www/html/8.5 --download-metadata --repo=rhel-8-for-x86_64-appstream-rpms <pre><code>##### on the target node\n/etc/yum.repos.d/BaseOS.repo\n</code></pre> [BaseOS] name=Red Hat Enterprise Linux 8.5 BaseOS enabled=1 gpgcheck=1 baseurl=http://192.168.89.29/8.5/rhel-8-for-x86_64-baseos-rpms/ <pre><code>/etc/yum.repos.d/AppStream.repo\n</code></pre> [AppStream] name=Red Hat Enterprise Linux 8.5 AppStream enabled=1 gpgcheck=1 baseurl=http://192.168.89.29/8.5/rhel-8-for-x86_64-appstream-rpms/ <pre><code>``` bash=\nyum clean all\nrm -rf /var/cache/yum/*\nyum makecache\nyum repolist\n</code></pre></p>"},{"location":"hackmd/RedHat/#specific-package","title":"specific package","text":"<ul> <li>Download RPM packages locally with DNF</li> </ul> <pre><code>dnf download --resolve podman\ndnf --disablerepo=\\* install *.rpm\n</code></pre>"},{"location":"hackmd/RedHat/#infiniband","title":"Infiniband","text":"<ul> <li>Configuring InfiniBand and RDMA networks Red Hat Enterprise Linux 8 | Red Hat Customer Portal<ul> <li>Configuring InfiniBand and RDMA networks Red Hat Enterprise Linux 8 | Red Hat Customer Portal</li> </ul> </li> </ul>"},{"location":"hackmd/RedHat/#chrome","title":"chrome","text":"<ul> <li>Google Chrome installation RHEL 8 - Red Hat Customer Portal</li> <li>Linux\u7cfb\u7d71\u5b89\u88ddGoogle Chrome\u700f\u89bd\u5668\u7684\u65b9\u6cd5 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/RedHat/#with-internet","title":"with internet","text":"<p>/etc/yum.repos.d/google-chrome.repo <pre><code>[google-chrome]\nname=google-chrome\nbaseurl=https://dl.google.com/linux/chrome/rpm/stable/x86_64\nenabled=1\ngpgcheck=1\ngpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub  \n</code></pre></p> <pre><code>sudo dnf upgrade\nsudo dnf install google-chrome-stable\n</code></pre>"},{"location":"hackmd/RedHat/#without-internet","title":"without internet","text":"<pre><code>sudo dnf install liberation-fonts vulkan\nsudo rpm -ivh google-chrome-stable-119.0.6045.159-1.x86_64.rpm\n</code></pre>"},{"location":"hackmd/RedHat/#rescue-mode","title":"rescue mode","text":"<ol> <li>Boot the system from the relevant <code>Binary DVD</code> or <code>boot disc</code> of the same major release as the system. </li> <li>Select <code>Troubleshooting/Rescue a Red Hat Enterprise Linux system</code> at the install menu</li> </ol> <p>After entering rescue mode - This shell exists in the installation/rescue environment, with the installed system optionally mounted under <code>/mnt/sysimage</code>.  - This shell has a number of tools available for rescuing a system, such as all common file system, disk, LVM, and networking tools.</p> <p>At the shell prompt, run df to see if the dev, sys, proc filesystems are mounted under /mnt/sysimage <pre><code># df\n\nmount -o bind /dev /mnt/sysimage/dev\nmount -o bind /sys /mnt/sysimage/sys\nmount -t proc /proc /mnt/sysimage/proc\nmount -o bind /dev/shm /mnt/sysimage/dev/shm\n</code></pre></p> <p>To chroot to the existing system root</p> <pre><code># chroot /mnt/sysimage\n</code></pre> <pre><code># chroot /mnt/sysroot\n</code></pre>"},{"location":"hackmd/RedHat/#customized-case-var-partition-are-exploded-due-to-keycloak-log","title":"customized case - /var partition are exploded due to keycloak log","text":"<p>chroot to the existing system root, and check <code>df -h</code> and found /var directories are not mounted. tried to mount /var and it failed till do </p> <pre><code># xfs_repair -L /dev/mapper/rhel-var\n</code></pre> <p>one of the log continue to grow  pass 25G  which is the max partition for /var. finally, remove it</p>"},{"location":"hackmd/RedHat/#xfs_repair","title":"xfs_repair","text":"<ul> <li>Chapter\u00a014.\u00a0Checking and repairing a file system Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/RedHat/#create-a-modified-red-hat-enterprise-linux-iso-with-kickstart-file","title":"Create a modified Red Hat Enterprise Linux ISO with kickstart file","text":"<ul> <li>How to create a modified Red Hat Enterprise Linux ISO with kickstart file or modified installation media? - Red Hat Customer Portal</li> <li>Prerequisites and step-by-step process | Install image mode for Red Hat Enterprise Linux using kickstart | Red Hat Developer</li> <li>Automate RHEL Installation: Red Hat Enterprise Linux | Medium</li> <li>Chapter\u00a03.\u00a0Customizing the boot menu | Red Hat Product Documentation</li> </ul> <pre><code>mkksiso --ks /home/foo/files/ISO/rhel-9.3-x86_64-dvd-ks.cfg /home/foo/files/ISO/rhel-9.3-x86_64-dvd.iso /home/foo/files/ISO/rhel-9.3-x86_64-dvd-embedded-ks.iso\n</code></pre> <pre><code># enable text mode\ntext\n\nrepo --name=\"AppStream\" --baseurl=file:///run/install/sources/mount-0000-cdrom/AppStream\n\n%packages\n@^server-product-environment\n\n%end\n\n# network configuration\nnetwork --bootproto=dhcp --device=link --activate\n\n# Use CDROM installation media\ncdrom\n\nignoredisk --only-use=sda\nclearpart --drives=sda --initlabel\nautopart\n\n# Root password\nrootpw --iscrypted $6$CJwHTZEau9/0iTFS$euGWh8wHxW.Kt1Fflk7VpRhZG/Icy3Si8Qfput1ekjxl.jwn8qSUJ1.OXEPRzvzjaGpN7HnateJ2pY7XceEOF1\nuser --groups=wheel --name=foo --password=$6$w.cf4rujMhOUTq9n$Hi3.xqgWZcBC6TnwJwIqC8IKCbnTBlAPHN040bNLX9bjd7TJubPSUEz5Gm2eA0UsGcw2UpGDL/TW6uP5IiHwk. --iscrypte\n</code></pre>"},{"location":"hackmd/RedHat/#redhat-certificate","title":"Redhat Certificate","text":"<ul> <li>Red Hat Certified OpenShift Administrator exam | EX280</li> <li>GitHub - mgonzalezo/RedHat_ex280: Red Hat Certified OpenShift Administrator exam (EX280) Overview and Preparation</li> </ul>"},{"location":"hackmd/Redfish/","title":"Redfish","text":"<ul> <li>\u4f7f\u7528 DMTF Redfish API \u7ba1\u7406\u7cfb\u7d71 - IBM \u8aaa\u660e\u6587\u4ef6</li> <li>RedfishRefGuide.pdf - supermicro<ul> <li>Supermicro Systems Resources and Management Software Download Center</li> </ul> </li> <li>Redfish Specification</li> <li>DMTF/Redfishtool: A Python34 program that implements a command line tool for accessing the Redfish API.</li> <li>Session<ul> <li>Redfish_School-Sessions</li> <li>a user can define session time from 30 to 86400 seconds</li> </ul> </li> </ul> <p>``` bash=</p>"},{"location":"hackmd/Redfish/#optional-view-the-session-service","title":"[optional] view the session service","text":"<p>curl -k 'https://172.27.47.51/redfish/v1/SessionService' --user \"foo:bar\"</p>"},{"location":"hackmd/Redfish/#optional-change-the-default-session-timeout","title":"[optional] change the default session timeout","text":"<p>curl -k --request PATCH 'https://172.27.47.51/redfish/v1/SessionService' --user \"foo:bar\" --data '{\"SessionTimeout\": 360}'</p>"},{"location":"hackmd/Redfish/#fetch-token-and-check-the-headerstxtx-auth-token","title":"Fetch token, and check the headers.txt(X-Auth-Token)","text":"<p>curl -k --request POST -D /tmp/headers.txt 'https://172.27.47.51/redfish/v1/SessionService/Sessions' --data '{\"UserName\":\"foo\",\"Password\":\"bar\"}'</p>"},{"location":"hackmd/Redfish/#virtual-iso-mount","title":"Virtual ISO mount","text":"<p>curl -k --request POST -H \"X-Auth-Token: gbrfixxdhz3dpsm5woot1e7qbg73fbjq\" 'https://172.31.35.186/redfish/v1/Managers/1/VirtualMedia/CD1/Actions/VirtualMedia.InsertMedia' --data '{\"Image\": \"http://172.31.58.225/ISO/ubuntu-22.04.4-live-server-amd64.iso\"}'</p>"},{"location":"hackmd/Redfish/#unmount","title":"unmount","text":"<p>curl -k --request POST -H \"X-Auth-Token: gbrfixxdhz3dpsm5woot1e7qbg73fbjq\" 'https://172.31.35.186/redfish/v1/Managers/1/VirtualMedia/CD1/Actions/VirtualMedia.EjectMedia' --data '{}'</p>"},{"location":"hackmd/Redfish/#boot-options-usb","title":"Boot Options: USB","text":"<p>curl -k --request PATCH -H \"X-Auth-Token: gbrfixxdhz3dpsm5woot1e7qbg73fbjq\" 'https://172.27.47.51/redfish/v1/Systems/1' --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"Usb\"}}'</p>"},{"location":"hackmd/Redfish/#boot-options-hdd-once","title":"Boot Options: HDD, Once","text":"<p>curl -k --request PATCH -H \"X-Auth-Token: gbrfixxdhz3dpsm5woot1e7qbg73fbjq\" 'https://172.27.47.51/redfish/v1/Systems/1' --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"Hdd\"}}'</p>"},{"location":"hackmd/Redfish/#boot-options-virtual-iso-once","title":"Boot Options: Virtual ISO, Once","text":""},{"location":"hackmd/Redfish/#httpswwwsupermicrocommanualsotherredfish-ref-guide-htmlcontentgeneral-contentbios-configurationhtmhighlightbootsourceoverridetarget","title":"https://www.supermicro.com/manuals/other/redfish-ref-guide-html/Content/general-content/bios-configuration.htm?Highlight=BootSourceOverrideTarget","text":""},{"location":"hackmd/Redfish/#notes-bootsourceoverridetargetcd-is-not-working","title":"notes: \"BootSourceOverrideTarget\":\"Cd\" is not working","text":"<p>curl -k --request PATCH -H \"X-Auth-Token: 39mhmi6mhwv5g0nygfjkmu97e683tv4c\" 'https://172.24.118.167/redfish/v1/Systems/1' --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"Legacy\",\"BootSourceOverrideTarget\":\"UsbCd\"}}' curl -k --request PATCH -H \"X-Auth-Token: ruvmm17i0xqgh1b8sm9ho3sf0zk1f0n1\" 'https://172.24.118.167/redfish/v1/Systems/1' --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"UsbCd\"}}'</p>"},{"location":"hackmd/Redfish/#boot-options-pxe-once","title":"Boot Options: Pxe, Once","text":"<p>curl -k --request PATCH -H \"X-Auth-Token: ruvmm17i0xqgh1b8sm9ho3sf0zk1f0n1\" 'https://172.24.118.167/redfish/v1/Systems/1' --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"Pxe\"}}' | python3 -m json.tool curl -k --request PATCH 'https://172.24.118.167/redfish/v1/Systems/1' --user \"foo:bar\" --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"Pxe\"}}' | python3 -m json.tool</p>"},{"location":"hackmd/Redfish/#boot-options-hdd-continuous","title":"Boot Options: HDD, Continuous","text":"<p>curl -k --request PATCH -H \"$(cat /tmp/headers.txt | grep X-Auth-Token | dos2unix)\" 'https://172.27.47.51/redfish/v1/Systems/1' --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Continuous\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"Hdd\"}}'</p>"},{"location":"hackmd/Redfish/#update-bios-firmware","title":"Update BIOS firmware","text":"<p>curl -k -i -X POST \\    -H \"Authorization:Basic U01DSTpTdXBlcjEyMw==\" \\    -H \"Content-Type:multipart/form-data\" \\    -F \"UpdateParameters={\\\"Targets\\\": [\\\"/redfish/v1/Systems/1/Bios\\\"],\\\"@Redfish.OperationApplyTime\\\": \\\"Immediate\\\",\\\"Oem\\\": {\\\"Supermicro\\\": { \\\"BIOS\\\": { \\\"PreserveME\\\": true, \\\"PreserveNVRAM\\\": true, \\\"PreserveSMBIOS\\\": true, \\\"BackupBIOS\\\": false }}}};type=application/json\" \\    -F \"UpdateFile=@\\\"/tmp/BIOS_BH12SSi-1B8F_20240131_2.8_STDsp.bin\\\";type=application/octet-stream\" \\  'https://172.31.34.164/redfish/v1/UpdateService/upload'</p>"},{"location":"hackmd/Redfish/#update-bmc-firmware","title":"Update BMC firmware","text":"<p>curl -k -i -X POST \\    -H \"Authorization:Basic U01DSTpTdXBlcjEyMw==\" \\    -H \"Content-Type:multipart/form-data\" \\    -F \"UpdateParameters={\\\"Targets\\\": [\\\"/redfish/v1/Managers/1\\\"],\\\"@Redfish.OperationApplyTime\\\": \\\"Immediate\\\",\\\"Oem\\\": {\\\"Supermicro\\\": { \\\"BMC\\\": { \\\"PreserveCfg\\\": true, \\\"PreserveSdr\\\": true, \\\"PreserveSsl\\\": true, \\\"BackupBMC\\\": true }}}};type=application/json\" \\    -F \"UpdateFile=@\\\"/tmp/BMC_B12AST2500-ROT-1201MS_20240210_01.04.12_STDsp.bin\\\";type=application/octet-stream\" \\  'https://172.31.34.164/redfish/v1/UpdateService/upload'</p>"},{"location":"hackmd/Redfish/#reset","title":"reset","text":"<p>curl -k --request POST -H \"X-Auth-Token: gbrfixxdhz3dpsm5woot1e7qbg73fbjq\" 'https://172.27.47.51/redfish/v1/Systems/1/Actions/ComputerSystem.Reset' --data '{\"ResetType\": \"GracefulRestart\"}' | python3 -m json.tool <pre><code>The values are allowed to set BootSourceOverrideTarget\n- BootSourceOVerRideMode: UEFI\n    - Pxe\n    - Cd\n    - Usb\n    - Hdd\n- BootSourceOVerRideMode: Legacy\n    - None\n    - Pxe\n    - Cd\n    - Floppy\n    - Usb\n    - Hdd\n    - BiosSetup\n    - UsbCd\n    - UefiBootNext\n\n\n\nmount and change the virtual iso, as well as reboot\n``` bash=\n#! /bin/bash\n\nREPO_SERVER=172.31.58.225\nISO=ubuntu-22.04.4-live-server-amd64.iso\n\nread -p \"Enter BMC Host: \" BMC_HOST\nread -p \"Enter BMC Account: \" ACCOUNT\nread -s -p \"Enter BMC Password: \" PASSWORD\ncurl -v -k --request POST -D /tmp/headers.txt  \"https://${BMC_HOST}/redfish/v1/SessionService/Sessions\" --data \"{\\\"UserName\\\":\\\"${ACCOUNT}\\\",\\\"Password\\\":\\\"${PASSWORD}\\\"}\"\n\nTOKEN=$(cat /tmp/headers.txt | grep X-Auth-Token | dos2unix)\necho \"Mount ${ISO} on ${BMC_HOST} by token ${TOKEN} and reboot\"\ncurl -v -k --request POST -H \"${TOKEN}\" \"https://${BMC_HOST}/redfish/v1/Managers/1/VirtualMedia/CD1/Actions/VirtualMedia.InsertMedia\" --data \"{\\\"Image\\\": \\\"http:\\/\\/${REPO_SERVER}\\/ISO\\/${ISO}\\\"}\"\ncurl -v -k --request PATCH -H \"${TOKEN}\" \"https://${BMC_HOST}/redfish/v1/Systems/1\" --data '{\"Boot\":{\"BootSourceOverrideEnabled\":\"Once\",\"BootSourceOverrideMode\":\"UEFI\",\"BootSourceOverrideTarget\":\"UsbCd\"}}'\n#curl -v -k --request POST -H \"${TOKEN}\" \"https://${BMC_HOST}/redfish/v1/Systems/1/Actions/ComputerSystem.Reset\" --data '{\"ResetType\": \"GracefulRestart\"}'\n</code></pre></p>"},{"location":"hackmd/SEO/","title":"SEO","text":"<ul> <li>Hexo\u641c\u5c0b\u5f15\u64ce\u512a\u5316</li> <li>\u8a66\u8457\u5b78 Hexo - SEO \u7bc7 - \u5148\u4f86\u804a\u804a Url \u5c0d\u65bc SEO \u7684\u5f71\u97ff</li> <li>\u8a66\u8457\u5b78 Hexo - SEO \u7bc7 - SEO \u89c0\u5ff5\u88dc\u5145</li> <li>\u641c\u5c0b\u5f15\u64ce\u6700\u4f73\u5316 (SEO) \u5165\u9580\u6307\u5357</li> <li>google official<ul> <li>Build and Submit a Sitemap | Google Search Central \u00a0|\u00a0 Documentation \u00a0|\u00a0 Google for Developers</li> <li>\u900f\u904e Sitemap \u5831\u544a\u7ba1\u7406 Sitemap - Search Console \u8aaa\u660e</li> </ul> </li> </ul>"},{"location":"hackmd/SQL/","title":"SQL","text":""},{"location":"hackmd/SQL/#transfer-data-from-table-a-to-table-b","title":"Transfer data from table A to table B","text":"<pre><code>-- ----------------------------\n-- Table structure for THREAT_REPORT\n-- ----------------------------\nDROP TABLE IF EXISTS `THREAT_REPORT`;\nCREATE TABLE `THREAT_REPORT` (\n  `FILE_HASH` varchar(256) NOT NULL,\n  `VENDOR` varchar(10) NOT NULL COMMENT 'preserved for 30 vendors, 2^30=1073741824',\n  `HASH_TYPE` enum('md5','sha1','sha256') NOT NULL,\n  `REPORT` json NOT NULL COMMENT 'threat report/encyclopedia info from vendor',\n  `REPORT_DIGEST` varchar(256) NOT NULL,\n  `CREATE_TIME` datetime DEFAULT CURRENT_TIMESTAMP COMMENT 'create time about the record',\n  `UPDATE_TIME` datetime DEFAULT CURRENT_TIMESTAMP COMMENT 'update time about the record',\n  PRIMARY KEY (`FILE_HASH`, `VENDOR`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n</code></pre>"},{"location":"hackmd/SQL/#insert-into-select","title":"INSERT INTO SELECT","text":"<pre><code>-- WebRoot\n-- format {\"4\": {\"det\": \"B\", \"md5\": \"00070b378c87e5bb935c60fcf55b0c9a\", \"fseen\": 1581019932, \"detdate\": 1581020431, \"pccount\": 1, \"filesize\": 385380, \"malwaregroup\": \"W32.Trojan.Emotet\"}}\nINSERT INTO THREAT_REPORT\nSELECT\nFILE_HASH,\nVIRUS_SOURCE,\nHASH_TYPE,\nJSON_EXTRACT(REPORT_RESULT, '$.\"4\"') as REPORT,\nMD5(CONCAT('{\"det\":', JSON_EXTRACT(REPORT_RESULT, '$.\"4\".det'), ',\"detdate\":', JSON_EXTRACT(REPORT_RESULT, '$.\"4\".detdate'),',\"filesize\":',JSON_EXTRACT(REPORT_RESULT, '$.\"4\".filesize'),',\"fseen\":', JSON_EXTRACT(REPORT_RESULT, '$.\"4\".fseen'),',\"malwaregroup\":',JSON_EXTRACT(REPORT_RESULT, '$.\"4\".malwaregroup'),',\"md5\":', JSON_EXTRACT(REPORT_RESULT, '$.\"4\".md5'), ',\"pccount\":',JSON_EXTRACT(REPORT_RESULT, '$.\"4\".pccount'),'}')) as REPORT_DIGEST,\nFROM_UNIXTIME(RESULT_TIMESTAMP) as CREATE_TIME,\nFROM_UNIXTIME(RESULT_TIMESTAMP) as UPDATE_TIME\nFROM `SCORE_DB` WHERE VIRUS_SOURCE=4 AND JSON_EXTRACT(REPORT_RESULT, '$.\"4\"')  is not null;\n</code></pre>"},{"location":"hackmd/SQL/#add-new-column-value-from-origin-column-in-the-same-table","title":"Add new column value from origin column in the same table","text":"<pre><code>ALTER TABLE REPUTATION_DB ADD CATEGORIES JSON;\n</code></pre> <pre><code>SET SQL_SAFE_UPDATES = 0;\n\nUPDATE REPUTATION_DB t1\nINNER JOIN REPUTATION_DB t2 ON t2.HOST = t1.HOST\nSET t1.CATEGORIES = CAST( CONCAT('[\"', REPLACE(t2.CATEGORY_NAME, ',', '\",\"'), '\"]') AS JSON);\n\nSET SQL_SAFE_UPDATES = 1;\n</code></pre>"},{"location":"hackmd/SQL/#add-multi-value-index","title":"add multi-value index","text":"<p>As of MySQL 8.0.17, InnoDB supports multi-valued indexes</p> <p>https://dev.mysql.com/doc/refman/8.0/en/create-index.html#create-index-multi-valued <pre><code>ALTER TABLE REPUTATION_DB ADD INDEX idx_categories_hosttype_rankscore( (CAST(CATEGORIES-&gt;'$' AS CHAR(32) ARRAY)), HOST_TYPE, RANK_SCORE );\n</code></pre></p> <pre><code>SELECT CATEGORIES, HOST, RANK_SCORE, SCORE\nFROM ZSDNDCDB.REPUTATION_DB\nwhere JSON_OVERLAPS(CATEGORIES-&gt;'$', CAST('[\"Anonymizers\", \"Browser Exploits\", \"Malicious Sites/Botnet\", \"Malicious Sites\", \"Malicious Downloads\", \"Phishing\", \"Spam URLs\", \"Spyware/Adware/Keyloggers\"]' AS JSON))\nAND HOST_TYPE = 'domain'\nORDER BY RANK_SCORE DESC\nLIMIT 0, 2500\n</code></pre>"},{"location":"hackmd/SQL/#retrieve-the-maximum-length-of-a-varchar-column","title":"Retrieve the maximum length of a VARCHAR column","text":"<ul> <li>Retrieve the maximum length of a VARCHAR column in SQL Server - Stack Overflow</li> </ul> <pre><code>SELECT MAX(LENGTH(Desc)) FROM table_name\n</code></pre>"},{"location":"hackmd/SQL/#select-the-longest-string-from-a-table","title":"select the longest 'string' from a table","text":"<ul> <li>mysql - How do I select the longest 'string' from a table when grouping - Stack Overflow</li> </ul> <pre><code>ORDER BY LENGTH(description) DESC LIMIT 1\n</code></pre>"},{"location":"hackmd/SQL/#get-the-average-number-of-characters-for-a-field","title":"get the average number of characters for a field","text":"<ul> <li>SQL: Is there a way to get the average number of characters for a field? - Stack Overflow</li> </ul> <pre><code>select avg(length(textfield)) from mytable;\n</code></pre>"},{"location":"hackmd/SSL/","title":"SSL","text":""},{"location":"hackmd/SSL/#overview","title":"Overview","text":"<ul> <li>\u6df1\u5165\u4e86\u89e3SSL/TLS</li> <li>\u7c21\u4ecb HTTPS / TLS \u5b89\u5168\u901a\u8a0a\u5354\u8b70</li> <li>An overview of the SSL Handshake</li> <li>HTTPS/SSL/TLS \u6982\u8ff0\uff0c\u6574\u9ad4\u6d41\u7a0b\u3001\u6191\u8b49\u3001\u6578\u4f4d\u7c3d\u7ae0</li> <li>\u5f9e SSL \u5230 SSL Pinning \u770b\u5b8c\u4f60\u5c31\u61c2</li> <li>What is certificate pinning</li> <li>Hostname Verification</li> <li>Requests-The User Guide-Advanced Usage</li> <li>\u7528\u6236\u7aef\u6191\u8b49\u8207\u4f3a\u670d\u5668\u6191\u8b49\u6709\u4f55\u5dee\u7570\uff1f</li> <li>Client Certificate Authentication (Part 1)</li> <li>Client Certificate vs Server Certificate: Simplifying the Difference</li> <li>What is a Root SSL Certificate</li> <li>OpenSSL client certificates vs server certificates</li> <li>SSL Handshake and HTTPS Bindings on IIS</li> <li>Day14|\u5bc6\u78bc\u5b78\u521d\u63a2(7)\uff1a\u975e\u5c0d\u7a31\u52a0\u5bc6\u8207\u6578\u4f4d\u7c3d\u7ae0</li> </ul>"},{"location":"hackmd/SSL/#_1","title":"\u6191\u8b49","text":"<ul> <li>DV (Domain validated)</li> <li>OV (Organization validated)<ul> <li>github</li> </ul> </li> <li>EV (Extended validation)<ul> <li>paypal</li> <li>momo</li> </ul> </li> </ul>"},{"location":"hackmd/SSL/#_2","title":"\u53c3\u8003","text":"<ul> <li>TLS/SSL\u6191\u8b49 DV, OV, EV \u5dee\u7570\u8207\u8b58\u5225\u65b9\u6cd5</li> <li>\u6548\u679c\u4e0d\u5927\uff0cChrome\u3001Firefox\u5c07\u7e2e\u6e1bEV\u7c3d\u7ae0\u6a19\u793a</li> <li>Wildcard SSL certificate for second-level subdomain</li> <li>Best location for SSL certificate and private keys on Ubuntu</li> </ul>"},{"location":"hackmd/SSL/#sni","title":"SNI","text":"<p>Customized SNI</p> <ol> <li>openssl</li> <li>Postman\u6539Host</li> </ol> <p>openssl <pre><code>openssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"diqz8h6n59coy.cloudfront.net\"\n\nopenssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"github.com\"\n\nopenssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"tw.yahoo.com\"\n\nopenssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"stackoverflow.com\"\n</code></pre></p>"},{"location":"hackmd/SUSE/","title":"SUSE","text":"<ul> <li>SLES 15 SP4 | Deployment Guide | Planning for SUSE Linux Enterprise Server</li> </ul> <pre><code>zypper lr -d\nzypper repos -d\nsudo zypper addrepo https://download.opensuse.org/repositories/openSUSE:Leap:42.1:Update/standard/openSUSE:Leap:42.1:Update.repo\nsudo zypper removerepo https://url-of-software-repository/\n</code></pre>"},{"location":"hackmd/SUSE/#registration","title":"Registration","text":"<ul> <li>Finding SUSE registration status offline - SUSE Product Topics / SUSE Customer Center - Rancher Labs</li> </ul> <pre><code>SUSEConnect --status\n</code></pre>"},{"location":"hackmd/SUSE/#nfs","title":"nfs","text":"<pre><code># nfs server\nmkdir -p /mnt/sle-15\nmount -o loop /install/SLE-15-SP3-Full-x86_64-QU4-Media1.iso /mnt/sle-15\nzypper addrepo /mnt/sle-15/Module-Basesystem/ sle-basesystem\nzypper refresh\nzypper install nfs-kernel-server\n</code></pre>"},{"location":"hackmd/SUSE/#network","title":"Network","text":"<ul> <li>SLES 15 SP4 | \u7ba1\u7406\u6307\u5357 | \u57fa\u672c\u7db2\u8def\u77e5\u8b58</li> </ul> <p>ib interface</p> <pre><code>sudo ip link set ib0 up\nsudo ip add add 10.10.1.2/24 brd + dev ib0\n</code></pre> <p>/etc/sysconfig/network/ifcfg-ib0 <pre><code>IPADDR='10.10.1.2/24'\nBOOTPROTO='static'\nSTARTMODE='auto'\nIPOIB_MODE=''\nZONE=public\n</code></pre></p>"},{"location":"hackmd/SVN/","title":"SVN","text":"<ul> <li>Git \u548c Subversion\u7684\u76f8\u6bd4 | \u9023\u7334\u5b50\u90fd\u80fd\u61c2\u7684Git\u5165\u9580\u6307\u5357 | \u8c9d\u683c\u6a02\uff08Backlog\uff09</li> <li>How to do an svn checkout with a different username | Sandro Cirulli</li> </ul> <p>svn checkout --username foo https://bar.com/repo</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/","title":"Scrum\u7b46\u8a18","text":"<p>\u6216\u8a31\u4e0d\u80fd\u50c5\u7528\u958b\u767c\u89d2\u5ea6(Development Team)\u53bb\u601d\u8003\u5b83</p> <p>The purpose of the Scrum framework is to develop products and solve complex problems by using an empirical process that promotes rapid feedback.</p> <p>Myth 3: In Scrum, releases are done only at the end of the Sprint</p> <ul> <li>\u3010Scrum\u898f\u5283\u6703\u8b70\u3011(\u4e00)\u5982\u4f55\u628a\u5de5\u4f5c\u76ee\u6a19\u8aaa\u6e05\u695a - \u6d41\u7a0b\u99ed\u5ba2\uff5c\u6578\u4f4d\uff58\u7ba1\u7406\uff58\u6d41\u7a0b - Medium</li> <li>\u3010Scrum\u898f\u5283\u6703\u8b70\u3011(\u4e8c)\u5982\u4f55\u7522\u51fa\u597d\u7684\u5f85\u8fa6\u6e05\u55ae - \u6d41\u7a0b\u99ed\u5ba2\uff5c\u6578\u4f4d\uff58\u7ba1\u7406\uff58\u6d41\u7a0b - Medium</li> <li>\u3010Scrum\u898f\u5283\u6703\u8b70\u3011(\u4e09)\u9032\u884cStory Point\u7684\u8a55\u5206. Scrum\u898f\u5283\u6703\u8b70\u8a55\u4f30Story\u2026 | by \u6d41\u7a0b\u99ed\u5ba2 Kevin Wu\uff5c\u6578\u4f4d\uff58\u7ba1\u7406\uff58\u6d41\u7a0b | \u6d41\u7a0b\u99ed\u5ba2\uff5c\u6578\u4f4d\uff58\u7ba1\u7406\uff58\u6d41\u7a0b | Medium</li> <li>\u3010Scrum\u898f\u5283\u6703\u8b70\u3011(\u56db)\u5982\u4f55\u64b0\u5beb\u5de5\u4f5c\u8a08\u756b\uff0c\u4e26\u7e3d\u7d50\u898f\u5283 - \u6d41\u7a0b\u99ed\u5ba2\uff5c\u6578\u4f4d\uff58\u7ba1\u7406\uff58\u6d41\u7a0b - Medium</li> </ul>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#sprint","title":"Sprint","text":"<p>\u611f\u89ba\u4e0a\u662f\u4e00\u7a2e\u6642\u9593\u55ae\u4f4d</p> <p>The purpose of each Sprint is to deliver Increments of potentially releasable functionality that adhere to the Scrum Team\u2019s current definition of \"Done\".</p> <p>The heart of Scrum is a Sprint, a time-box of one month or less during which a \"Done\", useable, and potentially releasable product Increment is created.</p> <p>The Scrum Guide</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#release","title":"\u548cRelease\u7684\u95dc\u4fc2","text":"<p>\u548cproduction release cycles\u7684\u95dc\u4fc2 \u53ef\u4ee5\u548cproduction release cycles\u812b\u9264</p> <p>\u548chotfix\u548curgent patch\u7684\u95dc\u4fc2</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#_1","title":"\u53c3\u8003","text":"<ul> <li>The Scrum Guide</li> <li>Production release cadence as relates to Sprint cycle</li> <li>Myth 3: In Scrum, releases are done only at the end of the Sprint</li> <li>How do you name Sprints in Scrum?</li> </ul>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#_2","title":"\u548c\u8edf\u9ad4\u958b\u767c\u7684\u95dc\u4fc2","text":"<p>Requirements Analysis System Analysis</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#retrospective","title":"Retrospective","text":"<p>\u63d0\u4f9b\u4e00\u500b\u8f03\u6b63\u5f0f\u7684\u5834\u57df\u53ef\u4ee5==\u6aa2\u8996==\u4e26==\u63d0\u51fa\u6539\u5584\u8a08\u756b== The Sprint Retrospective is an opportunity for the Scrum Team to inspect itself and create a plan for improvements to be enacted during the next Sprint.</p> <p>The purpose of the Sprint Retrospective is to - ==Inspect== how the last Sprint went with regards to people, relationships, process, and tools - ==Identify and order== the major items that went well and potential improvements - ==Create a plan== for implementing improvements to the way the Scrum Team does its work</p> <p>The Scrum Master ensures that the event takes place and that ==attendants understand its purpose==.</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#example","title":"Example","text":"<p>2020/5/28</p> <p>:::info - problem     - chaos commmits - type: process - plan     - List related project names with \"devops-manager\" repository, and Maoji will create the new repos for the related projects individually :::</p> <p>:::info - problem     - PyCharm IDE license - type: tool - plan     - Evaluate the price and limitation of PyCharm IDE license :::</p> <p>:::info - problem     - retrospective purpose - type: process - summary     - Team-wise         - frequency             - We may make the Retro on every weekly meeting instead of preserving the specific time slot to do it.             - We may forget the topic             - There is no topic on the specific time slot and it will cause dead air         - scope             1.  Topic Sharing             2.  Technical Discussion (Ex. System Infra Design)             3.  Highlight team workflow\u2019s good part and bad part     - Project-wise         - scope             1.  Discuss about the questions of project - plan     - Survey the agenda of Retro Meeting</p> <p>:::</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#_3","title":"\u57f7\u884c","text":"<ul> <li>\u5148\u4ee5\u5b9a\u671f\u548c\u5718\u968a\u5168\u54e1\u5728\u56fa\u5b9a\u6642\u9593\u5167\u9032\u884c\u9592\u804a\u4f5c\u70ba\u7b2c\u4e00\u500b\u653f\u7b56<ul> <li>\u85c9\u9019\u7a2e\u65b9\u5f0f\uff0c\u4e5f\u80fd\u8b93\u5718\u968a\u5728\u53ef\u80fd\u7dca\u7e43\u7684\u958b\u767c\u751f\u6d3b\u4e2d\uff0c\u505a\u9ede\u6b47\u606f\u3001\u5598\u53e3\u6c23</li> <li>\u4e00\u958b\u59cb\u5927\u5bb6\u90fd\u805a\u5728\u4e00\u8d77\uff0c\u6703\u4e0d\u6703\u5f7c\u6b64\u4e0d\u77e5\u9053\u8a72\u600e\u9ebc\u804a\u8d77\uff0c\u5c0e\u81f4\u773e\u4eba\u90fd\u4e7e\u5728\u90a3\u908a\uff0c\u51b7\u5834\u51b7\u7684\u5c37\u5c2c\u5462\uff1f \u6703XD</li> </ul> </li> <li>\u9019\u6642\u5019\u82e5\u6709\u4eba\u9858\u610f\u5206\u4eab\u4e00\u4e9b\u505a\u6cd5\u6216\u77e5\u8b58\uff0c\u5c31\u80fd\u6210\u70ba\u4e00\u500b\u597d\u7684\u958b\u59cb\u3002\u76ee\u7684\uff1a==\u88fd\u9020\u4e00\u500b\u8b93\u5718\u968a\u4ea4\u6d41\u7684\u7a7a\u9593==<ul> <li>\u5206\u4eab\u7684\u4e3b\u984c\u53ef\u4ee5\u662f\u65e2\u6709\u7684\u77e5\u8b58\u3001\u53ef\u4ee5\u662f\u67d0\u4ef6\u4e8b\u81ea\u5df1\u5fc3\u76ee\u4e2d\u7684\u7406\u60f3\u505a\u6cd5\u3001\u53ef\u4ee5\u53ea\u95dc\u65bc\u6280\u8853\u3001\u4e5f\u53ef\u4ee5\u804a\u804a\u5718\u968a\u5408\u4f5c\u4e0a\u7684\u5c0f\u6280\u5de7</li> <li>\u5206\u4eab\u6642\uff0c\u53ef\u4ee5==\u591a\u5e36\u4e00\u9ede\u4e3b\u898b==\uff0c\u800c\u4e0d\u7528\u64d4\u5fc3\u8207\u5176\u4ed6\u4eba\u4e0d\u540c\u3002\u76f8\u53cd\u7684\uff0c\u9019\u53ef\u80fd\u6703\u88fd\u9020\u51fa\u66f4\u591a\u8a0e\u8ad6\u7684\u6a5f\u6703\uff0c\u8b93\u6bcf\u500b\u4eba\u90fd\u85c9\u8457\u4e3b\u984c\u5206\u4eab\u81ea\u5df1\u7684\u89c0\u9ede\u8207\u7fd2\u6163\u6216\u662f\u8868\u9054\u5fc3\u4e2d\u7684\u7591\u60d1\u3002\u53ea\u8981==\u6709\u500b\u4eba\u80fd\u5e6b\u5fd9\u63a7\u5834==<ul> <li>\u63a7\u5834\u7684\u4eba\u5118\u91cf\u4e0d\u8981\u548c\u5206\u4eab\u4e3b\u984c\u7684\u6210\u54e1\u540c\u4e00\u500b\uff0c\u800c\u662f\u8b93\u63a7\u5834\u7684\u4eba\u6210\u70ba\u4e3b\u6301\u4eba</li> </ul> </li> <li>\u6bd4\u5982\u8aaa\u9650\u5b9a\u6bcf\u500b\u4eba\u7684\u767c\u8a00\u6642\u9593\uff0c\u6216\u662f\u8981\u6c42\u4e0d\u8981\u6253\u65b7\u5225\u4eba\u7684\u767c\u8a00\u22ef\u22ef\u7b49\u7b49\uff0c\u8b93\u5927\u5bb6\u80fd\u6709\u689d\u7406\u5730\u9032\u884c\u8faf\u8ad6\uff0c\u800c\u4e0d\u6703\u8b8a\u6210\u5435\u67b6\u5927\u6703\u3002\u9019\u90e8\u5206\u53ef\u4ee5\u5728\u5206\u4eab\u958b\u59cb\u524d\u5148\u5f7c\u6b64\u8aaa\u597d\uff0c\u8b93\u5718\u968a\u6210\u54e1\u4e3b\u52d5\u4e92\u76f8\u63d0\u9192<ul> <li>\u53ea\u8981\u80fd==\u71df\u9020\u4e00\u500b\u80fd\u4e92\u76f8\u5c0a\u91cd\u767c\u8a00\u6b0a\u5229\u7684\u57fa\u790e==\uff0c\u5c31\u4e0d\u592a\u6703\u6709\u554f\u984c\u4e86</li> <li>\u5728\u9019\u500b\u6d3b\u52d5\u4e2d\uff0c\u4e0d\u662f\u8981\u722d\u51fa\u5c0d\u932f\uff0c\u6bcf\u500b\u4eba\u90fd\u6709\u7fd2\u6163\u7684\u65b9\u5f0f\u548c\u8a8d\u540c\u7684\u54f2\u5b78\uff0c\u6c92\u6709\u552f\u4e00\u89e3\uff0c\u91cd\u9ede\u662f\u80fd\u8b93\u5f7c\u6b64\u66f4\u52a0\u66b8\u89e3</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#_4","title":"\u6d41\u7a0b","text":"<p>\u5206\u4eab\u4e3b\u984c=&gt;\u5718\u968a\u8a0e\u8ad6=&gt;\u4e00\u500b\u53ef\u843d\u5be6\u7684\u653f\u7b56\u6216\u660e\u78ba\u7684\u7d50\u8ad6</p> <p>\u5718\u968a\u8a0e\u8ad6\u53ef\u4ee5\u6e1b\u5c11\u5718\u968a\u5c0d\u65bc\u9019\u4e9b\u505a\u6cd5\u6c92\u6709\u8a8d\u540c\u611f\uff0c\u5c0e\u81f4\u96e3\u4ee5\u843d\u5be6</p>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#_5","title":"\u71df\u9020\u4e00\u500b\u80fd\u4e92\u76f8\u5c0a\u91cd\u767c\u8a00\u6b0a\u5229\u7684\u57fa\u790e","text":"<ul> <li>\u5718\u968a\u6210\u54e1\u4e3b\u52d5\u4e92\u76f8\u63d0\u9192\u70ba\u4e3b, \u4e3b\u6301\u4eba(Host)\u63a7\u5834\u70ba\u8f14</li> <li>\u8a0e\u8ad6\u7684\u65b9\u5f0f\u8207\u898f\u5247\u4e0a\u7684\u5171\u8b58(\u6642\u9593, \u80fd\u5426\u88ab\u4e2d\u65b7...)<ul> <li>\u8209\u4f8b<ul> <li>\u4e3b\u8b1b\u4eba\u628a\u6574\u500b\u5206\u4eab\u8b1b\u5b8c\u518d\u9032\u884c\uff0c\u9084\u662f\u4e2d\u9593\u53ef\u4ee5\u8209\u624b\u6253\u65b7</li> <li>\u8981\u80fd\u5c0a\u91cd\u73fe\u5728\u767c\u8a00\u7684\u5925\u4f34\uff0c\u7b49\u4ed6\u767c\u8a00\u5b8c\u518d\u63a5\u8457\u8b1b\u7b49\u7b49</li> <li>\u6bcf\u500b\u4eba\u7684\u767c\u8a00\u662f\u5426\u6709\u6642\u9593\u9650\u5236\uff0c\u6709\u7684\u8a71\u5927\u6982\u591a\u4e45</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#_6","title":"\u53c3\u8003","text":"<ul> <li>Sprint Retrospective</li> <li>\u70ba\u5718\u968a\u8207\u7d44\u7e54\u5c0e\u5165\u654f\u6377\u7684\u7d93\u9a57\u5206\u4eab<ul> <li>\u900f\u904e\u5206\u4eab\u53bb\u6fc0\u767c\u5718\u968a\u7684\u8a0e\u8ad6</li> </ul> </li> </ul>"},{"location":"hackmd/Scrum%E7%AD%86%E8%A8%98/#gitlab","title":"Gitlab","text":"<p>Follow the https://docs.gitlab.com/ee/tutorials/scrum_events/</p> <p>free tier Only have: Labels, Issues, Issue boards, Tasks, Milestones NO Burndown and burnup charts:https://docs.gitlab.com/ee/user/project/milestones/burndown_and_burnup_charts.html NO epic: https://docs.gitlab.com/ee/user/group/epics/ NO Iterations: https://docs.gitlab.com/ee/user/group/iterations/</p>"},{"location":"hackmd/Singularity/","title":"Singularity","text":"<ul> <li>SingularityCE User Guide \u2014 SingularityCE User Guide 4.0 documentation<ul> <li>Installing SingularityCE \u2014 SingularityCE Admin Guide 4.0 documentation</li> </ul> </li> <li>Singularity \u57fa\u790e\u4ecb\u7d39 - Yi Yang's Blog</li> <li>\u7db2\u8def\u9ed1\u8c93 BlackCat on Net / Champ Yen: Linux Developer \u90fd\u61c9\u8a72\u5b78\u7fd2\u7684 Container \u5de5\u5177 - Apptainer / Singularity</li> <li>Singularity - HackMD</li> <li>DevSecOps / Singularity Tutorial \u00b7 GitLab</li> <li>Why is Singularity used as opposed to Docker in HPC and what problems does it solve? : r/docker</li> <li>fakeroot<ul> <li>Singularity \u555f\u7528 Fakeroot - Yi Yang's Blog</li> </ul> </li> <li>workdir<ul> <li>Question: how to check and change the working directory while doing singularity exec ...? \u00b7 Issue #5730 \u00b7 apptainer/singularity \u00b7 GitHub</li> </ul> </li> <li>shpc<ul> <li>shpc Documentation</li> <li>Singularity HPC Library</li> </ul> </li> <li>mysql/mariadb<ul> <li>examples/database/mariadb/README.md at master \u00b7 sylabs/examples \u00b7 GitHub</li> <li>MySQL Server | High Performance Computing</li> </ul> </li> </ul> <pre><code># pull image from remote\nsingularity pull docker://mariadb:10.3.39\n\n# build image from def\nsingularity build mariadb.sif mariadb.def\nsingularity instance start --writable-tmpfs --bind ${PWD}/db/:/var/lib/mysql --bind ${PWD}/mysql/run/mysqld:/run/mysqld mariadb.sif mariadb\nsingularity shell instance://mariadb\n\nsingularity exec instance://mariadb mysql_install_db\nsingularity exec instance://mariadb mysqld_safe --datadir=/var/lib/mysql &amp;\nsingularity exec instance://mariadb mysql_secure_installation\nsingularity exec instance://mariadb mysql -u root -e \"create database slurm_acct_db;\"\nsingularity exec instance://mariadb mysql -u root -e \"create user 'slurm'@'127.0.0.1' identified by 'bar';\"\nsingularity exec instance://mariadb mysql -u root -e \"grant all privileges on slurm_acct_db.* to 'slurm'@'127.0.0.1';\"\n\n\n# list the instance\nsingularity instance list\n\n# stop the instance\nsingularity instance stop mariadb\n</code></pre>"},{"location":"hackmd/Singularity/#mpi","title":"MPI","text":"<ul> <li>No components were able to be opened in the pml framework<ul> <li>OpenMPI doens't utilise openucx in MPI communications \u00b7 Issue #11419 \u00b7 open-mpi/ompi \u00b7 GitHub</li> <li>Running UCX \u2014 OpenUCX documentation</li> <li>access to /dev/infiniband from user space</li> <li>Access to /dev/infiniband from user space - Q&amp;A - ask.CI</li> </ul> </li> </ul> <p><pre><code>mpirun -n 1 -mca pml ucx --mca pml_base_verbose 10 --mca mtl_base_verbose 10 -x OMPI_MCA_pml_ucx_verbose=10  singularity exec /root/amd_hpl/amd_hpl.sif /tmp/mpi-hello\n</code></pre> <pre><code>[slurm-compute-01:92608] mca: base: components_register: registering framework pml components\n[slurm-compute-01:92608] mca: base: components_register: found loaded component ucx\n[slurm-compute-01:92608] mca: base: components_register: component ucx register function successful\n[slurm-compute-01:92608] mca: base: components_open: opening pml components\n[slurm-compute-01:92608] mca: base: components_open: found loaded component ucx\n[slurm-compute-01:92608] common_ucx.c:174 using OPAL memory hooks as external events\n[slurm-compute-01:92608] pml_ucx.c:197 mca_pml_ucx_open: UCX version 1.15.0\n[slurm-compute-01:92608] mca: base: components_open: component ucx open function successful\n[slurm-compute-01:92608] select: initializing pml component ucx\n[slurm-compute-01:92608] common_ucx.c:332 self/memory: did not match transport list\n[slurm-compute-01:92608] common_ucx.c:332 tcp/ib0: did not match transport list\n[slurm-compute-01:92608] common_ucx.c:332 sysv/memory: did not match transport list\n[slurm-compute-01:92608] common_ucx.c:332 posix/memory: did not match transport list\n[slurm-compute-01:92608] common_ucx.c:332 cma/memory: did not match transport list\n[slurm-compute-01:92608] common_ucx.c:337 support level is none\n[slurm-compute-01:92608] select: init returned failure for component ucx\n--------------------------------------------------------------------------\nNo components were able to be opened in the pml framework.\n\nThis typically means that either no components of this type were\ninstalled, or none of the installed components can be loaded.\nSometimes this means that shared libraries required by these\ncomponents are unable to be found/loaded.\n\n  Host:      slurm-compute-01\n  Framework: pml\n--------------------------------------------------------------------------\n[slurm-compute-01:92608] PML ucx cannot be selected\n</code></pre></p> <pre><code>mpirun -n 1 -mca pml ucx --mca pml_base_verbose 10 --mca mtl_base_verbose 10 --mca opal_common_ucx_tls any --mca opal_common_ucx_devices any -x OMPI_MCA_pml_ucx_verbose=10 -x UCX_NET_DEVICES='ib0'  singularity exec /root/amd_hpl/amd_hpl.sif /tmp/mpi-hello\n</code></pre>"},{"location":"hackmd/Slurm/","title":"Slurm","text":"<ul> <li>Three ways to use slurm on a high performance computer (HPC) (CC130) - YouTube</li> <li>Slurm Workload Manager - Documentation<ul> <li>Node role</li> <li>Network<ul> <li>Slurm Workload Manager - Network Configuration Guide</li> </ul> </li> <li>Database<ul> <li>Slurm Workload Manager - Accounting and Resource Limits<ul> <li>MySQL or MariaDB is the preferred database.</li> <li>[slurm-users] slurmdbd database usage</li> </ul> </li> </ul> </li> <li>NFS<ul> <li>https://slurm.schedmd.com/quickstart.html<ul> <li>Slurm does not automatically migrate executable or data files to the nodes allocated to a job. Either the files must exists on local disk or in some global file system (e.g. NFS or Lustre).</li> </ul> </li> <li>How does Slurm sync files between compute and master nodes? | AWS re:Post</li> </ul> </li> <li>Slurm \u57fa\u672c\u8aaa\u660e - HackMD</li> <li>Slurm \u5b89\u88dd\u6d41\u7a0b - HackMD</li> <li>Setup Slurm Cluster | SSARCandy's Blog<ul> <li>Build a High Performance Computing Cluster on GCP | SSARCandy's Blog</li> </ul> </li> <li>slurm\u96c6\u7fa4\u90e8\u7f72 | SCOW</li> <li>SLURM Cluster in Docker Swarm Cluster | Ching-Chuan Chen's Blogger</li> <li>Deploying containerized workloads to Slurm on Compute Engine \u00a0|\u00a0 Cloud Architecture Center \u00a0|\u00a0 Google Cloud</li> <li>Slurm Workload Manager - Presentations</li> <li>SLE-HPC 15 SP5 | Administration Guide</li> <li>1. Slurm\u7b80\u4ecb \u2014 Slurm\u8d44\u6e90\u7ba1\u7406\u4e0e\u4f5c\u4e1a\u8c03\u5ea6\u7cfb\u7edf\u5b89\u88c5\u914d\u7f6e 2021-12 \u6587\u6863</li> <li>sbatch - slurm: How to submit a job under another user and prevent to read other users' files? - Stack Overflow</li> <li>Ubuntu<ul> <li>Slurm Quick Installation for Cluster on Ubuntu 20.04 | NekoDaemon's Blog</li> <li>How to install Slurm node on Ubuntu 18 | by Anar Mammadli | Medium</li> <li>\u5355\u8282\u70b9\u7684 slurm \u5b89\u88c5 - \u82cf\u5dde\u8d85\u96c6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8</li> <li>How to quickly set up Slurm on Ubuntu 20.04 for single node workload scheduling. | by Pritesh Tailor | Medium</li> <li>[Ubuntu] Slurm source install :: HPE CRAY \uc790\ub8cc \uacf5\uc720</li> <li>Ubuntu20.04\u5355\u673a\u5b89\u88c5slrum\u6559\u7a0b | \u6211\u5fc3\u6c38\u6052\u7684\u5c0f\u7ad9</li> <li>[slurm-users] Problem with cgroup plugin in Ubuntu22.04 and slurm 21.08.5<ul> <li>centos - slurmd: error: Couldn't find the specified plugin name for cgroup/v2 looking at all files - Stack Overflow</li> <li>Slurm Workload Manager - Control Group v2 plugin</li> </ul> </li> </ul> </li> <li>container<ul> <li>Containers in Slurm - SLUG 2023</li> </ul> </li> <li>REST API<ul> <li>REST API - SLUG23<ul> <li>Slurm Workload Manager - Slurm REST API</li> <li>Slurm Workload Manager - Slurm REST API doc</li> <li>Slurm Workload Manager - slurmrestd</li> <li>How to enable slurmrestd on ParallelCluster \u00b7 aws/aws-parallelcluster Wiki \u00b7 GitHub</li> <li>[slurm-users] slurmrestd configuration</li> <li>Re: [slurm-users] Setting up slurmrestd</li> </ul> </li> </ul> </li> </ul> </li> <li>Debug<ul> <li>Slurm and Munge \"Invalid Credential\" - Stack Overflow</li> </ul> </li> <li>Guide<ul> <li>Slurm Tutorial 1: Getting Started | RIT Research Computing Documentation</li> <li>Slurm Tutorial 2: Scaling Up | RIT Research Computing Documentation</li> <li>Slurm\u4f5c\u4e1a\u8c03\u5ea6\u7cfb\u7edf\u4f7f\u7528\u6307\u5357</li> <li>Slurm Overview - ULHPC Technical Documentation</li> <li>Introduction to SLURM and MPI - Batch Docs</li> <li>SLURM Guide - Storrs HPC - UConn Knowledge Base</li> <li>Axtasy @A100 \u4f7f\u7528\u6307\u5357 - HackMD</li> <li>Introducing Slurm | Princeton Research Computing<ul> <li>Top 10 Mistakes to Avoid on the Research Computing Clusters | Princeton Research Computing</li> </ul> </li> <li>account and user<ul> <li>Slurm Administration - TJ CSL</li> <li>Slurm account synchronization with UNIX groups and users</li> </ul> </li> <li>MPI<ul> <li>deepops/workloads/examples/slurm/mpi-hello/README.md at master \u00b7 NVIDIA/deepops \u00b7 GitHub</li> <li>infiniband - OpenMPI 4.1.1 There was an error initializing an OpenFabrics device Infinband Mellanox MT28908 - Stack Overflow</li> <li>linux - MPI hello_world to test infiniband - Stack Overflow</li> <li>[slurm-users] Question about networks and connectivity</li> </ul> </li> <li>Singularity<ul> <li>Using Singularity | USC Advanced Research Computing</li> </ul> </li> <li>Troubleshooting<ul> <li>\u30107\u3011\u5e38\u89c1\u95ee\u9898 \u00b7 Doc</li> <li>Frequently Asked Questions \u2014 Mercury Computing Cluster documentation Batch jobs - Documentation</li> </ul> </li> <li>HA<ul> <li>Slurm Workload Manager - Quick Start Administrator Guide -HIGH AVAILABILITY</li> <li>Slurm Workload Manager - slurm.conf - SlurmctldHost<ul> <li>example</li> </ul> </li> <li>Slurm Workload Manager - slurm.conf - StateSaveLocation<ul> <li> <p>If you have a secondary SlurmctldHost configured, this location should be readable and writable by both systems.</p> </li> </ul> </li> <li>Field_Notes_3.pdf - page 38<ul> <li>2413 \u2013 SLURM high availability with centos 7.2</li> </ul> </li> <li>[slurm-users] Slurmdbd High Availability</li> <li>[slurm-users] Ideal NFS exported StateSaveLocation size. [slurm-users] what is the possible reason for secondary slurmctld node not allocate job after takeover?</li> </ul> </li> </ul> </li> <li>Kubernetes vs. Slurm: Which Container Orchestration Tool is Right for You? #kubernetes #AI #MachineLearning</li> <li>Where should I store temporary files created by Slurm cluster jobs? | SESYNC</li> <li>NVIDIA<ul> <li>GitHub - NVIDIA/deepops: Tools for building GPU clusters</li> <li>DeepOps \u2013 An efficient way to deploy GPU cluster for computing - Speaker Deck</li> <li>deepops/docs/slurm-cluster at master \u00b7 NVIDIA/deepops \u00b7 GitHub</li> </ul> </li> <li>DELL<ul> <li>Playbooks | Architecture Guide\u2014Dell EMC HPC Ready Solution for AI and Data Analytics | Dell Technologies Info Hub</li> <li>GitHub - dell/omnia: An open-source toolkit for deploying and managing high performance clusters for HPC, AI, and data analytics workloads.</li> </ul> </li> <li>altair<ul> <li>High-performance Computing (HPC) and Cloud Solutions | Altair</li> </ul> </li> <li>ansible<ul> <li>GitHub - stackhpc/ansible-slurm-appliance: A Slurm-based HPC workload management environment, driven by Ansible.</li> <li>Institut Fran\u00e7ais de Bioinformatique / Ansible Roles / ansible-slurm \u00b7 GitLab</li> <li>GitHub - galaxyproject/ansible-slurm: Ansible role for installing and managing the Slurm Workload Manager</li> <li>Galaxy NG</li> <li>GitHub - fgci-org/ansible-role-slurm: For installing and configuring SLURM - Simple Linux Utility for Resource Management</li> </ul> </li> <li>container<ul> <li>9.3. Running Singularity containers on Slurm - HPC High Performance Computing - Guies BibTIC at Universitat Pompeu Fabra</li> <li>containers_workshop_fall2021.pdf</li> </ul> </li> <li>Slurm Alternatives(competitor)<ul> <li>Scheduling Basics - HPC Wiki</li> <li>Slurm Tutorial (formerly Slurm and Moab) | HPC @ LLNL<ul> <li>Slurm from SchedMD</li> <li>Spectrum LSF from IBM</li> <li>Tivoli Workload Scheduler (LoadLeveler) from IBM</li> <li>PBS from Altair Engineering</li> <li>TORQUE, Maui, Moab from Adaptive Computing</li> <li>Univa Grid Engine</li> <li>OpenLava</li> </ul> </li> <li>\u57fa\u4e8eHPC\u573a\u666f\u7684\u96c6\u7fa4\u4efb\u52a1\u8c03\u5ea6\u7cfb\u7edfLSF/SGE/Slurm/PBS_pbs slurm-CSDN\u535a\u5ba2<ul> <li>LSF<ul> <li>Spectrum LSF</li> <li>Platform LSF</li> <li>OpenLava</li> </ul> </li> <li>SGE<ul> <li>Altair Grid Engine</li> <li>Univa Grid Engine</li> </ul> </li> <li>Slurm<ul> <li>rosetta.pdf</li> </ul> </li> <li>PBS<ul> <li>openPBS</li> <li>Altair PBS Professional</li> <li>Torque</li> </ul> </li> <li>Kubernetes Scheduler<ul> <li>GitHub - flux-framework/flux-k8s: Project to manage Flux tasks needed to standardize kubernetes HPC scheduling interfaces</li> </ul> </li> </ul> </li> <li>PBS - HackMD</li> </ul> </li> <li>example<ul> <li>Using srun to Launch Applications Under Slurm - NREL HPC<ul> <li>HPC/slurm at master \u00b7 NREL/HPC</li> </ul> </li> <li>Job submit commands with examples | Math Faculty Computing Facility (MFCF) | University of Waterloo</li> <li></li> </ul> </li> </ul>"},{"location":"hackmd/Slurm/#deploy","title":"deploy","text":"<p>config the hostname properly on all nodes prepare /etc/hosts on all nodes be careful about firewall config</p> <pre><code>cat &gt;/etc/yum.repos.d/MariaDB.repo &lt;&lt;EOF\n[mariadb]\nname=MariaDB\nbaseurl=https://ftp.ubuntu-tw.org/mirror/mariadb/yum/10.5/centos7-amd64\ngpgkey=https://ftp.ubuntu-tw.org/mirror/mariadb/yum/RPM-GPG-KEY-MariaDB\ngpgcheck=1\nEOF\ndnf makecache\ndnf install -y epel-release\ndnf makecache\ndnf config-manager --set-enabled powertools\n\ngroupadd -g 901 munge\nuseradd -c \"MUNGE Uid 'N' Gid Emporium\" -d /var/lib/munge -g munge -m -s /sbin/nologin -u 901 munge\ngroupadd -g 902 slurm\nuseradd -c \"Slurm Workload Manager\" -d /var/lib/slurm -g slurm -m -s /bin/bash -u 902 slurm\n\n#https://forums.rockylinux.org/t/slurm-does-not-install-from-the-epel-repo/2832\ndnf install -y munge slurm slurm-contribs slurm-perlapi\n\n# login node\ndnf install -y slurm-devel slurm-pmi slurm-pmi-devel\n# control node\ndnf install -y slurm-slurmctld\n# database node\ndnf install -y mariadb-server slurm-slurmdbd\n# compute node\ndnf install -y slurm-slurmd slurm-pmi\n</code></pre>"},{"location":"hackmd/Slurm/#firewall-if-only-using-sbatch-and-srun","title":"firewall if only using sbatch and srun","text":"<pre><code># both control node and compute node\nsystemctl stop firewalld.service\n</code></pre>"},{"location":"hackmd/Slurm/#firewall-if-only-using-sbatch","title":"firewall if only using sbatch","text":"<p>Slurm Workload Manager - Network Configuration Guide The machines running srun also use a range of ports to be able to communicate with slurmstepd. By default these ports are chosen at random from the ephemeral port range, but you can use the SrunPortRange to specify a range of ports from which they can be chosen. This is necessary for login nodes that are behind a firewall. <pre><code># firewall on slurmctld\n# slurmctld for compute node access\nfirewall-cmd --permanent --zone=public --add-port=6817/tcp\n# mariadb access from outer client like workbench\nfirewall-cmd --permanent --zone=public --add-port=3306/tcp\n\n# firewall on slurmd\n# slurmd for control node access\nfirewall-cmd --permanent --zone=public --add-port=6818/tcp\n</code></pre></p>"},{"location":"hackmd/Slurm/#slurmrestd","title":"slurmrestd","text":"<ul> <li>Slurm Workload Manager - REST API Quick Start Guide</li> <li>[slurm-users] slurmrestd configuration</li> </ul> <pre><code>apt install -y libhttp-parser-dev libjson-c-dev libjwt-dev\n</code></pre> <p>change the systemd <pre><code>sudo useradd -M -r -s /usr/sbin/nologin -U slurmrestd\n</code></pre></p> <p>/lib/systemd/system/slurmrestd.service <pre><code>[Unit]\nDescription=Slurm REST daemon\nAfter=network-online.target slurmctld.service\nWants=network-online.target\nConditionPathExists=/etc/slurm/slurm.conf\n\n[Service]\nType=simple\nEnvironmentFile=-/etc/sysconfig/slurmrestd\nEnvironmentFile=-/etc/default/slurmrestd\n# slurmrestd should not run as root or the slurm user.\n# Please either use the -u and -g options in /etc/sysconfig/slurmrestd or\n# /etc/default/slurmrestd, or explicitly set the User and Group in this file\n# an unpriviledged user to run as.\nUser=slurmrestd\nGroup=slurmrestd\n# Default to listen on both socket and slurmrestd port\n#ExecStart=/usr/local/sbin/slurmrestd $SLURMRESTD_OPTIONS unix:/usr/local/com/slurmrestd.socket 0.0.0.0:6820\nExecStart=/usr/local/sbin/slurmrestd -a rest_auth/jwt -s openapi/v0.0.39  0.0.0.0:6820\n# Enable auth/jwt be default, comment out the line to disable it for slurmrestd\nEnvironment=\"SLURM_JWT=daemon\" \"SLURMRESTD_DEBUG=debug\"\nExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>prepare the jwt key on control node(slurmctld) and storage node(slurmdbd) - Slurm Workload Manager - JSON Web Tokens (JWT) Authentication <pre><code>dd if=/dev/random of=/var/spool/slurm/ctld/jwt_hs256.key bs=32 count=1\nchown slurm:slurm /var/spool/slurm/ctld/jwt_hs256.key\nchmod 0600 /var/spool/slurm/ctld/jwt_hs256.key\n</code></pre></p> <p>slurm.conf <pre><code>...\nAuthAltTypes=auth/jwt\nAuthAltParameters=jwt_key=/var/spool/slurm/ctld/jwt_hs256.key\n...\n</code></pre></p> <p>slurmdbd.conf <pre><code>...\nAuthAltTypes=auth/jwt\nAuthAltParameters=jwt_key=/var/spool/slurm/ctld/jwt_hs256.key\n...\n</code></pre></p> <pre><code>slurmrestd -a list\nslurmrestd -s list\n</code></pre> <pre><code>unset SLURM_JWT; export $(scontrol token)\ncurl -H \"X-SLURM-USER-TOKEN:$SLURM_JWT\" http://172.19.30.198:6820/slurm/v0.0.39/ping\n\ncurl -H \"X-SLURM-USER-TOKEN:$SLURM_JWT\" http://172.19.30.198:6820/slurm/v0.0.39/diag\n</code></pre>"},{"location":"hackmd/Slurm/#test-the-slurmnode-job","title":"Test the slurm(node, job)","text":"<p>\u63d0\u4ea4\u7b2c\u4e00\u500b Job - HackMD <pre><code># test\nsinfo\nsinfo -N\nsinfo -N -o \"%20N  %10c  %10m  %25f  %10G \"\nsinfo -o '%11P %5D %22N %4c %21G %7m %11l'\nscontrol show node\nscontrol show node slurm_compute_1\nscontrol show config\nscontrol ping\nsacctmgr list cluster\n\n# if test.sh in the \"foo\" directory, then the \"foo\" should be on everty compute node\nsbatch -p debug test.sh\nsqueue\nscontrol show job &lt;job_id&gt;\nsacct\n# https://ask.cyberinfrastructure.org/t/how-do-i-get-the-list-of-features-and-resources-of-each-node-in-slurm/201\nsacct --jobs={{ job_id }} --format JobID,JobName,Partition,Account,AllocCPUS,State,ExitCode,NodeList%40\nscancel &lt;jobid&gt;\n\n# interactive\nsalloc -N 1 -n 2 -p debug\nsrun date\nsrun hostname\n\n\n# after reboot compute node(Restart nodes in state down)\n# https://slurm.schedmd.com/prolog_epilog.html#failure_handling (drain status)\nsinfo -R\nscontrol update nodename=slurm-compute-01 state=resume\n</code></pre></p> <ul> <li>GPUs, Parallel Processing, and Job Arrays | ACCRE | Vanderbilt University</li> <li>Running GPU Jobs - Office of Research Computing - Wiki</li> <li>Job Examples - ZIH HPC Compendium</li> <li>SLURM\u4e0a\u8207\u8a08\u7b97\u6838\u5fc3\u6578/\u7bc0\u9ede\u6578\u6bd4\u8f03\u76f8\u95dc\u4e14\u5e38\u7528\u7684\u8a2d\u5b9a\uff0c\u6709\u4ee5\u4e0b4\u500b - \u570b\u7db2\u4e2d\u5fc3-\u8a08\u7b97\u8cc7\u6e90\u670d\u52d9\u7db2 <pre><code>srun --ntasks 24 hostname\nsrun --ntasks 24 --nodelist=slurm-compute-02 hostname\nsrun --ntasks 24 --nodelist=slurm-compute-01,slurm-compute-02 hostname\nsrun --ntasks 10 --nodelist=slurm-compute-01,slurm-compute-02 hostname\nsrun --ntasks 10 --ntasks-per-node=5 hostname\nsrun --ntasks 10 --nodes=2 hostname\nsrun --ntasks-per-node=10 --nodes=2 hostname\n\n\nsrun --nodes=1 --gres=gpu:tesla:1 nvidia-smi -L\nsrun --nodes=1 --ntasks-per-node=12 --gres=gpu:tesla:1 nvidia-smi -L\nsrun --nodes=1 --nodelist=slurm-compute-02 --gres=gpu:tesla:1 nvidia-smi -L\nsrun --nodes=2 --ntasks-per-node=12 --gres=gpu:tesla:1 nvidia-smi -L\n</code></pre></li> </ul> <p>account and user - Slurm Workload Manager - sacctmgr - [slurm-users] SlurmdSpoolDir     - /var/spool/slurm/d/ =&gt; 755     - /var/spool/slurm =&gt; <code>775</code></p> <p>create a user with password on <code>login nodes</code> and <code>control node</code> which exist slurmctld, for example, ben project_a is a virtual concept</p> <pre><code>useradd ben\npasswd ben\n</code></pre> <pre><code>sacctmgr list associations\nsacctmgr show assoc\nsacctmgr show tres\n\nsacctmgr create account name=project_a fairshare=50\nsacctmgr create user name=jimmy cluster=cluster account=project_a partition=debug\nsacctmgr delete user name=jimmy cluster=cluster account=project_a\n</code></pre>"},{"location":"hackmd/Slurm/#gpu","title":"GPU","text":"<ul> <li>Slurm Workload Manager - Generic Resource (GRES) Scheduling</li> </ul>"},{"location":"hackmd/Slurm/#nvml","title":"nvml","text":"<ul> <li>How to accelerate workloads with NVIDIA GPUs on Red Hat Device Edge<ul> <li>Disable Nouveau<ul> <li>Disable Nouveau - NVIDIA Docs</li> <li>deepops/roles/galaxy/nvidia.nvidia_driver/tasks/install-redhat.yml</li> <li>deepops/roles/nvidia-gpu-operator-node-prep/tasks/main.yml</li> </ul> </li> </ul> </li> <li>AutoDetect=nvml on gres.conf not working. Error \"fatal: We were configured to autodetect nvml functionality, but we weren't able to find that lib when Slurm was configured\" \u00b7 Issue #1214 \u00b7 NVIDIA/deepops \u00b7 GitHub</li> <li>Invalid generic resource (gres) specification<ul> <li>10827 \u2013 Invalid gres specification with AutoDetect=nvml</li> <li>[slurm-users] GRES and GPUs</li> <li>distributed computing - Cannot allocate GPU in Slurm - Stack Overflow</li> <li>Slurm srun cannot allocate ressources for GPUs - Invalid generic resource specification - Server Fault</li> </ul> </li> </ul> <pre><code>dnf config-manager --add-repo=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo\nrpm --import https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/D42D0685.pub\ndnf module install nvidia-driver:525\nsystemctl reboot\nnvidia-smi\n</code></pre> <p>method 1: build rpm - [slurm] rpmbuild with gpu :: HPE CRAY \uc790\ub8cc \uacf5\uc720 <pre><code>dnf install cuda-toolkit\ndnf module install nvidia-driver:525\nrpmbuild -ta /tmp/slurm-20.11.9.tar.bz2 --with mysql --define \"_with_nvml --with-nvml=/usr/local/cuda\"\nrpm -qlp /root/rpmbuild/RPMS/x86_64/slurm-20.11.9-1.el8.x86_64.rpm | grep nvml\nfind /usr -type f -name '*nvml*'\n</code></pre></p> <p>method 2: build and install reference: <code>deepops/roles/slurm/tasks/build.yml</code> <pre><code>dnf install cuda-toolkit\ndnf module install nvidia-driver:525\n./configure --prefix=/usr/local --disable-dependency-tracking --disable-debug --disable-x11 --enable-really-no-cray --enable-salloc-kill-cmd --with-hdf5=no --sysconfdir=/etc/slurm --enable-pam --with-pam_dir=/lib64/security --with-shared-libslurm --without-rpath --with-nvml=/usr/local/cuda\nmake -j$(nproc)\nmake -j$(nproc) contrib\nmake -j$(nproc) install\nfind /usr -type f -name '*nvml*'\n</code></pre></p>"},{"location":"hackmd/Slurm/#nvidia-smi","title":"nvidia-smi","text":"<pre><code>[root@slurm-compute-01 ~]# nvidia-smi --list-gpus\nGPU 0: Tesla T4 (UUID: GPU-2640e36d-125d-89fa-ed7c-ec40de7a44b4)\n[root@slurm-compute-01 ~]# \n[root@slurm-compute-01 ~]# nvidia-smi --query-gpu=gpu_name --format=csv,noheader\nTesla T4\n[root@slurm-compute-01 ~]# nvidia-smi --list-gpus\n\n\n[foo@slurm-compute-02 ~]$ nvidia-smi --list-gpus\nGPU 0: NVIDIA A100 80GB PCIe (UUID: GPU-a211d1d2-a220-6e1b-890d-c0b25fedcbda)\nGPU 1: NVIDIA A100 80GB PCIe (UUID: GPU-9d34191d-1da9-a613-2aad-935778eb6683)\n[foo@slurm-compute-02 ~]$ nvidia-smi --query-gpu=gpu_name --format=csv,noheader\nNVIDIA A100 80GB PCIe\nNVIDIA A100 80GB PCIe\n[foo@slurm-compute-02 ~]$\n</code></pre>"},{"location":"hackmd/Slurm/#run","title":"run","text":"<p>single-node multi-GPUs distributed training on multiple GPUs over multiple nodes using the SLURM</p> <ul> <li>4.7. Submitting multi-node/multi-gpu jobs - HPC High Performance Computing - Guies BibTIC at Universitat Pompeu Fabra</li> <li>Multi-Node Training using SLURM \u2014 pytorch_geometric documentation</li> <li>Efficient Training on Multiple GPUs</li> <li>How to launch a GPU job on multiple nodes? - Discovery Cluster / Slurm - USC Advanced Research Computing</li> <li>Multinode Training \u2014 PyTorch Tutorials 2.2.0+cu121 documentation<ul> <li>Fault-tolerant Distributed Training with torchrun \u2014 PyTorch Tutorials 2.2.0+cu121 documentation</li> </ul> </li> </ul>"},{"location":"hackmd/Slurm/#deepops","title":"DeepOps","text":""},{"location":"hackmd/Slurm/#release-2308-for-redhat-88","title":"release-23.08 for redhat 8.8","text":"<p>https://github.com/NVIDIA/deepops/tree/master/docs/slurm-cluster</p> <p>./scripts/setup.sh</p> <ul> <li>environment variable $ID</li> <li>python<ul> <li>seliux<ul> <li>sudo pip3.8 install selinux</li> </ul> </li> <li>virtualenv<ul> <li>sudo pip3.8 virtualenv</li> </ul> </li> </ul> </li> </ul> <p>ansible-playbook -l slurm-cluster playbooks/slurm-cluster.yml</p> <ul> <li>pmix<ul> <li>roles/slurm/tasks/pmix.yml</li> </ul> </li> </ul> <pre><code>- name: Enable repo\n  shell: subscription-manager repos --enable \"codeready-builder-for-rhel-8-x86_64-rpms\"\n  when: ansible_os_family == 'RedHat' and ansible_distribution_major_version == \"8\"\n- name: install pmix 'pandoc' build dependency for RHEL 8\n  dnf:\n    name: pandoc\n    state: present\n    enablerepo: powertools\n  when: ansible_os_family == 'RedHat' and ansible_distribution_major_version == \"8\"\n</code></pre> <ul> <li>pyxis<ul> <li>roles/galaxy/nvidia.enroot/tasks/redhat.yml</li> </ul> </li> </ul> <pre><code>- name: enroot rpm packages\n    yum:\n      name: \"{{ item }}\"\n      state: \"{{ enroot_package_state }}\"\n      disable_gpg_check: True\n    with_items: \"{{ enroot_rpm_packages }}\"\n    environment: \"{{proxy_env if proxy_env is defined else {}}}\"\n</code></pre> <ul> <li>firewall<ul> <li>systemctl status firewalld.service</li> </ul> </li> </ul>"},{"location":"hackmd/Slurm/#faq","title":"FAQ","text":"<ul> <li>Slurm Workload Manager - Slurm Troubleshooting Guide</li> <li>\u570b\u7db2\u4e2d\u5fc3-\u8a08\u7b97\u8cc7\u6e90\u670d\u52d9\u7db2</li> <li>centos - Restart nodes in state down - Stack Overflow</li> </ul>"},{"location":"hackmd/Spack/","title":"Spack","text":"<ul> <li>spack-cineca23-tutorial-slides.pdf</li> <li>Tutorial: Spack 101 \u2014 Spack Tutorial documentation</li> <li>Getting Started \u2014 Spack 0.20.0.dev0 documentation</li> <li>Spack \u5165\u95e8\u6307\u5357 \u2013 refraction-ray</li> <li>Spack \u6307\u4ee4\u6559\u5b78 - HackMD</li> <li>Package List \u2014 Spack 0.20.0.dev0 documentation</li> <li>Command Reference \u2014 Spack 0.20.0.dev0 documentation</li> <li>error<ul> <li>==&gt; Error: hdf5 does not depend on openmpi \u2014 Debugging Notes 0.1 documentation</li> </ul> </li> </ul>"},{"location":"hackmd/Spack/#changelog","title":"changelog","text":"<ul> <li>CHANGELOG.md \u00b7 develop \u00b7 spack / spack \u00b7 GitLab <p>LD_LIBRARY_PATH is no longer set by default by spack load or module loads. v0.19.1 (2023-02-07)</p> </li> </ul>"},{"location":"hackmd/Spack/#installuninstall","title":"install/uninstall","text":"<p>Spack can install software either from source or from a binary cache. Packages in the binary cache are signed with GPG for security.</p> <p>By default this will install the binary cached version if it exists and fall back on installing from source if it does not.</p> <p>The % sigil is used to specify compilers. The @ sigil is used to specify versions, both of packages and of compilers. Dependencies can be explicitly requested using the ^ sigil.</p> <p>The spec syntax also includes compiler flags.  Spack accepts cppflags, cflags, cxxflags, fflags, ldflags, and ldlibs parameters. The values of these fields must be quoted on the command line if they include spaces. </p> <p>Spack generates a hash for each spec.  This hash is a function of the full provenance of the package, so any change to the spec affects the hash.  Spack uses this value to compare specs and to generate unique installation directories for every combinatorial version. </p> <p>By default, Spack tries hard to reuse existing installations as dependencies, either from a local store or from configured remote buildcaches.</p> <p>:star: Spack models the dependencies of packages as a directed acyclic graph (DAG).</p> <p>We can use either -f (force) or -R (remove dependents as well) to remove packages that are required by another installed package.</p> <p>``` bash=</p>"},{"location":"hackmd/Spack/#add-spack-to-your-path","title":"add Spack to your path","text":"<p>. share/spack/setup-env.sh</p> <p>spack install zlib spack install zlib %clang spack versions zlib spack install zlib@1.2.8 spack install zlib %gcc@6.5.0 spack install zlib@1.2.8 cppflags=-O3 spack install tcl spack install tcl ^zlib@1.2.8 %clang</p>"},{"location":"hackmd/Spack/#query-installed-packages","title":"query installed packages","text":"<p>spack find</p>"},{"location":"hackmd/Spack/#the-l-flag-shows-the-hash-of-each-package-and","title":"The -l flag shows the hash of each package, and","text":""},{"location":"hackmd/Spack/#the-f-flag-shows-any-non-empty-compiler-flags-of-those-packages","title":"the -f flag shows any non-empty compiler flags of those packages.","text":""},{"location":"hackmd/Spack/#-d-flag-which-can-show-dependency-information","title":"-d flag, which can show dependency information","text":"<p>spack find -ldf</p> <p>spack uninstall -y zlib %gcc@6.5.0 spack uninstall zlib/2xc spack uninstall -y -R zlib/2xc <pre><code>HDF5 is a good example of a more complicated package, with an MPI dependency.\n\nIf we install it \u201cout of the box,\u201d it will build with OpenMPI.\n\nSpack packages can also have build options, called variants. Boolean variants can be specified using the + (enable) and ~ or - (disable) sigils.\n\nWe might also want to install HDF5 with a different MPI implementation. \nWhile MPI is not a package itself, packages can depend on abstract interfaces like MPI. \nSpack handles these through **virtual dependencies**. \nA package, such as HDF5, can depend on the MPI interface. Other packages (openmpi, mpich, mvapich2, etc.) provide the MPI interface. Any of these providers can be requested for an MPI dependency. \n\nFor example, we can build HDF5 with MPI support provided by MPICH by specifying a dependency on mpich. \nSpack also supports versioning of virtual dependencies. \nA package can depend on the MPI interface at version 3, and provider packages specify what version of the interface they provide.\n\n``` bash=\nspack install hdf5\nspack install hdf5~mpi\nspack install hdf5+hl+mpi ^mpich\nspack graph hdf5+hl+mpi ^mpich\n</code></pre></p> <p>let\u2019s look at an even more complicated package, Trilinos.</p> <p>Although we\u2019ve done a binary installation for the tutorial, a source installation of Trilinos using Spack takes about 3 hours (depending on the system), but only 20 seconds of programmer time.</p> <p>The ASCII output from spack graph can be difficult to parse for complicated packages. The output can be changed to the Graphviz .dot format using the --dot flag.</p> <p>``` bash= spack install trilinos spack install trilinos +hdf5 ^hdf5+hl+mpi ^mpich spack graph --dot trilinos | dot -Tpdf &gt; trilinos_graph.pdf <pre><code>## Customizing Compilers\n\nSpack manages a list of available compilers on the system, detected automatically from the user\u2019s PATH variable.\n\nThe compilers are maintained in a YAML file.\n~/.spack/linux/compilers.yaml\n\n``` bash=\nspack compiler list\nspack compilers\n\nspack install gcc@8.4.0\n# We can add GCC to Spack as an available compiler using the spack compiler add command.\nspack compiler add \"$(spack location -i gcc@8.4.0)\"\nspack compiler remove gcc@8.4.0\n</code></pre></p>"},{"location":"hackmd/Spack/#find","title":"find","text":"<p>``` bash=</p>"},{"location":"hackmd/Spack/#return-every-installed-package-that-depends-on-mpich","title":"return every installed package that depends on MPICH","text":"<p>spack find ^mpich</p>"},{"location":"hackmd/Spack/#return-every-package-which-was-built-with-cppflags-o3","title":"return every package which was built with cppflags=\"-O3\"","text":"<p>spack find cppflags=\"-O3\"</p>"},{"location":"hackmd/Spack/#show-which-packages-were-installed-explicitly-rather-than-pulled-in-as-a-dependency-using-the-lowercase-x-flag","title":"show which packages were installed explicitly (rather than pulled in as a dependency) using the lowercase -x flag.","text":""},{"location":"hackmd/Spack/#the-uppercase-x-flag-shows-implicit-installs-only","title":"The uppercase -X flag shows implicit installs only.","text":"<p>spack find -px</p> <pre><code>## Environment\n- [Environments Tutorial \u2014 Spack Tutorial documentation](https://spack-tutorial.readthedocs.io/en/latest/tutorial_environments.html#environments-tutorial)\n- [Stacks Tutorial \u2014 Spack Tutorial documentation](https://spack-tutorial.readthedocs.io/en/latest/tutorial_stacks.html)\n\n\nAn environment is like a virtualized Spack instance that you can use to aggregate package installations for a project or other purpose.\n\n``` bash=\n# add Spack to your path\n. share/spack/setup-env.sh\n\n\nspack env list\nspack env create foo\n# activate our environment\nspack env activate -p foo\nspack env status\nspack env deactivate\n</code></pre> <p>:::info If you use the -p option for spack env activate, Spack will prepend the environment name to the prompt. This is a handy way to be reminded if and which environment you are in. :::</p> <p>Environments are special in that you must add specs to them before installing.</p> <p>``` bash=</p> <pre><code>spack.yaml\n``` bash\nls -la var/spack/environments/foo/\n# other way\nspack cd -e foo\npwd &amp;&amp; ls -la\n\n\nspack config get\nspack config edit\n</code></pre> <p>There are two key files tracking the contents of environments: spack.yaml and spack.lock. </p> <p>The spack.yaml file holds the environment configuration that we previously edited through spack config edit.  The spack.lock file is automatically generated during concretization.</p> <p>``` bash= spack env create abstract-foo spack.yaml spack env create concrete-foo spack.lock <pre><code>## Modules\n- [Modules (modules.yaml) \u2014 Spack 0.20.0.dev0 documentation](https://spack.readthedocs.io/en/latest/module_file_support.html)\n\n\nSpack integrates with Environment Modules and Lmod by providing post-install hooks that generate module files and commands to manipulate them.\n\nSpack only generates modulefiles when a package is installed. If you attempt to install a package and it is already installed, Spack will not regenerate modulefiles for the package. \n\nthere is a subsection on regenerating modules that will allow you to bring your modules to a consistent state.\n\n``` bash=\nmodule avail\n# regenerating modules\nspack module tcl refresh\nmodule avail\n</code></pre></p>"},{"location":"hackmd/Spack/#spec","title":"spec","text":"<pre><code>spack spec -N hdf5\n</code></pre>"},{"location":"hackmd/UI%20Framework/","title":"UI Framework","text":"<ul> <li>UI \u5957\u4ef6\u8cde\u6790 | \u516d\u5c0f\u7de8 Editor Leon</li> <li>Airbnb \u7684\u8996\u89ba\u5316\u5716\u8868\u5143\u4ef6\u5eab - visx - MyApollo<ul> <li>https://airbnb.io/visx/gallery</li> </ul> </li> </ul>"},{"location":"hackmd/Ubuntu/","title":"Ubuntu","text":"<ul> <li>Ubuntu \u958b\u653e root \u767b\u5165 ssh - Linux \u6280\u8853\u624b\u672d</li> <li>Ubuntu\u7cfb\u7d71\u4e0bmake install\u6307\u4ee4\u524d\uff0c\u4e09\u601d\u800c\u5f8c\u884c \u00b7 Ivon\u7684\u90e8\u843d\u683c<ul> <li>Linux\u61c9\u8a72\u7528\u4f55\u7a2e\u65b9\u6cd5\u5b89\u88dd\u61c9\u7528\u7a0b\u5f0f\uff0c\u8ac7\u8ac7\u6211\u7684\u8edf\u9ad4\u5b89\u88dd\u504f\u597d\u4f86\u6e90 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> <li>\u5982\u4f55\u5b89\u88ddUbuntu\u81f3\u5916\u63a5SSD\uff0c\u518d\u5f9e\u786c\u789f\u5916\u63a5\u76d2\u958b\u6a5f \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/Ubuntu/#install","title":"install","text":"<ul> <li>install ubuntu server without internet - Linux - Spiceworks Community<ul> <li>if there is no internet when installation, disable the nic when installation selection gui</li> </ul> </li> </ul>"},{"location":"hackmd/Ubuntu/#package","title":"package","text":"<ul> <li>Package search</li> <li>Package management | Ubuntu</li> <li>apt - Debian: The repository CDROM does not have a Release file - Unix &amp; Linux Stack Exchange</li> <li>ubuntu - \"Repository does not have a release file\" error - Stack Overflow</li> <li>How to Fix \"Repository is not valid yet\" Error in Ubuntu Linux<ul> <li>The reason for the error is the difference in the time on the system and the time in real world.</li> <li>sudo apt update error: \"Release file is not yet valid\" - Ask Ubuntu</li> </ul> </li> <li>updates - How to I prevent Ubuntu from kernel version upgrade and notification? - Ask Ubuntu</li> <li>APT-GET\u201cCouldn\u2019t create temporary file for passing config to apt-key\u201d\u95ee\u9898\u89e3\u51b3 | Kaijia</li> </ul> <p>https://chatgpt.com/share/5c29bffa-77fa-4399-8c05-82bf52b45153 Package lists in /var/lib/apt/lists/ Package cache in /var/cache/apt/archives/ Status files in /var/lib/dpkg/status</p> <p>https://chatgpt.com/share/04254bb6-982d-4b57-95ad-80bba922d3e3 <pre><code>apt remove ansible\napt --purge autoremove\n</code></pre></p> <p>prevent kernel upgrade <pre><code>apt-mark hold $(uname -r)\n</code></pre></p>"},{"location":"hackmd/Ubuntu/#offiline-and-local-repository","title":"offiline and local repository","text":"<ul> <li>Repositories/CommandLine - Community Help Wiki<ul> <li>Understanding Ubuntu\u2019s Repository System [Beginner's Guide]<ul> <li>What is the Use of sources.list File in Ubuntu Linux?</li> <li>How to Enable Universe and Multiverse Repositories in Ubuntu</li> <li>PPA in Ubuntu Linux [Definitive Guide]</li> <li>Installing Packages From External Repositories in Ubuntu</li> </ul> </li> </ul> </li> <li>[Linux] Ubuntu \u5982\u4f55\u96e2\u7dda\u5b89\u88dd\u5957\u4ef6\uff0c\u89e3\u6c7a\u76f8\u4f9d\u6027\u5957\u4ef6\u554f\u984c - \u9756\u6280\u5834</li> <li>AptGet/Offline/Repository - Community Help Wiki</li> <li>How to Setup Local APT Repository Server on Ubuntu 22.04<ul> <li>apt-mirror</li> </ul> </li> <li>apt-offline</li> <li>proxy<ul> <li>[Ubuntu 22.04] APT proxy\u8a2d\u5b9a - Ianyc - Medium</li> <li>Apt through Socks proxy - Zeroplex \u751f\u6d3b\u96a8\u7b46</li> </ul> </li> <li>Debian Repository<ul> <li>https://chat.openai.com/share/fd934a1a-e755-4f24-a21b-ca7512474847</li> <li>How to create local Debian repository</li> <li>How to create a simple debian repository with minimal dependences \u00b7 GitHub</li> <li>Create local package repository on Ubuntu</li> </ul> </li> </ul> <pre><code>/etc/apt/sources.list\n/etc/apt/sources.list.d/\n/var/cache/apt/archives/\n/usr/share/keyrings/\n</code></pre> <pre><code>ls -la /var/cache/apt/archives\napt-get install --download-only abc\nsudo dpkg -i *.deb\n</code></pre> <pre><code>apt-cache policy\napt-cache policy rocm\napt list --installed\n</code></pre> <p>the Ubuntu software repository is organized into four \"components\" on the basis of the level of support Ubuntu can offer them and whether or not they comply with Ubuntu's Free Software Philosophy. - Main (officially supported software) - Restricted (supported software that is not available under a completely free license) - Universe (community-maintained, i.e. not officially-supported software) - Multiverse (software that is \"not free\").</p> <p>deb repo \u7684 url \u7d44\u6210 - Ubuntu 16.04 \u5efa\u7acb APT Mirror site \u2013 Mr. \u6c99\u5148\u751f <pre><code>deb http://nginx.org/packages/mainline/ubuntu xenial nginx\n</code></pre> xenial nginx \u5f9e dists \u5f8c\u7684\u76ee\u9304\u5230 binary-amd64, binary-i386, source</p> <pre><code>dpkg-scanpackages --multiversion . /dev/null | gzip -9c &gt; Packages.gz\n</code></pre> <pre><code>dpkg-scanpackages --multiversion . &gt; Packages\n</code></pre>"},{"location":"hackmd/Ubuntu/#pinning-file","title":"pinning file","text":"<ul> <li>https://chatgpt.com/share/a7e6b06d-e031-4d58-ad5c-e62d7ea394d7</li> </ul> <p>for local repository</p> <p>/etc/apt/sources.list.d/localrepo.list <pre><code>deb [trusted=yes] file:/root/install ./\n</code></pre></p> <p>/etc/apt/preferences.d/rocm-pin-600 <pre><code>Package: *\nPin: origin \"\"\nPin-Priority: 600\n</code></pre></p>"},{"location":"hackmd/Ubuntu/#apt-proxy","title":"apt proxy","text":"<ul> <li>[Ubuntu 22.04] APT proxy\u8a2d\u5b9a - Ianyc - Medium</li> <li>Ubuntu 18.04 Proxy \u8a2d\u5b9a | \u4e0d\u52d9\u6b63\u696d\u5de5\u7a0b\u5e2b\u7684\u5bb6</li> </ul> <p>/etc/apt/apt.conf.d/proxy.conf <pre><code>Acquire::http::Proxy \"http://&lt;Proxy_Server_IP&gt;:&lt;Port&gt;/\";\nAcquire::https::Proxy \"http://&lt;Proxy_Server_IP&gt;:&lt;Port&gt;/\";\n</code></pre></p> <pre><code>Acquire::http::Proxy \"http://user:password@proxy.server:port/\";\nAcquire::https::Proxy \"https://user:password@proxy.server:port/\";\n</code></pre>"},{"location":"hackmd/Ubuntu/#dns","title":"dns","text":"<ul> <li>[Ubuntu 22.04] DNS\u8a2d\u5b9a - Ianyc - Medium</li> <li>domain name system - systemd-resolve fails to resolve hostnames when using bind9 - Server Fault</li> </ul>"},{"location":"hackmd/Ubuntu/#iso","title":"ISO","text":"<ul> <li>GitHub - PJ-Singh-001/Cubic: The Official Web Site for Cubic (Custom Ubuntu ISO Creator) (https://github.com/PJ-Singh-001/Cubic)</li> </ul>"},{"location":"hackmd/Ubuntu/#netboot","title":"Netboot","text":"<ul> <li>DisklessUbuntuHowto - Community Help Wiki</li> <li>How to netboot the server installer on amd64 | Ubuntu</li> <li>iPXE \u5f15\u5bfc ubuntu \u5e76\u4f7f\u7528 preseed \u81ea\u52a8\u5b89\u88c5\u7cfb\u7edf | \u5c0f\u9a6c\u8fc7\u6cb3</li> <li>Network Boot Ubuntu Server ISO via Preboot Execution Environment (PXE) \u2013 Technical Scratchpad</li> <li>Netbooting the live server installer - Server - Ubuntu Community Hub</li> <li>\u73a9\u5177\u70cf\u6258\u90a6: Debian Live: \u628a\u5df2\u704c\u5165\u786c\u789f\u7684\u7cfb\u7d71\u8b8a\u6210 live cd</li> </ul>"},{"location":"hackmd/Ubuntu/#debootstrap","title":"debootstrap","text":"<ul> <li>blog-src/\u4f7f\u7528 debootstrap \u5efa\u7acb\u5b8c\u6574\u7684 Debian \u7cfb\u7d71.org at master \u00b7 KingBing/blog-src</li> <li>Is there a (current) debootstrap-like tool for Rocky/CentOS/RHEL distros? : r/linuxquestions</li> </ul> <p>```bash= debootstrap --arch amd64 jammy /tmp/test_ramos http://archive.ubuntu.com/ubuntu/ <pre><code>## autoinstall\n- [Autoinstall configuration reference manual - Ubuntu installation documentation](https://canonical-subiquity.readthedocs-hosted.com/en/latest/reference/autoinstall-reference.html)\n    - [cloud init \u4ecb\u7d39 - HackMD](https://hackmd.io/@txLtb1_dT1eziDq4utYbqA/ryUSQD_wu#%E4%B8%80%E5%88%87%E8%B3%87%E6%96%99%E7%9A%84%E8%B5%B7%E9%BB%9E--metadata-)\n- [Cloud config examples - cloud-init 24.2 documentation](https://docs.cloud-init.io/en/latest/reference/examples.html)\n- debug\n    - /var/log/installler/subiquity-server-debug.log\n\n\n## LiveCD\n- [Customising Ubuntu live ISOs with Docker \u00b7 Samuel Lai](https://slai.github.io/posts/customising-ubuntu-live-isos-with-docker/)\n- [GitHub - mvallim/live-custom-ubuntu-from-scratch](https://github.com/mvallim/live-custom-ubuntu-from-scratch)\n- [\u4ece\u96f6\u5236\u4f5c Ubuntu 20.04 LiveCD - \u873b\u8713\u7684\u7a9d](https://dragonfly.fun/linux/livecd.html)\n- [\u3010\u5fc3\u5f97\u3011\u88fd\u4f5c Linux LiveCD ... - studentc\u7684\u5275\u4f5c - \u5df4\u54c8\u59c6\u7279](https://home.gamer.com.tw/artwork.php?sn=4792613)\n\nTest failure\n``` bash\napt install debootstrap mksquashfs grub-efi mtools xorriso\nmkdir -p $HOME/live-ubuntu-from-scratch/target\nmkdir -p $HOME/live-ubuntu-from-scratch/livecd/{casper,boot/grub,EFI/boot}\ndebootstrap  --include=linux-image-generic,live-boot --components=main,universe,multiverse --arch=amd64  --variant=minbase jammy $HOME/live-ubuntu-from-scratch/target  http://archive.ubuntu.com/ubuntu\n\ncp $HOME/live-ubuntu-from-scratch/target/boot/vmlinuz-**-**-generic $HOME/live-ubuntu-from-scratch/livecd/casper/vmlinuz\ncp $HOME/live-ubuntu-from-scratch/target/boot/initrd.img-**-**-generic $HOME/live-ubuntu-from-scratch/livecd/casper/initrd.img\n\nchroot $HOME/live-ubuntu-from-scratch/target dpkg-query -W --showformat='${Package} ${Version}\\n' | sudo tee $HOME/live-ubuntu-from-scratch/livecd/casper/filesystem.manifest\n\nmksquashfs $HOME/live-ubuntu-from-scratch/target \\\n   $HOME/live-ubuntu-from-scratch/livecd/casper/filesystem.squashfs \\\n   -noappend -no-duplicates -no-recovery \\\n   -wildcards \\\n   -comp xz -b 1M -Xdict-size 100% \\\n   -e \"var/cache/apt/archives/*\" \\\n   -e \"root/*\" \\\n   -e \"root/.*\" \\\n   -e \"tmp/*\" \\\n   -e \"tmp/.*\" \\\n   -e \"swapfile\"\n\n\nsudo tee $HOME/live-ubuntu-from-scratch/livecd/boot/grub/grub.cfg &lt;&lt; EOF\nsearch --set=root --file /casper/vmlinuz\ninsmod all_video\nset timeout=30\nmenuentry \"Ubuntu 22.04 Live\" {\n   linux /casper/vmlinuz boot=casper nopersistent toram quiet splash --\n   initrd /casper/initrd.img\n}\nEOF\ngrub-mkstandalone \\\n  --format=x86_64-efi \\\n  --output=$HOME/live-ubuntu-from-scratch/livecd/EFI/boot/bootx64.efi \\\n  --locales=\"\" --fonts=\"\" \\\n   \"boot/grub/grub.cfg=$HOME/live-ubuntu-from-scratch/livecd/boot/grub/grub.cfg\"\n\nLC_CTYPE=C bash -s &lt;&lt; EOF\ndd if=/dev/zero of=efiboot.img bs=1M count=3 &amp;&amp; \\\nmkfs.vfat efiboot.img &amp;&amp; \\\nmmd -i efiboot.img efi efi/boot &amp;&amp; \\\nmcopy -i efiboot.img $HOME/live-ubuntu-from-scratch/livecd/EFI/boot/bootx64.efi ::efi/boot/\nEOF\n\nxorriso \\\n  -as mkisofs \\\n  -iso-level 3 \\\n  -full-iso9660-filenames \\\n  -volid \"UBUNTU\" \\\n  -output Ubuntu-22.04-LiveCD-x86_64.iso \\\n  -no-emul-boot -boot-load-size 4 -boot-info-table \\\n  --eltorito-catalog boot/grub/boot.cat \\\n  --grub2-boot-info \\\n  --grub2-mbr /usr/lib/grub/i386-pc/boot_hybrid.img \\\n  -eltorito-alt-boot -e EFI/efiboot.img -no-emul-boot -append_partition 2 0xef efiboot.img \\\n  -graft-points \"livecd\" \"/EFI/efiboot.img=efiboot.img\"\n</code></pre></p>"},{"location":"hackmd/Ubuntu/#autoinstall-iso","title":"Autoinstall ISO","text":"<ul> <li>Ubuntu 22.04 Server Autoinstall ISO | Puget Systems</li> </ul>"},{"location":"hackmd/Web%20Server/","title":"Web Server","text":""},{"location":"hackmd/Web%20Server/#apache","title":"Apache","text":"<p>a2dissite a2enmod a2dismod apache2ctl</p> <pre><code>sudo a2enmod headers\nsudo apache2ctl -M | grep headers\nsudo a2dismod headers\n\nsudo apache2ctl configtest\n\nsudo a2dissite 000-default.conf\n\nsudo service apache2 restart\n</code></pre> <p>/etc/apache2/sites-available/foo.com.conf <pre><code>&lt;Directory /var/www/foo.com/public_html&gt;\n        Options -Indexes -Includes\n        AllowOverride None\n&lt;/Directory&gt;\n&lt;VirtualHost *:80&gt;\n        ServerAdmin admin@foo.com\n        ServerName foo.com\n        DocumentRoot /var/www/foo.com/public_html\n\n        ErrorLog ${APACHE_LOG_DIR}/error.log\n        CustomLog ${APACHE_LOG_DIR}/access.log combined\n&lt;/VirtualHost&gt;\n\n&lt;VirtualHost *:443&gt;\n        ServerAdmin admin@foo.com\n        ServerName foo.com\n        DocumentRoot /var/www/foo.com/public_html\n\n        ErrorLog ${APACHE_LOG_DIR}/error.log\n        CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n        SSLEngine on\n        SSLCertificateFile /etc/apache2/ssl/foo.com_44C466971855FC81DFD6E1FC8B3CBE2A.cer\n        SSLCertificateKeyFile /etc/apache2/ssl/private/foo.com.key\n        SSLCertificateChainFile /etc/apache2/ssl/foo.com_intermediate.cer\n&lt;/VirtualHost&gt;\n\n# Headers for secutiry concern\n&lt;IfModule mod_headers.c&gt;\n        Header always append X-Frame-Options SAMEORIGIN\n        Header always append X-Content-Type-Options \"nosniff\"\n        Header set X-XSS-Protection \"1; mode=block\"\n        Header edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure\n&lt;/IfModule&gt;\n</code></pre></p>"},{"location":"hackmd/Web%20Server/#_1","title":"\u53c3\u8003","text":"<ul> <li>\u4e00\u53f0\u4e3b\u6a5f\u4f46\u9700\u8981\u67b6\u8a2d\u5169\u500b\u4ee5\u4e0a\u7684\u7db2\u7ad9 - Amazon EC2 Ubuntu \u8a2d\u5b9a Apache Virtual Hosts</li> <li>Apache Web Server Hardening and Security Guide</li> <li>how-to-config-apache2-to-redirect-url</li> <li>How To Increase Max Connections in Apache</li> <li>Apache Module mod_cache</li> </ul>"},{"location":"hackmd/Web%20Server/#ssl","title":"SSL","text":"<ul> <li>How to configure SSL/TLS in Apache httpd? - Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/Web%20Server/#nginx","title":"Nginx","text":"<ul> <li>nginx \u7b46\u8a18 - HackMD</li> <li>\u6dfa\u8ac7 Nginx \u57fa\u672c\u914d\u7f6e\u3001\u8ca0\u8f09\u5747\u8861\u3001\u7de9\u5b58\u548c\u53cd\u5411\u4ee3\u7406 - Max\u884c\u92b7\u8a8c</li> <li>[\u90e8\u5c6c\u7db2\u7ad9]Nginx + uWSGI + Flask - HackMD</li> <li>Nginx with SSL Termination | All About</li> </ul>"},{"location":"hackmd/Windows/","title":"Windows","text":"<ul> <li>\u5728 Windows \u4e0a\u8a2d\u5b9a\u958b\u767c\u74b0\u5883 | Microsoft Learn<ul> <li>\u5728 Windows 10 \u4e0a\u555f\u7528 Hyper-V | Microsoft Learn</li> <li>\u5b89\u88dd WSL | Microsoft Learn<ul> <li>Windows Subsystem for Linux - Microsoft Store \u61c9\u7528\u7a0b\u5f0f</li> </ul> </li> </ul> </li> <li>Windows Terminal - Microsoft Store \u61c9\u7528\u7a0b\u5f0f</li> <li>Moonlight + Sunshine + \u5916\u7db2\u9023\u7dda\u5b89\u88dd\u6559\u5b78\uff0cWindows\u9060\u7aef\u4e32\u6d41\u73a9\u904a\u6232 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>Windows 11 \u526a\u8cbc\u7c3f\u7121\u9650\u95b1\u8b80: Windows 11 \u7684\u65b0\u9ad4\u9a57 | \u524d\u7aef\u4e09\u5206\u9418 | \u4e00\u8d77\u7528\u4e09\u5206\u9418\u5206\u4eab\u6280\u8853\u8207\u77e5\u8b58</li> </ul> <p><code>Win + R</code> + <code>winver</code>:\u78ba\u8a8d\u7248\u672c\u8207\u7d44\u5efa\u865f\u78bc <code>Win + G</code>: \u958b\u555f\u9304\u5f71\u5de5\u5177\uff0c\u9304\u88fd\u7576\u524d\u7a0b\u5f0f\u756b\u9762\u7684\u64cd\u4f5c <code>Win + .</code>: \u53ef\u4ee5\u53eb\u51fa\u8868\u60c5\u7b26\u865f</p>"},{"location":"hackmd/Windows/#wsl","title":"WSL","text":"<p>basic - \u7528 WSL + VSCode \u91cd\u65b0\u6253\u9020 Linux \u958b\u767c\u74b0\u5883 \u2014 \u5b89\u5fb7\u9b6f\u7684\u90e8\u843d\u683c - \u4f7f\u7528 WSL 2 \u6253\u9020\u512a\u8cea\u7684\u591a\u91cd Linux \u958b\u767c\u74b0\u5883 | The Will Will Web     - WSL 2 \u662f\u5426\u4f7f\u7528 Hyper-V\uff1f \u662f\u5426\u53ef\u4ee5\u5728Windows 10 \u5bb6\u7528\u7248\u548cWindows 11 \u5bb6\u7528\u7248\u4e0a\u4f7f\u7528 - \u91dd\u5c0d\u9069\u7528\u65bc Linux \u7684 Windows \u5b50\u7cfb\u7d71\u9032\u884c\u7591\u96e3\u6392\u89e3 | Microsoft Learn - WSL \u7684\u57fa\u672c\u547d\u4ee4 | Microsoft Learn - \u7528 WSL \u5728 Windows \u4e0a\u6253\u9020 Linux \u7684\u958b\u767c\u9ad4\u9a57 - Luka \u7684 Python \u7b46\u8a18 - Neutrino's Blog: Windows \u5e73\u53f0\u6253\u9020\u6975\u81f4\u306e\u7a0b\u5f0f\u958b\u767c\u5de5\u4f5c\u74b0\u5883 - Rebooting Ubuntu on Windows without rebooting Windows? - Super User - In Ubuntu WSL, how can you store permanent environment variables? - Stack Overflow - Getting started with RHEL on WSL | Red Hat Developer - \u4e0d\u53eaUbuntu\uff01Windows WSL\u7528Distrobox\u88dd\u591a\u91cdLinux\u5bb9\u5668 \u00b7 Ivon\u7684\u90e8\u843d\u683c     - \u5728 WSL2 \u4e2d\u4f7f\u7528 Ubuntu \u684c\u9762\u74b0\u5883 - \u5728 WSL2 \u4e2d\u4f7f\u7528 Ubuntu \u684c\u9762\u74b0\u5883 - WSL \u52a0\u5165\u8a2d\u5b9a\u7684\u5716\u5f62\u4ecb\u9762 \u2013 Heresy's Space</p> <p>config - WSL \u4e2d\u7684\u9032\u968e\u8a2d\u5b9a\u7d44\u614b | Microsoft Learn - windows 10 - How do I change the DNS settings for WSL2? - Super User - networking - WSL-2: Which ports are automatically forwarded? - Stack Overflow</p> <pre><code>wsl --export Ubuntu D:\\Backup\\wsl\\ubuntu-20-dev.tar\n</code></pre> <p>docker - WSL\uff5c\u5728 WSL2 \u4e2d\u5b89\u88c5 Docker - HackMD - \u4f7f\u7528WSL2\u5728Windows\u4e0b\u5feb\u901f\u6253\u9020Linux\u958b\u767c\u74b0\u5883(\u542bDocker)</p> <p>```bash= $ curl -fsSL https://get.docker.com -o get-docker.sh $ sudo sh get-docker.sh $ sudo service docker start <pre><code>systemd support\n- [Systemd support is now available in WSL! - Windows Command Line](https://devblogs.microsoft.com/commandline/systemd-support-is-now-available-in-wsl/)\n    - windows 11\n- [systemd \u652f\u63f4](https://learn.microsoft.com/zh-tw/windows/wsl/wsl-config#systemd-support)\n- [Systemd support is now available in WSL! - Windows Command Line](https://devblogs.microsoft.com/commandline/systemd-support-is-now-available-in-wsl/)\n    - [WSL2 \u4e2d\u4f7f\u7528 systemd \u7ba1\u7406 podman \u7684 container | omegaatt](https://www.omegaatt.com/blogs/develop/2023/wsl2_systemd_podman/)\n\n\npycharm\n- [Getting PyCharm to recognize python on the windows linux subsystem (bash on windows) - Stack Overflow](https://stackoverflow.com/questions/37000166/getting-pycharm-to-recognize-python-on-the-windows-linux-subsystem-bash-on-wind)\n- [Can't make a virtual env in PyCharm using a WSL Python interpreter - Stack Overflow](https://stackoverflow.com/questions/64087507/cant-make-a-virtual-env-in-pycharm-using-a-wsl-python-interpreter)\n- [cant find WSL interpreter in Pycharm add python interpreter screen - Stack Overflow](https://stackoverflow.com/questions/63233224/cant-find-wsl-interpreter-in-pycharm-add-python-interpreter-screen)\n- [Compare PyCharm Professional vs. PyCharm Community - JetBrains IDE](https://www.jetbrains.com/products/compare/?product=pycharm&amp;product=pycharm-ce)\n    - The Remote Interpreter feature is not available with the Community Edition\n- [Working with projects on WSL is extremely slow, basically not possible to work with : WI-63786](https://youtrack.jetbrains.com/issue/WI-63786/Working-with-projects-on-WSL-is-extremely-slow-basically-not-possible-to-work-with)\n\nvscode\n- [Cannot launch code from WSL, cannot launch remote WSL server in VSCode \u00b7 Issue #107485 \u00b7 microsoft/vscode \u00b7 GitHub](https://github.com/microsoft/vscode/issues/107485)\n\nssh key\n- [WSL \u8207 Windows \u5171\u7528 SSH \u91d1\u9470\u767b\u5165\u9060\u7aef\u4e3b\u6a5f-\u9ed1\u6697\u57f7\u884c\u7dd2](https://blog.darkthread.net/blog/share-sshkey-between-win-n-wsl/)\n\n## Hype-V\n- [\u5728 Windows 10 Creators Update \u4e0a\u4f7f\u7528 Hyper-V \u5efa\u7acb\u865b\u64ec\u6a5f\u5668 | Microsoft Learn](https://learn.microsoft.com/zh-tw/virtualization/hyper-v-on-windows/quick-start/quick-create-virtual-machine)\n- [How to access Guest PC folder from Host? - Microsoft Q&amp;A](https://learn.microsoft.com/en-us/answers/questions/48276/how-to-access-guest-pc-folder-from-host.html)\n- [Using Enhanced Mode Ubuntu 18.04 for Hyper-V on Windows 10 - Scott Hanselman's Blog](https://www.hanselman.com/blog/using-enhanced-mode-ubuntu-1804-for-hyperv-on-windows-10)\n- [virtual machine - Hyper-V Enhanced Session. Cannot share disk between Ubuntu and Windows 10 - Super User](https://superuser.com/questions/1505636/hyper-v-enhanced-session-cannot-share-disk-between-ubuntu-and-windows-10)\n\n## OpenVPN\n- [OpenVPN-GUI-New \u2013 OpenVPN Community](https://community.openvpn.net/openvpn/wiki/OpenVPN-GUI-New#gui-group)\n- [How To Add Users to the OpenVPN Administrators Group - Smart Home Pursuits](https://smarthomepursuits.com/how-to-add-users-to-the-openvpn-administrators-group/)\n\n## vscode\n- [Work in Windows Subsystem for Linux with Visual Studio Code](https://code.visualstudio.com/docs/remote/wsl-tutorial)\n- [Get Started Tutorial for Python in Visual Studio Code](https://code.visualstudio.com/docs/python/python-tutorial#_install-a-python-interpreter)\n- [\u4f7f\u7528 Dev Tunnels (\u958b\u767c\u4eba\u54e1\u901a\u9053) \u5feb\u901f\u6253\u9020\u4e00\u500b\u5c0d\u5916\u516c\u958b\u7684\u6e2c\u8a66\u9023\u7d50 | The Will Will Web](https://blog.miniasp.com/post/2023/12/25/Port-forwarding-local-services-with-Dev-Tunnels)\n- [VS Code \u64f4\u5145\u63a8\u85a6 \u2014 Rainbow CSV - MyApollo](https://myapollo.com.tw/blog/vscode-rainbow-csv/)\n- [VS Code \u64f4\u5145\u63a8\u85a6 - Live Server - MyApollo](https://myapollo.com.tw/blog/vscode-live-server/)\n- [Visual Studio Live Share: \u5373\u6642\u7a0b\u5f0f\u78bc\u5171\u540c\u4f5c\u696d\u5de5\u5177](https://visualstudio.microsoft.com/zh-hant/services/live-share/?fbclid=IwAR3B2oFFd4kuofFKVm5qh7r5T-QCdOXSSta87b87jBhGGTdob4Ztl3Gp6-U)\n    - [VSCode live share \u4f7f\u7528\u5165\u9580\uff0c\u5f9e\u5b89\u88dd\u5230\u591a\u4eba\u5354\u4f5c\u5bebcode | XiaoSean](https://xiaosean.github.io/vscode/2018-05-19-VSCode-Live-share/)\n    - [\u4f7f\u7528 Visual Studio Live Share \u4f86\u5373\u6642\u5171\u540c\u958b\u767c \u2014 Pair programming - Dean Lin - Medium](https://medium.com/dean-lin/%E4%BD%BF%E7%94%A8-visual-studio-live-share-%E4%BE%86%E5%8D%B3%E6%99%82%E5%85%B1%E5%90%8C%E9%96%8B%E7%99%BC-pair-programming-3da182e9be3c)\n    - [\u5728 Visual Studio Code \u4e2d\u5b89\u88dd\u4e26\u767b\u5165 Live Share - Live Share | Microsoft Learn](https://learn.microsoft.com/zh-tw/visualstudio/liveshare/use/install-live-share-visual-studio-code)\n- [Visual Studio Code - JSON Tools](https://womanonrails.com/visual-studio-code)\n    - alt + M: Minify\n- [Python \u53ef\u57f7\u884c\u4f46 VSCode \u8b66\u793a\u627e\u4e0d\u5230\u5957\u4ef6-\u9ed1\u6697\u57f7\u884c\u7dd2](https://blog.darkthread.net/blog/package-not-resolved-warning-in-vscode/)\n- [Announcing a free GitHub Copilot for VS Code](https://code.visualstudio.com/blogs/2024/12/18/free-github-copilot)\n    - [Github Copilot \u514d\u8cbb\u7248 + \u76e4\u9ede\u597d\u7528\u65b0\u529f\u80fd-\u9ed1\u6697\u57f7\u884c\u7dd2](https://blog.darkthread.net/blog/github-copilot-free-plan/)\n    - [\u5728VS Code\u4e2d\u4f7f\u7528GitHub Copilot - \u4e0d\u53ca\u683c\u7814\u7a76\u5ba4](https://blog.twshop.asia/%e5%9c%a8vs-code%e4%b8%ad%e4%bd%bf%e7%94%a8github-copilot/)\n\n\nctrl + alt + \u9375\u76e4\u4e0a\u4e0b: \u540c\u6642\u7de8\u8f2f\u591a\u6e38\u6a19\n\u9078\u53d6\u4e00\u6bb5\u6587\u5b57, shift + alt + I: \u540c\u6642\u5728\u884c\u5c3e\u7de8\u8f2f\u591a\u6e38\u6a19\n\nctrl + \\` :terminal\n\nctrl + , (Control + comma): settings\n\n## SMB\n- [iPhone &amp; Windows \u900f\u904e\u5171\u7528\u8cc7\u6599\u593e\u76f4\u63a5\u4e92\u50b3\u6a94\u6848\uff0c\u4e0d\u7528\u8f14\u52a9\u8edf\u9ad4](https://www.xiaoyao.tw/2021/03/iphone-windows-share-files.html)\n\n## \u5de5\u4f5c\u6aa2\u8996\n- [\u865b\u64ec\u684c\u9762\u5feb\u6377\u9375\u653b\u7565\uff1a Windows 10 \u5fc5\u5b78\u7b2c\u4e00\u5de5\u4f5c\u6280\u5de7](https://www.playpcesor.com/2015/08/windows-10-task-view.html)\n\n## Copilot\n- [Edge \u4e2d\u7684 Copilot | Microsoft Learn](https://learn.microsoft.com/zh-tw/copilot/edge)\n\n## rsync\n- [cwRsync - Rsync for Windows | itefix.net](https://www.itefix.net/cwrsync)\n\n## proxy\n- [How can I set socks proxy on windows? - Super User](https://superuser.com/questions/1528185/how-can-i-set-socks-proxy-on-windows)\n\n## Server\n\n### DHCP server\n- [\u5728 Windows Server \u4e0a\u5b89\u88dd\u548c\u8a2d\u7f6e DHCP \u4f3a\u670d\u5668 | Microsoft Learn](https://learn.microsoft.com/zh-tw/windows-server/networking/technologies/dhcp/quickstart-install-configure-dhcp-server?tabs=gui)\n    - [DHCP Server \u5b89\u88dd\u6559\u5b78-\u65bc Windows Server \u74b0\u5883 | KJie Notes](https://www.kjnotes.com/windows/112)\n    - [DHCP Server \u8a2d\u5b9a IPv4 \u4f4d\u5740\u5132\u5099\u6c60\u6559\u5b78-\u65bc Windows Server \u74b0\u5883 | KJie Notes](https://www.kjnotes.com/windows/113)\n    - [Introduction to DHCP Policies | Microsoft Learn](https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2012-r2-and-2012/dn425039(v=ws.11))\n- [Installing and Configuring DHCP for PXE Boot on Windows Server 2016 2019 2022 - Knowledgebase 8.0 - Macrium Reflect Knowledgebase](https://knowledgebase.macrium.com/display/KNOW80/Installing+and+Configuring+DHCP+for+PXE+Boot+on+Windows+Server+2016+2019+2022)\n- [iPXE - open source boot firmware [howto:msdhcp]](https://ipxe.org/howto/msdhcp)\n- [DHCP configuration - Windows Terminal Ware](http://wtware.com/docs5/dhcp.html)\n- [Windows Terminal Ware. Boot by network. dhcp and tftp services optimization.](http://wtware.com/netman/netman1.html#dhcp)\n\n\n003 Router\n006 DNS Servers\n015 DNS Domain Name\n066 Boot Server Host Name =&gt; it seems like the next server(TFTP server)\n067 Bootfile Name\n\n``` powershell\nRestart-Service -Name \"DHCPServer\"\n</code></pre></p>"},{"location":"hackmd/bitwise%20world/","title":"bitwise world","text":"<ul> <li>8 bytes, many meanings - Julia Evans</li> <li>\u5f9e IEEE 754 \u6a19\u6e96\u4f86\u770b\u70ba\u4ec0\u9ebc\u6d6e\u9ede\u8aa4\u5dee\u662f\u7121\u6cd5\u907f\u514d\u7684. \u4ec0\u9ebc\u60c5\u6cc1\u4e0b\u53ef\u80fd\u6703\u7522\u751f\u6d6e\u9ede\u8aa4\u5dee\u3001\u53c8\u8a72\u5982\u4f55\u8655\u7406 | by Larry Lu | Starbugs Weekly \u661f\u5df4\u54e5\u6280\u8853\u5c08\u6b04 | Medium<ul> <li>\u4e4b\u6240\u4ee5\u6703\u6709\u6d6e\u9ede\u8aa4\u5dee\uff0c\u662f\u56e0\u70ba\u5341\u9032\u5236\u8f49\u4e8c\u9032\u5236\u7684\u904e\u7a0b\u4e2d\u6c92\u8fa6\u6cd5\u628a\u6240\u6709\u7684\u5c0f\u6578\u90e8\u5206\u90fd\u585e\u9032 fraction</li> <li>IEEE-754 Floating Point Converter</li> <li>Why does 0.1 + 0.2 = 0.30000000000000004?</li> </ul> </li> </ul>"},{"location":"hackmd/cloud-init/","title":"cloud-init","text":"<ul> <li>cloud init \u4ecb\u7d39 - HackMD</li> <li>Chapter\u00a02.\u00a0Introduction to cloud-init Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/container/","title":"container","text":"<ul> <li>Under the hood<ul> <li>Containers under the Hood<ul> <li>chroot: By changing the root we can isolate the process filesystem and protect the system filesystem from unwanted changes.<ul> <li>change the apparent root directory for a process (and its children).</li> </ul> </li> <li>namespace: create a sliced view on the system resources such as process IDs, mount points, networks, users, etc.</li> <li>cgroup: restrict various computer resources for processes</li> </ul> </li> <li>Ervin Szil\u00e1gyi - Containers: Under the Hood</li> <li>Learning Containers From The Bottom Up<ul> <li>some containers can be implemented using mechanisms other than namespaces and cgroups.</li> </ul> </li> </ul> </li> <li>Docker</li> <li>podman</li> <li>k8s</li> </ul> <p>container: a way of executing processes in isolation k8s: scale out by workflow</p>"},{"location":"hackmd/ffmpeg/","title":"ffmpeg","text":"<ul> <li>\u4f7f\u7528 ffmpeg \u81ea\u52d5\u7dda\u4e0a\u4e32\u6d41\u5f71\u7247\u5230 youtube \u4e0a - SSORC.tw</li> <li>\u73a9\u5177\u70cf\u6258\u90a6: DVD \u8f49\u958b\u653e\u7684\u5f71\u7247\u683c\u5f0f mkv\uff0c \u542b\u5b57\u5e55</li> <li>https://ffmpegbyexample.com/</li> </ul>"},{"location":"hackmd/influxdb/","title":"Influxdb","text":"<ul> <li>Get started with InfluxDB | InfluxDB OSS 2.0 Documentation</li> <li>Query with the InfluxDB API | InfluxDB OSS 2.0 Documentation</li> </ul>"},{"location":"hackmd/influxdb/#basic","title":"basic","text":"<p>``` bash= ./influxd <pre><code>## Telegraf\n- [Install Telegraf | Telegraf 1.27 Documentation](https://docs.influxdata.com/telegraf/v1.27/install/)\n\n``` bash=\nsudo vim /etc/telegraf/telegraf.conf\nsudo systemctl restart telegraf.service\n</code></pre></p>"},{"location":"hackmd/influxdb/#inputs","title":"inputs","text":"<ul> <li>[Feature Request] ipmitool dcmi power reading \u00b7 Issue #1566 \u00b7 influxdata/telegraf \u00b7 GitHub</li> <li>Remote SNMP Host in Chronograf host list - InfluxDB 2 / Dashboards - InfluxData Community Forums</li> </ul> <p>ipmi <pre><code>[[inputs.ipmi_sensor]]\nservers = [\"foo:bar@lan(172.17.30.139)\"]\ninterval = \"30s\"\ntimeout = \"20s\"\nmetric_version = 2\n\n\n[[inputs.exec]]\n  timeout = \"5s\"\n  data_format = \"influx\"\n  environment = [\n    \"server=172.17.30.139\",\n    \"username=foo\",\n    \"password=bar\",\n    \"interface=lan\"\n  ]\n  name_suffix=\"_dcmi_power_reading\"\n  commands = ['/bin/bash -c \"ipmitool -I $interface -H $server -U $username -P $password -c dcmi power reading | grep -Po \\\"(\\d+)(?=\\sWatts)\\\" -m1 | sed \\\"s/.*/ipmi_sensor,server=${server},name=psu_power,rack=r1,unit=watts value=&amp;/\\\"\"']\n</code></pre></p>"},{"location":"hackmd/influxdb/#outputs","title":"outputs","text":"<pre><code> [[outputs.influxdb_v2]]\n  ## The URLs of the InfluxDB cluster nodes.\n  ##\n  ## Multiple URLs can be specified for a single cluster, only ONE of the\n  ## urls will be written to each interval.\n  ## urls exp: http://127.0.0.1:9999\n  urls = [\"http://172.17.30.109:8086\"]\n\n  ## Token for authentication.\n  token = \"$INFLUX_TOKEN\"\n\n  ## Organization is the name of the organization you wish to write to; must exist.\n  organization = \"foo\"\n\n  ## Destination bucket to write into.\n  bucket = \"/tmp/t-data\"\n</code></pre>"},{"location":"hackmd/javascript/","title":"javascript","text":"<ul> <li>JavaScript | MDN</li> <li>\u4ecb\u7d39 DOM \u53ca\u4e8b\u4ef6\u6d41\u7a0b</li> <li>\u6df1\u5165\u73fe\u4ee3\u524d\u7aef\u958b\u767c<ul> <li>\u5e38\u898b\u9762\u8a66\u8003\u984c\u4e4b Vue \u8207 React \u5dee\u7570\u5728\u54ea\u88e1\uff1f\u4ee5\u53ca\u70ba\u4ec0\u9ebc React \u6bd4\u8f03\u7d05\uff1f | \u662f Ray \u4e0d\u662f Array</li> </ul> </li> <li>JavaScript \u6838\u5fc3\u7bc7<ul> <li>JavaScript \u6838\u5fc3\u7bc7 - \u9081\u5411\u9054\u4eba\u4e4b\u8def | \u516d\u89d2\u5b78\u9662</li> </ul> </li> <li>\u91cd\u65b0\u8a8d\u8b58 JavaScript</li> <li>JavaScript\u57fa\u672c\u529f\u4fee\u7149</li> <li>Basic<ul> <li>single thread</li> <li>Hoisting<ul> <li>\u512a\u9ede\u5728\u65bc\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728\u8a72\u5ba3\u544a\u4e4b\u524d\u88ab\u547c\u53eb\u4ee5\u53ca\u4f7f\u7528</li> <li>\u51fd\u5f0f\u6bd4\u8b8a\u6578\u6709\u66f4\u9ad8\u7684\u512a\u5148\u6b0a(\u50c5\u9650\u65bc\u51fd\u5f0f\u9673\u8ff0\u5f0f, \u51fd\u5f0f\u8868\u9054\u5f0f\u4e0d\u7406\u9019\u4e00\u5957)</li> <li>No failure fast</li> </ul> </li> <li>\u533f\u540d\u51fd\u5f0f</li> <li>undefined / not defined \u5dee\u7570<ul> <li>\u7576\u4e00\u500b\u8b8a\u6578\u6c92\u6709\u88ab\u8ce6\u4e88\u4efb\u4f55\u503c\uff0cJavaScript\u6703\u81ea\u52d5\u8ce6\u4e88undefined</li> </ul> </li> <li>\u9663\u5217<ul> <li>\u95dc\u65bc JavaScript \u9663\u5217 20 \u7a2e\u64cd\u4f5c\u7684\u65b9\u6cd5 | \u662f Ray \u4e0d\u662f Array</li> <li>Javascript \u5e38\u898b\u64cd\u4f5c\u7c21\u4ecb | \u6df1\u5165\u73fe\u4ee3\u524d\u7aef\u958b\u767c</li> </ul> </li> <li>BOM</li> </ul> </li> <li>Advance<ul> <li>closure<ul> <li>\u51fd\u5f0f\u5de5\u5ee0</li> </ul> </li> </ul> </li> <li>ES6<ul> <li>let &amp; const<ul> <li>\u51fa\u73fe\u524d\uff0c\u4e0d\u5c11\u958b\u767c\u8005\u90fd\u6703\u7528\u7acb\u5373\u51fd\u5f0f\u4f86\u907f\u514d\u6c59\u67d3\u5230\u5168\u57df\u8b8a\u6578<ul> <li>\u56de\u50b3\u51fd\u5f0f\u8207\u7acb\u5373\u51fd\u5f0f(IIFE)</li> </ul> </li> </ul> </li> <li>\u7bad\u982d\u51fd\u5f0f - Arrow function<ul> <li>\u6ce8\u610fthis</li> </ul> </li> <li>\u89e3\u69cb\u8ce6\u503c</li> <li>Promise<ul> <li>\u8a9e\u6cd5\u7cd6\uff1aasync/await</li> </ul> </li> </ul> </li> <li>\u548c\u5176\u4ed6\u8cc7\u6599\u6e90\u62ff<ul> <li>JavaScript\u57fa\u672c\u529f\u4fee\u7df4\uff1aDay28 - Fetch\u7df4\u7fd2(GET\u548cPOST\u8acb\u6c42)</li> <li>JavaScript\u57fa\u672c\u529f\u4fee\u7df4\uff1aDay29 - axios\u57fa\u672c\u8a9e\u6cd5\u8207\u7df4\u7fd2(GET\u3001POST\u8acb\u6c42)<ul> <li>\u4f7f\u7528Axios\u4f60\u7684API\u90fd\u600e\u9ebc\u7ba1\u7406\uff1f - I am Mike - Medium</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/javascript/#nodejs","title":"nodejs","text":"<ul> <li>\u5728\u539f\u751f Windows \u4e0a\u8a2d\u5b9a NodeJS | Microsoft Learn</li> </ul>"},{"location":"hackmd/javascript/#react","title":"react","text":"<ul> <li>\u201cEvery React Concept Explained in 12 Minutes<ul> <li>\u7528 12 \u5206\u9418\u7684\u6642\u9593\u5148\u5927\u81f4\u8a8d\u8b58\u4e00\u4e0b React \u91cd\u8981\u7684\u89c0\u5ff5\u4ee5\u53ca\u529f\u80fd\uff0c\u5305\u542b Components, JSX, Props, Children, State, Hooks, Refs, Context, Effects \u7b49\u7b49\uff0c\u9019\u4e9b\u90fd\u662f\u958b\u767c React \u61c9\u7528\u6703\u7528\u5230\u7684\u5de5\u5177</li> </ul> </li> <li>\u5b78\u7fd2\u6307\u5357\uff1aReact \u4ecb\u7d39 \u2013 React<ul> <li>Quick Start \u2013 React</li> <li>Thinking in React \u2013 React</li> </ul> </li> <li>\u7d42\u7a76\u90fd\u8981\u5b78 React \u4f55\u4e0d\u73fe\u5728\u5b78\u5462\uff1f - \u9435\u4eba\u8cfd\u5f8c\u8a18 - \u76ee\u9304 - (30) | \u662f Ray \u4e0d\u662f Array<ul> <li>\u958b\u59cb\u4e4b\u524d\u61c9\u8a72\u8981\u77e5\u9053\u7684DOM\u548cES6</li> <li>\u5b78\u597d React \u9700\u8981\u7684\u524d\u7f6e\u57fa\u672c\u529f<ul> <li>[JS] \u7bad\u982d\u51fd\u5f0f\uff08arrow function\uff09\u548c\u5b83\u5c0d this \u7684\u5f71\u97ff | PJCHENder \u672a\u6574\u7406\u7b46\u8a18</li> </ul> </li> </ul> </li> <li>\u7d66\u521d\u5165JS\u6846\u67b6\u65b0\u624b\u7684React.js\u5165\u9580 :: \u7b2c 11 \u5c46 iThome \u9435\u4eba\u8cfd</li> <li>\u5f9e\u6bd4\u5165\u9580\u518d\u5f80\u524d\u4e00\u9ede\u958b\u59cb\uff0c\u4e00\u76f4\u5230\u6df1\u5165React.js :: \u7b2c 12 \u5c46 iThome \u9435\u4eba\u8cfd</li> <li>\u4e00\u6b21\u6253\u7834 React \u5e38\u898b\u7684\u5b78\u7fd2\u9580\u6abb\u8207\u89c0\u5ff5\u8aa4\u89e3 :: 2022 iThome \u9435\u4eba\u8cfd</li> <li>Building Full Stack Applications With Python and ReactJS - YouTube</li> <li>A GUI tool to build your react app in the fastest way with all components</li> <li>Create a GUI for Python using React | by Code Review Doctor | Medium</li> <li>A Python developer's guide to React - LogRocket Blog</li> <li>UI Componets<ul> <li>React Material UI Tutorial - YouTube</li> <li>Material-UI Grid Tutorial and Examples | React.School<ul> <li>A Complete Guide to Flexbox | CSS-Tricks - CSS-Tricks</li> <li>Flexbox Patterns - Intro</li> </ul> </li> <li>shadcn UI</li> <li>The Most Popular React UI Component Libraries in 2022 - SitePoint</li> <li>React UI Components Libraries: Our Top Picks for 2023</li> <li>20+ Best React UI Component Libraries / Frameworks for 2023</li> <li>Tailwind CSS \u5230\u5e95\u662f\u826f\u85e5\u9084\u662f\u6bd2\u85e5\uff1f | Summer\u3002\u6851\u83ab\u3002\u590f\u5929</li> </ul> </li> <li>IDE<ul> <li>Retool | Build internal tools, remarkably fast.</li> </ul> </li> </ul>"},{"location":"hackmd/javascript/#concept","title":"concept","text":"<ul> <li>JSX: html in js<ul> <li>React \u91dd\u5c0d JavaScript \u6240\u51fa\u7684\u64f4\u5145\u8a9e\u6cd5</li> <li>\u662f\u4e00\u7a2e\u8a9e\u6cd5\u7cd6</li> <li>\u700f\u89bd\u5668\u4e26\u4e0d\u61c2\u4ec0\u9ebc\u53eb\u505a JSX</li> <li>key\u7684\u5f71\u97ff</li> <li>\u8868\u9054\u5f0f (Expression)<ul> <li>JavaScript \u6838\u5fc3\u89c0\u5ff5(11)-\u904b\u7b97\u5b50\u3001\u578b\u5225\u8207\u6587\u6cd5-\u9673\u8ff0\u5f0f\u8207\u8868\u9054\u5f0f | \u662f Ray \u4e0d\u662f Array</li> <li>:x: \u7121\u6cd5\u5728 JSX \u4e2d\u64b0\u5beb if...else \u5224\u65b7\u5f0f</li> <li>:heavy_check_mark: \u4e09\u5143\u904b\u7b97\u5b50</li> <li>:heavy_check_mark: \u81ea\u52d5\u5c55\u958b\u9663\u5217\u5167\u5bb9</li> <li>HTML Style \u5c31\u8981\u6ce8\u610f JSX \u63a1\u7528\u7684\u662f camelCase \u64b0\u5beb\u65b9\u5f0f</li> <li>class \u8b8a\u6210 className</li> </ul> </li> </ul> </li> <li>Class Component(\u65e9\u671f\u5beb\u6cd5): \u4f7f\u7528 ES6 \u7684 Class \u8a9e\u6cd5\u4f86\u5efa\u7acb</li> <li>Function Component(after Class Component): \u6bd4 Class Component \u7c21\u6f54\u8a31\u591a<ul> <li>\u5f9e\u5be6\u969b\u6848\u4f8b\u770b class \u8207 function component \u7684\u5dee\u7570</li> </ul> </li> <li>React Hooks: React 16.8 \u65b0\u589e\u7684\u529f\u80fd\uff0c\u800c\u5b83\u4e3b\u6253\u7684\u5c31\u662f\u4f60\u4e0d\u7528\u518d\u5beb class \u5c31\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 React \u76f8\u95dc\u529f\u80fd<ul> <li>Hooks API Reference \u2013 React</li> <li>\u4f7f\u7528\u898f\u5247<ul> <li>\u53ea\u80fd\u5728\u51fd\u5f0f\u9802\u5c64\u4f7f\u7528</li> <li>\u53ea\u80fd\u7528\u65bc Function Component<ul> <li>\u57fa\u65bc Function Component \u6240\u8a2d\u8a08\u7684\uff0c\u56e0\u6b64\u5c31\u53ea\u80fd\u5728 Function Component \u4e2d\u4f7f\u7528\uff0c\u662f\u4e0d\u80fd\u5728 Class Components \u4e2d\u4f7f\u7528\u7684</li> </ul> </li> </ul> </li> <li>React State<ul> <li>State Hook</li> <li>useState \u51fd\u5f0f\u6703\u56de\u50b3\u4e00\u500b\u9663\u5217<ul> <li>\u4f7f\u7528 \u9663\u5217\u89e3\u69cb \u53d6\u51fa\u5169\u500b\u8b8a\u6578\uff0c\u7b2c\u4e00\u500b\u8b8a\u6578\u6703\u4f5c\u70ba\u6e32\u67d3\u986f\u793a\u7528\u3001\u55ae\u7d14\u7684\u8cc7\u6599\uff0c\u7b2c\u4e8c\u500b\u5247\u662f\u544a\u77e5 React \u8cc7\u6599\u6709\u8b8a\u5316\uff0c\u6240\u4ee5\u8981\u91cd\u65b0 re-render</li> <li>\u89f8\u767c\u756b\u9762\u91cd\u65b0\u6e32\u67d3\u7684\u95dc\u9375 Hook</li> <li>\u53ef\u4ee5\u50b3\u5165\u5404\u5f0f\u5404\u6a23\u7684\u578b\u5225<ul> <li>\u9663\u5217\u8ddf\u7269\u4ef6</li> </ul> </li> </ul> </li> </ul> </li> <li>Side Effect<ul> <li>useEffect<ul> <li>\u4e3b\u8981\u5927\u591a\u7528\u9014\u90fd\u662f\u5728\u65bc\u6211\u5011\u756b\u9762 render \u4e4b\u5f8c\u8981\u505a\u67d0\u4e9b\u4e8b\u60c5<ul> <li>ex. AJAX \u884c\u70ba\u3001\u4fee\u6539 DOM \u64cd\u4f5c</li> </ul> </li> <li>\u884c\u70ba<ul> <li>After Ever Render</li> <li>Once</li> <li>On State</li> </ul> </li> <li>cleanup function<ul> <li>\u6642\u6a5f\u53ea\u6709\u5728\u4f60\u89f8\u767c\u91cd\u65b0\u6e32\u67d3\u756b\u9762\u6642\u624d\u6703\u88ab\u547c\u53eb\u4e00\u6b21</li> <li>\u9069\u5408\u7528\u65bc\u521d\u59cb\u5316\u72c0\u614b\u6216\u8005\u6e05\u9664\u7279\u5b9a\u7684\u4e8b\u4ef6\u7d81\u5b9a -\u4f7f\u7528 Props \u5c07\u8cc7\u6599\u5f80\u4e0b\u50b3\u905e, \u50b3\u905e\u592a\u6df1</li> </ul> </li> </ul> </li> <li>useContext<ul> <li>\u4e3b\u8981\u5927\u591a\u7528\u65bc\u8de8\u5143\u4ef6\u6e9d\u901a\u7684\u6280\u5de7</li> <li>\u53ea\u80fd\u63a5\u53d7 Context Object</li> </ul> </li> </ul> </li> </ul> </li> <li>\u4e8b\u4ef6\u8655\u7406<ul> <li>React \u4e8b\u4ef6\u8655\u7406\u5beb\u6cd5\u8207\u8207 \u300cInline events\u300d \u6709\u9ad8\u5ea6\u7684 87% \u795e\u4f3c</li> <li><code>on+[\u4e8b\u4ef6\u540d\u7a31]={ \u51fd\u5f0f }</code><ul> <li>\u4e8b\u4ef6\u540d\u7a31\u9996\u5b57\u6703\u662f\u5927\u5beb\u4e14\u63a1\u7528 camelCase \u65b9\u5f0f</li> <li>SyntheticEvent \u2013 React</li> </ul> </li> </ul> </li> <li>Component<ul> <li>\u6a21\u7d44\u5316\u7684\u6982\u5ff5</li> <li>\u5de2\u72c0\u7d50\u69cb</li> <li>Props: Component\u4e4b\u9593\u7684\u8cc7\u6599\u4ea4\u63db<ul> <li>\u55ae\u5411\u6578\u64da\u6d41<ul> <li>OnlyRead (\u552f\u8b80)</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/javascript/#redux","title":"Redux","text":"<ul> <li>[Redux] Redex \u6838\u5fc3\u6982\u5ff5\u7b46\u8a18</li> <li>[Redux] Redux Basic \u57fa\u790e | PJCHENder \u672a\u6574\u7406\u7b46\u8a18</li> <li>[week 23] \u6dfa\u8ac7 Redux\uff1a\u72c0\u614b\u7ba1\u7406\u662f\u4e00\u9580\u5b78\u554f - HackMD</li> </ul>"},{"location":"hackmd/javascript/#docker-with-mui","title":"docker with mui","text":"<p>Dockerfile <pre><code>FROM node:latest\n\nRUN npx create-react-app main\n\nWORKDIR /main\n\nRUN yarn add @mui/material @emotion/react @emotion/styled &amp;&amp; yarn add @fontsource/roboto &amp;&amp; yarn add @mui/icons-material\n\nEXPOSE 3000\n\nENTRYPOINT [\"npm\", \"start\"]\n</code></pre></p> <p>docker-compose.yml ``` yml= version: '3'</p> <p>services:   react-mui:     container_name: react-mui     build:       context: .     image: react-mui     working_dir: /main     ports:       - \"3000:3000\" <pre><code>``` bash=\ndocker build -t react-mui .\ndocker compose up -d\n</code></pre></p> <p>src/APP.js ``` javascript= import logo from './logo.svg'; import './App.css'; import Board from './Board'; import Notification from './Notification';</p> <p>function App() {   return (            {/ <p>           Edit <code>src/App.js</code> and save to reload.         </p>            Learn React          /}           ); }</p> <p>export default App; <pre><code>src/Board.js\n``` javascript=\nimport React from 'react';\nimport Table from '@mui/material/Table';\nimport TableBody from '@mui/material/TableBody';\nimport TableCell from '@mui/material/TableCell';\nimport TableContainer from '@mui/material/TableContainer';\nimport TableHead from '@mui/material/TableHead';\nimport TableRow from '@mui/material/TableRow';\nimport Paper from '@mui/material/Paper';\nimport Button from '@mui/material/Button';\n\nclass Board extends React.Component {\n    constructor(props) {\n      super(props);\n      this.state = {\n        rows: [\n          this.createData('Frozen yoghurt', 159, 6.0, 24, 4.0),\n          this.createData('Ice cream sandwich', 237, 9.0, 37, 4.3),\n          this.createData('Eclair', 262, 16.0, 24, 6.0),\n          this.createData('Cupcake', 305, 3.7, 67, 4.3),\n          this.createData('Gingerbread', 356, 16.0, 49, 3.9),\n        ],\n      };\n    }\n\n    createData(name, calories, fat, carbs, protein) {\n      return { name, calories, fat, carbs, protein };\n    }\n\n    handleClick() {\n      const rows = this.state.rows.slice();\n      rows.push(this.createData('Test', 356, 16.0, 49, 3.9))\n      this.setState({rows: rows});\n    }\n\n    render() {\n        return (\n            &lt;TableContainer component={Paper}&gt;\n            &lt;Table sx={{ minWidth: 650 }} aria-label=\"simple table\"&gt;\n              &lt;TableHead&gt;\n                &lt;TableRow&gt;\n                  &lt;TableCell&gt;Dessert (100g serving)&lt;/TableCell&gt;\n                  &lt;TableCell align=\"right\"&gt;Calories&lt;/TableCell&gt;\n                  &lt;TableCell align=\"right\"&gt;Fat&amp;nbsp;(g)&lt;/TableCell&gt;\n                  &lt;TableCell align=\"right\"&gt;Carbs&amp;nbsp;(g)&lt;/TableCell&gt;\n                  &lt;TableCell align=\"right\"&gt;Protein&amp;nbsp;(g)&lt;/TableCell&gt;\n                &lt;/TableRow&gt;\n              &lt;/TableHead&gt;\n              &lt;TableBody&gt;\n                {this.state.rows.map((row) =&gt; (\n                  &lt;TableRow\n                    key={row.name}\n                    sx={{ '&amp;:last-child td, &amp;:last-child th': { border: 0 } }}\n                  &gt;\n                    &lt;TableCell component=\"th\" scope=\"row\"&gt;\n                      {row.name}\n                    &lt;/TableCell&gt;\n                    &lt;TableCell align=\"right\"&gt;{row.calories}&lt;/TableCell&gt;\n                    &lt;TableCell align=\"right\"&gt;{row.fat}&lt;/TableCell&gt;\n                    &lt;TableCell align=\"right\"&gt;{row.carbs}&lt;/TableCell&gt;\n                    &lt;TableCell align=\"right\"&gt;{row.protein}&lt;/TableCell&gt;\n                  &lt;/TableRow&gt;\n                ))}\n              &lt;/TableBody&gt;\n            &lt;/Table&gt;\n            &lt;Button variant=\"contained\" onClick={() =&gt; this.handleClick()} &gt;Submit&lt;/Button&gt;\n          &lt;/TableContainer&gt;\n        );\n      }\n}\n\nexport default Board;\n</code></pre></p> <p>src/Notification.js ``` javascript= import * as React from 'react'; import Badge from '@mui/material/Badge'; import MailIcon from '@mui/icons-material/Mail';</p> <p>export default function SimpleBadge() {   return (         ); } ```</p>"},{"location":"hackmd/pacemaker/","title":"pacemaker","text":"<ul> <li>Chapter\u00a02.\u00a0Getting started with Pacemaker Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> <li>CentOS 7 \u2013 HA \u5be6\u4f5c (Pacemaker + Corosync) (\u66f4\u65b0\u5167\u5bb9-2022-1104) \u2013 Ken Wu</li> <li>How To Set Up an Apache Active-Passive Cluster Using Pacemaker on CentOS 7 | DigitalOcean</li> <li>Linux \u2022 \u7121\u9650: High-Availability \u7684\u641c\u5c0b\u7d50\u679c</li> <li>Fencing in a Red Hat High Availability Cluster - Red Hat Customer Portal</li> <li>web gui<ul> <li>Chapter\u00a09.\u00a0Getting started with the pcsd Web UI Red\u00a0Hat Enterprise\u00a0Linux 8 | Red Hat Customer Portal</li> </ul> </li> <li>xcat<ul> <li>Setup xCAT HA Mgmt with NFS pacemaker and corosync \u2014 xCAT 2.16.5 documentation</li> </ul> </li> <li>error<ul> <li>Virtual IP<ul> <li>\"ERROR: [findif] failed\" shown in Pacemaker - Red Hat Customer Portal</li> <li>pacemaker - PCS resource ipaddr2 failed to start with exitreason='[findif] failed' - Stack Overflow</li> </ul> </li> </ul> </li> </ul> <pre><code>sudo vim /etc/corosync/corosync.conf\nsudo vim /etc/httpd/conf.d/status.conf\n\n---\n# LoadModule status_module modules/mod_status.so\n&lt;Location /server-status&gt;\nSetHandler server-status\nOrder deny,allow\nDeny from all\nAllow from 127.0.0.1\nAllow from ::1\n&lt;/Location&gt;\n---\n\ncurl http://localhost/server-status\ncurl http://167.22.10.3/\n\nsudo pcs resource remove ClusterIP\nsudo pcs resource remove WebSite\nsudo pcs resource create ClusterIP ocf:heartbeat:IPaddr2 ip=167.22.10.3 cidr_netmask=16 op monitor interval=20s --group apachegroup\nsudo pcs resource create WebSite ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf statusurl=\"http://localhost/server-status\" op monitor interval=20s --group apachegroup\nsudo pcs resource create WebSite ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf statusurl=\"http://localhost/server-status\" --group apachegroup\n\nsudo pcs status\n\nsudo pcs resource cleanup WebSite\nsudo pcs resource debug-start WebSite --full\n\nsudo pcs node standby s8cn001\nsudo pcs node unstandby s8cn001\n\n\nsudo pcs cluster stop --all\n\n# fence\nsudo pcs stonith status\n</code></pre>"},{"location":"hackmd/podman/","title":"podman","text":"<ul> <li>20210127 Docker \u8207 Podman \u540c\u8207\u4e0d\u540c - Speaker Deck</li> <li>Podman: Managing pods and containers in a local container runtime | Red Hat Developer<ul> <li>https://developers.redhat.com/cheat-sheets/podman-basics</li> </ul> </li> <li>Replace docker with podman - Jiajun\u7684\u6280\u672f\u7b14\u8bb0</li> <li>Podman on Windows: \u8f15\u9b06\u8f49\u63db\u672c\u5730\u5bb9\u5668\u958b\u767c\u74b0\u5883. \u4f7f\u7528 Docker \u5df2\u7d93\u4e94\u5e74\u591a\u4e86\uff0c\u6211\u4e4b\u524d\u90fd\u662f\u5728 Linux\u2026 | by Ken Sun | Medium<ul> <li>podman compose, when Podman 4.7.0 or greater.</li> </ul> </li> </ul> <pre><code>podman ps\npodman pod list\n</code></pre>"},{"location":"hackmd/prometheus/","title":"prometheus","text":"<ul> <li>Getting started | Prometheus</li> <li>\u4f7f\u7528 Prometheus \u548c Grafana \u6253\u9020 Flask Web App \u76e3\u63a7\u9810\u8b66\u7cfb\u7d71</li> <li>Prometheus \u5b78\u7fd2\u7b46\u8a18 - \u57fa\u672c\u67b6\u69cb\u8207\u8cc7\u6599\u7d50\u69cb | omegaatt</li> <li>PromLabs | PromQL Cheat Sheet</li> <li>exporter<ul> <li>GitHub - prometheus-community/ipmi_exporter: Remote IPMI exporter for Prometheus</li> <li>GitHub - prometheus/snmp_exporter: SNMP Exporter for Prometheus</li> </ul> </li> <li>How to export Prometheus metrics into a CSV format - Red Hat Customer Portal</li> <li>Export data from Prometheus to CSV | by Aneesh Puttur | Medium</li> <li>PromQL \u5907\u5fd8 - Jiajun\u7684\u6280\u672f\u7b14\u8bb0</li> <li>\u7a0b\u5e8f\u7684 Metrics \u4f18\u5316\u2014\u2014Prometheus \u6587\u6863\u7f3a\u5931\u7684\u4e00\u7ae0 | \u5361\u74e6\u90a6\u5676\uff01<ul> <li>label\u9700\u8981\u53ef\u5217\u8209</li> <li>\u78ba\u8a8d\u9700\u6c42\u7684\u591a\u5c0d\u591a\u95dc\u4fc2\u662f\u5fc5\u8981\u7684\u55ce</li> </ul> </li> <li>\u7167\u9867 Prometheus \u7684\u751f\u6d3b\u8d77\u5c45. \u4e00\u6bb5\u628a\u5c4e\u628a\u5c3f\u7684\u6545\u4e8b | by smalltown | Starbugs Weekly \u661f\u5df4\u54e5\u6280\u8853\u5c08\u6b04 | Medium</li> <li>\u4f7f\u7528 Grafana \u8207 Prometheus \u76e3\u63a7\u6a5f\u5668\u8cc7\u6e90\u4f7f\u7528\u91cf</li> <li>Prometheus &amp; Grafana No Data \u6392\u67e5\u624b\u518c | \u5361\u74e6\u90a6\u5676\uff01</li> <li>\u5982\u4f55\u76d1\u63a7 Nginx | crossoverJie's Blog</li> <li>Prometheus \u5b78\u7fd2\u7b46\u8a18 - \u57fa\u672c\u67b6\u69cb\u8207\u8cc7\u6599\u7d50\u69cb | omegaatt</li> <li>\u76e3\u63a7\u786c\u9ad4\u8a2d\u5099(Prometheus + Exporter + Grafana) - HackMD</li> </ul> <p>``` bash= wget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz wget https://github.com/prometheus-community/ipmi_exporter/releases/download/v1.6.1/ipmi_exporter-1.6.1.linux-amd64.tar.gz tar zxvf prometheus-2.45.0.linux-amd64.tar.gz tar zxvf ipmi_exporter-1.6.1.linux-amd64.tar.gz ./prometheus --config.file=prometheus.yml <pre><code>prometheus.yml\n``` yml=\n# my global config\nglobal:\n  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\n  # scrape_timeout is set to the global default (10s).\n\n# Alertmanager configuration\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n          # - alertmanager:9093\n\n# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.\nrule_files:\n  # - \"first_rules.yml\"\n  # - \"second_rules.yml\"\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it's Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.\n  - job_name: \"prometheus\"\n\n    # metrics_path defaults to '/metrics'\n    # scheme defaults to 'http'.\n\n    static_configs:\n      - targets: [\"localhost:9090\"]\n  - job_name: \"ipmi\"\n    scrape_interval: 10s\n    scrape_timeout: 5s\n    metrics_path: /metrics\n    scheme: http\n    static_configs:\n    - targets:\n      - 167.22.10.1:9290\n      labels:\n        rack: 'r1'\n    - targets:\n      - 167.22.1.99:9290\n      labels:\n        rack: 'r3'\n</code></pre></p> <p>http://172.17.30.109:9090/metrics http://172.17.30.109:9290/metrics http://172.17.30.109:9090/api/v1/query?query=ipmi_dcmi_power_consumption_watts[10m] http://172.17.30.109:9090/api/v1/query?query=ipmi_temperature_celsius{name=~%22.*%20Temp%22}[1m] http://172.17.30.109:9090/api/v1/query?query=sum%20by(rack)%20(ipmi_dcmi_power_consumption_watts)</p>"},{"location":"hackmd/python%20web/","title":"python web","text":"<ul> <li>\u6dfa\u8ac7 Gunicorn \u5404\u500b worker type \u9069\u5408\u7684\u60c5\u5883</li> <li>How to use Flask with gevent (uWSGI and Gunicorn editions)</li> <li>Downloading file using flask</li> <li>Flask Quickstart</li> <li>Dockerizing Flask with Postgres, Gunicorn, and Nginx</li> </ul>"},{"location":"hackmd/python/","title":"python","text":"<p>Instagram Pinkoi iCHEF carousell Dcard - \u5728 Dcard \u6211\u5011\u5982\u4f55\u7528 Python \u6253\u9020\u63a8\u85a6\u7cfb\u7d71\uff5c\u9673\u5b50\u5143\uff5cPyCon Taiwan 2023 - YouTube - Coding Is Magic - Speaker Deck - \u70ba\u4f60\u81ea\u5df1\u5b78 PYTHON | \u70ba\u4f60\u81ea\u5df1\u5b78 PYTHON</p>"},{"location":"hackmd/python/#dev-environment","title":"dev environment","text":"<pre><code># pip style\npip install -r requirements.txt\npip freeze\n\n# \u6aa2\u67e5\u76f8\u4f9d\u6027\npython -m requests.help\n\n# \u5b89\u88ddvirtualenv\npython -m venv {virtualenv dir}\n\n# Test\npython3 -c 'import math;print( math.sqrt( 512 * 1024 *1024 * 1024 * 0.85 / 8 ))'\n\n# simple http server\npython -m http.server\n\n# Pretty-Printing JSON with Python's JSON Tool\ncurl http://api.joind.in | python3 -m json.tool\n</code></pre>"},{"location":"hackmd/python/#build","title":"build","text":"<pre><code>sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget liblzma-dev -y\ncurl https://pyenv.run | bash\ncat &gt; ~/.bashrc &lt;&lt; EOF\n# pyenv\nexport PYENV_ROOT=\"$HOME/.pyenv\"\ncommand -v pyenv &gt;/dev/null || export PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init -)\"\neval \"$(pyenv virtualenv-init -)\"\nEOF\nsource ~/.bashrc\npyenv install 3.10.4\n</code></pre>"},{"location":"hackmd/python/#_1","title":"\u5404\u7248\u672c","text":"<ul> <li>A reverse chronology of some Python features<ul> <li>Real Multithreading is Coming to Python 3.12</li> <li>Summary of Major Changes Between Python Versions</li> <li>Is Python Really That Slow? - miguelgrinberg.com</li> </ul> </li> <li>awesome-python</li> <li>python-mini-projects</li> </ul>"},{"location":"hackmd/python/#python-developers-survey","title":"Python Developers Survey","text":"<ul> <li>Python Developers Survey 2022 Results</li> <li>Big Tech Best Practices : r/Python</li> </ul>"},{"location":"hackmd/python/#performance","title":"performance","text":"<ul> <li>\u597d\u5f71\u7247\u63a8\u85a6 \u2014 How Fast can Python Parse 1 Billion Rows of Data? - MyApollo</li> <li>\u597d\u6587\u5206\u4eab \u2014 Python Big O: the time complexities of different data structures in Python - MyApollo<ul> <li>Python Big O: the time complexities of different data structures in Python - Python Morsels</li> </ul> </li> </ul>"},{"location":"hackmd/python/#layout","title":"Layout","text":"<ul> <li>Python Application Layouts: A Reference<ul> <li>One-Off Script<ul> <li>You just make a .py script, and it\u2019s gravy, right? No need to install\u2014just run the script in its directory</li> </ul> </li> <li>Installable Single Package<ul> <li>Let\u2019s imagine that helloworld.py is still the main script to execute, but you\u2019ve moved all helper methods to a new file called helpers.py</li> </ul> </li> <li>Application with Internal Packages<ul> <li>In larger applications, you may have one or more internal packages that are either tied together with a main runner script or that provide specific functionality to a larger library you are packaging</li> </ul> </li> </ul> </li> <li>Packaging a python library</li> </ul>"},{"location":"hackmd/python/#type-hint","title":"Type hint","text":"<ul> <li>Type hints cheat sheet (Python 3)</li> </ul>"},{"location":"hackmd/python/#pypi","title":"PyPI","text":"<ul> <li>How to Publish an Open-Source Python Package to PyPI<ul> <li>The most common formats for distribution packages are source archives and Python wheels<ul> <li>What Are Python Wheels and Why Should You Care</li> </ul> </li> <li>setup.py + twine<ul> <li><code>python setup.py sdist bdist_wheel</code></li> <li><code>twine check dist/*</code></li> </ul> </li> <li>Cookiecutter</li> <li>Flit</li> <li>Poetry</li> <li>What Are Python Wheels and Why Should You Care</li> <li>Python packaging: wheels vs tarball (tar.gz)</li> </ul> </li> <li>Packaging and distributing projects</li> <li>\u6253\u5305python module \u5230PYPI \u4e0a</li> <li>PIP Install Local Package - PIP Install Wheel - PIP Install Packages Offline</li> <li>How can I install packages using pip according to the requirements.txt file from a local directory</li> <li>PyPI\u9694\u96e2\u63aa\u65bd\u594f\u6548\uff0c\u6578\u6708\u963b\u64cb\u903e\u767e\u60e1\u610f\u5c08\u6848 | iThome<ul> <li>\u99ed\u5ba2\u5047\u501f\u63d0\u4f9bAI\u5de5\u5177DeepSeek\u7684\u540d\u7fa9\uff0c\u5728PyPI\u6563\u5e03\u60e1\u610f\u8edf\u9ad4\uff0c\u4e0d\u5230\u4e00\u5c0f\u6642\u5c31\u6709\u903e200\u4eba\u4e0a\u7576 | iThome</li> </ul> </li> <li>Installing Python packages from local file system folder to virtualenv with pip ```python= pip install -r requirements.txt --no-index --find-links file:///tmp/packages <pre><code>### GIL\n- [\u6df1\u5165 GIL: \u5982\u4f55\u5beb\u51fa\u5feb\u901f\u4e14 thread-safe \u7684 Python - Grok the GIL: How to write fast and thread-safe Python | louie\\_lu's blog](https://blog.louie.lu/2017/05/19/%e6%b7%b1%e5%85%a5-gil-%e5%a6%82%e4%bd%95%e5%af%ab%e5%87%ba%e5%bf%ab%e9%80%9f%e4%b8%94-thread-safe-%e7%9a%84-python-grok-the-gil-how-to-write-fast-and-thread-safe-python/)\n\n### \u7a0b\u5f0f\u78bc\u4fdd\u8b77\n- [\u5982\u4f55\u4fdd\u8b77\u4f60\u7684python\u7a0b\u5f0f\u78bc](https://zhuanlan.zhihu.com/p/54296517)\n\n\u7a0b\u5f0f\u78bc\u6df7\u6dc6: obfuscator\n- [How to obfuscate Python code effectively](https://stackoverflow.com/questions/3344115/how-to-obfuscate-python-code-effectively)\n- [Python Source Code Obfuscation](https://medium.com/geekculture/python-source-code-obfuscation-6b97f88a460d)\n- [Python package obfuscation](https://stackoverflow.com/questions/68691077/python-package-obfuscation)\n- [Distributing python packages protected with Cython](https://medium.com/swlh/distributing-python-packages-protected-with-cython-40fc29d84caf)\n- [How to Deploy a Cython Package to PyPI](https://levelup.gitconnected.com/how-to-deploy-a-cython-package-to-pypi-8217a6581f09)\n- [Publishing Proprietary Python Packages on PyPI Using Poetry](https://d39l7znklsxxzt.cloudfront.net/zh/blog/2021/01/19/publishing-a-proprietary-python-package-on-pypi-using-poetry/)\n\n#### virtualenv\n- [virtualenv\u7684\u539f\u7406 | \u5361\u74e6\u90a6\u5676\uff01](https://www.kawabangga.com/posts/3543)\n- [\u4f60\u7684 Python \u5305\u90fd\u88c5\u5230\u54ea\u4e86\uff1f | Frost's Blog](https://frostming.com/2019/03-13/where-do-your-packages-go/)\n\n#### venv\n- [Python \u865b\u64ec\u74b0\u5883--venv - DEV Community](https://dev.to/codemee/python-xu-ni-huan-jing-venv-nbg)\n- [\u628a Python \u7684 venv \u79fb\u5230\u5176\u4ed6\u6a5f\u5668 | Pan in the Nutshell](https://blog.pan93.com/posts/move-venv-to-other-machines/)\n\n\n#### pyenv\n- [Python \u7248\u672c\u7ba1\u7406\u7684\u597d\u5de5\u5177 - pyenv - MyApollo](https://myapollo.com.tw/blog/pyenv/)\n    - [GitHub - pyenv/pyenv-virtualenv: a pyenv plugin to manage virtualenv (a.k.a. python-virtualenv)](https://github.com/pyenv/pyenv-virtualenv)\n    - [pyenv no module named '\\_sqlite3' - DEV Community](https://dev.to/waylonwalker/pyenv-no-module-named-sqlite3-3ea2?comments_sort=latest)\n</code></pre> pyenv versions pyenv install --list pyenv install 3.10.8 pyenv global 3.10.8</li> </ul> <p>pyenv virtualenvs pyenv virtualenv 3.10.0 ansible-playbook-graph pyenv activate ansible-playbook-graph pyenv deactivate pyenv uninstall ansible-playbook-graph <pre><code>#### poetry\n- [koko's Note \u2013 Python - \u53d6\u4ee3 Pipenv \u7684\u65b0\u5957\u4ef6\u7ba1\u7406\u5668 Poetry](https://note.koko.guru/posts/using-poetry-manage-python-package-environments)\n- [\u518d\u898b\u4e86 pip\uff01\u6700\u4f73 Python \u5957\u4ef6\u7ba1\u7406\u5668\u2014\u2014Poetry \u5b8c\u5168\u5165\u9580\u6307\u5357 - Code and Me](https://blog.kyomind.tw/python-poetry/)\n- [Create and Publish a Python Package with Poetry](https://johnfraney.ca/blog/create-publish-python-package-poetry/)\n- [Install](https://python-poetry.org/docs/#installation)\n\n```bash=\ncurl -sSL https://install.python-poetry.org | python -\n</code></pre></p>"},{"location":"hackmd/python/#hatch","title":"hatch","text":"<ul> <li>GitHub - pypa/hatch: Modern, extensible Python project management</li> </ul>"},{"location":"hackmd/python/#call-by-what","title":"call by what","text":"<ul> <li>Python Names and Values</li> </ul>"},{"location":"hackmd/python/#pycon","title":"PyCon","text":"<ul> <li>PyCon Taiwan 2023 - YouTube</li> </ul>"},{"location":"hackmd/python/#pythonic","title":"Pythonic","text":"<ul> <li>Pythonic \u5be6\u8e10\uff1a\u5be6\u7528\u7684 python \u6163\u7528\u6cd5\u6574\u7406 | Mr. Opengate</li> <li>\u53cb\u597d\u7684 Python\uff1a\u9762\u5411\u5bf9\u8c61\u63a5\u53e3 | Frost's Blog</li> <li>\u53cb\u597d\u7684 Python\uff1a\u6269\u5c55\u53cb\u597d | Frost's Blog</li> </ul>"},{"location":"hackmd/python/#error","title":"error","text":"<ul> <li>python - Python3: ImportError: No module named '_ctypes' when using Value from module multiprocessing - Stack Overflow</li> <li>The Ultimate Guide to Error Handling in Python - miguelgrinberg.com</li> </ul>"},{"location":"hackmd/python/#pacakge","title":"pacakge","text":"<p>Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an __init__.py</p>"},{"location":"hackmd/python/#offiline-installation","title":"offiline installation","text":"<ul> <li>https://superuser.com/questions/1523218/how-to-install-python-packages-with-all-dependencies-offline-via-pip3</li> </ul> <pre><code>python3 -m pip download ansible -d /tmp/ansible-offiline\n</code></pre> <pre><code>python3 -m pip install --no-index --find-links /tmp/ansible-offiline ansible\n</code></pre>"},{"location":"hackmd/python/#_2","title":"\u53c3\u8003","text":"<ul> <li>python docs</li> <li>__init__.py<ul> <li>Python Modules and Packages \u2013 An Introduction<ul> <li>This can be used for execution of package initialization code, such as initialization of package-level data</li> <li>__init__.py can also be used to effect automatic importing of modules from a package.</li> </ul> </li> <li>What is __init__.py for?</li> <li>What's your opinion on what to include in __init__.py ?</li> </ul> </li> <li>organizie<ul> <li>Structuring Your Project</li> <li>The Pythonic way of organizing modules and packages</li> </ul> </li> <li>Can someone explain __all__ in Python?</li> <li>\u64a5\u958b Python, pip, site-packages \u7684\u85cd\u8272\u8718\u86db\u7db2</li> <li>:star: How to create a Python package in 2022 | Mathspp</li> </ul>"},{"location":"hackmd/python/#module","title":"module","text":""},{"location":"hackmd/python/#module-vs-class","title":"module vs class","text":"<ul> <li>Why use python classes over modules with functions</li> <li>Difference between Module and Class in Python</li> <li>choosing between Modules and Classes</li> <li>Classes vs. modules in Python</li> </ul> <p>file (name) - variables - functions     - parameters - classes     - elements         - fields         - methods     - ==store/share== state between methods     - multiple instances</p>"},{"location":"hackmd/python/#import","title":"import","text":""},{"location":"hackmd/python/#_3","title":"\u53c3\u8003","text":"<ul> <li>Complete Guide to Imports in Python: Absolute, Relative, and More</li> <li>Python - import</li> </ul>"},{"location":"hackmd/python/#_4","title":"\u539f\u751f\u8a9e\u6cd5","text":"<ul> <li>Pydon'ts | Mathspp</li> <li>Make Each Line Count, Keeping Things Simple In Python - Pybites<ul> <li>all()</li> <li>List comprehensions</li> <li>set()</li> <li>from collections import Counter</li> </ul> </li> <li>Every dunder method in Python - Python Morsels</li> <li>Object<ul> <li>\u53cb\u597d\u7684 Python\uff1a\u9762\u5411\u5bf9\u8c61\u63a5\u53e3 | Frost's Blog<ul> <li>classmethod\u7684\u4f7f\u7528\u6642\u6a5f</li> </ul> </li> <li>\u53cb\u597d\u7684 Python\uff1a\u5c01\u88c5\u548c\u590d\u7528 | Frost's Blog</li> <li>\u53cb\u597d\u7684 Python\uff1a\u6269\u5c55\u53cb\u597d | Frost's Blog<ul> <li>register</li> </ul> </li> <li>Python - super() \u51fd\u5f0f\u8207 MRO \u8a73\u89e3 - MyApollo</li> </ul> </li> <li>Python's Built-in Functions: A Complete Exploration \u2013 Real Python</li> <li>Python \u55ae\u96d9\u661f\u865f(* &amp; **)\u89e3\u8aaa - MyApollo</li> <li>Python \u6dfa\u8ac7 with \u8a9e\u53e5 - MyApollo<ul> <li>Python \u6a21\u7d44\u4ecb\u7d39 - contextlib - MyApollo</li> </ul> </li> <li>Python \u6a21\u7d44\u6559\u5b78 - \u65b9\u4fbf\u53c8\u5be6\u7528\u7684 dataclasses - MyApollo</li> <li>[Python] @contextmanager \u88dd\u98fe\u5668\u7684\u4f7f\u7528\u65b9\u5f0f - Clay-Technology World</li> </ul>"},{"location":"hackmd/python/#dictionary","title":"dictionary","text":"<p>sorted</p> <ul> <li>How do I sort a dictionary by value? </li> <li>[Day21]\u6392\u5e8f\uff1findex sort? lambda\u53c8\u6709\u4f60\u7684\u4e8b\u4e86</li> </ul> <p>copy - How to copy a dictionary and only edit the copy</p> <p>get key - How to return dictionary keys as a list in Python?</p> <p>```python=  newdict = {1:0, 2:0, 3:0} [*newdict]</p>"},{"location":"hackmd/python/#1-2-3","title":"[1, 2, 3]","text":"<pre><code>### list\n[How do I concatenate two lists in Python?](https://stackoverflow.com/questions/1720421/how-do-i-concatenate-two-lists-in-python)\n\n[Create list with numbers between 2 values](https://stackoverflow.com/questions/18265935/python-create-list-with-numbers-between-2-values?rq=1)\n``` python=\nlist(range(11, 17))\n# [11, 12, 13, 14, 15, 16]\n</code></pre>"},{"location":"hackmd/python/#dataclass","title":"dataclass","text":"<ul> <li>Python3.7 \u7279\u8272(1)-dataclasses</li> <li>\u6dfa\u8ac7\u5728Python\u4e2d\u5efa\u7acb\u7269\u4ef6: class, namedtuple, NamedTuple and dataclass</li> <li>Data Classes vs typing.NamedTuple primary use cases</li> </ul>"},{"location":"hackmd/python/#__str__-and-__repr","title":"__str__ and __repr","text":"<ul> <li>What is the difference between __str__ and __repr__</li> </ul>"},{"location":"hackmd/python/#type-hint_1","title":"Type hint","text":"<ul> <li>Python Type Hints \u6559\u5b78\uff1a\u6211\u72af\u904e\u7684 3 \u500b\u83dc\u9ce5\u932f\u8aa4</li> <li>My journey to type checking 7521 lines of Python<ul> <li>mypy</li> </ul> </li> </ul>"},{"location":"hackmd/python/#divmod","title":"divmod","text":"<ul> <li>\u6bd4\u8f03 Python \u8207\u9664\u6cd5\u76f8\u95dc\u7684\u904b\u7b97\u5b50\u8207\u51fd\u5f0f \u2013 /\u3001//\u3001% \u8207 divmod</li> </ul>"},{"location":"hackmd/python/#str","title":"str","text":"<ul> <li>What's the difference between str.isdigit, isnumeric and isdecimal in python</li> <li>Membership test operations<ul> <li>Runtime of python's if substring in string</li> <li>Python string 'in' operator implementation algorithm and time complexity</li> <li>Python efficient way to check if very large string contains a substring</li> <li>What's a faster operation, re.match/search or str.find?</li> </ul> </li> </ul>"},{"location":"hackmd/python/#decorator","title":"decorator","text":"<ul> <li>dokelung.me</li> <li>\u770b\u4e86\u80af\u5b9a\u6703\u7684 Python \u88dd\u98fe\u5b50(decorator)\u6559\u5b78 - MyApollo</li> <li>Python \u590d\u7528\u88c5\u9970\u5668\u4ee3\u7801 | \u5361\u74e6\u90a6\u5676\uff01</li> <li>Python\u9032\u968e\u6280\u5de7 (3) \u2014 \u795e\u5947\u53c8\u7f8e\u597d\u7684 Decorator \uff0c\u55f7\u55da\uff01 | by Jack Cheng | \u6574\u500b\u7a0b\u5f0f\u90fd\u662f\u6211\u7684\u5496\u5561\u9928 | Medium</li> <li>real world example<ul> <li>Python Decorators for Data Engineering: 5 Real-World Use Cases | by Mani Kolbe | Medium</li> <li>Primer on Python Decorators \u2013 Real Python</li> </ul> </li> </ul>"},{"location":"hackmd/python/#_5","title":"\u6848\u4f8b","text":"<p>\u7d00\u9304\u5206\u5c64\u5e36\u5165\u7684\u51fd\u5f0f\u540d\u7a31\u548c\u53c3\u6578, \u56e0\u70ba\u53c3\u6578\u53ef\u80fd\u6703\u5728\u904e\u7a0b\u4e2d\u88ab\u4fee\u6539\u800c\u9020\u6210\u932f\u8aa4 \u5206\u5c64: view =&gt; business =&gt; dao</p> <p>\u4f7f\u7528decorator \u5728\u904e\u7a0b\u4e2d\u7d00\u9304\u51fd\u5f0f\u540d\u7a31\u548c\u53c3\u6578 \u540d\u7a31\u7684\u90e8\u5206\u4f7f\u7528qualname, \u53c3\u6578\u7684\u90e8\u5206\u4f7f\u7528args, kwargs \u4e26\u5728\u9700\u8981\u7d00\u9304\u7684\u51fd\u5f0f\u52a0\u4e0a\u8a72decorator</p>"},{"location":"hackmd/python/#eval-and-astliteral_eval","title":"eval() and ast.literal_eval()","text":"<p>https://stackoverflow.com/questions/15197673/using-pythons-eval-vs-ast-literal-eval</p> <p>ast.literal_eval() only considers a small subset of Python's syntax to be valid</p> <p>Passing import('os').system('rm -rf /a-path-you-really-care-about') into ast.literal_eval() will raise an error, but eval() will happily delete your files.</p>"},{"location":"hackmd/python/#re","title":"re","text":"<ul> <li>Regex Tester and Debugger Online - Javascript, PCRE, PHP</li> <li>python - What is the difference between re.search and re.match? - Stack Overflow</li> <li>re \u2014 Regular expression operations \u2014 Python 3.10.6 documentation</li> <li>py_regular_expressions</li> </ul> <p>``` python= def get_previous_version(version: str, is_breaking_change: bool):     previous_version = '1.0'     if version is None:         return previous_version     matched = re.match('([\\d]{1}).([\\d]{1})', version)     if matched:         if is_breaking_change:             previous_major_version = int(matched.group(1)) - 1 if int(matched.group(1)) &gt; 0 else int(matched.group(1))             previous_version = f'{previous_major_version}.{matched.group(2)}'         else:             previous_minor_version = int(matched.group(2)) - 1 if int(matched.group(2)) &gt; 0 else int(matched.group(2))             previous_version = f'{matched.group(1)}.{previous_minor_version}'     return previous_version <pre><code>``` python=\ndef is_feeback_type_valid(feedback_type: str) -&gt; bool:\n    valid_length = len(feedback_type) &lt;= 63\n    invalid_regulation = re.search('[^a-zA-Z0-9,_\\s]{1,63}$', feedback_type)\n    return valid_length and not invalid_regulation\n</code></pre></p>"},{"location":"hackmd/python/#class-name","title":"class name","text":"<ul> <li>Fetching python class name while using abstract classes with <code>abc</code> library</li> </ul> <p>```python= class Foo:     def init(self):         print(self.class.name) <pre><code>```python=\nimport abc\n\nclass AService(abc.ABC):\n    pass\n\nclass A1Service(AService):\n    pass\n\n\na1 = A1Service()\nprint(A1Service.__class__.__name__)\nprint(A1Service.__name__)\nprint(a1.__class__.__name__)\nprint(a1.__name__)\n\n# ABCMeta\n# A1Service\n# A1Service\n# Traceback (most recent call last):\n#   File \"name.py\", line 14, in &lt;module&gt;\n#     print(a1.__name__)\n# AttributeError: 'A1Service' object has no attribute '__name__'\n</code></pre></p>"},{"location":"hackmd/python/#global","title":"global","text":"<ul> <li>Python: change global variable from within another file</li> <li>Accessing module level variables, from within a function in the module<ul> <li>sys.modules[name].var = something()</li> </ul> </li> </ul>"},{"location":"hackmd/python/#nonlocal","title":"nonlocal","text":"<ul> <li>[Python]\u81ea\u5b78 Python 100 \u5929\uff0c\u5168\u57df\u8b8a\u6578\u3001\u5340\u57df\u8b8a\u6578(global\u3001nonlocal) - KTing\u2019s Blog</li> </ul>"},{"location":"hackmd/python/#enum","title":"enum","text":"<ul> <li>How do I if int value exists in Python Enum without using try/catch?</li> </ul> <p>``` python= class DoaminSource(Enum):     A = (0, 'a')     B = (1, 'b')</p> <pre><code>def __init__(self, identity, name):\n    self.id = identity\n    self.human_readable = name\n\ndef to_dict(self):\n    return {'id': self.id, 'name': self.human_readable}\n\n@classmethod\ndef get_item_by_id(cls, source_id):\n    for enum_item in cls.__members__.values():\n        if source_id == enum_item.id:\n            return enum_item\n</code></pre> <p>``` </p>"},{"location":"hackmd/python/#isinstance","title":"isinstance","text":"<ul> <li>python - List of classinfo Types - Stack Overflow </li> </ul>"},{"location":"hackmd/python/#getattr","title":"getattr","text":"<ul> <li>Python using getattr to call function with variable parameters</li> <li>python - Access object methods from getattr() - Stack Overflow</li> <li>shell - Is it bad practice to use python's getattr extensively? - Stack Overflow</li> <li>what scenario can use the getattr and what is the security concern </li> </ul>"},{"location":"hackmd/python/#functools","title":"functools","text":"<ul> <li>The Correct Way to Overload Functions in\u00a0Python | Martin Heinz | Personal Website &amp; Blog </li> </ul>"},{"location":"hackmd/python/#multiprocessing","title":"multiprocessing","text":"<ul> <li>multiprocessing \u6a21\u7d44\u9032\u968e\u7bc7 - Pipe, Queue, Array, RawArray \u4ee5\u53ca Structure \u4e4b\u6559\u5b78\u7bc4\u4f8b - MyApollo</li> <li>Developing an Asynchronous Task Queue in Python | TestDriven.io</li> <li>Speeding Up Python with Concurrency, Parallelism, and asyncio | TestDriven.io </li> </ul>"},{"location":"hackmd/python/#_6","title":"\u5176\u4ed6","text":"<p>lambda   </p>"},{"location":"hackmd/python/#python-standard-library","title":"Python Standard Library","text":"<ul> <li>The Python Standard Library </li> </ul>"},{"location":"hackmd/python/#logging","title":"logging","text":"<p>leverage log quickly <code>python= FORMAT = '%(asctime)s %(levelname)s: %(message)s' logging.basicConfig(level=logging.DEBUG, filename='filter.log', filemode='a', format=FORMAT) logging.info('test')</code></p> <p>``` python= import logging</p> <p>logging.basicConfig(     level=logging.DEBUG,      format='[%(asctime)s][%(levelname)s][%(filename)s %(lineno)d]: %(message)s',     handlers=[         logging.FileHandler('/tmp/foo.log'),         logging.StreamHandler()     ] ) logger = logging.getLogger(name) <pre><code>- [Logging Cookbook](https://docs.python.org/3/howto/logging-cookbook.html#adding-contextual-information-to-your-logging-output)\n- [Understanding logging in Python ](https://gist.github.com/mariocj89/73824162a3e35d50db8e758a42e39aab)\n- [Understanding Python\u2019s logging module](https://www.electricmonk.nl/log/2017/08/06/understanding-pythons-logging-module/)\n- [Logging in Python like a PRO](https://guicommits.com/how-to-log-in-python-like-a-pro/)\n- [Python logging: create log if not exists or open and continue logging if it does](https://stackoverflow.com/questions/41764941/python-logging-create-log-if-not-exists-or-open-and-continue-logging-if-it-does)\n- [python - logger configuration to log to file and print to stdout - Stack Overflow](https://stackoverflow.com/questions/13733552/logger-configuration-to-log-to-file-and-print-to-stdout)\n\nLoggers have a hierarchy\nAt the top of the hierarchy is the root logger, and the logger names don\u2019t include the root logger\n- created by asking a parent logger for a new child logger\n- use dot notation\n\nmessage propagation\nthe level of the message is **only checked** by the logger you give the message to. If the message\u2019s level is lower or equal to the logger\u2019s, the message is propagated up the hierarchy, but none of the other loggers will check the level! They\u2019ll simply invoke their handlers.\nlevel\u50c5\u5728\u9032\u5165\u9ede\u6aa2\u67e5\u4e00\u6b21\nwhen giving a message to a logger, the logger checks the level. After that, the level on the loggers is no longer checked and all handlers in the entire chain are invoked, regardless of level.\n\nWhen you log a message, the level is only checked at the logger you logged the message against. If it passes, every handler on every logger up the hierarchy is called, regardless of that logger\u2019s level.\n\n### time\n- [Python \u7a0b\u5f0f\u6548\u80fd\u5206\u6790:\u91cf\u6e2c\u904b\u884c\u6642\u9593 \u2014 1010Code](https://andy6804tw.github.io//2023/06/22/time_profiler/)\n\nISO 8601\n``` python=\nfrom datetime import datetime, timezone, timedelta\n\ndatetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n\ndatetime.now(datetime.utcnow().astimezone().tzinfo).isoformat(timespec=\"seconds\")\n\n# iso 8601 string to datetime\nresult_time = datetime.datetime.strptime('2022-04-27T09:43:17+0800', '%Y-%m-%dT%H:%M:%S%z')\n</code></pre></p> <p>time shift ``` python= import datetime</p> <p>expired = datetime.datetime.now() + datetime.timedelta(seconds=30) expired_timestamp = int(expired.timestamp()) <pre><code>timestamp to datetime\n``` python=\nimport datetime\ndatetime.fromtimestamp(finished_at)\n</code></pre></p> <p>str to datetime ``` python= import datetime d = datetime.datetime.strptime('2021-03-18 10:51:22', '%Y-%m-%d %H:%M:%S')</p>"},{"location":"hackmd/python/#if-the-string-is-utc0","title":"if the string is utc+0","text":"<p>d.astimezone(datetime.timezone.utc) <pre><code>str to timestamp\n``` python=\ndt = datetime.datetime.strptime('2021-03-18 10:51:22', '%Y-%m-%d %H:%M:%S')\nutc_time = dt.replace(tzinfo=datetime.timezone.utc)\nutc_timestamp = utc_time.timestamp()\n</code></pre></p> <p>today format string ``` python= today = datetime.today().strftime('%Y%m%d') <pre><code>### pathlib\n- [Python pathlib \u6559\u5b78\uff1a\u6a94\u6848\u8def\u5f91\u64cd\u4f5c\u8d85\u7c21\u55ae\uff0c\u4e0d\u518d\u7169\u60f1\u524d\u659c\u7dda\u6216\u5f8c\u659c\u7dda\uff01 \u2022 \u597d\u8c6a\u7b46\u8a18](https://haosquare.com/python-pathlib/)\n- [Python \u597d\u7528\u6a21\u7d44 - pathlib - MyApollo](https://myapollo.com.tw/blog/python-pathlib/)\n\n\nmake dir if not exist\n``` python=\np_foo = Path('foo')\np_foo.mkdir(parents=True, exist_ok=True)\n</code></pre></p> <p>use exist Path ``` python= p_foo = Path('foo') p_csv = p_foo / 'csv' <pre><code>find files by specific pattern\n``` python=\np_foo = Path('/foo')\nfiles = p_foo.glob('*.csv')\nfor file in files:\n    # handle the file\n</code></pre></p> <p>Get name of current script in Python ``` python= from pathlib import Path Path(file).name <pre><code>vs\n\n``` python=\n__name__\n# if execute by script, output is __main__\n</code></pre></p>"},{"location":"hackmd/python/#csv","title":"csv","text":"<p>``` python=</p> <p>with open(file) as csvfile:     rows = csv.DictReader(csvfile)     headers = list(rows.fieldnames)     for row in rows:         # logging.info(row) <pre><code>### unittest\n\nassertRaises\nhttps://docs.python.org/3/library/unittest.html#unittest.TestCase.assertRaises\n``` python=\nwith self.assertRaises(SomeException) as cm:\n    do_something()\n\nthe_exception = cm.exception\nself.assertEqual(the_exception.error_code, 3)\n</code></pre></p>"},{"location":"hackmd/python/#patch","title":"patch","text":"<ul> <li>Why your mock doesn\u2019t work</li> </ul>"},{"location":"hackmd/python/#shutil","title":"shutil","text":"<ul> <li>The Right Way to Run Shell Commands From Python | Martin Heinz | Personal Website &amp; Blog</li> <li>Python subprocess \u6a21\u7d44\u4f7f\u7528\u6559\u5b78 - MyApollo</li> </ul> <pre><code>import subprocess\nimport shlex\n\nipmi_dcmi_power = shlex.split('ipmitool dcmi power reading')\nipmi_sdr_elist_full =  shlex.split('ipmitool -c sdr elist full')\n\n#p = subprocess.run('ipmitool dcmi power reading', shell=True, check=True, capture_output=True, encoding='utf-8')\np = subprocess.run(ipmi_dcmi_power, check=True, capture_output=True, encoding='utf-8')\nprint(f'Command {p.args} exited with {p.returncode} code, output: \\n{p.stdout}')\n\nfor line in p.stdout.splitlines():\n  print(line.strip())\n  if 'Instantaneous power reading' in line.strip():\n    print(line.strip().split())\n\n\n#p = subprocess.run('ipmitool -c sdr elist full', shell=True, check=True, capture_output=True, encoding='utf-8')\np = subprocess.run(ipmi_sdr_elist_full, check=True, capture_output=True, encoding='utf-8')\nfor line in p.stdout.splitlines():\n  print(line.strip())\n  print(line.strip().split(','))\n</code></pre> <p>``` python= import subprocess import logging import shlex</p> <p>logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)s: %(message)s') logger = logging.getLogger(name)</p> <p>def run(cmd_string):     data = ''     cmd = shlex.split(cmd_string)     try:         p = subprocess.run(cmd, check=True, capture_output=True, encoding='utf-8')         logger.debug(f'Command {p.args} exited with {p.returncode} code, output: \\n{p.stdout}')         data = p.stdout     except subprocess.SubprocessError as e:         logger.error(e)</p> <pre><code>return data\n</code></pre> <pre><code>``` python=\nimport asyncio\nimport logging\nimport datetime\nimport shlex\nimport threading\n\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)s: %(message)s')\nlogger = logging.getLogger(__name__)\n\nasync def run(cmd, host, location):\n    logger.debug(f'{datetime.datetime.now().isoformat()}, thread id {threading.current_thread().ident}')\n    proc = await asyncio.create_subprocess_exec(\n        *shlex.split(cmd),\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE)\n\n    stdout, stderr = await proc.communicate()\n\n    logger.info(f'[{cmd!r} exited with {proc.returncode}]')\n\n    if stdout:\n        logger.debug(f'[stdout]\\n{stdout.decode()}')\n    if stderr:\n        logger.debug(f'[stderr]\\n{stderr.decode()}')\n    return host, location, proc.returncode, stdout.decode(), stderr.decode()\n\nasync def main(tasks):\n    logger.debug(f'main {datetime.now().isoformat()}, thread id {threading.current_thread().ident}')\n    return_values = await asyncio.gather(*tasks)\n    logger.debug(f'main {datetime.now().isoformat()}, thread id {threading.current_thread().ident}')\n    return return_values\n\ndef generate_tasks():\n    tasks = list()\n    tasks.append(run('cat abc', 'pd010', 'r1'))\n    tasks.append(run('cat abc', 'pd011', 'r2'))\n\nif __name__ == '__main__':\n    tasks = generate_tasks()\n    return_values = asyncio.run(main(tasks))\n    for result in return_values:\n        logger.debug(f'result =&gt; {result}')\n</code></pre>"},{"location":"hackmd/python/#secrets","title":"secrets","text":"<p>https://docs.python.org/3/library/secrets.html</p> <p>```python=</p>"},{"location":"hackmd/python/#randomrandint1-1024","title":"random.randint(1, 1024)","text":"<p><pre><code>### urllib.parse\nhttps://docs.python.org/3/library/urllib.parse.html\n</code></pre> import secrets secrets.choice(list(range(1, 1024))) <pre><code>### ipaddress\n- [python - Convert an IP string to a number and vice versa - Stack Overflow](https://stackoverflow.com/questions/9590965/convert-an-ip-string-to-a-number-and-vice-versa)\n\n### ayncio\n- [Python asyncio \u5f9e\u4e0d\u6703\u5230\u4e0a\u8def | My.APOLLO](https://myapollo.com.tw/zh-tw/begin-to-asyncio/)\n    - [Asyncio Task Cancellation Best Practices - Super Fast Python](https://superfastpython.com/asyncio-task-cancellation-best-practices/)\n- [python\u7684asyncio\u6a21\u7d44(\u4e00)\uff1a\u7570\u6b65\u57f7\u884c\u7684\u597d\u8655 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929](https://ithelp.ithome.com.tw/articles/10199385)\n- [Strategies for Testing Async Code in Python](https://agariinc.medium.com/strategies-for-testing-async-code-in-python-c52163f2deab)\n- [Testing asynchronous code in Python](https://promity.com/2020/06/03/testing-asynchronous-code-in-python/)\n- subprocess\n    - [python 3.x - Using asyncio to wait for results from subprocess - Stack Overflow](https://stackoverflow.com/questions/63782892/using-asyncio-to-wait-for-results-from-subprocess)\n    - [Subprocesses \u2014 Python 3.11.5 documentation](https://docs.python.org/3/library/asyncio-subprocess.html)\n\n\n### sqllite\n- [Recipes from Python SQLite docs \u00b7 Redowan's Reflections](https://rednafi.github.io/reflections/recipes-from-python-sqlite-docs.html)\n\n### fcntl\n- [Python - fcntl.flock(fd, op) \u6a94\u6848\u9396\u61c9\u7528\u7bc4\u4f8b - MyApollo](https://myapollo.com.tw/blog/python-fcntl-flock/)\n    - [Python : Locking text file on NFS - Stack Overflow](https://stackoverflow.com/questions/37633951/python-locking-text-file-on-nfs)\n        - [Barry Warsaw / FLUFL Lock \u00b7 GitLab](https://gitlab.com/warsaw/flufl.lock)\n\n\n### xml\n- [xml.etree.ElementTree \u7b46\u8a18 - HackMD](https://hackmd.io/@top30339/rJYlKYpml?type=view)\n- [Updating XML elements and attribute values using Python etree - Stack Overflow](https://stackoverflow.com/questions/9177360/updating-xml-elements-and-attribute-values-using-python-etree)\n- [xml - Python Element Tree Writing to New File - Stack Overflow](https://stackoverflow.com/questions/37713184/python-element-tree-writing-to-new-file)\n- [python - How to write XML declaration using xml.etree.ElementTree - Stack Overflow](https://stackoverflow.com/questions/15356641/how-to-write-xml-declaration-using-xml-etree-elementtree)\n\n``` python\nimport sys\nimport logging\nimport xml.etree.ElementTree as ET\n\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(levelname)s: %(message)s')\nlogger = logging.getLogger(__name__)\n\n\nif __name__ == '__main__':\n    try:\n        benchmark_bios_config = sys.argv[1]\n        logger.info(f'benchmark_bios_config: {benchmark_bios_config}')\n        tree = ET.parse(benchmark_bios_config)\n        root = tree.getroot()\n\n        settings = root.findall(\".//Setting\")\n        for setting in settings:\n            logger.info(f\"{setting.get('name')}  {setting.get('selectedOption')}\")\n\n        default_setting = root.find(f\".//Setting[@name='foo']\")\n        default_setting.set('selectedOption', 'bar')\n        with open('output_file', 'wb') as f:\n            tree.write(f, encoding='utf-8')\n\n    except IndexError as e:\n        logger.error(e)\n    except ET.ParseError as e:\n        logger.error(e)\n</code></pre></p>"},{"location":"hackmd/python/#difflib","title":"difflib","text":"<ul> <li>[Python] \u4f7f\u7528 difflib \u6a21\u7d44\u6bd4\u8f03\u5e8f\u5217\u5dee\u7570 - Clay-Technology World</li> </ul>"},{"location":"hackmd/python/#nice-tools","title":"nice tools","text":"<ul> <li>Python's Missing Batteries: Essential Libraries You're Missing Out On | Martin Heinz | Personal Website &amp; Blog</li> <li>Python for DevOps | Pulumi Blog</li> </ul>"},{"location":"hackmd/python/#configparser","title":"configparser","text":"<p>CLI\u5f48\u6027\u8f38\u5165</p>"},{"location":"hackmd/python/#command-line-argument-parsing-library","title":"command-line argument parsing library","text":"<ul> <li>configparser</li> <li>click<ul> <li>argparse \u7684\u9ad8\u7ea7\u7528\u6cd5 | Frost's Blog</li> </ul> </li> <li>typer</li> <li>prompt-toolkit/python-prompt-toolkit: Library for building powerful interactive command line applications in Python<ul> <li>\u5982\u4f55 (\u6feb\u7528) prompt_toolkit \u7684\u81ea\u52d5\u88dc\u9f4a\u529f\u80fd\u505a\u5230\u4e92\u52d5\u5f0f\u547d\u4ee4\u5217\u5de5\u5177 | louie_lu's blog</li> </ul> </li> </ul>"},{"location":"hackmd/python/#ssh-tunnel","title":"ssh tunnel","text":"<ul> <li>https://blog.ruanbekker.com/blog/2018/04/23/setup-a-ssh-tunnel-with-the-sshtunnel-module-in-python/</li> </ul>"},{"location":"hackmd/python/#streaming-large-json","title":"streaming large json","text":"<ul> <li>ijson</li> <li>bigjson</li> </ul>"},{"location":"hackmd/python/#logger","title":"logger","text":"<ul> <li>python-json-logger</li> <li>concurrent-log-handler</li> </ul>"},{"location":"hackmd/python/#face_recognition","title":"face_recognition","text":"<ul> <li>face_recognition</li> </ul>"},{"location":"hackmd/python/#python-dependency-visualization","title":"Python dependency visualization","text":"<ul> <li>Import structure<ul> <li>pydeps</li> </ul> </li> <li>Classes hierachy<ul> <li>Pyreverse in pylint<ul> <li>analyses Python code and extracts UML class diagrams and package dependencies</li> <li>\u4f7f\u7528Graphviz\u548cPyreverse\u7ed8\u5236Python\u9879\u76ee\u7ed3\u6784\u56fe | \u591c\u4e0d\u80fd\u5bd0</li> </ul> </li> </ul> </li> <li>visual scripting framework for python<ul> <li>PyFlow</li> <li>code2flow: Pretty good call graphs for dynamic languages</li> </ul> </li> </ul>"},{"location":"hackmd/python/#faker","title":"Faker","text":"<ul> <li>Python Faker</li> </ul>"},{"location":"hackmd/python/#project-template","title":"project template","text":"<ul> <li>cookiecutter</li> <li>ordained<ul> <li>ORDAINED: The Python Project Template</li> </ul> </li> </ul>"},{"location":"hackmd/python/#change-log","title":"change log","text":"<ul> <li>Automating Version Tags and Changelogs for your Python Projects</li> </ul>"},{"location":"hackmd/python/#pandas","title":"pandas","text":"<ul> <li>How do I read and write tabular data? \u2014 pandas 2.1.1 documentation</li> <li>Comparison with SQL \u2014 pandas 2.1.1 documentation</li> <li>pandas.DataFrame.between_time \u2014 pandas 2.1.1 documentation</li> <li>Pandas \u4e2d\u5982\u4f55\u5f9e\u6587\u5b57\u6a94\u6848\u8f09\u5165\u8cc7\u6599 | D\u68e7 - Delft Stack</li> <li>python - Dataframe set_index not setting - Stack Overflow</li> <li>Python Pandas Select Index where index is larger than x - Stack Overflow</li> </ul> <p>read multiple csv https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe</p> <p>```python= import glob</p> <p>df = pd.concat(map(pd.read_csv, glob.glob('data/*.csv'))) <pre><code>example\n``` python\nimport os\nimport glob\nimport pandas as pd\n\ndate = '11-08'\nbegin_time = '07:47'\nend_time = '08:45'\nmanual_gpu = 6000\n\n# single file\n#df = pd.read_table(\"/opt/power_consumption/data/pdu/d23pd015_r9v-l_snmpwalk.txt\", sep='\\s+')\n\n# multiple files\npath = '/opt/power_consumption/data/pdu'\nall_files = glob.glob(os.path.join(path, \"*.txt\"))\ndf = pd.concat((pd.read_table(f,sep='\\s+') for f in all_files), ignore_index=True)\n\ndf[\"time\"] = pd.to_datetime(df['TimeStamp'],format= '%m%d:%H%M' )\ndf.set_index('time', inplace=True)\ndf['all-w'] = df['1-w'] + df['2-w'] + df['3-w']\nprint(df)\ndf.to_csv('all_pdu.csv', index=False)\n\n\n#print(df[df.index &gt;= pd.to_datetime(date, format='%m-%d')].between_time(begin_time, end_time))\n#print(df[df.index &gt;= pd.to_datetime(date, format='%m-%d')].between_time(begin_time, end_time).groupby(\"TimeStamp\").agg({'all-w': 'sum'}))\n\n#print(df[(df.index &gt;= pd.to_datetime(date, format='%m-%d')) &amp; (df['TimeStamp'] == '1108:0752' )])\n#pdu_df = df[df.index &gt;= pd.to_datetime(date, format='%m-%d')].between_time(begin_time, end_time).groupby([\"Host\", \"TimeStamp\"]).agg({'all-w': 'sum'}).reset_index()\n#print(pdu_df)\n#print(pdu_df[pdu_df['TimeStamp'] == '1108:0752'])\n\nfinal_df = df[df.index &gt;= pd.to_datetime(date, format='%m-%d')].between_time(begin_time, end_time).groupby(\"TimeStamp\").agg({'all-w': 'sum'})\nfinal_df['all-w-with-gpu'] = final_df['all-w'] + manual_gpu\nprint(final_df)\nprint(final_df.describe())\n</code></pre></p>"},{"location":"hackmd/python/#mysql","title":"MySQL","text":"<ul> <li>What's the difference between PyMySQL and mysqlclient-python</li> <li>What's the difference between MySQLdb, mysqlclient and MySQL connector/Python</li> </ul>"},{"location":"hackmd/python/#orm","title":"ORM","text":"<ul> <li>Python SQLAlchemy ORM - 1</li> <li>[python] sqlalchemy \u95b1\u8b80\u7b46\u8a18</li> <li>Basic Relationship Patterns</li> <li>Reflecting Views<ul> <li>This example illustrates one way of embedding CREATE VIEW / DROP VIEW into SQLAlchemy along with a selectable unit that can be used to generate SELECT statements as well as be mapped with the ORM</li> </ul> </li> </ul> <p>engine session base</p>"},{"location":"hackmd/python/#sqlalchemy","title":"SQLAlchemy","text":"<ul> <li>Unlocking the Power of Composite Primary Keys in SQLAlchemy | by Thinesh Ramanathan | Medium</li> <li>python - SQLAlchemy ORM not working with composite foreign keys - Stack Overflow</li> <li>Postgresql + Sqlalchemy ORM CRUD\u65b9\u5f0f - HackMD</li> </ul>"},{"location":"hackmd/python/#database-migration","title":"database migration","text":"<ul> <li>\u4f7f\u7528 Alembic \u4f86\u9032\u884c\u8cc7\u6599\u5eab\u7248\u672c\u7ba1\u7406</li> <li>Get Started With Alembic</li> <li>FastAPI with Async SQLAlchemy, SQLModel, and Alembic</li> <li>Sqlalchemy with Flask-Migrate - HackMD</li> </ul>"},{"location":"hackmd/python/#secure","title":"secure","text":"<ul> <li>Secure Password Handling in Python</li> <li>How to secure your Python software supply chain</li> </ul>"},{"location":"hackmd/python/#pycryptodome","title":"PyCryptodome","text":"<p>signature with PSS https://pycryptodome.readthedocs.io/en/latest/src/signature/pkcs1_pss.html ``` python= from Crypto.Signature import pss from Crypto.Hash import SHA256 from Crypto.PublicKey import RSA from Crypto import Random from base64 import b64encode, b64decode</p> <p>message = 'foo'.encode() key = RSA.import_key(open('private_key.pem').read()) h = SHA256.new(message) signature = pss.new(key).sign(h) sig_base64 = b64encode(signature).decode() print(sig_base64)</p> <p>key = RSA.import_key(open('public_key.pem').read()) a = SHA256.new(message) verifier = pss.new(key) try:     verifier.verify(a, b64decode(sig_base64))     print(\"The signature is authentic.\") except (ValueError, TypeError):     print(\"The signature is not authentic.\") <pre><code>### passlib\n- [How to generate a password hash in Python? - The Security Buddy](https://www.thesecuritybuddy.com/cryptography-and-python/how-to-generate-a-password-hash-in-python/)\n\n### requests\n- [Advanced usage of Python requests - timeouts, retries, hooks](https://findwork.dev/blog/advanced-usage-python-requests-timeouts-retries-hooks/)\n- [Requests Timeouts](https://docs.python-requests.org/en/master/user/advanced/#timeouts)\n- [Send HTTP requests using python-requests with timeout, tcp reuse(session) and retry. \u00b7 GitHub](https://gist.github.com/laixintao/e9eae48a835e741969ae06af3ad45f71)\n    - https://twitter.com/laixintao/status/1737693034270339406\n\nRequest hooks and `raise_for_status()`\ntimeouts\nRetry on failure\n\n``` python=\nfrom http import HTTPStatus\ntry:\n    ...\n    r = requests.post()\n    r.raise_for_status()\nexcept requests.exceptions.HTTPError as err:\n    if r.status_code == HTTPStatus.TOO_MANY_REQUESTS:\n        pass\n</code></pre></p>"},{"location":"hackmd/python/#pyppeteer","title":"pyppeteer","text":"<ul> <li>Read html file and make pdf with pyppeteer \u00b7 GitHub</li> <li>python - Is it possible to get pdf page using pyppeteer? - Stack Overflow</li> <li>GitHub - kiwi0fruit/pyppdf: Pyppeteer PDF. Print html sites and files to pdf via pyppeteer (uses patched pyppeteer that by default downloads updated Chromium revision via https with certifi).</li> </ul>"},{"location":"hackmd/python/#ruff","title":"ruff","text":"<ul> <li>GitHub - astral-sh/ruff: An extremely fast Python linter and code formatter, written in Rust.<ul> <li> <p>Ruff \u662f\u7531 Rust \u7de8\u5beb\u7684\u9ad8\u901f Python \u6aa2\u67e5\u5668\u548c\u7a0b\u5f0f\u78bc\u683c\u5f0f\u5316\u5de5\u5177\uff0c\u53ef\u901a\u904e pip \u5b89\u88dd\uff0c\u652f\u63f4\u81f3 Python 3.12\u3002\u5b83\u5177\u6709\u8d85\u904e 700 \u500b\u5167\u5efa\u898f\u5247\uff0c\u4e26\u80fd\u66ff\u4ee3 Flake8\u3001isort \u548c Black \u7b49\u5de5\u5177\uff0c\u4e14\u57f7\u884c\u901f\u5ea6\u9060\u8d85\u904e\u9019\u4e9b\u5de5\u5177\u3002https://twitter.com/daininduyuanma/status/1717141469822386435</p> </li> </ul> </li> <li>\u65b0\u4e16\u4ee3\u7684 Python Linter - Ruff - MyApollo</li> <li>Python \u958b\u767c\uff1aRuff Linter\u3001Formatter \u4ecb\u7d39 + \u8a2d\u5b9a\u6559\u5b78 - Code and Me</li> </ul>"},{"location":"hackmd/python/#csvtotable","title":"csvtotable","text":"<ul> <li>csvtotable \u00b7 PyPI</li> </ul>"},{"location":"hackmd/python/#fingerprint","title":"fingerprint","text":"<ul> <li>uap-python</li> <li>thefuzz</li> <li>fingerprintjs<ul> <li>The Beginner\u2019s Guide to Browser Fingerprinting for Fraud Detection</li> </ul> </li> </ul>"},{"location":"hackmd/python/#type-helper","title":"Type helper","text":"<ul> <li>dataclasses-json</li> <li>pydantic \u5c0f\u7b46\u8a18</li> <li>pydantic \u7684\u611b\u6068\u7cfe\u845b</li> </ul> <p>pydantic \u6700\u5927\u7684\u554f\u984c\u662f\u5b83\u4e5f\u6709\u6240\u8b02\u7684 model \u548c schema\uff0c\u7576\u518d\u628a\u8cc7\u6599\u5eab\u7684\u6982\u5ff5\u647b\u9032\u4f86\u5c31\u9020\u6210\u8a9e\u610f\u4e0a\u7684\u6df7\u4e82\u3002 \u4e0d\u50c5\u662f\u8a9e\u610f\u4e0a\uff0c\u7a0b\u5f0f\u78bc\u770b\u8d77\u4f86\u4e5f\u6703\u76f8\u7576\u5197\u9918\uff0c\u4ee5\u524d\u9762\u7684 User \u8cc7\u6e90\u70ba\u4f8b\uff0c\u9664\u4e86\u6709 pydantic model \u7684\u5b9a\u7fa9\u5916\uff0c\u5728 ORM \u5927\u6982\u4e5f\u8981\u5beb\u4e00\u4efd\u6975\u5176\u76f8\u4f3c\u7684\u300cmodel\u300d</p>"},{"location":"hackmd/python/#web-framework","title":"web framework","text":"<ul> <li>Django vs Flask vs FastAPI \u2013 A Comparative Guide to Python Web Frameworks</li> </ul>"},{"location":"hackmd/python/#malware","title":"malware","text":"<ul> <li>quicksand</li> </ul>"},{"location":"hackmd/python/#markdown","title":"markdown","text":"<ul> <li>grip</li> </ul> <pre><code>grip doc/control-node-install-config-guide.md --export doc/control-node-install-config-guide.html\n</code></pre>"},{"location":"hackmd/python/#sqlite-utils","title":"sqlite utils","text":"<ul> <li>sqlite-utils<ul> <li>simonw/sqlite-utils: Python CLI utility and library for manipulating SQLite databases</li> <li>sqlite-utils: a nice way to import data into SQLite for analysis</li> </ul> </li> </ul>"},{"location":"hackmd/python/#iwhat","title":"iwhat","text":"<ul> <li>GitHub - yihong0618/iWhat: What is it? Using AI Inspired by pyWhat</li> </ul>"},{"location":"hackmd/python/#ipmi","title":"ipmi","text":"<ul> <li>GitHub - kontron/python-ipmi: A pure python IPMI library<ul> <li>python-ipmi/ipmitool.py at dbaf735df7736e581a8160b640e969d1d3fcf36d \u00b7 kontron/python-ipmi \u00b7 GitHub</li> <li>python-ipmi/dcmi.py at master \u00b7 kontron/python-ipmi \u00b7 GitHub</li> <li>How to get sdr/ sensor \u00b7 Issue #17 \u00b7 kontron/python-ipmi \u00b7 GitHub</li> </ul> </li> </ul> <pre><code>def print_sdr_list_entry(record_id, number, id_string, value, states):\n    if number:\n        number = str(number)\n    else:\n        number = 'na'\n\n    if states:\n        states = hex(states)\n    else:\n        states = 'na'\n\n    print(\"0x%04x | %3s | %-18s | %9s | %s\" % (record_id, number,\n                                               id_string, value, states))\n\n# Example usage\nip = \"167.222.1.33\"\nusername = \"foo\"\npassword = \"foo\"\n\ninterface = pyipmi.interfaces.create_interface(interface='rmcp',\n                                             slave_address=0x81,\n                                             host_target_address=0x20,\n                                             keep_alive_interval=1)\nipmi = pyipmi.create_connection(interface)\nipmi.session.set_session_type_rmcp(host=ip, port=623)\nipmi.session.set_auth_type_user(username=username, password=password)\n\nipmi.target = pyipmi.Target(ipmb_address=0x20)\n\nipmi.session.establish()\ndevice_id = ipmi.get_device_id()\nprint('''\nDevice ID:          %(device_id)s\nDevice Revision:    %(revision)s\nFirmware Revision:  %(fw_revision)s\nIPMI Version:       %(ipmi_version)s\nManufacturer ID:    %(manufacturer_id)d (0x%(manufacturer_id)04x)\nProduct ID:         %(product_id)d (0x%(product_id)04x)\nDevice Available:   %(available)d\nProvides SDRs:      %(provides_sdrs)d\nAdditional Device Support:\n'''[1:-1] % device_id.__dict__)\nfunctions = (\n        ('SENSOR', 'Sensor Device'),\n        ('SDR_REPOSITORY', 'SDR Repository Device'),\n        ('SEL', 'SEL Device'),\n        ('FRU_INVENTORY', 'FRU Inventory Device'),\n        ('IPMB_EVENT_RECEIVER', 'IPMB Event Receiver'),\n        ('IPMB_EVENT_GENERATOR', 'IPMB Event Generator'),\n        ('BRIDGE', 'Bridge'),\n        ('CHASSIS', 'Chassis Device')\n)\nfor n, s in functions:\n    if device_id.supports_function(n):\n        print('  %s' % s)\nif device_id.aux is not None:\n    print('Aux Firmware Rev Info:  [%s]' % (\n            ' '.join('0x%02x' % d for d in device_id.aux)))\n\nfor selector in range(1, 6):\n    caps = ipmi.get_dcmi_capabilities(selector)\n    print('Selector: {} '.format(selector))\n    print('  version:  {} '.format(caps.specification_conformence))\n    print('  revision: {}'.format(caps.parameter_revision))\n    print('  data:     {}'.format(caps.parameter_data))\n\nrsp = ipmi.get_power_reading(1)\n\nprint('Power Reading')\nprint('  current:   {}'.format(rsp.current_power))\nprint('  minimum:   {}'.format(rsp.minimum_power))\nprint('  maximum:   {}'.format(rsp.maximum_power))\nprint('  average:   {}'.format(rsp.average_power))\nprint('  timestamp: {}'.format(rsp.timestamp))\nprint('  period:    {}'.format(rsp.period))\nprint('  state:     {}'.format(rsp.reading_state))\n\nfor s in ipmi.device_sdr_entries():\n    try:\n        number = None\n        value = None\n        states = None\n\n        if s.type is pyipmi.sdr.SDR_TYPE_FULL_SENSOR_RECORD:\n            (value, states) = ipmi.get_sensor_reading(s.number)\n            number = s.number\n            if value is not None:\n                value = s.convert_sensor_raw_to_value(value)\n\n        elif s.type is pyipmi.sdr.SDR_TYPE_COMPACT_SENSOR_RECORD:\n            (value, states) = ipmi.get_sensor_reading(s.number)\n            number = s.number\n\n        id_string = getattr(s, 'device_id_string', None)\n\n        print_sdr_list_entry(s.id, number, id_string, value, states)\n\n    except pyipmi.errors.CompletionCodeError as e:\n        if s.type in (pyipmi.sdr.SDR_TYPE_COMPACT_SENSOR_RECORD,\n                        pyipmi.sdr.SDR_TYPE_FULL_SENSOR_RECORD):\n            print('0x{:04x} | {:3d} | {:18s} | ERR: CC=0x{:02x}'.format(\n                    s.id,\n                    s.number,\n                    s.device_id_string,\n                    e.cc))\n</code></pre>"},{"location":"hackmd/python/#streamlit","title":"Streamlit","text":"<ul> <li>Streamsync \u2014 Streamlit \u7684\u6311\u6230\u8005 - MyApollo</li> <li>(2023\u5e74\u65b0\u7248) \u4f7f\u7528 Streamlit \u7c21\u55ae\u53c8\u5feb\u901f\u5efa\u7acb Dashboard \u7db2\u9801 \u2013 IT \u7a7a\u9593</li> <li>Streamlit cheat sheet \u00b7 Streamlit</li> <li>App Gallery \u2022 Streamlit</li> </ul>"},{"location":"hackmd/python/#celery","title":"Celery","text":"<ul> <li>Asynchronous Tasks with FastAPI and Celery | TestDriven.io</li> </ul>"},{"location":"hackmd/python/#pytest","title":"pytest","text":"<ul> <li>pytest daemon: 10X Local Test Iteration Speed</li> </ul>"},{"location":"hackmd/python/#mkdocs","title":"mkdocs","text":"<ul> <li>Deploy MkDocs \u00b7 Actions \u00b7 GitHub Marketplace \u00b7 GitHub</li> <li>Document your project with MkDocs and GitHub Pages - DEV Community</li> </ul> <pre><code>mkdocs build\nmkdocs serve\nmkdocs serve -a localhost:8888\n</code></pre> <p>use the system daemon /etc/systemd/system/xxx.service <pre><code>[Unit]\nDescription=Job that runs the python SimpleHTTPServer daemon\nDocumentation=man:SimpleHTTPServer(1)\n\n[Service]\nType=simple\nWorkingDirectory=/home/supermicro/smci-doc/site\nExecStart=/usr/bin/python3 -m http.server 8888\nExecStop=/bin/kill `/bin/ps aux | /bin/grep http.server | /bin/grep -v grep | /usr/bin/awk '{ print $2 }'`\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <pre><code>site_name: My Docs\n# plugins:\n#   - offline\nmarkdown_extensions:\n  - admonition\n  - pymdownx.details\n  - pymdownx.highlight:\n      anchor_linenums: true\n      line_spans: __span\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - pymdownx.superfences\n  - pymdownx.tabbed:\n      alternate_style: true\ntheme:\n  name: material\n  features:\n    - navigation.top\n    - navigation.path\n    - search.highlight\n    - search.share\n    - navigation.footer\n    - content.code.copy\n    - content.code.select\n    - content.code.annotate\nextra:\n  social:\n    - icon: fontawesome/brands/gitlab \n      link: https://gitlab.supermicro.com/\ncopyright: Copyright &amp;copy; 2023\n</code></pre>"},{"location":"hackmd/python/#pywifi","title":"pywifi","text":"<ul> <li>\u7528 Python \u7834\u89e3\u9694\u58c1\u8001\u738b\u5bb6\u7684 Wi-Fi \u5bc6\u7801\uff0c\u523a\u6fc0\uff01 - FooFish</li> </ul>"},{"location":"hackmd/python/#pyee","title":"pyee","text":"<ul> <li>\u5f9e pyee \u8a8d\u8b58\u89c0\u5bdf\u8005\u6a21\u5f0f | \u516d\u5c0f\u7de8 Editor Leon</li> </ul>"},{"location":"hackmd/python/#diagrams","title":"diagrams","text":"<ul> <li>Python \u5957\u4ef6\u4ecb\u7d39 \u2014 Diagrams - MyApollo</li> </ul>"},{"location":"hackmd/python/#airflow","title":"airflow","text":"<ul> <li>LeeMeng - \u4e00\u6bb5 Airflow \u8207\u8cc7\u6599\u5de5\u7a0b\u7684\u6545\u4e8b\uff1a\u8ac7\u5982\u4f55\u7528 Python \u8ffd\u6f2b\u756b\u9023\u8f09</li> </ul>"},{"location":"hackmd/python/#ansible-playbook-grapher","title":"ansible-playbook-grapher","text":"<ul> <li>GitHub - haidaraM/ansible-playbook-grapher: A command line tool to create a graph representing your Ansible playbook tasks and roles</li> </ul>"},{"location":"hackmd/python/#glances","title":"glances","text":"<ul> <li>GitHub - nicolargo/glances: Glances an Eye on your system. A top/htop alternative for GNU/Linux, BSD, Mac OS and Windows operating systems.</li> </ul>"},{"location":"hackmd/python/#tw_stocker","title":"tw_stocker","text":"<ul> <li>voidful/tw_stocker: keep tracking and store taiwan stock information - \u6bcf\u5929\u66f4\u65b0\u53f0\u80a1\u6b77\u53f2\u8cc7\u6599\u5eab<ul> <li>s9891326/tw_stocker: keep tracking and store taiwan stock information</li> </ul> </li> </ul>"},{"location":"hackmd/python/#docling","title":"Docling","text":"<ul> <li>\u900f\u904e Docling \u8f15\u9b06\u89e3\u6790\u5e38\u898b\u6587\u4ef6\uff0c\u532f\u51fa\u6210 JSON\u3001Markdown\u3001HTML \u683c\u5f0f \u2013 IT \u7a7a\u9593</li> </ul> <p>alternative: microsoft/markitdown: Python tool for converting files and office documents to Markdown.</p>"},{"location":"hackmd/python/#garmin-grafana","title":"garmin-grafana","text":"<ul> <li>GitHub - arpanghosh8453/garmin-grafana: A Dockerized python Script to fetch Garmin health data and populate that in a InfluxDB Database, for visualization long term health trends with Grafana</li> </ul>"},{"location":"hackmd/python/#software-development-tools","title":"software development tools","text":"<ul> <li>Python\u7684\u4e00\u4e9b\u5957\u4ef6(black\u3001isort\u3001pylint) + pre-commit - HackMD</li> <li>pre-commit<ul> <li>\u63d0\u5347\u7a0b\u5f0f\u78bc\u54c1\u8cea\uff1a\u4f7f\u7528 Pre-Commit (Git Hooks) | Mr. Opengate</li> <li>pre-commit \u8a2d\u5b9a Git Hooks \u6559\u5b78\uff1a\u4ee5 Flake8\u3001isort\u3001yapf \u70ba\u4f8b - Code and Me</li> <li>pre-commit</li> <li>GitHub - pre-commit/pre-commit-hooks: Some out-of-the-box hooks for pre-commit<ul> <li>commitlint \u00b7 PyPI<ul> <li>pre-commit install --hook-type commit-msg</li> </ul> </li> </ul> </li> </ul> </li> <li>git-changelog<ul> <li>GitHub - pawamoy/git-changelog: Automatic Changelog generator using Jinja2 templates.<ul> <li>git-changelog \u00b7 PyPI</li> <li>Usage - git-changelog</li> </ul> </li> <li>Conventional Commits</li> <li>How To Automatically Generate A Helpful Changelog From Your Git Commit Messages | Michael Hoffmann</li> </ul> </li> </ul> <p>.pre-commit-config.yaml <pre><code>repos:\n  - repo: https://github.com/opensource-nepal/commitlint\n    rev: v1.2.0\n    hooks:\n      - id: commitlint\n</code></pre></p> <pre><code>git-changelog -io CHANGELOG.md -c angular\n</code></pre>"},{"location":"hackmd/python/#cheat-sheet","title":"Cheat Sheet","text":"<ul> <li>Python 3 Cheat Sheet</li> </ul>"},{"location":"hackmd/shell%20script/","title":"shell script","text":"<ul> <li>BashGuide<ul> <li>BashWeaknesses - Greg's Wiki</li> </ul> </li> <li>Bash Scripting Tutorial</li> <li>GitHub - neurobin/shc: Shell script compiler<ul> <li>\u5c07Bash shell script\u8f49\u63db\u6210ELF\uff08\u53ef\u57f7\u884c\u53ca\u53ef\u9023\u7d50\u7684\u683c\u5f0f\uff09</li> <li><code>shc -e \"dd/mm/yyyy\" -m \"&lt;comments&gt;\" -r -f &lt;bash_script&gt;</code></li> </ul> </li> <li>Minimal safe Bash script template</li> <li>Bash-Oneliner</li> <li>\u6211\u8207BASH shell scripting\u7684\u6bcf\u4e00\u5929</li> <li>linux - What is the difference between executing a Bash script vs sourcing it? - Super User</li> <li>nice examples<ul> <li>go-xcat</li> </ul> </li> <li>[\u5be6\u4f5c\u7b46\u8a18] Bash \u8f38\u51fa\u5f69\u8272\u6280\u5de7 | Marsen's Blog</li> </ul>"},{"location":"hackmd/shell%20script/#variable","title":"variable","text":"<ul> <li>Variable substitution with an exclamation mark in bash</li> <li>What is the meaning of the ${0##...} syntax with variable, braces and hash character in bash</li> <li>shell - What does mean $$ or $! in bash? - Stack Overflow</li> <li>shell script - How do I trim leading and trailing whitespace from each line of some output? - Unix &amp; Linux Stack Exchange</li> <li>declare array in the function<ul> <li>Bash array declared in a function is not available outside the function - Unix &amp; Linux Stack Exchange<ul> <li> <p>When used in a function, declare makes each name local, as with the local command, unless the \u2018-g\u2019 option is used.</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/shell%20script/#arrays","title":"Arrays","text":"<ul> <li>Bash append to array</li> <li>Passing arrays as parameters in bash</li> <li>How to pass multiple arguments including arrays to a function in Bash where order is not defined and array elements can have multiple words</li> <li>How to pass array as an argument to a function in Bash</li> <li>loop<ul> <li>Loop through an array of strings in Bash? - Stack Overflow</li> <li>Bash Loop Through a List of Strings</li> </ul> </li> </ul> <p>``` bash=</p>"},{"location":"hackmd/shell%20script/#usrbinbash","title":"! /usr/bin/bash","text":"<p>declare -a _temperature_entities=(\"CPU Temp\" \"System Temp\" \"AOC_NIC Temp\")</p> <p>for reqsubstr in \"${_temperature_entities[@]}\"; do     echo \"reqsubstr: $reqsubstr\" done <pre><code>append and combine\n``` bash=\nfruits=(\"apple\" \"banana\")\necho \"Initial array: ${fruits[@]}\"\n\nfruits+=(orange)\necho \"Appended array: ${fruits[@]}\"\n\ncombined_value=$(IFS=\",\" ; echo \"${fruits[*]}\")\necho \"Combined Value: $combined_value\"\n</code></pre></p> <p>pass arrays as parameters ``` bash=</p>"},{"location":"hackmd/shell%20script/#binbash","title":"!/bin/bash","text":""},{"location":"hackmd/shell%20script/#declare-two-arrays","title":"declare two arrays","text":"<p>array1=(1 2 3 4 5) array2=(\"a\" \"b\" \"c\" \"d\" \"e\")</p>"},{"location":"hackmd/shell%20script/#function-that-accepts-two-array-parameters","title":"function that accepts two array parameters","text":"<p>my_function() {   local arr1=(\"${@:1:${#}/2}\")  # copy the first array into a local variable   local arr2=(\"${@:$(( ${#}/2 + 1 ))}\")  # copy the second array into a local variable   echo \"The first array elements are: ${arr1[@]}\"   echo \"The second array elements are: ${arr2[@]}\" }</p>"},{"location":"hackmd/shell%20script/#call-the-function-with-the-two-arrays-as-parameters","title":"call the function with the two arrays as parameters","text":"<p>my_function \"${array1[@]}\" \"${array2[@]}\" <pre><code>## substring\n- [How to check if a string contains a substring in Bash](https://stackoverflow.com/questions/229551/how-to-check-if-a-string-contains-a-substring-in-bash/229585#229585)\n\n## iterate\n- [Bash: Iterating over lines in a variable - Super User](https://superuser.com/questions/284187/bash-iterating-over-lines-in-a-variable)\n\n``` bash=\nwhile IFS= read -r line; do\n    echo \"... $line ...\"\ndone &lt;&lt;&lt; \"$list\"\n</code></pre></p>"},{"location":"hackmd/shell%20script/#background-task","title":"background task","text":"<p>``` bash=</p>"},{"location":"hackmd/shell%20script/#usrbinbash_1","title":"! /usr/bin/bash","text":"<p>main_task() {     #sleep 5     echo \"main task done\"     exit 1 }</p> <p>main_task &amp; ret=$? echo \"ret is $ret\" <pre><code>:::info\nret is 0\nmain task done\n:::\n\n``` bash=\n#! /usr/bin/bash\n\nmain_task()\n{\n    #sleep 5\n    echo \"main task done\"\n    exit 1\n}\n\nmain_task &amp;\nbgprocess1=$!\nwait $bgprocess1\nret=$?\necho \"ret is $ret\"\n</code></pre></p> <p>:::info main task done ret is 1 :::</p>"},{"location":"hackmd/shell%20script/#regular-expression","title":"regular expression","text":"<p>=~ ``` bash= [[ \"CPU1 Temp        | 01h | ok  |  3.1 | 84 degrees C\" =~ CPU[0-9]?* ]] ; echo $? <pre><code>``` bash=\n#! /bin/bash\n\nOSVER=ubuntu20.04.3\nubuntu_major_ver_list=('20' '22')\nif [[ $OSVER =~ ^ubuntu([[:digit:]]{2}).([[:digit:]]{2}).([[:digit:]]{1}) ]]; then\n    distribution_major_ver=${BASH_REMATCH[1]}\n        echo \"$distribution_major_ver\"\n    msgutil_r \"$MASTER_IP\" \"debug\" \"Ubuntu distribution and major version is ${distribution_major_ver}\" \"/var/log/xcat/xcat.log\" \"$log_label\"\n    # Check if the string $distribution_major_ver is in the list\n    for reqsubstr in \"${ubuntu_major_ver_list[@]}\"; do\n        echo \"reqsubstr: $reqsubstr\"\n        if [[ $distribution_major_ver = $reqsubstr ]]; then\n            echo $distribution_major_ver\n            break\n        fi\n    done\nfi\n</code></pre></p>"},{"location":"hackmd/shell%20script/#regx-group","title":"regx group","text":"<p>``` bash= _ipmi_host=127.0.0.1 declare -A _phase_meta snmp_out=$(snmpwalk -v2c -c public ${_ipmi_host} .1.3.6.1.4.1.1718.4.1.5.2.1.4)</p>"},{"location":"hackmd/shell%20script/#snmpv2-smienterprises1718415214111-string-aal1-l2","title":"SNMPv2-SMI::enterprises.1718.4.1.5.2.1.4.1.1.1 = STRING: \"AA:L1-L2\"","text":""},{"location":"hackmd/shell%20script/#snmpv2-smienterprises1718415214112-string-aal2-l3","title":"SNMPv2-SMI::enterprises.1718.4.1.5.2.1.4.1.1.2 = STRING: \"AA:L2-L3\"","text":""},{"location":"hackmd/shell%20script/#snmpv2-smienterprises1718415214113-string-aal3-l1","title":"SNMPv2-SMI::enterprises.1718.4.1.5.2.1.4.1.1.3 = STRING: \"AA:L3-L1\"","text":"<p>while IFS= read -r line; do     logDebug \"Read line: $line\"     regex=\"enterprises.[0-9]{4}.([0-9].){6}([0-9].{1})([0-9].{1})([0-9]{1}) = STRING: \\\"AA:(L[0-9]-L[0-9])\"     if [[ $line =~ $regex ]]     then         unit=${BASH_REMATCH[2]}         cord=${BASH_REMATCH[3]}         phase_idx=${BASH_REMATCH[4]}         phase_label=${BASH_REMATCH[5]}         echo \"${unit} ${cord} ${phase_idx} ${phase_label}\"         # _phase_meta[${phase_idx}]=${phase_label}         local _phase_meta[a]=b         declare -p _phase_meta     else         logWarn \"$line doesn't match\" &gt;&amp;2 # this could get noisy if there are a lot of non-matching files     fi done &lt;&lt;&lt; \"$snmp_out\" <pre><code>## pass an associative array as an argument to a function\n\n\n## others\n- [looping through `ls` results in bash shell script](https://superuser.com/questions/31464/looping-through-ls-results-in-bash-shell-script)\n- [bash - How do you list all functions and aliases in a specific script? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/260627/how-do-you-list-all-functions-and-aliases-in-a-specific-script)\n\n\n### Test\n- [Unit Test Shell Scripts:Part One](https://www.leadingagile.com/2018/10/unit-test-shell-scripts-part-one/)\n- [Unit testing for shell scripts](https://stackoverflow.com/questions/971945/unit-testing-for-shell-scripts)\n- [Shell Script \u4e5f\u53ef\u4ee5\u5beb\u6e2c\u8a66](https://ithelp.ithome.com.tw/articles/10139122)\n    - [shunit2](https://github.com/kward/shunit2)\n\n### Debug\n- [shell - How can I debug a Bash script? - Stack Overflow](https://stackoverflow.com/questions/951336/how-can-i-debug-a-bash-script)\n- [bash -x command - Stack Overflow](https://stackoverflow.com/questions/10107124/bash-x-command)\n- [command line - How to list all variables names and their current values? - Ask Ubuntu](https://askubuntu.com/questions/275965/how-to-list-all-variables-names-and-their-current-values)\n\n### Reuse\n- [[Shell Script] Day28-\u592a\u591a\u5171\u540c\u7684 function \u600e\u9ebc\u8fa6](https://ithelp.ithome.com.tw/articles/10138849)\n- [bash - How shall I reuse a function in multiple scripts? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/448031/how-shall-i-reuse-a-function-in-multiple-scripts)\n\n## example\n\nBuild shx from source code\n``` bash=\nsrc_dir=foo/bin\nexpired=30/04/2023\nnotes=\"Notes for foo demo purpose\"\nfind ${src_dir} -type f -name \"*.sh\" | xargs -n1 'shc -e \"${expired}\" -m \"${notes}\" -r -f'\nfind ${src_dir} -type f -name \"*.sh.x.c\" | xargs rm\nfind ${src_dir} -type f -name \"*.sh.x\"\n</code></pre></p>"},{"location":"hackmd/xcat/","title":"xcat","text":"<ul> <li>man8 \u2014 xCAT 2.16.4 documentation</li> <li>debug<ul> <li>cluster.log no content</li> <li>Adding an additional network driver to the genesis image for x86_64 architecture \u00b7 Issue #7109 \u00b7 xcat2/xcat-core \u00b7 GitHub<ul> <li>genesis boot failing on Intel E810 NIC cards using xCAT 2.16.4 version \u00b7 Issue #7401 \u00b7 xcat2/xcat-core \u00b7 GitHub</li> </ul> </li> <li>CentOS 8.3 xCAT 3.0 copycds can't recognize cumulus image \u00b7 Issue #6947 \u00b7 xcat2/xcat-core \u00b7 GitHub</li> <li>Re: [xcat-user] missing entries in /tftpboot/xcat/xnba/nets | xCAT<ul> <li>mknb x86_64</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/xcat/#basic","title":"basic","text":"<pre><code>lsdef\nlsdef -t node\nlsdef -t node cn1\nnodels\nman node\n\ntabdump\ntabdump {table}\ntabdump -d {table}\nman {table}\nman xcatdb\n\nchdef -t site master=\"xcat_master_ip\"\nchtab key=system passwd.username=root passwd.password=`openssl passwd -1 abc123`\nchtab key=xcat passwd.username=xcatws passwd.password=`openssl passwd -1 abc123`\n\nchdef -t node -o cn1 ip=\"192.168.89.30\"\nchdef -t network 10_0_0_0-255_255_0_0 dynamicrange=\"10.0.100.1-10.0.100.100\"\n\nmkdef -t node cn1 --template x86_64-template ip=192.168.89.29 mac=3C:EC:EF:6E:FD:F2 bmc=172.17.43.236 bmcusername=aaa bmcpassword=vvv\n\nxcatprobe xcatmn -i ens160\n\ncopycds rhel-8.5-x86_64-dvd.iso\n\nxcatprobe osdeploy -n cn1\n\nmakenetworks\n\nchdef -t osimage rhels8.8.0-x86_64-netboot-compute pkglist=/install/custom/package/rh8/compute.rhels8.x86_64.pkglist\n\nrmimage rhels8.8.0-custom-statelite\nrm /install/netboot/rhels8.8.0/x86_64/compute/rootimg-statelite.gz\n\nmkdef -t osimage -o rhels8.8.0-x86_64-netboot-compute-ted --template rhels8.8.0-x86_64-netboot-compute\nchdef -t osimage -o rhels8.8.0-x86_64-netboot-compute-ted rootimgdir=/install/netboot/rhels8.8.0/x86_64/compute/ted\nchdef -t osimage -o rhels8.8.0-x86_64-netboot-compute-ted -p postbootscripts=customzied_setup_node\n\n\nchdef -t node -o p2an002 -p postbootscripts=customzied_setup_node\n\n\n# ntp\nchdef -t site extntpservers=\"0.pool.ntp.org,1.pool.ntp.org\"\nmakentp\n\n# backup\nlsdef -z node12 &gt; predefined.stanzas.node12\n# remove xcat node info\nnodepurge node12\n\n# restore\ncat predefined.stanzas.node12 | mkdef -z\n</code></pre> <p>/install/postscripts/customzied_setup_node <pre><code>#!/bin/bash\n\necho \"mypostbootscript begin\"\ndf -hT\nuseradd -m foo \necho 'foo:bar' | chpasswd\necho \"mypostbootscript end\"\n</code></pre></p>"},{"location":"hackmd/xcat/#travesal","title":"travesal","text":"<p>Set static BMC IP using different IP address (recommended) \u2014 xCAT 2.16.4 documentation</p> <p>``` bash= bmcdiscover --range 172.17.30.124 -u {bmc_id} -p {bmc_pwd} -z &gt; predefined.stanzas cat predefined.stanzas | mkdef -z <pre><code>### mtms discovery\n- [Re: [xcat-user] [External] XCAT 2.16 Discovery Mode - Genesis](https://www.mail-archive.com/xcat-user@lists.sourceforge.net/msg07844.html)\n    -  You can enter multiple macs for a node and specify NOIP for macs you don't want it to boot from (mac table entry: node,,\"1:2:3:4|5:6:7:8!NOIP\"). Make sure to run makedhcp after doing this.\n\nxcat 2.16.5\nneed to change the code `/opt/xcat/lib/perl/xCAT_plugin/bmcdiscover.pm`\nLine 1205 to 1221\n``` perl\n#if (($fru_output =~ /Chassis Part Number\\s*:\\s*(\\S*).*Chassis Serial\\s*:\\s*(\\S*)/)) {\n# \u00a0 \u00a0$mtm \u00a0 \u00a0= $1;\n# \u00a0 \u00a0$serial = $2;\n# \u00a0 \u00a0last;\n#}\n#if (($fru_output =~ /Product Part Number \u00a0 :\\s*(\\S*).*Product Serial \u00a0 \u00a0 \u00a0 \u00a0:\\s*(\\S*)/)) {\n# \u00a0 \u00a0$mtm \u00a0 \u00a0= $1;\n# \u00a0 \u00a0$serial = $2;\n# \u00a0 \u00a0last;\n#}\nif (($fru_output =~ /Product Manufacturer\\s+:\\s+(.*?)\\s+Product Part Number\\s+:\\s+(.*?)\\s+P.*?roduct Serial\\s+:\\s+(\\S+)/)) {\n\u00a0 \u00a0 $mtm \u00a0 \u00a0= $1.\":\".$2;\n\u00a0 \u00a0 $serial = $3;\n\u00a0 \u00a0 last;\n}\n</code></pre></p> <p>root cause is from https://github.com/xcat2/xcat-core/blob/1534231ae7b7e0b4136ffef16374c0a870710a75/xCAT-genesis-scripts/usr/bin/dodiscovery#L93</p> <p>follow MTMS-based Discovery \u2014 xCAT 2.16.5 documentation</p>"},{"location":"hackmd/xcat/#internal","title":"internal","text":"<p>https://github.com/xcat2/xcat-core/blob/f7e389a0c03fb18f8f1236cb4ad3fe8605765c51/xCAT-server/lib/xcat/plugins/bmcdiscover.pm#L619 scan_process nmap to get live_ip ipmitool-xcat to get mc info</p>"},{"location":"hackmd/xcat/#bmc-discovery-issues","title":"bmc discovery issues","text":"<ul> <li>ipmitool - Error: Unable to establish IPMI v2 / RMCP+ session - Stack Overflow</li> <li>FAQ Entry | Online Support | Support - Super Micro Computer, Inc.</li> </ul>"},{"location":"hackmd/xcat/#build-gensis-image-on-rhel-93","title":"build gensis image on rhel 9.3","text":"<pre><code>cd /tmp\ngit clone -b master https://github.com/xcat2/xcat-core.git\ncd /tmp/xcat-core/xCAT-genesis-builder\n# chnage the xcat-cmdline.sh, add all drivers\n# before:\n# for line in `cat /lib/modules/$KERVER/modules.dep |grep -vE 'tunnel|ieee|ifb|bond|dummy|fjes|hv_netvsc|ntb_netdev|xen-netfront|hdlc_fr|dlci'| awk -F: '{print \\$1}' | sed -e \"s/\\(.*\\)\\.ko.*/\\1/\"`; do\n# after:\n# for line in `cat /lib/modules/$KERVER/modules.dep | awk -F: '{print \\$1}' | sed -e \"s/\\(.*\\)\\.ko.*/\\1/\"`; do\nrm -rf /root/rpmbuild\n./buildrpm\nrpm -qa | grep 'xCAT-genesis-base-x86_64'\nrpm -e --nodeps $(rpm -qa | grep 'xCAT-genesis-base-x86_64')\ncd /root/rpmbuild/RPMS/noarch\nrpm -ivh xCAT-genesis-base*.rpm\n\n# for missing packages\ndnf install dhclient rng-tools device-mapper\ngrep -irn '/lib/udev/rules.d/69-dm-lvm*' /tmp/xcat-core/xCAT-genesis-builder/install\n# replace /lib/udev/rules.d/69-dm-lvm-metad.rules into /lib/udev/rules.d/69-dm-lvm.rules in the /tmp/xcat-core/xCAT-genesis-builder/install\n\nmknb x86_64\n</code></pre>"},{"location":"hackmd/xcat/#initialize-after-docker-container-start","title":"initialize after docker container start","text":"<ul> <li>Quick Start Guide \u2014 xCAT 2.16.4 documentation</li> </ul>"},{"location":"hackmd/xcat/#basic_1","title":"basic","text":"<p>``` bash=</p>"},{"location":"hackmd/xcat/#xcat_master_ip-is-1921688910","title":"xcat_master_ip is 192.168.89.10","text":"<p>chdef -t site domain=\"polab\" chdef -t site master=\"{xcat_master_ip}\" chdef -t site dhcpinterfaces=\"ens192\" chtab key=system passwd.username=root passwd.password=<code>openssl passwd -1 abc123</code> echo \"192.168.89.10 xcatmn xcatmn.polab\" &gt;&gt; /etc/hosts</p>"},{"location":"hackmd/xcat/#networks","title":"networks","text":"<p>mkdef -t network -o provision_net net=192.168.89.0 mask=255.255.255.0 gateway=192.168.89.254 mgtifname=ens192 dhcpserver=192.168.89.10 tftpserver=192.168.89.10 nameservers=192.168.89.10 dynamicrange=192.168.89.30-192.168.89.40 staticrange=192.168.89.29-192.168.89.29 mtu=1500 tabch -d netname=172_18_0_0-255_255_0_0 networks # remove docker related net</p>"},{"location":"hackmd/xcat/#node","title":"node","text":"<p>mkdef -t node cn1 --template x86_64-template ip=192.168.89.29 mac=3C:EC:EF:6E:FD:F2 bmc=172.17.43.236 bmcusername=aaa bmcpassword=vvv</p>"},{"location":"hackmd/xcat/#dns","title":"dns","text":"<p>makehosts cn1 # check the /etc/hosts makedns -n # systemctl status named</p>"},{"location":"hackmd/xcat/#dhcp","title":"dhcp","text":"<p>makedhcp -n # check the /etc/dhcp/dhcpd.conf makedhcp -a # check the /var/lib/dhcpd/dhcpd.leases in redhat; /var/lib/dhcp/dhcpd.leases in ubuntu</p>"},{"location":"hackmd/xcat/#verity-environment-is-ok-for-deploying-os","title":"verity environment is ok for deploying os","text":"<p>xcatprobe xcatmn -i ens192</p>"},{"location":"hackmd/xcat/#deploy-os","title":"deploy os","text":"<p>copycds CentOS-7-x86_64-DVD-2009.iso lsdef -t osimage rinstall cn1 osimage=centos-stream8-x86_64-install-compute</p>"},{"location":"hackmd/xcat/#check-the-deploy-status","title":"check the deploy status","text":"<p>xcatprobe osdeploy -n cn1</p> <p><pre><code>### use existed node info\n</code></pre> lsdef -z node22 &gt; predefined.stanzas cat predefined.stanzas | mkdef -z <pre><code>## networks\n- [Set attributes in the networks table \u2014 xCAT 2.16.4 documentation](https://xcat-docs.readthedocs.io/en/stable/guides/admin-guides/manage_clusters/ppc64le/configure/networks.html?highlight=static%20dhcp)\n- [Use Customized Scripts To Configure NIC \u2014 xCAT 2.16.4 documentation](https://xcat-docs.readthedocs.io/en/stable/guides/admin-guides/manage_clusters/common/deployment/network/cfg_network_custom_scripts.html?highlight=staticrange)\n\n### rest api\n\n``` bash=\n# run the xcat command xcatconfig to generate a new server certificate based on the correct hostname\nxcatconfig -c\n\n# change the ssl config file\nexport sslcfgfile=/etc/httpd/conf.d/ssl.conf\nsed -i 's/^\\(\\s*\\)SSLCertificateFile.*$/\\1SSLCertificateFile \\/etc\\/xcat\\/cert\\/server-cred.pem/' $sslcfgfile\nsed -i 's/^\\(\\s*SSLCertificateKeyFile.*\\)$/#\\1/' $sslcfgfile\nsystemctl restart httpd\n\n# create the user who can access rest api\ntabch key=xcat,username=root passwd.password=`openssl passwd -1 123456`\n\n# download the xCAT certificate CA from the xCAT http server to authenticate the certificate of the server. \ncd /root &amp;&amp; wget http://xcatmn.polab/install/postscripts/ca/ca-cert.pem\n\n# test\ncurl -X GET --cacert /root/ca-cert.pem 'https://xcatmn.polab/xcatws/nodes?userName=root&amp;userPW=123456'\n\n# token\ncurl -X POST --cacert /etc/pki/tls/certs/localhost.crt -H Content-Type:application/json --data '{\"userName\":\"root\",\"userPW\":\"123456\"}' 'https://xcatmn.polab/xcatws/tokens?pretty=1'\n\ncurl -X GET --cacert /etc/pki/tls/certs/localhost.crt -H X-Auth-Token:9b4481fd-9eab-4c7d-81fc-064af4420efe 'https://xcatmn.polab/xcatws/nodes'\n</code></pre></p>"},{"location":"hackmd/xcat/#httpd","title":"httpd","text":"<p>check the /etc/httpd/conf.d/xcat.conf</p> <p>if redhat, it means that local repo  - BaseOS - AppStream</p>"},{"location":"hackmd/xcat/#remote-console","title":"remote console","text":"<ul> <li>rcons - Remote Console \u2014 xCAT 2.16.5 documentation</li> </ul>"},{"location":"hackmd/xcat/#customized","title":"customized","text":""},{"location":"hackmd/xcat/#partition","title":"partition","text":"<ul> <li>Configure Disk Partition \u2014 xCAT 2.16.4 documentation</li> </ul>"},{"location":"hackmd/xcat/#package-list","title":"package list","text":"<ul> <li>Add Additional Software Packages \u2014 xCAT 2.16.5 documentation<ul> <li>Install Additional OS Packages for RHEL and SLES \u2014 xCAT 2.16.5 documentation</li> </ul> </li> </ul>"},{"location":"hackmd/xcat/#log-rotation","title":"log rotation","text":"<ul> <li>Re: [xcat-user] Change rolling mechanism for xcat logs</li> </ul> <p>/etc/logrotate.d/xcat <pre><code>/var/log/xcat/*.log {\n    daily\n    rotate 3\n    size 1G\n    missingok\n    sharedscripts\n    copytruncate\n    compress\n    delaycompress\n    postrotate\n        test -f /var/run/rsyslogd.pid &amp;&amp; kill -HUP `cat /var/run/rsyslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true\n        test -f /var/run/syslogd.pid &amp;&amp; kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true\n        test -f /var/run/xcat/cmdlogservice.pid &amp;&amp; kill -HUP `cat /var/run/xcat/cmdlogservice.pid 2&gt; /dev/null` 2&gt; /dev/null || true\n    endscript\n}\n</code></pre></p> <pre><code>sudo logrotate -d /etc/logrotate.d/xcat\n</code></pre>"},{"location":"hackmd/xcat/#cli","title":"CLI","text":""},{"location":"hackmd/xcat/#makehosts","title":"makehosts","text":"<p>sets up /etc/hosts from the xCAT hosts table. makehosts.8 \u2014 xCAT 2.16.4 documentation</p>"},{"location":"hackmd/xcat/#makedns","title":"makedns","text":"<p>By default, makedns sets up the named service and updates the DNS records on the local system (management node).</p> <p>makedns.8 \u2014 xCAT 2.16.4 documentation</p>"},{"location":"hackmd/xcat/#makedhcp","title":"makedhcp","text":"<ul> <li>Switch-based Discovery \u2014 xCAT 2.16.4 documentation</li> </ul> <pre><code>cat /var/lib/dhcpd/dhcpd.leases\n</code></pre>"},{"location":"hackmd/xcat/#copycds","title":"copycds","text":"<p>Select or Create an osimage Definition \u2014 xCAT 2.16.4 documentation copy all contents of Distribution DVDs/ISOs or Service Pack DVDs/ISOs to a destination directory, and create several relevant osimage definitions by default.</p> <ul> <li><code>&lt;os&gt;-&lt;arch&gt;-install-compute</code> is the default osimage definition used for diskful installation</li> <li><code>&lt;os&gt;-&lt;arch&gt;-netboot-compute</code> is the default osimage definition used for diskless installation</li> <li><code>&lt;os&gt;-&lt;arch&gt;-install-service</code> is the default osimage definition used for service node deployment which shall be used in hierarchical environment</li> </ul>"},{"location":"hackmd/xcat/#rinstall","title":"rinstall","text":"<p>rinstall.8 \u2014 xCAT 2.16.4 documentation</p>"},{"location":"hackmd/xcat/#noderange","title":"noderange","text":"<p>noderange.3 \u2014 xCAT 2.16.4 documentation</p>"},{"location":"hackmd/xcat/#group","title":"group","text":"<p>group \u2014 xCAT 2.16.4 documentation - static     - contain a specific set of cluster nodes. - dynamic     - determined by specifying a selection criteria for node attributes.     - The selection criteria is a list of attr\\&lt;operator&gt;val pairs that can be used to determine the members of a group</p> <pre><code>lsdef -t group\n</code></pre> <p>:::info In a large cluster environment it is recommended to focus on group definitions as much as possible and avoid setting the attribute values in the individual node definition. :::</p> <p>There are two basic ways to create xCAT static node groups.  1. You can either set the groups attribute of the node definition 2. you can create a group definition directly.</p> <p>These two options will result in exactly the same definitions and attribute values being created in the xCAT database.</p>"},{"location":"hackmd/xcat/#diskless","title":"Diskless","text":"<ul> <li>Diskless Installation \u2014 xCAT 2.16.5 documentation<ul> <li>Generate Diskless Image \u2014 xCAT 2.16.5 documentation</li> <li>Initialize the Compute for Deployment \u2014 xCAT 2.16.5 documentation<ul> <li>rsetboot.1 \u2014 xCAT 2.16.5 documentation</li> <li>genimage.1 \u2014 xCAT 2.16.6 documentation</li> </ul> </li> </ul> </li> </ul> <p>``` bash=</p>"},{"location":"hackmd/xcat/#prepare-rhel-latest-iso-and-copycds","title":"prepare rhel latest iso and copycds","text":"<p>copycds /tmp/rhel-8.8-x86_64-dvd.iso</p>"},{"location":"hackmd/xcat/#optionalcustomized-some-behavior-for-example","title":"[optional]customized some behavior for example","text":"<p>lsdef -t osimage -o rhels8.8.0-x86_64-netboot-compute -i postinstall chdef -t osimage -o rhels8.8.0-x86_64-netboot-compute -p postinstall=/install/custom/postinstall/rh8/mypostscript</p>"},{"location":"hackmd/xcat/#optionalcustimized-package-list","title":"[optional]custimized package list","text":"<p>lsdef -t osimage -o rhels8.8.0-x86_64-netboot-compute -i pkglist chdef -t osimage rhels8.8.0-x86_64-netboot-compute pkglist=/install/custom/package/rh8/compute.rhels8.x86_64.pkglist</p>"},{"location":"hackmd/xcat/#generate-a-diskless-image","title":"generate a diskless image","text":"<p>genimage rhels8.8.0-x86_64-netboot-compute</p>"},{"location":"hackmd/xcat/#after-running-genimage-to-create-the-image-run-packimage-to-create-the-ramdisk","title":"After running genimage to create the image, run packimage to create the ramdisk","text":"<p>packimage rhels8.8.0-x86_64-netboot-compute</p>"},{"location":"hackmd/xcat/#associate-a-specific-image-to-a-node","title":"associate a specific image to a node","text":"<p>nodeset  osimage=rhels8.8.0-x86_64-netboot-compute"},{"location":"hackmd/xcat/#start-the-os-deployment","title":"Start the OS Deployment","text":"<p>rsetboot  net -u rpower  reset <pre><code>/install/custom/postinstall/rh8/mypostscript\n</code></pre>"},{"location":"hackmd/xcat/#binsh","title":"!/bin/sh","text":"<p>installroot=$1 osver=$2 arch=$3 profile=$4 workdir=$5</p> <p>echo \"167.22.10.1:/opt_shared /opt_shared nfs defaults,x-systemd.automount,x-systemd.requires=network-online.target,x-systemd.mount-timeout=30 0 0\" &gt;&gt; $installroot/etc/fstab test -d \"$installroot/opt_shared\"  &amp;&amp; echo \"$installroot/opt_shared exist\" ||  mkdir $installroot/opt_shared <pre><code>default\n/opt/xcat/share/xcat/netboot/rh/compute.rhels8.x86_64.pkglist\n</code></pre> @minimal-environment chrony kernel net-tools nfs-utils openssh-server rsync tar util-linux wget python3 tar bzip2 bc dracut dracut-network rsyslog hostname e2fsprogs ethtool parted openssl dhclient openssh-clients bash vim-minimal rpm iputils perl-interpreter <pre><code>customized\n/install/custom/package/rh8/compute.rhels8.x86_64.pkglist\n</code></pre> @Server with GUI @development @infiniband @performance @scientific @system-tools chrony net-tools nfs-utils openssh-server rsync util-linux wget python3 tar bzip2 perl-interpreter <pre><code>/install/custom/compute.rhels8.x86_64.exlist\n</code></pre> ./boot ./usr/lib/locale ./usr/lib64/perl5/Encode/CN ./usr/lib64/perl5/Encode/JP ./usr/lib64/perl5/Encode/TW ./usr/lib64/perl5/Encode/KR ./lib/kbd/keymaps/i386 ./lib/kbd/keymaps/mac ./lib/kdb/keymaps/include ./usr/local/include ./usr/local/share/man ./usr/share/man ./usr/share/cracklib ./usr/share/doc ./usr/share/gnome ./usr/share/i18n +./usr/share/i18n/en_US ./usr/share/info ./usr/share/locale/ +./usr/share/locale/en_US +./usr/share/locale/C +./usr/share/locale/locale.alias +./usr/lib/locale/locale-archive +./usr/lib/locale/en +./usr/lib/locale/C ./usr/share/man ./usr/share/omf ./usr/share/vim/site/doc ./usr/share/vim/vim74/doc ./var/cache/man ./var/lib/yum ./tmp <pre><code>### Change the rootfs size\n- [linux - What sets the size of tmpfs? What happens when its full? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/205174/what-sets-the-size-of-tmpfs-what-happens-when-its-full)\n    - The default is half of your physical RAM without swap\n- [genimage.1 \u2014 xCAT 2.16.6 documentation](https://xcat-docs.readthedocs.io/en/latest/guides/admin-guides/references/man1/genimage.1.html?highlight=rootlimit)\n</code></pre> genimage rhels8.8.0-x86_64-netboot-compute -l 8g <pre><code>## Offline installation\n\nfor redhat 8\n``` bash=\nwget https://raw.githubusercontent.com/xcat2/xcat-core/master/xCAT-server/share/xcat/tools/go-xcat\nchmod +x go-xcat\nwget https://xcat.org/files/xcat/xcat-core/2.16.x_Linux/xcat-core/xcat-core-2.16.5-linux.tar.bz2\nwget https://xcat.org/files/xcat/xcat-dep/2.x_Linux/xcat-dep-2.16.5-linux.tar.bz2\n./go-xcat --yes --xcat-core=/tmp/xcat-core-2.16.5-linux.tar.bz2 --xcat-dep=/tmp/xcat-dep-2.16.5-linux.tar.bz2 install\n</code></pre></p> <p>for rhel 9.3 <pre><code># build the CRB and epel offline for rhel 9\nsubscription-manager identity\nsubscription-manager unregister\nsubscription-manager register --username TedChangchien@supermicro.com --auto-attach\ndnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm -y\nsudo tee /etc/yum.repos.d/crb.repo &gt; /dev/null &lt;&lt;EOF\n[CRB]\nname=Centos Stream \\$releasever - CRB\nbaseurl=https://mirror.stream.centos.org/9-stream/CRB/x86_64/os\ngpgcheck=1\nrepo_gpgcheck=0\nmetadata_expire=6h\ncountme=1\nenabled=1\nEOF\nmkdir /tmp/xcat-2.17.0_offline_redhat-9\ndnf download --downloaddir=/tmp/xcat-2.17.0_offline_redhat-9 --resolve perl-Crypt-CBC\ndnf download --downloaddir=/tmp/xcat-2.17.0_offline_redhat-9 --resolve perl-IO-Tty\ndnf download --downloaddir=/tmp/xcat-2.17.0_offline_redhat-9 --resolve perl-Expect\ndnf download --downloaddir=/tmp/xcat-2.17.0_offline_redhat-9 --resolve perl-Crypt-Rijndael\ndnf download --downloaddir=/tmp/xcat-2.17.0_offline_redhat-9 --resolve perl-Sys-Virt\ndnf download --downloaddir=/tmp/xcat-2.17.0_offline_redhat-9 --resolve perl-Crypt-SSLeay\ncd /tmp &amp;&amp; tar zcvf xcat-2.17.0_offline_redhat-9.tar.gz xcat-2.17.0_offline_redhat-9\n\n\n# CRB and epel offline\ntar zxvf xcat-2.17.0_offline_redhat-9.tar.gz\n# rpm -ivh xcat-2.17.0_offline_redhat-9/*.rpm\nsudo dnf install -y xcat-2.17.0_offline_redhat-9/*.rpm --allowerasing\n\n# rhel 9.3 BaseOS and AppStream offline\nwget http://172.19.30.2/ISO/rh/rhel-9.3-x86_64-dvd.iso\nsudo mount -o loop rhel-9.3-x86_64-dvd.iso /mnt\nshopt -s dotglob\nmkdir -p /install/rhel-9.3\ncp -avRpf /mnt/* /install/rhel-9.3/\nsudo tee /etc/yum.repos.d/LocalRhel.repo &gt; /dev/null &lt;&lt;EOF\n[BaseOS]\nname=Red Hat Enterprise Linux 9.3 BaseOS\nenabled=1\ngpgcheck=0\nbaseurl=file:///install/rhel-9.3/BaseOS\n\n[AppStream]\nname=Red Hat Enterprise Linux 9.3 AppStream\nenabled=1\ngpgcheck=0\nbaseurl=file:///install/rhel-9.3/AppStream\nEOF\ndnf clean all\ndnf makecache\ndnf repolist\ndnf repolist all\nsudo dnf config-manager --disable \\*\nsudo dnf config-manager --enable BaseOS,AppStream\n# sudo dnf config-manager --disable rhel-9-for-x86_64-baseos-rpms,rhel-9-for-x86_64-appstream-rpms,epel,epel-cisco-openh264,CRB,docker-ce-stable\n\n\n# install\nwget https://raw.githubusercontent.com/xcat2/xcat-core/master/xCAT-server/share/xcat/tools/go-xcat &amp;&amp; chmod +x go-xcat\nwget http://172.19.30.2/archive/xcat/xcat-core-2.17.0-linux.tar.bz2\nwget http://172.19.30.2/archive/xcat/xcat-dep-2.17.0-linux.tar.bz2\nip route del default\nip route del default\n./go-xcat -y --xcat-core=/tmp/xcat-core-2.17.0-linux.tar.bz2 --xcat-dep=/tmp/xcat-dep-2.17.0-linux.tar.bz2 install\n</code></pre></p> <p>for ubuntu ``` bash= wget https://raw.githubusercontent.com/xcat2/xcat-core/master/xCAT-server/share/xcat/tools/go-xcat chmod +x go-xcat wget https://xcat.org/files/xcat/xcat-core/2.16.x_Ubuntu/xcat-core/xcat-core-2.16.5-ubuntu.tar.bz2 wget https://xcat.org/files/xcat/xcat-dep/2.x_Ubuntu/xcat-dep-2.16.5-ubuntu.tar.bz2 ./go-xcat --yes --xcat-core=xcat-core-2.16.5-ubuntu.tar.bz2 --xcat-dep=xcat-dep-2.16.5-ubuntu.tar.bz2 install <pre><code>## support ubuntu\n- [Ubuntu 20.04 support \u00b7 Issue #6681 \u00b7 xcat2/xcat-core \u00b7 GitHub](https://github.com/xcat2/xcat-core/issues/6681#issuecomment-1574655538)\n    - [Sample xCAT Subiquity template \u00b7 GitHub](https://gist.github.com/sjjf/5dfa794b7eb8d8712620c86d2c881518)\n    - https://github.com/xcat2/xcat-core/pull/6975#issuecomment-948732489\n    - https://github.com/xcat2/xcat-core/pull/6975#issuecomment-996069563\n\n\n``` bash=\nnodeset node21 osimage=ubuntu22.04.4-x86_64-install-compute\nrsetboot node21 net -u\nrpower node21 reset\nxcatprobe osdeploy -n  node21\n</code></pre></p> <pre><code>/install/autoinst/node21.pre &gt;&gt; storage\n/install/autoinst/node21/user-data &gt;&gt; autoinstall\n</code></pre> <pre><code>/opt/xcat/share/xcat/install/scripts/pre.ubuntu.subiquity\n</code></pre>"},{"location":"hackmd/xcat/#package-issue-when-provision","title":"package issue when provision","text":"<pre><code>Apr 18 00:56:18 node21 subiquity_log.2571[30806]: INFO  Running in chroot, ignoring command 'start'\nApr 18 00:56:18 node21 subiquity_event.2571[2571]: INFO      subiquity/Install/install/configure_apt/cmd-in-target: curtin command in-target\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:1 file:/cdrom jammy InRelease\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Ign:1 file:/cdrom jammy InRelease\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:2 file:/cdrom jammy Release [1072 B]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:2 file:/cdrom jammy Release [1072 B]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:3 file:/cdrom jammy Release.gpg [833 B]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:3 file:/cdrom jammy Release.gpg [833 B]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:4 file:/cdrom jammy/main amd64 Packages [34.5 kB]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Ign:4 file:/cdrom jammy/main amd64 Packages\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:5 file:/cdrom jammy/restricted amd64 Packages [648 B]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Ign:5 file:/cdrom jammy/restricted amd64 Packages\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:4 file:/cdrom jammy/main amd64 Packages [34.5 kB]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:5 file:/cdrom jammy/restricted amd64 Packages [648 B]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Err:5 file:/cdrom jammy/restricted amd64 Packages\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO    Hash Sum mismatch\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO    Hashes of expected file:\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO     - Filesize:1009 [weak]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO     - SHA256:886da05863935c3df41454d5cf3b5c6a54735d16e5b0ac3393803f279501c3df\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO    Hashes of received file:\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO     - SHA256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO     - Filesize:0 [weak]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO    Last modification reported: Thu, 18 Apr 2024 02:36:12 +0000\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO    Release file created at: Thu, 21 Apr 2022 17:16:08 +0000\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\nApr 18 00:56:18 node21 subiquity_log.2571[30324]: INFO  Hit:7 http://au.archive.ubuntu.com/ubuntu jammy InRelease\nApr 18 00:56:19 node21 subiquity_log.2571[30324]: INFO  Get:8 http://au.archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\nApr 18 00:56:19 node21 subiquity_log.2571[30324]: INFO  Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1346 kB]\nApr 18 00:56:19 node21 systemd-timesyncd[1415]: INFO  Timed out waiting for reply from 172.19.44.245:123 (172.19.44.245).\n...\n...\n...\nApr 18 00:56:35 node21 subiquity_log.2571[30324]: INFO  Get:43 http://au.archive.ubuntu.com/ubuntu jammy-backports/universe Translation-en [16.2 kB]\nApr 18 00:56:35 node21 subiquity_log.2571[30324]: INFO  Get:44 http://au.archive.ubuntu.com/ubuntu jammy-backports/universe amd64 c-n-f Metadata [644 B]\nApr 18 00:56:35 node21 subiquity_log.2571[30324]: INFO  Get:45 http://au.archive.ubuntu.com/ubuntu jammy-backports/multiverse amd64 c-n-f Metadata [116 B]\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO  Fetched 10.7 MB in 16s (654 kB/s)\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO  Reading package lists...\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO  E: Failed to fetch store:/cdrom/dists/jammy/restricted/binary-amd64/Packages  Hash Sum mismatch\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO     Hashes of expected file:\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO      - Filesize:1009 [weak]\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO      - SHA256:886da05863935c3df41454d5cf3b5c6a54735d16e5b0ac3393803f279501c3df\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO     Hashes of received file:\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO      - SHA256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO      - Filesize:0 [weak]\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO     Last modification reported: Thu, 18 Apr 2024 02:36:12 +0000\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO     Release file created at: Thu, 21 Apr 2022 17:16:08 +0000\nApr 18 00:56:38 node21 subiquity_log.2571[30324]: INFO  E: Some index files failed to download. They have been ignored, or old ones used instead.\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['udevadm', 'settle'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  TIMED subp(['udevadm', 'settle']): 0.016\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['mount', '--make-private', '/tmp/tmp5nkye71l/mount/sys/firmware/efi/efivars'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['umount', '/tmp/tmp5nkye71l/mount/sys/firmware/efi/efivars'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['mount', '--make-private', '/tmp/tmp5nkye71l/mount/sys'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['umount', '/tmp/tmp5nkye71l/mount/sys'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['mount', '--make-private', '/tmp/tmp5nkye71l/mount/run'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['umount', '/tmp/tmp5nkye71l/mount/run'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['mount', '--make-private', '/tmp/tmp5nkye71l/mount/proc'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['umount', '/tmp/tmp5nkye71l/mount/proc'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['mount', '--make-private', '/tmp/tmp5nkye71l/mount/dev'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  Running command ['umount', '/tmp/tmp5nkye71l/mount/dev'] with allowed return codes [0] (capture=False)\nApr 18 00:56:38 node21 subiquity_log.2571[29699]: INFO  finish: cmd-in-target: FAIL: curtin command in-target\nApr 18 00:56:38 node21 curtin_event.2571.3[29699]: DEBUG  finish: cmd-in-target: FAIL: curtin command in-target\nApr 18 00:56:38 node21 systemd[1]: NOTICE  run-u34.service: Main process exited, code=exited, status=100/n/a\nApr 18 00:56:38 node21 systemd[1]: WARNING  run-u34.service: Failed with result 'exit-code'.\nApr 18 00:56:38 node21 systemd[1]: INFO  run-u34.service: Consumed 6.250s CPU time.\nApr 18 00:56:38 node21 subiquity_event.2571[2571]: INFO    subiquity/Install/install/configure_apt: Command '['systemd-run', '--wait', '--same-dir', '--property', 'SyslogIdentifier=subiquity_log.2571', '--property', 'PrivateMounts=yes', '--setenv', 'PATH=/snap/subiquity/5495/bin:/snap/subiquity/5495/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/subiquity/5495/bin:/snap/subiquity/5495/sbin', '--setenv', 'PYTHONPATH=:/snap/subiquity/5495/lib/python3.10/site-packages', '--setenv', 'PYTHON=/snap/subiquity/5495/usr/bin/python3.10', '--setenv', 'SNAP=/snap/subiquity/5495', '--', '/snap/subiquity/5495/usr/bin/python3.10', '-m', 'curtin', '--showtrace', '-vvv', '--set', 'json:reporting={\"subiquity\": {\"type\": \"journald\", \"identifier\": \"curtin_event.2571.3\"}}', 'in-target', '-t', '/tmp/tmp5nkye71l/mount', '--', 'apt-get', 'update']' returned non-zero exit status 100.\nApr 18 00:56:38 node21 subiquity_event.2571[2571]: INFO  subiquity/Install/install: Command '['systemd-run', '--wait', '--same-dir', '--property', 'SyslogIdentifier=subiquity_log.2571', '--property', 'PrivateMounts=yes', '--setenv', 'PATH=/snap/subiquity/5495/bin:/snap/subiquity/5495/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/subiquity/5495/bin:/snap/subiquity/5495/sbin', '--setenv', 'PYTHONPATH=:/snap/subiquity/5495/lib/python3.10/site-packages', '--setenv', 'PYTHON=/snap/subiquity/5495/usr/bin/python3.10', '--setenv', 'SNAP=/snap/subiquity/5495', '--', '/snap/subiquity/5495/usr/bin/python3.10', '-m', 'curtin', '--showtrace', '-vvv', '--set', 'json:reporting={\"subiquity\": {\"type\": \"journald\", \"identifier\": \"curtin_event.2571.3\"}}', 'in-target', '-t', '/tmp/tmp5nkye71l/mount', '--', 'apt-get', 'update']' returned non-zero exit status 100.\nApr 18 00:56:38 node21 subiquity_event.2571[2571]: INFO    subiquity/ErrorReporter/1713426998.094931126.install_fail/add_info\nApr 18 00:56:39 node21 subiquity_event.2571[2571]: INFO      subiquity/Install/install/configure_apt/cmd-in-target: curtin command in-target\nApr 18 00:56:39 node21 subiquity_event.2571[2571]: INFO    subiquity/ErrorReporter/1713426998.094931126.install_fail/add_info: written to /var/crash/1713426998.094931126.install_fail.crash\nApr 18 00:56:39 node21 subiquity_event.2571[2571]: INFO  subiquity/Error/run\nApr 18 00:56:39 node21 subiquity_event.2571[2571]: INFO    subiquity/Error/run/run\nApr 18 00:56:39 node21 subiquity_event.2571[2571]: INFO      subiquity/Error/run/run/command_0: tar -c --transform='s/^/node21-logs\\//' /var/crash /var/logs/installer |nc -l 8080\nApr 18 00:56:39 node21 subiquity_echo.2571[2571]: INFO    running tar -c --transform='s/^/node21-logs\\//' /var/crash /var/logs/installer |nc -l 8080\nApr 18 00:56:39 node21 subiquity_echo.2571[56000]: INFO  tar: Removing leading `/' from member names\nApr 18 00:56:39 node21 subiquity_echo.2571[56000]: INFO  tar: Removing leading `/' from hard link targets\n</code></pre> <p>failure provision <pre><code>[root@orch-xcat ubuntu22.04.4]# ls -la /install/ubuntu22.04.4/x86_64/dists/jammy/restricted/binary-amd64/\ntotal 4\ndr-xr-xr-x 2 root root  41 Apr 17 19:36 .\ndr-xr-xr-x 5 root root  59 Feb 16 15:51 ..\n-rw-r--r-- 1 root root   0 Apr 17 19:36 Packages\n-r--r--r-- 1 root root 648 Feb 16 15:52 Packages.gz\n</code></pre></p> <p>success provision <pre><code>[root@orch-xcat ubuntu22.04.4]# ls -la /install/ubuntu22.04.4/x86_64/dists/jammy/restricted/binary-amd64/\ntotal 8\ndr-xr-xr-x 2 root root   41 Apr 18 02:52 .\ndr-xr-xr-x 5 root root   59 Feb 16 15:51 ..\n-r--r--r-- 1 root root 1009 Apr 18 02:52 Packages\n-r--r--r-- 1 root root  648 Feb 16 15:52 Packages.gz\n</code></pre></p> <pre><code>[root@orch-xcat ~]# chdef -t node -o node22 kcmdline=\"modprobe.blacklist=nvidiafb\"\n[root@orch-xcat ~]# chdef -t node -o node22 installnic=\"mac\"\n</code></pre> <pre><code>[root@orch-xcat ~]# lsdef -t node node21\nObject name: node21\n    arch=x86_64\n    bmc=172.19.47.21\n    bmcpassword=Super123\n    bmcusername=SMCI\n    cons=ipmi\n    currchain=boot\n    currstate=install ubuntu22.04.4-x86_64-compute\n    getmac=ipmi\n    groups=all\n    installnic=mac\n    ip=172.19.48.21\n    kcmdline=modprobe.blacklist=nvidiafb\n    mac=3c:ec:ef:6e:ff:42\n    mgt=ipmi\n    netboot=xnba\n    os=ubuntu22.04.4\n    postbootscripts=otherpkgs\n    postscripts=syslog,remoteshell,syncfiles\n    profile=compute\n    provmethod=ubuntu22.04.4-x86_64-install-compute\n    serialport=0\n    serialspeed=115200\n    status=booting\n    statustime=04-18-2024 03:01:45\n    usercomment=the system X node definition\n    xcatmaster=172.19.48.10\n</code></pre>"},{"location":"hackmd/xcat/#ssh-issue-after-provision","title":"ssh issue after provision","text":"<ul> <li>Unable to connect after Ubuntu upgrade | AWS re:Post<ul> <li>3410 \u2013 Since 8.9p1 MaxStartups &gt;=1024, in sshd_config, causes \"error: ppoll: Invalid argument\" comment the <code>MaxStartups 1024</code> in /etc/ssh/sshd_config</li> </ul> </li> </ul>"},{"location":"hackmd/xcat/#retrying-flag-update","title":"Retrying flag update","text":"<ul> <li>https://github.com/xcat2/xcat-core/issues/7147#issuecomment-1107274460</li> </ul>"},{"location":"hackmd/xcat/#install-xcat-in-docker","title":"install xcat in docker","text":"<pre><code>docker run --rm -it -v /sys/fs/cgroup:/sys/fs/cgroup:rw --tmpfs /run --tmpfs /run/lock --name xcat-on-ubuntu xcat-on-docker-ubuntu /lib/systemd/systemd\n</code></pre> <p>https://serverfault.com/questions/1053187/systemd-fails-to-run-in-a-docker-container-when-using-cgroupv2-cgroupns-priva <pre><code>docker run --rm -it --tmpfs /run --tmpfs /run/lock --privileged --name xcat-on-ubuntu xcat-on-docker-ubuntu /lib/systemd/systemd\ndocker run --rm -it --privileged --name xcat-on-ubuntu xcat-on-docker-ubuntu /lib/systemd/systemd\n</code></pre></p>"},{"location":"hackmd/xcat/#pxe-boot","title":"pxe boot","text":"<p>-/tftpboot/xcat/xnba/nets/172.19.50.0_24.uefi - TFTP - Learning Lounge - start command     - in.tftpd(8) - Linux man page</p> <p>ps aux |grep tftp <pre><code>root        1406  0.0  0.0   4940   640 ?        Ss   Jul24   0:00 /usr/sbin/in.tftpd -v -l -s /tftpboot -m /etc/tftpmapfile4xcat.conf\n</code></pre></p>"},{"location":"hackmd/xcat/#debug","title":"debug","text":"<pre><code># bypass the certificate check\nXCATBYPASS=1 lsdef -t node\n</code></pre>"},{"location":"hackmd/xcat/#ssl","title":"SSL","text":"<ul> <li>The SSL Certificates in xCAT \u2014 xCAT 2.17.0 documentation</li> <li>OpenSSL Configuration \u2014 xCAT 2.17.0 documentation</li> </ul> <pre><code>Unable to open socket connection to xcatd daemon on localhost:3001.\nVerify that the xcatd daemon is running and that your SSL setup is correct.\nConnection failure:  at /opt/xcat/lib/perl/xCAT/Client.pm line 282.\n</code></pre>"},{"location":"hackmd/%E4%BD%BF%E7%94%A8%E8%80%85%E9%AB%94%E9%A9%97/","title":"\u4f7f\u7528\u8005\u9ad4\u9a57","text":"<ul> <li>Designing Better Links for Websites and Emails</li> </ul>"},{"location":"hackmd/%E4%BD%BF%E7%94%A8%E8%80%85%E9%AB%94%E9%A9%97/#avg","title":"AVG","text":""},{"location":"hackmd/%E4%BD%BF%E7%94%A8%E8%80%85%E9%AB%94%E9%A9%97/#github","title":"github","text":"<ul> <li>An update on recent service disruptions</li> <li>Github status</li> </ul>"},{"location":"hackmd/%E5%82%99%E4%BB%BD%E9%82%84%E5%8E%9F/","title":"\u5099\u4efd\u9084\u539f","text":""},{"location":"hackmd/%E5%82%99%E4%BB%BD%E9%82%84%E5%8E%9F/#clonezilla","title":"Clonezilla","text":"<ul> <li>Clonezilla Live\u5c0dWindows\u7cfb\u7d71\u7684\u5099\u4efd\u8207\u9084\u539f<ul> <li>\u5916\u63a5\u88dd\u7f6e\u5099\u4efd\u9084\u539f</li> <li>\u7761\u89ba\u5439\u6ce1\u6ce1: \u521d\u5b78\u8005\u4e5f\u6703\u7684 clonezilla \u518d\u751f\u9f8d \u7cfb\u7d71\u5099\u4efd\u8207\u9084\u539f - \u4ee5XP\u70ba\u4f8b\uff0c\u5099\u4efdC\u69fd\u4f5c\u696d\u7cfb\u7d71</li> <li>Disk to disk clone : \u8907\u88fd\u5c0f\u786c\u789f\u5230\u5927\u786c\u789f(\u4ee5 8G \u5230 16G \u786c\u789f\u70ba\u4f8b) </li> <li>\u5229\u7528Clonezilla Live\u5b89\u88ddWindows XP\u8a18\u4e8b - \u5e03\u4e01\u5e03\u4e01\u5403\u4ec0\u9ebc\uff1f</li> </ul> </li> <li>Clonezilla - clonezilla live\u7684\u4f7f\u7528</li> <li>Clonezilla live \u6587\u4ef6\u96c6<ul> <li>Clonezilla - \u76f8\u95dc\u6587\u4ef6</li> </ul> </li> <li>**\u4f7f\u7528Clonezilla\u5099\u4efd\u9084\u539f\u5b8c\u6574\u786c\u789f** - HackMD</li> <li>Clonezilla\u518d\u751f\u9f8d\u8a73\u7d30\u6307\u5357: \u4e0b\u8f09\u5b89\u88dd\u6559\u5b78&amp;\u5099\u4efd\u786c\u789f\u5206\u5340 [2025]</li> <li>[\u6559\u5b78][\u5716\u591a]\u4e00\u6b65\u6b65\u6559\u4f60\u4f7f\u7528\u518d\u751f\u9f8dClonezilla\u8f15\u9b06\u88fd\u4f5c\u9084\u539f\u6a94\u53ca\u9084\u539f\u5149\u789f - Mobile01</li> <li>Clonezilla \u518d\u751f\u9f8d\u5f9e\u5927 HDD \u8f49\u79fb Windows 10 \u5230\u5c0f SSD | \u9662\u9577\u7684\u7b46\u8a18\u672c</li> <li>CloneZilla \u518d\u751f\u9f8d\u5ba2\u88fd\u5316\uff0c\u9084\u539f\u5f8c\u81ea\u52d5\u64f4\u5927\u6307\u5b9a\u5206\u5272\u5340\u7684\u5bb9\u91cf - \u77f3\u982d\u9592\u8a9e</li> </ul>"},{"location":"hackmd/%E5%82%99%E4%BB%BD%E9%82%84%E5%8E%9F/#ventoy","title":"Ventoy","text":"<ul> <li>\u7528 Ventoy \u5c07 CloneZilla \u548c GParted \u653e\u5728\u540c\u4e00\u96bb USB \u958b\u6a5f\u789f - \u77f3\u982d\u9592\u8a9e<ul> <li>Get start . Ventoy</li> <li>disk_layout . Ventoy<ul> <li>\u96a8\u8eab\u789f\u683c\u5f0f\u5316\u6559\u5b78\uff1aFAT32\u3001NTFS\u3001exFAT\u600e\u9ebc\u9078\uff1f - \u51cc\u5a01\u79d1\u6280</li> </ul> </li> </ul> </li> <li>Ventoy\u6559\u5b78\uff1a\u88fd\u4f5c\u80fd\u7576Linux\uff06Windows\u958b\u6a5f\u789f\u53c8\u7576\u8cc7\u6599\u789f\u7684USB\u96a8\u8eab\u789f \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/%E5%82%99%E4%BB%BD%E9%82%84%E5%8E%9F/#gparted","title":"GParted","text":"<ul> <li>GParted \u78c1\u789f\u5206\u5272\u5de5\u5177\u4f7f\u7528\u6559\u5b78 \u2013 G. T. Wang</li> </ul>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/","title":"\u55ae\u5143\u6e2c\u8a66\u7684\u85dd\u8853","text":""},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_2","title":"\u55ae\u5143\u6e2c\u8a66\u57fa\u790e","text":"<p>:::warning \u55ae\u5143\u6e2c\u8a66\u7684\u50f9\u503c? \u958b\u767c\u4eba\u54e1\u63d0\u5347\u7a0b\u5f0f\u54c1\u8cea, \u52a0\u6df1\u7406\u89e3\u985e\u5225\u6216\u65b9\u6cd5\u529f\u80fd\u9700\u6c42\u7684\u6700\u4f73\u65b9\u5f0f\u4e4b\u4e00</p> <p>\u6ce8\u610f\u7dad\u8b77\u6210\u672c\u548c\u6642\u9593 :::</p> <p>\u5de5\u4f5c\u55ae\u5143 \u6700\u7d42\u7d50\u679c</p> <p>\u6574\u5408\u6e2c\u8a66</p> <p>\u55ae\u5143\u6e2c\u8a66\u6846\u67b6</p> <p>\u77e5\u9053\u5982\u4f55\u5340\u5206\u55ae\u5143\u6e2c\u8a66\u548c\u6574\u5408\u6e2c\u8a66</p>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_3","title":"\u7b2c\u4e00\u500b\u55ae\u5143\u6e2c\u8a66","text":"<p>\u5728\u771f\u5be6\u4e16\u754c\u4e2d, \u4f60\u61c9\u8a72\u6e2c\u8a66\u4efb\u4f55\u5305\u542b\u908f\u8f2f\u7a0b\u5f0f\u78bc\u7684\u65b9\u6cd5, \u4e0d\u7ba1\u5b83\u770b\u8d77\u4f86\u6709\u591a\u7c21\u55ae \u908f\u8f2f\u53ef\u80fd\u6709\u6642\u6703\u5931\u6557, \u800c\u4e14\u4f60\u60f3\u77e5\u9053\u4f55\u6642\u6703\u5931\u6557, \u5931\u6557\u662f\u751a\u9ebc\u539f\u56e0\u6240\u5c0e\u81f4</p>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_4","title":"==\u6e2c\u8a66\u547d\u540d==\u548c\u4f4d\u7f6e\u7684\u57fa\u672c\u898f\u5247","text":"<ul> <li>UnitOfWorkName<ul> <li>\u88ab\u6e2c\u8a66\u7684\u65b9\u6cd5</li> <li>\u4e00\u7d44\u65b9\u6cd5</li> <li>\u4e00\u7d44\u985e\u5225</li> </ul> </li> <li>Scenario<ul> <li>\u6e2c\u8a66\u9032\u884c\u7684\u5047\u8a2d\u689d\u4ef6<ul> <li>\u8209\u4f8b: \u767b\u5165\u5931\u6557, \u7121\u6548\u7684\u4f7f\u7528\u8005, \u5bc6\u78bc\u6b63\u78ba, \u7cfb\u7d71\u8a18\u61b6\u9ad4\u4e0d\u8db3, \u7121\u6b64\u4f7f\u7528\u8005, \u8a72\u4f7f\u7528\u8005\u5df2\u7d93\u5b58\u5728</li> </ul> </li> </ul> </li> <li>ExpectedBehavior<ul> <li>\u5728\u6e2c\u8a66\u60c5\u5883\u6307\u5b9a\u7684\u689d\u4ef6\u4e0b, \u5c0d==\u88ab\u6e2c\u8a66\u65b9\u6cd5\u884c\u70ba==\u7684\u9810\u671f<ul> <li>\u56de\u50b3\u4e00\u500b\u7d50\u679c\u503c(\u771f\u5be6\u7684\u503c\u6216\u662f\u4f8b\u5916)</li> <li>\u7cfb\u7d71\u72c0\u614b\u7684\u6539\u8b8a<ul> <li>\u8209\u4f8b: \u5728\u7cfb\u7d71\u4e2d\u65b0\u589e\u4e86\u4e00\u500b\u4f7f\u7528\u8005, \u5c0e\u81f4\u5728\u4e0b\u4e00\u6b21\u767b\u5165\u6642\u7cfb\u7d71\u7684\u884c\u70ba\u767c\u751f\u8b8a\u5316</li> </ul> </li> <li>\u547c\u53eb\u4e86\u5916\u90e8\u7b2c\u4e09\u65b9\u7cfb\u7d71\u6240\u63d0\u4f9b\u7684\u670d\u52d9<ul> <li>\u8209\u4f8b: \u548c\u4e00\u500b\u5916\u90e8\u7684Web\u670d\u52d9\u9032\u884c\u4e92\u52d5</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_5","title":"\u4e00\u500b\u55ae\u5143\u6e2c\u8a66\u901a\u5e38\u5305\u542b\u4e86\u4e09\u500b\u884c\u70ba","text":"<ul> <li>\u6e96\u5099(Arrange)\u7269\u4ef6, \u5efa\u7acb\u7269\u4ef6, \u9032\u884c\u5fc5\u8981\u7684\u8a2d\u5b9a</li> <li>\u64cd\u4f5c(Act)\u7269\u4ef6</li> <li>\u9a57\u8b49(Assert)\u67d0\u4ef6\u4e8b\u7b26\u5408\u9810\u671f</li> </ul>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_6","title":"\u4f7f\u7528\u53c3\u6578\u4f86\u91cd\u69cb\u6e2c\u8a66","text":"<pre><code>LogAnalyzer analyzer = new LogAnalyzer();\n...\n</code></pre> <p>\u5047\u8a2d\u73fe\u5728\u5df2\u7d93\u5beb\u4e86\u4e09\u500b\u6e2c\u8a66, \u88e1\u9762\u90fd\u5305\u542b\u4e86\u4e0a\u9762\u7684\u6e96\u5099\u7269\u4ef6\u7a0b\u5f0f\u78bc \u82e5\u5728\u985e\u5225LogAnalyzer\u7684\u5efa\u69cb\u5f0f\u52a0\u5165\u4e00\u500b\u53c3\u6578, \u90a3\u9ebc\u4e09\u500b\u6e2c\u8a66\u90fd\u6703\u7de8\u8b6f\u5931\u6557 \u82e5\u771f\u5be6\u74b0\u5883\u4e2d\u4e0d\u662f\u4e09\u500b\u800c\u662f30\u6216300\u500b\u5462?</p> <p>\u53c3\u6578\u5316\u6e2c\u8a66(parameterized tests)</p>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_7","title":"\u55ae\u5143\u6e2c\u8a66\u7684\u751f\u547d\u9031\u671f\u6ce8\u610f\u4e8b\u9805","text":"<p>\u9032\u884c\u55ae\u5143\u6e2c\u8a66\u6642, \u5f88\u91cd\u8981\u7684\u4e00\u9ede\u662f\u78ba\u4fdd\u4e4b\u524d\u6e2c\u8a66\u904e\u7a0b\u4e2d\u6240\u907a\u7559\u4e0b\u4f86\u7684\u8cc7\u6599\u6216\u57f7\u884c\u500b\u9ad4\u5f97\u4ee5\u92b7\u6bc0 \u65b0\u7684\u6e2c\u8a66\u57f7\u884c\u6642, \u72c0\u614b\u662f\u91cd\u7f6e\u904e\u7684</p> <p>setup\u548cteardown \u5fc5\u9808\u6ce8\u610f\u7684\u662f\u4f7f\u7528setup\u8d8a\u591a, \u6e2c\u8a66\u7a0b\u5f0f\u7684\u53ef\u8b80\u6027\u5c31\u8d8a\u5dee :::warning \u70ba\u4e86\u7406\u89e3\u6e2c\u8a66\u662f\u600e\u9ebc\u5f97\u5230\u7269\u4ef6\u57f7\u884c\u500b\u9ad4, \u4f7f\u7528\u7684\u7269\u4ef6\u662f\u751a\u9ebc\u578b\u5225, \u4eba\u5011\u4e0d\u5f97\u4e0d\u540c\u6642\u53bb\u770b\u6a94\u6848\u88cf\u9762\u7684\u5169\u8655\u7a0b\u5f0f :::</p> <p>\u672c\u66f8\u4f5c\u8005\u4e26\u4e0d\u4f7f\u7528setup\u4f86\u521d\u59cb\u5316\u88ab\u6e2c\u8a66\u985e\u5225\u7684\u7269\u4ef6\u57f7\u884c\u500b\u9ad4, \u800c\u662f\u63a1\u7528==\u5de5\u5ee0\u65b9\u6cd5==(factory method)\u4f86\u521d\u59cb\u5316\u88ab\u6e2c\u8a66\u7684\u7269\u4ef6\u57f7\u884c\u500b\u9ad4</p> <p>\u5728\u55ae\u5143\u6e2c\u8a66\u7684\u5c08\u6848\u4e2d, \u5e7e\u4e4e\u6c38\u9060\u4e0d\u6703\u7528\u5230TearDown\u6216TestFixture\u65b9\u6cd5 \u53ea\u6709\u4e00\u7a2e\u60c5\u6cc1\u4e0b\u5728\u55ae\u5143\u6e2c\u8a66\u4e2d\u4f7f\u7528TearDown\u662f\u6709\u610f\u7fa9\u7684, \u4ea6\u5373\u9700\u8981\u5728\u6e2c\u8a66\u548c\u6e2c\u8a66\u4e4b\u9593\u91cd\u8a2d\u4e00\u500b\u975c\u614b\u8b8a\u6578\u6216\u55ae\u4f8b(Singleton)\u7684\u72c0\u614b \u4efb\u4f55\u5176\u4ed6\u7684\u60c5\u6cc1\u4e0b\u4f7f\u7528TearDown, \u90fd\u53ef\u80fd\u662f\u5728\u9032\u884c\u6574\u5408\u6e2c\u8a66</p>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_8","title":"\u6e2c\u8a66\u7cfb\u7d71\u72c0\u614b\u7684\u6539\u8b8a\u800c\u975e\u9a57\u8b49\u56de\u50b3\u503c","text":"<p>\u9a57\u8b49\u88ab\u6e2c\u8a66\u7cfb\u7d71\u5728\u57f7\u884c\u67d0\u500b\u52d5\u4f5c\u7684\u524d\u5f8c\uff0c\u5176\u884c\u70ba\u6240\u767c\u751f\u7684\u8b8a\u5316\u662f\u5426\u7b26\u5408\u9810\u671f</p>"},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_9","title":"\u900f\u904e\u865b\u8a2d\u5e38\u5f0f\u89e3\u6c7a\u4f9d\u8cf4\u554f\u984c","text":""},{"location":"hackmd/%E5%96%AE%E5%85%83%E6%B8%AC%E8%A9%A6%E7%9A%84%E8%97%9D%E8%A1%93/#_10","title":"\u4f7f\u7528\u6a21\u64ec\u7269\u4ef6\u9a57\u8b49\u4e92\u52d5","text":""},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/","title":"\u5947\u6280\u6deb\u5de7","text":""},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/#customized-sni","title":"Customized SNI","text":"<ol> <li>openssl</li> <li>Postman \u6539Host</li> </ol> <pre><code>openssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"diqz8h6n59coy.cloudfront.net\"\n\nopenssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"github.com\"\n\nopenssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"tw.yahoo.com\"\n\nopenssl s_client -connect \"diqz8h6n59coy.cloudfront.net:443\" -servername \"stackoverflow.com\"\n</code></pre>"},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/#_2","title":"\u53d6\u4ee3\u4e0a\u4e0b\u6587","text":"<p>https://stackoverflow.com/questions/11500695/notepad-regulare-expression-to-replace search with regular expression <code>request.getParameter\\(\"(.*?)\"\\)</code> replace with <code>StringEscapeUtils.escapeHtml\\(request.getParameter\\(\"\\1\"\\)\\)</code></p>"},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/#twitter-mute-words","title":"Twitter mute words","text":"<p>https://twitter.com/oobe/status/1476426833721962499?s=12</p>"},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/#hackmd-expoert-all","title":"HackMD Expoert all","text":"<pre><code>curl  --cookie \"userid=&lt;from cookie&gt; ; connect.sid=&lt;from cookie&gt;\" -o /tmp/hackmd_backup.zip 'https://hackmd.io/exportAllNotes'\n</code></pre> <pre><code>#! /bin/bash\nif [[ \"$#\" -ne 1 ]]; then\n    echo \"Usage: $0 HACKMD_API_TOKEN\" &gt;&amp;2\n  exit 1\nfi\nHACKMD_API_TOKEN=$1\nuserid=$(curl \"https://api.hackmd.io/v1/me\" -H \"Authorization: Bearer ${HACKMD_API_TOKEN}\" | jq -r '.id')\ncurl --cookie-jar \"cookies.txt\" 'https://hackmd.io/'\nsession_id=$(cat cookies.txt | grep connect.sid | awk '{print $7}')\necho \"user_id: ${userid}\"\necho \"session_id: ${session_id}\"\ncurl  --cookie \"userid=${userid} ; connect.sid=${session_id}\" -o /tmp/hackmd_backup.zip 'https://hackmd.io/exportAllNotes'\n</code></pre>"},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/#wsl-can-not-access-remote-linux-and-use-rsync","title":"wsl can not access remote linux and use rsync","text":"<p>mobaxterm</p> <pre><code>cd \\\\\\\\wsl$\\\\Ubuntu\\\\home\\\\foo\\\\\nrsync -avzh --dry-run ./bar smci@172.17.43.113:/home/foo/bar/\n</code></pre>"},{"location":"hackmd/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/#nextcloud-box","title":"nextcloud box","text":"<p>Download a file from a Nextcloud public link (pointing to a folder!) via command-line - Stack Overflow</p>"},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/","title":"\u6301\u7e8c\u6574\u5408","text":""},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/#github-action","title":"Github action","text":"<ul> <li>awesome-actions</li> <li>marketplace</li> <li>Viewing your GitHub Actions usage</li> <li>Environment variables</li> <li>GitHub-hosted runners<ul> <li>Customizing GitHub-hosted runners</li> </ul> </li> <li>How to run GitHub Actions workflow only if the pushed files are in a specific folder<ul> <li>Paths Changes Filter<ul> <li>dorny/paths-filter: Conditionally run actions based on files modified by PR, feature branch or pushed commits</li> </ul> </li> </ul> </li> <li>python<ul> <li>Building and testing Python</li> <li>Building and testing Python</li> </ul> </li> <li>Deploying Self-Hosted GitHub Actions Runners with Docker</li> <li>Running Github Actions On Local Machine<ul> <li>act</li> </ul> </li> <li>Containerised Lambdas, Terraform &amp; GitHub Actions</li> <li>\u597d\u6587\u5206\u4eab \u2014 How to run pytest in parallel on GitHub actions - MyApollo</li> <li>[GitHub] \u4f7f\u7528 GitHub CLI (gh) \u89f8\u767c\u9084\u5728 PR \u4e2d\u7684 GitHub Actions workflow \u6e2c\u8a66 | EPH \u7684\u7a0b\u5f0f\u65e5\u8a18</li> </ul> <p>make is ok tests/auto_test.sh: line 7: virtualenv: command not found</p> <p>``` = name: Github Actions CI</p> <p>on:   push:     branches: [         develop,         feature/,         hotfix/     ]</p> <p>jobs:   build:     runs-on: ubuntu-latest</p> <pre><code>steps:\n  - uses: actions/checkout@v2\n  - name: Set up Python 3.9\n    uses: actions/setup-python@v2\n    with:\n      python-version: 3.9\n  - name: Build RDS/Reddis/ElasticSearch by docker-compose\n    run: |\n      cd test_tools/docker-compose\n      docker-compose up -d\n  - name: Install dependencies\n    run: |\n      pip install --upgrade pip\n      pip install -r portal/djangoprojects/mysite/requirements.txt\n      pip install -r portal/djangoprojects/mysite/unit_test_requirements.txt\n  - name: Run Tests\n    run: |\n      cd portal/djangoprojects/mysite/\n      python manage.py test --exclude-tag=aws\n</code></pre> <p>``` </p>"},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/#execute-job-in-a-workflow-only-if-some-file-in-a-subfolder-is-changed","title":"Execute job in a workflow only if some file in a subfolder is changed","text":"<p><code>yaml= jobs:   # JOB to run change detection   changes:     runs-on: ubuntu-latest     # Set job outputs to values from filter step     outputs:       backend: ${{ steps.filter.outputs.backend }}       frontend: ${{ steps.filter.outputs.frontend }}     steps:     # For pull requests it's not necessary to checkout the code     - uses: dorny/paths-filter@v2       id: filter       with:         filters: |           backend:             - 'backend/**'           frontend:             - 'frontend/**'    # JOB to build and test backend code   backend:     needs: changes     if: ${{ needs.changes.outputs.backend == 'true' }}     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v2       - ...    # JOB to build and test frontend code   frontend:     needs: changes     if: ${{ needs.changes.outputs.frontend == 'true' }}     runs-on: ubuntu-latest     steps:       - uses: actions/checkout@v2       - ...</code></p>"},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/#mysql","title":"mysql","text":"<ul> <li>Docker MySQL Github Actions Connection Refused</li> <li>Can't connect Node.js with Docker MySQL database in GitHub actions</li> </ul>"},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/#configuring-openid-connect-in-amazon-web-services","title":"Configuring OpenID Connect in Amazon Web Services","text":"<ul> <li>Configuring OpenID Connect in Amazon Web Services</li> <li>Configure AWS Credentials\" Action For GitHub Actions</li> <li>AWS Policy - StringLike for multiple</li> </ul> <p>Edit the trust relationship in IAM Role setting to add the sub field to the validation conditions</p> <pre><code>\"Condition\": {\"StringLike\": {\"token.actions.githubusercontent.com:sub\": \"repo:github_account/repo_name:*\"}}\n</code></pre> <p>for any repo in your GitHub account <pre><code>token.actions.githubusercontent.com:sub: repo:github_account/*\n</code></pre></p> <p>scoped to a specific branch <pre><code>token.actions.githubusercontent.com:sub: repo:github_account/*:ref:refs/heads/main\n</code></pre></p> <p>multiple repos <pre><code>\"Condition\": {\"StringLike\": {\"token.actions.githubusercontent.com:sub\": [\n        \"repo:github_account_1/repo_name:*\",\n        \"repo:github_account_2/repo_name:*\",\n        \"repo:github_account_3/repo_name:*\"\n      ]}}\n</code></pre></p> <p>total example <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Federated\": \"arn:aws:iam::999999999999:oidc-provider/token.actions.githubusercontent.com\"\n            },\n            \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"token.actions.githubusercontent.com:aud\": \"sts.amazonaws.com\"\n                },\n                \"StringLike\": {\n                    \"token.actions.githubusercontent.com:sub\": [\n                        \"repo:Tom/*:*\",\n                        \"repo:Jimmy/*:*\",\n                        \"repo:Mary/*:*\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n</code></pre></p>"},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/#docker-compose","title":"docker compose","text":"<ul> <li>Get docker-compose.yml file location from running container?</li> </ul> <pre><code>docker inspect &lt;docker id or name&gt; | grep com.docker.compose\n</code></pre>"},{"location":"hackmd/%E6%8C%81%E7%BA%8C%E6%95%B4%E5%90%88/#gitlab","title":"Gitlab","text":"<ul> <li>\u5982\u4f55\u5f9e\u982d\u6253\u9020\u5c08\u5c6c\u7684 GitLab CI/CD \u2013 PIN-YI</li> <li>\u5728 GitLab CI Pipeline \u904b\u7528 SonarQube \u505a\u7a0b\u5f0f\u78bc\u54c1\u8cea\u5206\u6790 | \u8266\u9577\uff0c\u4f60\u6709\u4e8b\u55ce\uff1f</li> </ul>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/","title":"\u6392\u5217\u7d44\u5408\u8207\u6a5f\u7387","text":"<ul> <li>\u770b\u898b\u7d71\u8a08 - \u57fa\u790e\u6982\u7387\u8ad6</li> </ul>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#_2","title":"\u6392\u5217\u7d44\u5408","text":"<ul> <li>\u6392\u5217\u7d44\u5408 \u5165\u9580 \u5230 \u9032\u968e</li> <li>\u300c\u515c\u5708\u5b50 = \u60f3\u6e05\u695a \u2260 \u767d\u8cbb\u529b\u6c23\u300d \u2014 \u6392\u5217\u7d44\u5408\u9032\u968e</li> <li>\u53e4\u5178\u6a5f\u7387 \u2014 \u5230\u5e95\u8a72\u4e0d\u8a72\u7528 C</li> <li>\u6392\u5217&amp;\u7d44\u5408 \u7b46\u8a18</li> <li>\u5b78\u6392\u5217\u7d44\u5408\uff0c\u6709\u5e7e\u500b\u5883\u754c</li> <li>\u52a0\u6cd5\u539f\u7406\u8207\u4e58\u6cd5\u539f\u7406\u7684\u5340\u5206<ul> <li>\u9ad8\u4e00\u4e0b\u6578\u5b78 \u6a5f\u7387 01 \u4e5f\u662f\u6709\u5f88\u591a\u4eba\u6703\u628a\u6a39\u72c0\u5716\u756b\u932f</li> </ul> </li> </ul> <p>\u5efa\u7acb\u601d\u8003\u57fa\u6e96\uff1a \u5168\u76f8\u7570 vs \u5168\u76f8\u7570\u76841\u5c0d1\u914d\u5c0d \u5f88\u50cf\u8cc7\u6599\u5eab\u7684join</p> <p>8! devide and conquer \u53ef\u4ee5\u7528\u6a6b\u5411\u6a39\u72c0\u5716\u53bb\u601d\u8003\u548c\u60f3\u50cf\uff0c\u4e5f\u53ef\u4ee5\u8a55\u4f30\u5982\u4f55\u5207\u5272\u554f\u984c\u624d\u4e0d\u6703\u6df7\u6dc6\u81ea\u5df1\uff0c\u55ae\u4e00\u6a39\u72c0\u5716\u8def\u5f91\u7528\u4e58\u6cd5\uff08join)\uff0c\u4e0d\u540c\u6a39\u72c0\u5716\u8def\u5f91\u7528\u52a0\u6cd5</p> <p>/8! \u5f88\u50cf\u8cc7\u6599\u5eab\u7684group</p> <p>\u7403\u6578=\u4eba\u6578 \u7403\u6578\uff01=\u4eba\u6578 \u7403\u5206\u7d66\u4eba, \u7403\u6392\u6210\u4e00\u5217, \u7403\u4e0d\u9808\u6392\u6210\u4e00\u5217(\u9806\u5e8f\u6027) \u4e00\u4eba\u4e00\u9846, \u62ff\u597d\u62ff\u6eff \u4e00\u4eba\u591a\u9846, \u62ff\u597d\u62ff\u6eff \u7b49\u6548</p>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#1-vs-11","title":"\u601d\u8003\u57fa\u6e961: \u5168\u76f8\u7570 vs \u5168\u76f8\u7570\u76841\u5c0d1\u914d\u5c0d","text":"<p>\u7403\u6578=\u4eba\u6578 8\u9846\u7403, 8\u500b\u4eba, \u5206\u914d\u4e0b\u53bb\u6bcf\u4eba\u4e00\u9846 abcdefgh, 12345678 8\u9846\u7403, 8\u500b\u4eba, \u7403\u6709\u91cd\u8907 abcdefff, 12345678</p> <p>\u7403\u6578 != \u4eba\u6578 5\u9846\u7403, 8\u500b\u4eba, \u5206\u914d\u4e0b\u53bb, \u6bcf\u4eba\u6700\u591a\u4e00\u9846 abcde, 12345678 8\u9846\u7403, 5\u500b\u4eba, \u5206\u914d\u4e0b\u53bb, \u6bcf\u4eba\u6700\u591a\u4e00\u9846(\u6703\u67093\u9846\u5269\u4e0b) abcdefgh, 12345</p> <p>8\u9846\u7403, \u53d6\u51fa5\u9846\u7403\u6392\u6210\u4e00\u5217 8\u9846\u7403, \u53d6\u51fa5\u9846\u7403(\u4e0d\u9808\u6392\u5217) 8\u9846\u7403, \u53d6\u51fa3\u9846\u7403(\u4e0d\u9808\u6392\u5217)</p>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#2","title":"\u601d\u8003\u57fa\u6e962","text":"<p>8\u9846\u7403, \u52063\u9846\u7d66A, \u52063\u9846\u7d66B, \u5206\u5169\u9846\u7d66C 8\u4f4d\u5b78\u751f, \u5206\u62103\u7d44, A\u7d443\u4eba, B\u7d443\u4eba, C\u7d442\u4eba 8\u4ef6\u79ae\u7269, \u5206\u62103\u5806, 2\u58063\u4ef6, 1\u58062\u4ef6</p>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#_3","title":"\u6a5f\u7387","text":"<ul> <li>\u8a8d\u8b58\u6a5f\u7387 - \u9ec3\u6587\u748b</li> <li>\u6a5f\u7387\u5165\u9580 - \u77e5\u4e4e</li> <li>\u51fd\u6570\u3001\u6982\u7387\u3001\u4fe1\u606f\u7684\u57fa\u7840\u4e32\u8bb2 - \u77e5\u4e4e</li> <li>\u53e4\u5178\u6a5f\u7387\u3001\u76f8\u5c0d\u6b21\u6578\u6a5f\u7387\u8207\u4e3b\u89c0\u6a5f\u7387</li> </ul> <p>\u70ba\u4ec0\u9ebc\u6a39\u72c0\u5716\u4e0a\u7684\u6a5f\u7387\u503c\u53ef\u4ee5\u76f8\u4e58\uff1f</p> <p>\u4eba\u5011\u8a55\u4f30\u4e8b\u4ef6\u767c\u751f==\u53ef\u80fd\u6027==\u4e4b==\u5927\u5c0f==\u7684\u5e7e\u7a2e\u601d\u7dad</p> <p>\u53e4\u5178\u7684\u6a5f\u7387, \u57fa\u672c\u5047\u8a2d\u662f\u201c==\u76f8\u540c\u7684\u53ef\u80fd\u6027==\u201d\u3002 \u5148\u6c42\u51fa\u89c0\u6e2c\u7684\u73fe\u8c61\u5171\u6709\u5e7e\u7a2e\u53ef\u80fd, \u518d\u6c42\u51fa\u5176\u4e2d \u6709\u5e7e\u4ef6\u662f\u6211\u5011\u6709\u8208\u8da3\u7684\u3002 \u5c07\u5f8c\u8005\u9664\u4ee5\u524d\u8005, \u5373\u70ba\u6240\u8981\u7684\u6a5f\u7387\u3002</p> <p>\u904e\u53bb\u7684\u7d00\u9304\u986f\u793a, \u4f0d\u8332\u5982\u80fd\u5e36\u845754\u6d1e\u9818\u5148\u9032\u5165\u6c7a\u8cfd\u5708, \u6230\u7e3e\u662f35\u52dd1\u6557\u3002 \u4f60\u8981\u4e0d\u8981\u731c\u5f8c\u4f86\u4ed6\u8d0f\u4e86\u6c92\u6709? \u904b\u52d5\u6bd4\u8cfd, \u5f80\u5f80\u6709\u904e\u53bb\u8cc7\u6599\u53ef\u53c3\u8003, \u6b64\u6642\u76f8\u540c\u7684\u53ef\u80fd\u6027\u4fbf\u4e0d\u5b9c\u7528\u4e86\u3002 36\u6b21\u4e2d\u6210\u529f35\u6b21, \u201c \u76f8\u5c0d\u983b \u7387\u201d\u70ba35/36(\u7d040.972)\u3002 \u9019\u7a2e\u4ee5\u76f8\u5c0d\u983b\u7387\u4f86\u89e3\u91cb\u6a5f\u7387, \u662f\u5e38\u6709\u7684\u4f5c\u6cd5\u3002 ==\u9069\u7528\u80fd\u91cd\u8907\u89c0\u6e2c\u7684\u73fe\u8c61==\u3002\u6703\u4e0d\u6703\u6709\u7206\u51fa\u51b7\u9580\u7684\u6642\u5019? \u7576\u7136\u6709\u3002 \u53ea\u662f\u5c0d\u4e00\u7279\u5b9a\u4e8b\u4ef6, \u7528\u904e\u53bb\u591a\u6b21\u540c\u6a23\u60c5\u6cc1\u4e0b, \u8a72\u4e8b\u4ef6\u767c\u751f \u7684\u76f8\u5c0d\u983b\u7387, \u4f86\u4f30\u8a08\u4e0b\u4e00\u6b21\u4e8b\u4ef6\u767c\u751f\u7684\u6a5f\u7387, \u4e43\u662f\u5728\u6c92\u6709\u66f4\u591a\u8cc7\u8a0a\u4e0b, \u5e38\u88ab\u8a8d\u70ba\u4e00\u5c6c\u65bc\u5ba2\u89c0\u7684\u8fa6 \u6cd5\u3002</p> <p>\u67d0\u541b\u770b\u4e0a\u4e00\u5973\u5b69, \u9a5a\u70ba\u5929\u4eba, \u89ba\u5f97\u9019\u662f\u4ed6\u4eca\u751f\u7684\u65b0\u5a18\u3002 \u8a55\u4f30\u5f8c\u4fe1\u5fc3\u6eff\u6eff, \u81ea\u8a8d\u8ffd\u4e0a\u7684\u6a5f\u6703\u6709 8\u6210\u3002 \u65c1\u4eba\u537b\u90fd\u4e0d\u770b\u597d, \u554f\u4ed68\u6210\u9019\u4e00\u6578\u5b57, \u662f\u5982\u4f55\u5192\u51fa\u4f86\u7684? \u8a72\u541b\u8209\u8b49\u6b77\u6b77, \u4e00\u500b\u53c8\u4e00\u500b\u7684\u8de1 \u8c61, \u986f\u793a\u90a3\u5973\u5b69\u5c0d\u4ed6\u5f88\u6709\u597d\u611f\u3002 \u9019\u500b0.8\u7684\u6a5f\u7387, \u5c31\u662f\u6240\u8b02 \u4e3b\u89c0\u6a5f\u7387\u3002 ==\u6709\u4e9b\u73fe\u8c61\u5c31\u662f\u4e0d\u80fd\u91cd\u8907\u89c0\u6e2c==\u3002 \u5982\u6838\u80fd\u96fb\u5ee0\u7684\u610f\u5916, \u53ca\u5f57\u661f\u649e\u5730\u7403\u7b49\u3002 \u4ee5\u8ffd\u5973\u5b69\u70ba\u4f8b, \u5927\u7d04\u5c11\u6709\u5973\u5b69, \u6703\u8b93\u4f60\u505a\u5be6\u9a57, \u53cd\u8986\u5730\u8ffd, \u7136\u5f8c\u6578\u4e00\u6578\u5176\u4e2d\u6210\u529f\u5e7e\u6b21, \u4f86\u5b9a\u4e0b\u5979\u6703\u88ab\u4f60\u8ffd\u4e0a\u7684\u6a5f\u7387\u3002 \u5c0d\u9019\u985e\u7121\u6cd5\u91cd\u8907\u89c0\u6e2c\u7684\u73fe\u8c61, \u5728\u8ac7\u6a5f\u7387\u6642, \u4e3b\u89c0\u6a5f\u7387\u5c31\u5e38\u6d3e\u4e0a \u7528\u5834\u3002</p> <p>\u5f15\u9032\u6a5f\u7387\u8207\u7d71\u8a08, \u4e43\u70ba\u4e86\u5354\u52a9\u6211\u5011\u505a\u6c7a\u7b56\u53ef\u4ee5\u66f4\u7cbe\u6e96\u3002 \u800c\u6c7a\u7b56\u53ef\u4ee5\u8207\u6642\u63a8\u79fb, \u4e26\u975e\u4e0d\u80fd\u66f4\u6539</p> <p>\u4ee5\u516c\u7406\u5316\u7684\u65b9\u5f0f, \u4f86\u5f15\u9032\u6a5f\u7387? \u5148\u8981\u6709\u4e00\u500b\u96c6\u5408, \u7a31\u505a \u6a23\u672c\u7a7a\u9593, \u7576\u505a\u67d0\u4e00\u89c0\u6e2c\u4e4b\u6240\u6709\u53ef\u80fd\u7d50\u679c\u7684\u96c6\u5408\u3002 \u53ef\u4ee5\u771f\u7684\u6709\u9019\u4e00\u89c0\u6e2c, \u6216\u53ea\u662f\u865b\u64ec\u7684\u3002 \u6a23\u672c\u7a7a\u9593\u7684\u67d0\u4e9b\u5b50\u96c6\u5408, \u662f\u6211\u5011\u6709\u8208\u8da3\u7684, \u9019\u4e9b\u5c31\u662f\u4e00\u500b\u500b\u7684 \u4e8b\u4ef6\u3002 \u6240\u6709\u4e8b\u4ef6\u4e5f\u69cb\u6210\u4e00\u96c6\u5408\u3002 \u6700\u5f8c\u5b9a\u51fa\u4e00 \u6a5f\u7387\u51fd\u6578, \u5373\u5c0d\u6bcf\u4e00\u4e8b\u4ef6, \u7d66\u4e00\u4ecb\u65bc0, 1\u9593\u7684\u503c, \u70ba\u8a72\u4e8b\u4ef6\u4e4b\u6a5f\u7387\u3002 \u6a23\u672c\u7a7a\u9593\u3001\u4e8b\u4ef6\u7684\u96c6\u5408, \u53ca\u6a5f\u7387\u51fd\u6578, \u4e09\u8005\u4fbf\u69cb\u6210 \u6a5f\u7387\u7a7a\u9593 (probability space)\u3002</p>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#_4","title":"\u62bd\u6a23","text":"<ul> <li>\u62bd\u6a23\u8207\u62bd\u6a23\u5206\u914d</li> </ul>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#labs","title":"labs","text":"<p>https://jupyter.org/try-jupyter/lab/</p> <ul> <li>random.gauss() function in Python</li> </ul> <p>\u5e38\u614b\u5206\u5e03\u7b46\u8a18 <pre><code>    # \u5e38\u7528\u53c3\u6578\u4ecb\u7d39\uff1a\n    # np.random.normal\uff1a\n    # https://docs.scipy.org/doc//numpy-1.10.4/reference/generated/numpy.random.normal.html\n    #     loc \u671f\u671b\u503c\n    #     scale \u6a19\u6e96\u5dee\n    #     size \u57fa\u65bcnormal distribution\u751f\u6210\u7684\u6578\u91cf\n    # plt.hist\uff1a\n    # https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.hist.html\n    #     Parameters:\n    #         bins: \u76f4\u65b9\u5716\u7684\u67f1\u6578\uff0c\u53ef\u9078\u9805\uff0c\u9ed8\u8a8d\u70ba10\uff1b\n    #         density: \u662f\u5426\u5c07\u5f97\u5230\u7684\u76f4\u65b9\u5716\u5404 bin \u7684\u6578\u91cf\u898f\u4e00\u5316\u3002\u9ed8\u8a8d\u70ba False\uff1b\n    #         color\uff1a\u984f\u8272\u5e8f\u5217\uff0c\u9ed8\u8a8d\u70baNone\uff1b\n    #         facecolor: \u76f4\u65b9\u5716\u984f\u8272\uff1b\n    #         edgecolor: \u76f4\u65b9\u5716\u908a\u6846\u984f\u8272\uff1b\n    #         alpha: \u900f\u660e\u5ea6\uff1b\n    #         histtype: \u76f4\u65b9\u5716\u985e\u578b\uff0c\u300ebar\u300f, \u300ebarstacked\u300f, \u300estep\u300f, \u300estepfilled\u300f\n    #     Returns:\n    #         n: \u6bcf\u500b\u76f4\u65b9\u67f1\u5c0d\u61c9\u7684\u6578\u503c\uff0c\u82e5 density=True\uff0c\u5247\u70ba\u898f\u4e00\u5316\u5f8c\u7684\u6578\u503c\n    #         bins: \u6bcf\u500b\u5206\u7d44\u7684\u908a\u754c\u6578\u503c\n    #         patches\n    # scipy.stats.norm.pdf \u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578\n    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n    #     Parameters:\n    #         x: \u96a8\u6a5f\u8b8a\u91cf\u6578\u503c\n    #         loc: \u671f\u671b\u503c\n    #         scale: \u6a19\u6e96\u5dee\n    #     Returns:\n    #         y: \u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578\u6578\u503c\n    # :return: None\nimport numpy as np\nimport scipy.stats\nimport matplotlib.pyplot as plt\nmu = 30\nsigma = 1.5\nsize = 86400\nnp.random.seed(0)\ndnormal = np.random.normal(mu, sigma, size)\n_, bins_edge, _ = plt.hist(dnormal, bins=50, density=True, alpha=0.5)\n\n# \u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578\u66f2\u7dda\ny = scipy.stats.norm.pdf(bins_edge, mu, sigma)\nplt.plot(bins_edge, y, label='$\\mu$=%.1f, $\\sigma^2$=%.1f'%(mu, sigma))\n\nplt.xlabel('Expectation')\nplt.ylabel('Probability')\nplt.title('histogram of normal distribution:')\nplt.legend(loc=0, ncol=1)\nplt.show()\n\ns = sum(dnormal)\nprint(s)\n</code></pre> \u5e38\u614b\u5206\u5e03\u9664\u4e86\u5e73\u5747\u503c(mu)\u548c\u6a19\u6e96\u5dee(sigma)\uff0c\u9084\u6709\u4e00\u4e9b\u7279\u5fb5\uff1a - \u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578\u63a5\u8fd1\u5c0d\u7a31 - \u5e73\u5747\u503c\u8207\u5b83\u7684\u773e\u6578\uff08statistical mode\uff09\u4ee5\u53ca\u4e2d\u4f4d\u6578\uff08median\uff09\u540c\u4e00\u6578\u503c\u3002 - \u51fd\u6578\u66f2\u7dda\u4e0b68.3 %\u7684\u9762\u7a4d\u5728\u5e73\u5747\u6578\u5de6\u53f3\u76841\u500b\u6a19\u6e96\u5dee(sigma)\u7bc4\u570d\u5167\u3002 - \u51fd\u6578\u66f2\u7dda\u4e0b95.4 %\u7684\u9762\u7a4d\u5728\u5e73\u5747\u6578\u5de6\u53f3\u76842\u500b\u6a19\u6e96\u5dee(sigma)\u7bc4\u570d\u5167\u3002 - \u51fd\u6578\u66f2\u7dda\u4e0b99.7 %\u7684\u9762\u7a4d\u5728\u5e73\u5747\u6578\u5de6\u53f3\u76843\u500b\u6a19\u6e96\u5dee(sigma)\u7bc4\u570d\u5167\u3002</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats\nmu = 70\nsigma = 5\nsize = 86400\nnp.random.seed(0)\ndnormal = np.random.normal(mu, sigma, size)\n_, bins_edge, _ = plt.hist(dnormal, bins=50, density=True, alpha=0.5)\n\n# \u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578\u66f2\u7dda\ny = scipy.stats.norm.pdf(bins_edge, mu, sigma)\nplt.plot(bins_edge, y, label='$\\mu$=%.1f, $\\sigma^2$=%.1f'%(mu, sigma))\ns = sum(dnormal)\nprint(s)\n\nmu = 80\nsigma = 1\nsize = 86400\nnp.random.seed(0)\ndnormal = np.random.normal(mu, sigma, size)\n_, bins_edge, _ = plt.hist(dnormal, bins=50, density=True, alpha=0.5)\n\n# \u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578\u66f2\u7dda\ny = scipy.stats.norm.pdf(bins_edge, mu, sigma)\nplt.plot(bins_edge, y, label='$\\mu$=%.1f, $\\sigma^2$=%.1f'%(mu, sigma))\ns = sum(dnormal)\nprint(s)\n\nplt.xlabel('Expectation')\nplt.ylabel('Probability')\nplt.title('histogram of normal distribution:')\nplt.legend(loc=0, ncol=1)\nplt.show()\n</code></pre>"},{"location":"hackmd/%E6%8E%92%E5%88%97%E7%B5%84%E5%90%88%E8%88%87%E6%A9%9F%E7%8E%87/#_5","title":"\u53c3\u8003","text":"<ul> <li>\u8d70\u4e00\u8d9f\u9ad8\u4e2d\u6a5f\u7387\u6559\u5b78\u4e4b\u65c5 - \u4e01\u6751\u6210</li> <li>\u6a5f\u7387\u8ad6 - \u984f\u570b\u52c7 - \u6210\u5927\u6578\u5b78\u7cfb</li> <li>\u689d\u4ef6\u6a5f\u7387\u8207\u8c9d\u6c0f\u5b9a\u7406\uff1a\u8499\u63d0\u970d\u723e\u3001\u53f2\u5bc6\u65af\u5148\u751f\u548c\u9a57\u5b55\u68d2</li> <li>Basics of Probability for Data Science explained with examples in R</li> <li>40 Questions on Probability for data science</li> <li>10001 \u7d71\u8a08\u5b78\u7814\u7a76\u6240 \u6a5f\u7387\u8ad6 - \u6e05\u5927 \u912d\u5c11\u70ba \u6559\u6388</li> <li>\u62bd\u6a23\u8aa4\u5dee\u7684\u89c0\u5ff5\u6975\u7c21\u89e3\u8aaa - HackMD</li> </ul>"},{"location":"hackmd/%E6%95%88%E8%83%BD/","title":"\u6548\u80fd","text":"<p>\u5c0e\u8b80\u300a\u6253\u9020\u9ad8\u901f\u7db2\u7ad9\uff0c\u5f9e\u7db2\u7ad9\u6307\u6a19\u958b\u59cb\uff01\u5168\u65b9\u4f4d\u63d0\u5347\u4f7f\u7528\u8005\u9ad4\u9a57\u8207\u6d41\u91cf\u7684\u95dc\u9375\u300b\u9010\u5b57\u7a3f@\u65b0\u7af9\u654f\u6377</p>"},{"location":"hackmd/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/","title":"\u6a5f\u5668\u5b78\u7fd2","text":"<ul> <li>Precision and recall</li> <li>F-score</li> <li>2021 \u5e74\uff0c\u5916\u5546\u8cc7\u6599\u79d1\u5b78\u5bb6\u6c42\u8077\u7d93\u9a57\u5206\u4eab \u2022 \u597d\u8c6a\u7b46\u8a18<ul> <li>\u8cc7\u6599\u79d1\u5b78\u7af6\u8cfd\uff0c\u80fd\u7372\u5f97\u4ec0\u9ebc\uff1f \u2022 \u597d\u8c6a\u7b46\u8a18</li> </ul> </li> <li>Data \ud83d\udcca \u95dc\u65bc\u8cc7\u6599\u79d1\u5b78 \u2026 \u6211\u60f3\u8aaa\u7684\u662f(\u4e0a). \u9019\u5341\u5e74\u4f86\uff0c\u8cc7\u6599\u79d1\u5b78\u76f8\u95dc\u6280\u8853\u7684\u78ba\u662f\u98db\u5feb\u6210\u9577\uff0c\u4f46\u662f\u6838\u5fc3\u50f9\u503c\u672a\u66fe\u6539\u8b8a\uff0c\u66fe\u7d93\u6211\u4e5f\u4ee5\u70ba\u638c\u63e1\u2026 | by Sobi | \u7a0b\u5f0f\u733f\u5403\u9999\u8549 | Aug, 2022 | Medium</li> <li>Knock Knock! Deep Learning :: \u7b2c 12 \u5c46 iThome \u9435\u4eba\u8cfd</li> <li>\u767d\u8a71\u6587\u544a\u8a34\u4f60 - \u4ec0\u9ebc\u662f Embedding \u00b7 YWC \u79d1\u6280\u7b46\u8a18</li> <li>\u4ece\u795e\u7ecf\u7f51\u7edc\u5230 Hugging Face | \u80e1\u6d82\u8bf4</li> <li>\u672c\u6a5f\u67b6\u8a2d\u81ea\u5df1\u7684 embedding \u670d\u52d9 \u00b7 YWC \u79d1\u6280\u7b46\u8a18</li> <li>\u4f7f\u7528 RAG \u6253\u9020\u500b\u4eba\u77e5\u8b58\u5eab\uff0cLlamaIndex \u642d\u914d Gemini \u6a21\u578b \u2013 IT \u7a7a\u9593</li> <li>LLM 30\u79d2\u5165\u9580\u7c21\u4ecb</li> <li>\u96e2\u7dda\u7248ChatGPT\u5b89\u88dd\u65b9\u6cd5\uff01\u5728\u500b\u4eba\u96fb\u8166\u8dd1AI\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u958b\u6e90\u8edf\u9ad4\u5217\u8868 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> <li>Math For Machine Learning [Resources]</li> <li>\u751f\u6210\u5f0f AI \u5e74\u6703\u5927\u79ae\u5305</li> <li>\u4f7f\u7528 Microsoft BIPIA \u6846\u67b6\u8a55\u4f30 LLM \u9632\u79a6\u80fd\u529b - Clay-Technology World</li> <li>\u4f7f\u7528 Outlines \u5de5\u5177\u7d50\u69cb\u5316\u6a21\u578b\u7684\u8f38\u51fa - Clay-Technology World</li> <li>DBSCAN \u5206\u7fa4\u6f14\u7b97\u6cd5\u4ecb\u7d39\u8207\u5be6\u969b\u61c9\u7528\u7bc4\u4f8b - MyApollo</li> <li>NotebookLM\uff1a\u4f60\u7684\u5c08\u5c6c AI \u7814\u7a76\u52a9\u7406 \u2022 \u597d\u8c6a\u7b46\u8a18</li> <li>Dify<ul> <li>Dify \u4f7f\u7528\u5b89\u5168\u55ce\uff1f \u9a30\u8a0a\u516c\u53f8\uff1f \u5b89\u5168\u55ce\uff1f \u2013 \u8cc7\u6599\u6cbb\u7406\u8207\u6578\u4f4d\u8f49\u578b\u7522\u5b78\u806f\u76df</li> <li>\u4f7f\u7528 Dify API \u5feb\u901f\u5efa\u7acb\u4e00\u500b\u5305\u542b\u524d\u5f8c\u6587\u8a18\u61b6\u7684\u5c0d\u8ac7\u6a5f\u5668\u4eba</li> <li>\u4f7f\u7528\u5bb9\u5668\u5316\u6280\u8853\u904b\u884c Dify</li> </ul> </li> <li>Linux\u7528docker-compose\u90e8\u7f72Open WebUI + Ollama\u8a9e\u8a00\u6a21\u578b\u7db2\u9801\u754c\u9762 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/#kaggle","title":"Kaggle","text":"<ul> <li>Find Open Datasets and Machine Learning Projects - Beginner | Kaggle</li> <li>Tutorias<ul> <li>Learn Python, Data Viz, Pandas &amp; More | Tutorials | Kaggle<ul> <li>Learn Intro to Machine Learning Tutorials</li> </ul> </li> <li>Comprehensive data exploration with Python | Kaggle</li> <li>A Data Science Framework: To Achieve 99% Accuracy | Kaggle</li> </ul> </li> <li>Kaggle \u5f59\u6574 \u2022 \u597d\u8c6a\u7b46\u8a18</li> <li>How to select your final models in a Kaggle competition | Data Science and Machine Learning</li> <li>Titanic<ul> <li>\u65b0\u624b\u73a9Kaggle\u5165\u9580 \u00ab Terrence\u7684\u5b85\u5b85\u5e7b\u60f3</li> <li>Exploring Survival on the Titanic | Kaggle</li> <li>Titanic - Machine Learning from Disaster | Kaggle</li> <li>Titanic Data Science Solutions | Kaggle</li> <li>Data analysis and feature extraction with Python | Kaggle</li> </ul> </li> <li>House Prices<ul> <li>\ud83c\udfe1 The Best Journeys Takes You Home \ud83c\udfe2 | Kaggle</li> <li>How to get to TOP 25% with Simple Model (sklearn) | Kaggle<ul> <li>Advance<ul> <li>In-Depth 8 Models to Predict Rent [&gt;80%] | Kaggle</li> </ul> </li> </ul> </li> </ul> </li> <li>World Population<ul> <li>World Population EDA With World Map Visualization | Kaggle</li> </ul> </li> <li>Anime Ratings<ul> <li>\u26e9\ufe0fAnime Ratings \ud83d\udcc8Analysis &amp; \ud83e\udd16Recommender System | Kaggle</li> </ul> </li> </ul>"},{"location":"hackmd/%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%A4%BA%E6%B3%95/","title":"\u6b63\u898f\u8868\u793a\u6cd5","text":"<p>lookahead \u4f7f\u7528\u4e0a\u611f\u89ba\u50cfpostfix lookbehind \u4f7f\u7528\u4e0a\u611f\u89ba\u50cfprefix</p>"},{"location":"hackmd/%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%A4%BA%E6%B3%95/#add-commas-to-number","title":"add-commas-to-number","text":"<p>https://www.delftstack.com/howto/javascript/javascript-add-commas-to-number/ /\\B(?=(\\d{3})+(?!\\d))/g</p> <p>\\B(?=(\\d{3})+(?!\\d)) \\B(?=(\\d{3}){1}(?!\\d)) 1(?=(\\d{3})+(?!\\d)) 3(?=(\\d{3})+(?!\\d)) 3(?=((\\d{3}){2})(?!\\d)) (\\d{3})+(?!\\d)</p> <p>Test String: 4156416541564156199 dsfdfsd5dsf dsfkllkjs sdjfkljlkj 213231221 9213231223</p> <p>:::info (\\d{3})+(?!\\d) =&gt; \u4f4d\u6578\u70ba3\u7684\u500d\u6578\u7684\u6578\u5b57, ex. 221, 231221, 564156199 (\\d{3}){1}(?!\\d) =&gt; \u53ea\u80fd3\u4f4d\u6578 (\\d{3}){2}(?!\\d) =&gt; \u53ea\u80fd6\u4f4d\u6578</p> <p>3(?=((\\d{3}){2})(?!\\d)) =&gt; \u8981match\u5f8c\u9762\u53ea\u80fd\u63a56\u4f4d\u6578\u7684\u6578\u5b573</p> <p>:::</p>"},{"location":"hackmd/%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%A4%BA%E6%B3%95/#_2","title":"\u53c3\u8003","text":"<ul> <li>\u6b63\u898f\u8868\u793a\u6cd5 Regular Expression (Regex)</li> <li>Rex Egg</li> <li>RegExp \u8e29\u96f7\uff1aLookbehind Assertions</li> <li>Test<ul> <li>regex101</li> <li>Regex Tester</li> </ul> </li> </ul>"},{"location":"hackmd/%E6%B8%AC%E8%A9%A6%E5%B7%A5%E5%85%B7/","title":"\u6e2c\u8a66\u5de5\u5177","text":"<p>siege ab</p> <ul> <li>\u4f7f\u7528 ApacheBench \u9032\u884c\u7db2\u7ad9\u7684\u58d3\u529b\u6e2c\u8a66</li> </ul>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/","title":"\u7121\u7dda\u7db2\u8def","text":""},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#_2","title":"\u67e5\u8a62\u96fb\u8166\u7121\u7dda\u7db2\u5361\u652f\u63f4\u7684\u5354\u5b9a","text":"<pre><code>netsh wlan show drivers\n\nC:\\Windows\\System32&gt;netsh wlan show drivers\n\n\u4ecb\u9762\u540d\u7a31: Wi-Fi\n\n    \u9a45\u52d5\u7a0b\u5f0f                  : Qualcomm Atheros AR956x Wireless Network Adapter\n\n    \u5ee0\u5546                      : Qualcomm Atheros Communications Inc.\n    \u63d0\u4f9b\u8005                    : Qualcomm Atheros Communications Inc.\n    \u65e5\u671f                      : 2013/11/12\n    \u7248\u672c                      : 10.0.0.274\n    INF \u6a94\u6848                  : C:\\windows\\INF\\oem17.inf\n    \u6a94\u6848                      : \u7e3d\u5171 2 \u500b\n                                C:\\windows\\system32\\DRIVERS\\athwbx.sys\n                                C:\\windows\\system32\\drivers\\vwifibus.sys\n    \u985e\u578b                      : \u539f\u59cb Wi-Fi \u9a45\u52d5\u7a0b\u5f0f\n    \u652f\u63f4\u7684\u7121\u7dda\u96fb\u6ce2\u985e\u578b        : 802.11b 802.11g 802.11n\n</code></pre>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#_3","title":"\u66f4\u63db\u7121\u7dda\u5206\u4eab\u5668\u548c\u7db2\u5361","text":"<p>\u7b46\u96fb\u70baLenovo G50, \u7121\u7dda\u7db2\u5361\u50c5\u652f\u63f4\u5230802.11n</p>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#p1","title":"P1 \u62c9\u7db2\u8def\u7dda","text":"<p>\u9084\u662f\u9700\u8981\u66f4\u63db\u7121\u7dda\u5206\u4eab\u5668, \u66f4\u63db\u5b8c\u6210\u5f8c\u62c9\u7dda</p>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#p2","title":"P2 \u66f4\u63db\u5167\u5efa\u7db2\u5361","text":"<p>\u9700\u67e5\u8a62\u6709\u54ea\u4e9b\u898f\u683c \u6ce8\u610f\u6709\u4e9b\u724c\u5b50\u53ef\u80fd\u6703\u9396\u7db2\u5361(HP, Lenovo) ax200</p>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#p3-usb","title":"P3 \u5916\u63a5USB\u7db2\u5361","text":"<p>USB 3.0\u7121\u7dda\u7db2\u5361, \u50f9\u683c\uff0c\u904e\u71b1\u7a69\u5b9a\u6027 TP Link Archer T4U $799 T3U $599</p>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#p4-ap","title":"P4 \u7121\u7ddaAP\u7576\u4f5c\u7db2\u5361","text":"<p>\u7a69\u5b9a\u6027\u76f8\u5c0d\u5916\u63a5usb\u7db2\u5361\u9ad8 \u5360\u4e86\u4e00\u500b\u7a7a\u9593 \u5e7e\u4e4e\u627e\u4e0d\u5230\u652f\u63f4Client mode\u7684\u57fa\u5730\u53f0</p>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#_4","title":"\u7121\u7dda\u5206\u4eab\u5668","text":"<p>AC1750 $1500 TPLINK C80\uff0cC7 AX3000 $2500 TPLINK AX55</p>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#_5","title":"\u53c3\u8003","text":"<ul> <li>\u3010\u9078\u8cfc\u8207\u63a8\u85a6\u3011\u7121\u7dda\u8def\u7531\u5668 &amp; \u4ea4\u63db\u5668<ul> <li>\u5c0d\u5916\u9023\u7db2(\u5916\u7db2) \u3001\u5c0d\u5167IP\u5206\u4eab(\u5167\u7db2)\u3001\u7121\u7dda\u7db2\u8def(WIFI)</li> <li>\u5927B\u8ddf\u5c0fb<ul> <li>\u96fb\u8166\u50b3\u8f38\u901f\u5ea6\u4ee5Byte (\u4f4d\u5143\u7d44)\u70ba\u55ae\u4f4d (\u5927B)</li> <li>\u7db2\u8def\u50b3\u8f38\u901f\u5ea6\u4ee5bit (\u4f4d\u5143) \u70ba\u55ae\u4f4d (\u5c0fb)</li> </ul> </li> <li>\u6709\u7dda\u7db2\u901f\uff0c\u4f8b\u5982\uff1a10/100/1000(Gigabits)</li> <li>\u5e38\u898b\u7684\u7121\u7dda\u6a19\u6e96\u662f802.11ac(WiFi 5) \u53ca 802.11ax(WiFi 6)</li> <li>\u4ee5AC1200\u4f86\u8aaa\uff0c\u7121\u7dda\u7db2\u8def\u652f\u63f4\u96d9\u983b2.4G+5G\uff0c\u4f8b\u5982300 Mbps+867 Mbps= 1167 (\u5dee\u4e0d\u591a\u7b49\u65bc1200)</li> <li>\u7121\u7dda\u67092.4GHz\u548c5GHz\u5169\u7a2e\u983b\u6bb5<ul> <li>2.4GHz\uff1a\u8986\u84cb\u5ee3\u3001\u901f\u5ea6\u6162\u3001\u7a7f\u900f\u529b\u5f37</li> <li>5GHz(\u96d9\u983b)\uff1a\u8986\u84cb\u5c0f\u3001\u901f\u5ea6\u5feb\uff0c\u7a7f\u900f\u529b\u5f31</li> </ul> </li> <li>\u55ae\u983b\u5c31\u662f\u53ea\u67092.4GHz, \u96d9\u983b\u662f\u63072.4GHz\u53ca5GHz\u9019\u5169\u7a2e\u983b\u6bb5\u90fd\u6709, \u4e09\u983b\u662f\u63071\u500b2.4GHz\u53ca2\u500b5GHz(\u4f8b\u5982Mesh)</li> </ul> </li> </ul>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#static-route","title":"\u8a2d\u5b9astatic route","text":"<p>windows <pre><code>route\nroute print\nroute add\n</code></pre></p> <p>\u60c5\u5883: hackmd.io\u88ab\u64cb\u6389 \u4f7f\u7528\u624b\u6a5f\u71b1\u9ede + static route</p> <pre><code>\u7121\u7dda\u5340\u57df\u7db2\u8def\u4ecb\u9762\u5361 \u7121\u7dda\u7db2\u8def\u9023\u7dda 8:\n\n   \u9023\u7dda\u7279\u5b9a DNS \u5c3e\u78bc . . . . . . . . :\n   IPv6 \u4f4d\u5740. . . . . . . . . . . . .: 2401:e180:8861:ad79:b8b9:44f8:ba71:26a9\n   \u81e8\u6642 IPv6 \u4f4d\u5740. . . . . . . . . . : 2401:e180:8861:ad79:d17e:b1c3:ec1c:5132\n   \u9023\u7d50-\u672c\u6a5f IPv6 \u4f4d\u5740 . . . . . . . : fe80::b8b9:44f8:ba71:26a9%24\n   IPv4 \u4f4d\u5740 . . . . . . . . . . . . : 172.20.10.3\n   \u5b50\u7db2\u8def\u906e\u7f69 . . . . . . . . . . . .: 255.255.255.240\n   \u9810\u8a2d\u9598\u9053 . . . . . . . . . . . . .: fe80::1838:82a5:4ed:6842%24\n                                       172.20.10.1\n\u4e59\u592a\u7db2\u8def\u5361 \u5340\u57df\u9023\u7dda 2:\n\n   \u9023\u7dda\u7279\u5b9a DNS \u5c3e\u78bc . . . . . . . . : foo.com\n   \u9023\u7d50-\u672c\u6a5f IPv6 \u4f4d\u5740 . . . . . . . : fe80::fc50:1a8:b303:8183%18\n   IPv4 \u4f4d\u5740 . . . . . . . . . . . . : 10.253.63.32\n   \u5b50\u7db2\u8def\u906e\u7f69 . . . . . . . . . . . .: 255.255.255.0\n</code></pre> <pre><code>===========================================================================\n\u4ecb\u9762\u6e05\u55ae\n 33...00 ff 67 d1 c1 ad ......TAP-Windows Adapter V9\n 26...36 de 1a a3 44 b4 ......Microsoft Virtual WiFi Miniport Adapter #6\n 25...36 de 1a a3 44 b3 ......Microsoft Virtual WiFi Miniport Adapter #5\n 24...34 de 1a a3 44 b3 ......Intel(R) Dual Band Wireless-AC 3160 #4\n 23...34 de 1a a3 44 b7 ......Bluetooth \u88dd\u7f6e (\u500b\u4eba\u5340\u57df\u7db2\u8def)\n 18...fc 3f db 39 68 89 ......Realtek PCIe GBE Family Controller #2\n 28...00 50 56 c0 00 08 ......VMware Virtual Ethernet Adapter for VMnet8\n 32...0a 00 27 00 00 20 ......VirtualBox Host-Only Ethernet Adapter\n  1...........................Software Loopback Interface 1\n 30...00 00 00 00 00 00 00 e0 Microsoft ISATAP Adapter #3\n 14...00 00 00 00 00 00 00 e0 Microsoft 6to4 Adapter\n 34...00 00 00 00 00 00 00 e0 Microsoft ISATAP Adapter #6\n 29...00 00 00 00 00 00 00 e0 Microsoft ISATAP Adapter #7\n===========================================================================\n\nIPv4 \u8def\u7531\u8868\n===========================================================================\n\u4f7f\u7528\u4e2d\u7684\u8def\u7531:\n\u7db2\u8def\u76ee\u7684\u5730                 \u7db2\u8def\u906e\u7f69         \u9598\u9053          \u4ecb\u9762       \u8a08\u91cf\n          0.0.0.0          0.0.0.0    10.253.63.254     10.253.63.32     20\n          0.0.0.0          0.0.0.0      172.20.10.1      172.20.10.3     25\n      10.253.63.0    255.255.255.0            \u5728\u9023\u7d50\u4e0a      10.253.63.32    276\n     10.253.63.32  255.255.255.255            \u5728\u9023\u7d50\u4e0a      10.253.63.32    276\n    10.253.63.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a      10.253.63.32    276\n      75.2.77.152  255.255.255.255      172.20.10.1      172.20.10.3   1525\n    99.83.179.177  255.255.255.255      172.20.10.1      172.20.10.3   1525\n        127.0.0.0        255.0.0.0            \u5728\u9023\u7d50\u4e0a         127.0.0.1    306\n        127.0.0.1  255.255.255.255            \u5728\u9023\u7d50\u4e0a         127.0.0.1    306\n  127.255.255.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a         127.0.0.1    306\n      172.20.10.0  255.255.255.240            \u5728\u9023\u7d50\u4e0a       172.20.10.3    281\n      172.20.10.3  255.255.255.255            \u5728\u9023\u7d50\u4e0a       172.20.10.3    281\n     172.20.10.15  255.255.255.255            \u5728\u9023\u7d50\u4e0a       172.20.10.3    281\n     192.168.56.0    255.255.255.0            \u5728\u9023\u7d50\u4e0a      192.168.56.1    266\n     192.168.56.1  255.255.255.255            \u5728\u9023\u7d50\u4e0a      192.168.56.1    266\n   192.168.56.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a      192.168.56.1    266\n    192.168.223.0    255.255.255.0            \u5728\u9023\u7d50\u4e0a     192.168.223.1    276\n    192.168.223.1  255.255.255.255            \u5728\u9023\u7d50\u4e0a     192.168.223.1    276\n  192.168.223.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a     192.168.223.1    276\n        224.0.0.0        240.0.0.0            \u5728\u9023\u7d50\u4e0a         127.0.0.1    306\n        224.0.0.0        240.0.0.0            \u5728\u9023\u7d50\u4e0a      10.253.63.32    276\n        224.0.0.0        240.0.0.0            \u5728\u9023\u7d50\u4e0a      192.168.56.1    266\n        224.0.0.0        240.0.0.0            \u5728\u9023\u7d50\u4e0a     192.168.223.1    276\n        224.0.0.0        240.0.0.0            \u5728\u9023\u7d50\u4e0a       172.20.10.3    281\n  255.255.255.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a         127.0.0.1    306\n  255.255.255.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a      10.253.63.32    276\n  255.255.255.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a      192.168.56.1    266\n  255.255.255.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a     192.168.223.1    276\n  255.255.255.255  255.255.255.255            \u5728\u9023\u7d50\u4e0a       172.20.10.3    281\n===========================================================================\n</code></pre> <pre><code>nslookup hackmd.io\nipconfig\nroute add 99.83.179.177 172.20.10.1 metric 1500 IF 24\nroute add 75.2.77.152 172.20.10.1 metric 1500 IF 24\ntracert -4 hackmd.io\n</code></pre> <pre><code>\u5728\u4e0a\u9650 30 \u500b\u8e8d\u9ede\u4e0a\n\u8ffd\u8e64 hackmd.io [99.83.179.177] \u7684\u8def\u7531:\n\n  1     1 ms     3 ms    88 ms  172.20.10.1\n  2     *        *        *     \u8981\u6c42\u7b49\u5019\u903e\u6642\u3002\n  3    42 ms    27 ms    66 ms  172.20.114.1\n  ...\n</code></pre> <pre><code>\u5728\u4e0a\u9650 30 \u500b\u8e8d\u9ede\u4e0a\n\u8ffd\u8e64 google.com [142.251.43.14] \u7684\u8def\u7531:\n\n  1     1 ms     1 ms     1 ms  10.253.63.253\n  2     1 ms    &lt;1 ms    &lt;1 ms  10.253.201.126\n  3    &lt;1 ms    &lt;1 ms    &lt;1 ms  10.253.241.254\n  4     1 ms     1 ms    &lt;1 ms  192.168.249.129\n  5     1 ms     1 ms     1 ms  twpcmt01549-03.mitrastar.com [192.168.5.100]\n  6     6 ms     4 ms     5 ms  192.168.251.252\n  7     4 ms     3 ms     5 ms  192.168.64.1\n  8    11 ms     9 ms     9 ms  61-222-86-254.hinet-ip.hinet.net [61.222.86.254]\n</code></pre>"},{"location":"hackmd/%E7%84%A1%E7%B7%9A%E7%B6%B2%E8%B7%AF/#_6","title":"\u53c3\u8003","text":"<ul> <li>Windows 7 \u7db2\u8def\u5361\u512a\u5148\u9806\u5e8f</li> <li>Windows 7: Route single IP over different interface (wlan)</li> <li>\u5728Windows\u8a2d\u5b9aStatic Route</li> <li>[\u6559\u5b78]\u624b\u52d5\u65b0\u589e\u8def\u7531\u8868\uff0c\u4e09\u7db2\u6bb5\u8a2d\u5b9a\u65b9\u5f0f</li> </ul>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E5%AF%A6%E5%8B%99/","title":"\u7269\u4ef6\u5c0e\u5411\u7cfb\u7d71\u5206\u6790\u8207\u8a2d\u8a08","text":"<p>\u5b58\u53d6\u65b9\u5f0f\u4e0d\u8b8a, \u5167\u5bb9\u7269\u6703\u8b8a \u8209\u4f8b: \u624b\u6416\u98f2, \u7528\u5438\u7ba1\u5b58\u53d6, \u98f2\u6599\u53ef\u4ee5\u66ff\u63db</p> <p>\u4ecb\u9762 \u5be6\u9ad4\u66f8, \u96fb\u5b50\u66f8 \u64cd\u4f5c: \u7ffb\u4e0a\u4e00\u9801, \u7ffb\u4e0b\u4e00\u9801, \u756b\u7dda, \u66f8\u7c64, \u8cbc\u6a19\u7c64\u8cbc\u7d19</p>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/","title":"\u7269\u4ef6\u5c0e\u5411\u7cfb\u7d71\u5206\u6790\u8207\u8a2d\u8a08","text":""},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_2","title":"\u7cfb\u7d71\u958b\u767c\u751f\u547d\u9031\u671f","text":"<ol> <li>\u8a08\u5283\u968e\u6bb5<ul> <li>\u5efa\u7acb\u7cfb\u7d71\u7684==\u76ee\u7684==\u548c==\u5be6\u8cea\u5229\u76ca==</li> <li>\u53ef\u884c\u6027\u5206\u6790<ul> <li>\u6280\u8853\u9762<ul> <li>POC</li> </ul> </li> <li>\u7d93\u6fdf\u9762</li> </ul> </li> <li>\u56de\u7b54Why</li> </ul> </li> <li>\u5206\u6790\u968e\u6bb5<ul> <li>\u4e86\u89e3\u7cfb\u7d71\u7684\u9700\u6c42\u662f\u4ec0\u9ebc(==What==), \u5148\u4e0d\u7ba1\u9019\u4e9b\u9700\u6c42\u8981\u5982\u4f55\u9054\u6210(How)</li> <li>\u4ee5\u529f\u80fd\u9700\u6c42\u548c\u975e\u529f\u80fd\u9700\u6c42\u7684\u63cf\u8ff0\u70ba\u4e3b, \u800c\u4e0d\u6703\u727d\u6d89\u5230\u5be6\u4f5c\u7684\u7d30\u7bc0</li> <li>\u56de\u7b54What<ul> <li>External Spec</li> </ul> </li> </ul> </li> <li>\u8a2d\u8a08\u968e\u6bb5<ul> <li>\u4e86\u89e3\u7cfb\u7d71\u7684\u9700\u6c42\u5982\u4f55\u88ab\u9054\u6210(How)</li> <li>\u56de\u7b54How<ul> <li>Internal Spec</li> </ul> </li> </ul> </li> <li>\u5be6\u4f5c\u968e\u6bb5<ul> <li>Coding and Unit Test</li> </ul> </li> <li>\u6e2c\u8a66\u968e\u6bb5<ul> <li>Functional Test</li> <li>Integration Test</li> <li>User Acceptance Test</li> <li>Performace Test</li> <li>Capacity Test</li> </ul> </li> </ol>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_3","title":"\u529f\u80fd\u89c0\u9ede","text":""},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_4","title":"\u9700\u6c42\u64f7\u53d6\u8207\u5206\u6790","text":""},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_5","title":"\u9818\u57df\u5206\u6790","text":"<p>:::info \u6839\u64da\u65e2\u6709\u7cfb\u7d71\u53ca\u5176\u958b\u767c\u7684\u6b77\u53f2, \u9818\u57df\u5c08\u5bb6\u7684\u77e5\u8b58, \u80cc\u5f8c\u7684\u7406\u8ad6 \u8fa8\u5225, \u6536\u96c6\u4ee5\u53ca\u7d44\u7e54\u76f8\u95dc\u8cc7\u8a0a\u7684\u904e\u7a0b :::</p> <p>\u904e\u7a0b\u4e2d\u6703\u63a5\u89f8\u5230\u8a31\u591a\u8207\u8a08\u5283\u76f8\u95dc\u7684\u53c3\u8207\u4eba\u54e1, \u4f8b\u5982:\u9818\u57df\u5c08\u5bb6, \u65e2\u6709\u7cfb\u7d71\u7684\u4f7f\u7528\u8005, \u4ed6\u5011\u5c0d==\u4f01\u696d\u7684\u5404\u9805\u6d3b\u52d5\u4ee5\u53ca\u696d\u52d9\u6d41\u7a0b==\u6700\u719f\u6089, \u4ed6\u5011\u6703\u5728\u5206\u6790\u968e\u6bb5\u626e\u6f14\u91cd\u8981\u89d2\u8272</p>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_6","title":"\u9700\u6c42\u64f7\u53d6\u65b9\u5f0f","text":"<ul> <li>\u65e2\u6709\u7684\u5831\u8868\u53ca\u8868\u55ae</li> <li>\u8a2a\u8ac7</li> <li>\u8166\u529b\u6fc0\u76ea</li> </ul>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_7","title":"\u9700\u6c42\u5206\u6790","text":"<ul> <li>\u5206\u985e<ul> <li>\u529f\u80fd\u6027\u9700\u6c42(Functional Requirement)<ul> <li>\u8f38\u5165</li> <li>\u8655\u7406\u6d41\u7a0b\u8207\u6b65\u9a5f</li> <li>\u8f38\u51fa</li> </ul> </li> <li>\u975e\u529f\u80fd\u6027\u9700\u6c42(Non-Functional Requirement)<ul> <li>\u548c\u7cfb\u7d71\u7684\u57f7\u884c\u6548\u7387, \u6548\u80fd\u76f8\u95dc\u7684\u9700\u6c42, \u4e14\u53ef\u6e2c\u91cf(Measurable)</li> <li>\u8209\u4f8b<ul> <li>Response Time</li> <li>Usability</li> <li>Reliability</li> <li>Performance</li> <li>Maintainability</li> </ul> </li> </ul> </li> </ul> </li> <li>\u63cf\u8ff0<ul> <li>\u5f9e\u4f7f\u7528\u8005\u7684\u89c0\u9ede\u51fa\u767c, \u5b9a\u7fa9\u51fa\u6240\u8981\u89e3\u6c7a\u7684\u554f\u984c<ul> <li>\u76f8\u95dc\u6d41\u7a0b\u6558\u8ff0\u9700\u8981\u660e\u78ba\u5730\u8a18\u9304</li> </ul> </li> </ul> </li> <li>\u4e8b\u4ef6<ul> <li>\u7cfb\u7d71\u662f\u8207\u4f7f\u7528\u8005\u4e92\u52d5\u7684</li> <li>\u5c0d\u65bc\u529f\u80fd\u7684\u9700\u6c42\u63cf\u8ff0, \u53ef\u4ee5\u5c07\u5b83\u5011\u6b78\u7d0d\u6210\u4e8b\u4ef6</li> <li>\u89f8\u767c\u5668: \u4ee3\u8868\u5f15\u767c\u4e8b\u4ef6\u7684\u8cc7\u6599<ul> <li>\u9867\u5ba2\u4e0b\u8a02\u55ae\u7684\u89f8\u767c\u5668\u662f\u8a02\u55ae</li> <li>\u7522\u751f\u6708\u5831\u8868\u7684\u89f8\u767c\u5668\u662f\u6642\u9593</li> </ul> </li> <li>\u601d\u8003\u65b9\u5411<ul> <li>\u6709\u4ec0\u9ebc\u4e8b\u60c5\u662f\u5fc5\u9808\u7531\u7cfb\u7d71\u4f86\u81ea\u52d5\u5316\u57f7\u884c</li> <li>\u60f3\u8981\u5f9e\u7cfb\u7d71\u53d6\u5f97\u67d0\u4e9b\u6771\u897f\u7684\u5916\u90e8\u6216\u5167\u90e8\u5be6\u9ad4</li> <li>\u9700\u8981\u88ab\u5132\u5b58\u7684\u8cc7\u6599</li> <li>\u7531CRUD\u6aa2\u8996\u7cfb\u7d71\u53ef\u80fd\u767c\u751f\u7684\u4e8b\u4ef6\u884c\u70ba</li> <li>\u662f\u5426\u6709\u4ee5\u8cc7\u6599\u70ba\u5c0e\u5411\u7684\u4e8b\u4ef6</li> <li>\u662f\u5426\u6709\u4ee5\u6642\u9593\u70ba\u5c0e\u5411\u7684\u4e8b\u4ef6</li> </ul> </li> </ul> </li> <li>\u8a5e\u5f59\u8868(Glossary)<ul> <li>\u8207\u9818\u57df\u76f8\u95dc\u7684\u8cc7\u6599\u8207\u6982\u5ff5</li> <li>\u601d\u8003\u65b9\u5411<ul> <li>\u6355\u6349\u6240\u6709\u51fa\u73fe\u65bc\u9700\u6c42\u63cf\u8ff0\u7684==\u540d\u8a5e==</li> <li>\u6355\u6349\u6240\u6709\u51fa\u73fe\u65bc\u4e8b\u4ef6\u8868\u4e2d\u7684\u540d\u8a5e\u4ee5\u53ca\u6240\u4f34\u96a8\u7684\u8cc7\u6599\u9805\u76ee</li> <li>\u6355\u6349\u65e2\u6709\u7cfb\u7d71, \u73fe\u884c\u7a0b\u5e8f, \u65e2\u6709\u7684\u5831\u8868\u53ca\u8868\u55ae\u4e2d\u7684\u76f8\u95dc\u8cc7\u8a0a </li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_8","title":"\u4f7f\u7528\u6848\u4f8b","text":"<p>\u6558\u8ff0\u5167\u5bb9\u61c9\u7d00\u9304 - \u4f7f\u7528\u6848\u4f8b\u5982\u4f55\u958b\u59cb - \u4f7f\u7528\u6848\u4f8b\u5982\u4f55\u7d50\u675f - \u4f7f\u7528\u8005\u5982\u4f55\u8207\u7cfb\u7d71\u4e92\u52d5     - \u4e92\u52d5\u904e\u7a0b\u4e2d\u6709\u4ec0\u9ebc\u6a23\u7684\u8a0a\u606f\u4ea4\u63db     - \u4e92\u52d5\u884c\u70ba\u7684\u6b63\u5e38\u904e\u7a0b\u4ee5\u53ca\u5176\u4ed6\u6216\u662f\u4f8b\u5916\u7684\u904e\u7a0b         - ==\u60c5\u7bc0==\u662f\u6307\u4f7f\u7528\u6848\u4f8b\u7684\u67d0\u55ae\u4e00\u57f7\u884c\u8def\u5f91</p> <p>:::warning \u4e0d\u8981\u5728\u63cf\u8ff0\u4e2d\u8ac7\u8ad6\u8a2d\u8a08\u7d30\u7bc0\u6216\u662f\u7279\u5b9a\u7684\u5be6\u4f5c\u65b9\u6cd5 :::</p> <p>\u8209\u4f8b: ==\u7cfb\u7d71\u986f\u793a\u7522\u54c1\u76ee\u9304\u7d66\u4f7f\u7528\u8005==, \u9019\u6bb5\u63cf\u8ff0\u4e26\u6c92\u6709\u63d0\u5230\u5982\u4f55\u986f\u793a, \u986f\u793a\u5728\u54ea\u88e1, \u683c\u5f0f, \u5982\u4f55\u5132\u5b58\u7522\u54c1\u76ee\u9304\u7684\u8cc7\u6599...\u7b49</p>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_9","title":"\u6d3b\u52d5\u5716","text":"<ul> <li>\u5851\u6a21\u51fa\u7cfb\u7d71\u5c64\u7d1a\u7684\u8655\u7406\u908f\u8f2f\u6216\u662f\u57f7\u884c\u7a0b\u5e8f</li> <li>\u5e6b\u52a9\u6211\u5011\u767c\u73fe\u6c92\u627e\u5230\u7684\u4f8b\u5916\u8def\u5f91<ul> <li>\u5c08\u6ce8\u5728\u6bcf\u4e00\u500b\u6d3b\u52d5\u4e26\u627e\u5c0b\u6709\u53ef\u80fd\u767c\u751f\u7684\u72c0\u6cc1</li> </ul> </li> <li> <p>\u6aa2\u9a57\u4f7f\u7528\u6848\u4f8b\u63cf\u8ff0\u7684\u6b63\u78ba\u6027</p> </li> <li> <p>[UML]\u5b78\u7fd2\u7b46\u8a18-\u6d3b\u52d5\u5716\u578b(Activity Diagrams)</p> </li> </ul>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_10","title":"\u975c\u614b\u89c0\u9ede","text":"<p>\u5206\u6790\u6982\u5ff5\u7684\u7d44\u6210\u95dc\u4fc2\u548c\u7d50\u69cb\u95dc\u4fc2</p>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_11","title":"\u985e\u5225\u5716","text":"<ul> <li>\u3010UML\u3011Class Diagram \u985e\u5225\u5716</li> </ul>"},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_12","title":"\u6982\u5ff5\u6a21\u578b","text":""},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_13","title":"\u52d5\u614b\u89c0\u9ede","text":""},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_14","title":"\u72c0\u614b\u5716","text":""},{"location":"hackmd/%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91%E7%B3%BB%E7%B5%B1%E5%88%86%E6%9E%90%E8%88%87%E8%A8%AD%E8%A8%88/#_15","title":"\u4f48\u7f72\u89c0\u9ede","text":""},{"location":"hackmd/%E7%A1%AC%E9%AB%94%E6%A6%82%E5%BF%B5/","title":"\u786c\u9ad4\u6982\u5ff5","text":"<ul> <li>PCIe\uff08\u4e00\uff09 \u2014\u2014 \u57fa\u7840\u6982\u5ff5\u4e0e\u8bbe\u5907\u6811 | Soul Orbit</li> <li>PCIe\uff08\u4e8c\uff09 \u2014\u2014 \u914d\u7f6e\u7a7a\u95f4 | Soul Orbit</li> <li>PCIe\uff08\u4e09\uff09\u2014\u2014 PCIe\u534f\u8bae\u6808\uff0c\u4e8b\u52a1\u5c42\u548c\u6570\u636e\u94fe\u8def\u5c42 | Soul Orbit</li> <li>PCIe\uff08\u56db\uff09\u2014\u2014 \u7269\u7406\u5c42 | Soul Orbit</li> <li>Driver and Firmware</li> <li>BIOS\u548cCPLD\u7684\u5dee\u7570\u662f\u4ec0\u9ebc</li> </ul>"},{"location":"hackmd/%E7%A8%8B%E5%BC%8F%E6%9C%AC%E8%B3%AA/","title":"\u7a0b\u5f0f\u672c\u8cea","text":""},{"location":"hackmd/%E7%A8%8B%E5%BC%8F%E6%9C%AC%E8%B3%AA/#_2","title":"\u8cc7\u8a0a\u79d1\u6280\u7684\u672c\u8cea","text":"<ul> <li>\u8a08\u7b97 compute<ul> <li>\u91cf\u5316</li> <li>\u5224\u65b7\u908f\u8f2f(\u5132\u5b58\uff0c\u696d\u52d9\u908f\u8f2f)</li> </ul> </li> <li>\u5132\u5b58 storage<ul> <li>persistent </li> <li>long-term memory</li> <li>\u67d0\u500b\u6642\u9593\u9ede\u7684\u72c0\u614b<ul> <li>Time Machine \u7684\u5099\u4efd\u63d0\u6848</li> </ul> </li> <li>\u6ce8\u610f\u4e8b\u9805<ul> <li>\u8981\u8a18\u4f4f\u4ec0\u9ebc</li> <li>\u600e\u9ebc\u8a18(\u7d50\u69cb, \u683c\u5f0f, \u5b58\u53d6)</li> <li>\u8a18\u591a\u4e45</li> </ul> </li> </ul> </li> <li>\u50b3\u8f38 communicate <ul> <li>\u6e9d\u901a\u65b9\u5f0f</li> <li>\u4ecb\u9762</li> <li>\u8cc7\u6599\u4ea4\u63db</li> </ul> </li> <li>\u696d\u52d9\u908f\u8f2f(\u4eba\u985e\u898f\u5247\uff0c\u81ea\u7136\u898f\u5247)<ul> <li>\u89e3\u6c7a\u4eba\u985e\u554f\u984c<ul> <li>\u7522\u54c1\u7d93\u7406\u96fb\u5546\u898f\u5283\u5be6\u9304\uff0c\u89e3\u69cb\u7d9c\u5408\u6027\u96fb\u5546\u5168\u7dad\u5ea6\u898f\u5283\u5fc3\u6cd5</li> <li>Rules Engine \u898f\u5247\u5f15\u64ce</li> </ul> </li> <li>\u89e3\u6c7a\u8a08\u7b97\u6a5f\u672c\u8eab\u7684\u554f\u984c<ul> <li>\u6211\u505a\u7cfb\u7edf\u67b6\u69cb\u7684\u4e00\u4e9b\u539f\u5247</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/%E7%A8%8B%E5%BC%8F%E6%9C%AC%E8%B3%AA/#_3","title":"\u6ce8\u610f\u4e8b\u9805","text":"<p>\u9806\u5e8f order \u7bc4\u570d scope \u6e9d\u901a\u65b9\u5f0f communication</p>"},{"location":"hackmd/%E7%A8%8B%E5%BC%8F%E6%9C%AC%E8%B3%AA/#_4","title":"\u62bd\u8c61\u5316","text":""},{"location":"hackmd/%E7%A8%8B%E5%BC%8F%E6%9C%AC%E8%B3%AA/#_5","title":"\u7de8\u78bc","text":"<ul> <li>Unicode Normalization \u6587\u5b57\u6a19\u6e96\u5316</li> <li>\u83dc\u96de\u6293\u87f2: Url \u8b8a\u5f97\u602a\u602a\u7684\uff1f\u4f60\u53ef\u80fd\u662f\u96f6\u5bec\u7a7a\u683c\uff08ZWSP\uff09\u7684\u53d7\u5bb3\u8005\uff01 | \u4f0a\u679c\u7684\u6c92\u4eba\u770b\u7b46\u8a18\u672c</li> </ul>"},{"location":"hackmd/%E7%A8%8B%E5%BC%8F%E6%9C%AC%E8%B3%AA/#_6","title":"\u6a21\u7d44\u5316","text":"<p>Python modulation programming    - log   - businesses definition data     - enum     - exceptions   - config data     - credential protection function    - data source accessor      - database     - cache     - vendor api   - response</p>"},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/","title":"\u7cfb\u7d71\u7684\u50f9\u503c","text":"<p>\u7bc0\u7701\u6642\u9593\u3001\u7cbe\u529b \u5f97\u5230\u6a02\u8da3\u3001\u6210\u9577 \u6eff\u8db3\u617e\u671b\u3001\u9700\u6c42</p> <p>\u6b63\u78ba\u4e14\u6709\u6548\u7387\u7684\u8cc7\u6599\u4ea4\u63db(\u5132\u5b58\u548c\u8a08\u7b97)</p> <p>\u8edf\u9ad4\u5de5\u5177\u662f\u7522\u54c1, Dropbox \u8edf\u9ad4\u5de5\u5177\u662f\u5e73\u53f0, Pinkoi, Uber \u8edf\u9ad4\u5de5\u5177\u662f\u8f14\u52a9\u7ba1\u7406</p>"},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/#_2","title":"\u4f60\u4f7f\u7528\u8cc7\u8a0a\u79d1\u6280\u89e3\u6c7a\u554f\u984c\u9084\u662f\u88fd\u9020\u66f4\u591a\u554f\u984c","text":"<p>\u8655\u7406\u554f\u984c - TonyQ \u53f0\u7063\u5927\u8eca\u968a - \u53f0\u9435\u6625\u7bc0\u8a02\u7968\u7db2\u9801\u9806\u66a2 \u71b1\u9580\u6642\u6bb520\u5206\u552e\u5b8c - Finfo-\u81f4\u529b\u65bc\u6d88\u9664\u6240\u6709\u8cb7\u4fdd\u96aa\u7684\u4e0d\u6109\u5feb\u8207\u9ebb\u7169\u4e8b   - Finfo\u4fdd\u8cbb\u8a66\u7b97   - \u58fd\u96aa|\u6709\u4e9b\u6642\u5019, \u7e3d\u662f\u4f86\u4e0d\u53ca\u8aaa\u518d\u898b - \u9ad8\u9435\u5047\u671f, \u5728KKdays\u8a02\u7684\u611f\u89ba\u548c\u5728\u5b98\u7db2\u8a02(\u4e0d\u77e5\u539f\u56e0\u7684\u9a57\u8b49\u932f\u8aa4) - excalidraw - \u6b50\u967d\u7acb\u4e2d\u73ed\u89aa\u6703\u7528Line\u81ea\u52d5\u56de\u5fa9 - \u9ede\u5b50\u4ecd\u7136\u91cd\u8981 / idea still count   - \u5275\u4f5c\u8005\u7684\u5d1b\u8d77 - \u5beb\u7a0b\u5f0f - \u65cb\u8f49\u62cd\u8ce3 Carousell Transactional Service\u4e4b\u7522\u54c1\u67b6\u69cb\u6f14\u9032     - \u5728\u65cb\u8f49\u62cd\u8ce3 Carousell \u4e00\u5e74\u770b\u5230\u7684\u5f8c\u7aef\u67b6\u69cb\u3001\u6311\u6230\u8207\u751f\u6d3b - How I accidentally built a Podcast API business - When users never use the features they asked for - \u8ac7 POS \u8a2d\u8a08\u80cc\u5f8c\u7684\u539f\u5247 - GitHub \u642d\u914d\u5feb\u6377\u6307\u4ee4\uff0c\u81ea\u52d5\u7d00\u9304\u6bcf\u5929\u5f97\u8d77\u5e8a\u6642\u9593 - \u70ba\u4ec0\u9ebc\u4f60\u53ef\u80fd\u4e0d\u9700\u8981intercom\uff1f\u6f5b\u5728\u7684\u6210\u672c\u8207\u66ff\u4ee3\u65b9\u6848 - \u4e0d\u53ea\u514b\u670d\u75ab\u60c5\u56f0\u5883\u66f4\u958b\u5275\u65b0\u5546\u6a21\uff0cIT\u52a9KKday\u8f49\u578bB2B\u5e73\u81fa\u5546 | iThome - \u5982\u4f55\u5728\u6709\u9650\u8cc7\u6e90\u4e0b\u5be6\u73fe\u5341\u5e74\u7684\u5f8c\u7aef\u670d\u52d9\u6f14\u9032 - Speaker Deck - \u5343\u4eba\u5e73\u81fa\u5de5\u7a0b\u7149\u6210\u8a18 | iThome     - \u3010SRE\u5de5\u7a0b\u4e3b\u7ba14\u5e74\u5be6\u6230\u9996\u5ea6\u5728\u81fa\u5206\u4eab\u3011Zalando\u5343\u4eba\u5e73\u81fa\u5de5\u7a0b\u6f14\u5316\u6b77\u7a0b\u5927\u516c\u958bPart 1 | iThome     - \u8b8a\u9769\u73fe\u5834\uff1a\u6211\u5728Zalando\u5b78\u5230\u7684\u7b2c\u4e00\u5802\u8ab2 | iThome         - &gt; \u6280\u8853\u672c\u8eab\u6c92\u6709\u50f9\u503c\uff01\u9664\u975e\u6280\u8853\u5e6b\u52a9\u4eba\u5011\u5b8c\u6210\u4efb\u52d9\uff0c\u624d\u80fd\u5f9e\u4efb\u52d9\u505a\u5230\u591a\u597d\uff0c\u770b\u51fa\u6280\u8853\u7684\u50f9\u503c         - &gt; \u60f3\u8981\u5f9eZalando\u6280\u8853\u8b8a\u9769\u7684\u6f14\u5316\u7d93\u9a57\u4e2d\u53d6\u7d93\uff0c\u95dc\u9375\u4e0d\u662f\u770bZalando\u9078\u64c7\u4e86\u4ec0\u9ebc\u6280\u8853\uff0c\u800c\u662f\u8981\u770bZalando\u5728\u300c\u4ec0\u9ebc\u6642\u9593\u300d\u9078\u64c7\u4e86\u4ec0\u9ebc\u6280\u8853\u3002Zalando\u5728\u4e0d\u540c\u767c\u5c55\u968e\u6bb5\uff0c\u5404\u6709\u4e0d\u540c\u696d\u52d9\u9762\u548c\u5de5\u7a0b\u9762\u7684\u8003\u91cf\u3002 - \u3010\u8b6f\u5236\u3011Ness Labs \u5c08\u8a2a Heptabase \u806f\u5408\u5275\u59cb\u4eba Alan Chan | \u69ff\u5448Goidea     - Heptabase Public Roadmap | Heptabase Public Wiki     - \u5927\u591a\u6578\u4eba\u53ea\u60f3\u627e\u5230\u4e00\u4e2a\u500b\u958b\u7bb1\u5373\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5927\u591a\u6578\u4eba\u4e26\u4e0d\u95dc\u5fc3\u4f60\u5728\u7cfb\u7edf\u4e2d\u5f15\u5165\u7684\u6240\u6709\u6982\u5ff5\u548c\u529f\u80fd\u3002\u800c\u4e14\uff0c\u4e0d\u7ba1\u4f60\u7684\u6280\u8853\u6709\u591a\u597d\uff0c\u5982\u679c\u6ca1\u6709\u591a\u5c11\u4eba\u4f7f\u7528\uff0c\u4f60\u6700\u7ec8\u4e5f\u6703\u4e00\u4e8b\u7121\u6210     - \u5982\u679c\u4f60\u8a8d\u70ba\u81ea\u5df1\u53ea\u77e5\u9053\u5e7e\u4ef6\u4e8b\u60c5\uff0c\u90a3\u9ebc\u4f60\u53ef\u4ee5\u5148\u8a2d\u8a08\u4e00\u500b\u80fd\u5f88\u597d\u5730\u8655\u7406\u9019\u5e7e\u4ef6\u4e8b\u60c5\u7684\u7cfb\u7d71\uff0c\u7136\u5f8c\u5c07\u5176\u6295\u5165\u4f7f\u7528\uff0c\u770b\u770b\u4eba\u5011\u662f\u5982\u4f55\u4f7f\u7528\u5b83\u7684\uff0c\u5f9e\u800c\u7372\u5f97\u66f4\u591a\u95dc\u65bc\u4eba\u5011\u5982\u4f55\u5de5\u4f5c\u7684\u77e5\u8b58\uff0c\u4e26\u5229\u7528\u9019\u4e9b\u77e5\u8b58\u4f86\u767c\u5c55\u4f60\u7684\u7cfb\u7d71\uff0c\u4ee5\u9069\u61c9\u66f4\u591a\u7684\u529f\u80fd\uff0c\u540c\u6642\u517c\u9867\u53ef\u7528\u6027\u3002 - \u95dc\u65bcSSO\u670d\u52d9\u7684DB\u7fa4\u96c6\u7bc0\u9ede\u8abf\u6574\u8a2d\u5b9a\u7d93\u9a57\u9019\u4ef6\u4e8b | \u53c8LAG\u96a8\u6027\u7b46\u8a18 - Firstory\u4e0d\u6015\u6bcf\u6708PB\u7d1a\u6d41\u91cf\uff0c\u56db\u5e74\u7df4\u6210\u5718\u968aFinOps\u601d\u7dad | iThome - \u7b2c\u516d\u5c46\u53f0\u7a4d\u96fb\u6821\u5712\u9ed1\u5ba2\u677e 2025 TSMC IT CareerHack - n8n     - [AI \u81ea\u52d5\u5316] \u7528 n8n \u505a\u5237\u5361\u6d88\u8cbb\u8a18\u9304\uff08\u5bcc\u90a6\u3001\u570b\u6cf0\u3001\u532f\u8c50\uff09     - n8n \u57fa\u790e\u5165\u9580\u73ed - GitHub - opensource4you/readme: \u6e90\u4f86\u9069\u4f60\u7684\u5404\u7a2e\u6587\u7ae0\u3001\u91d1\u53e5\u3001\u516b\u5366\u548c\u6587\u5b57\u5099\u4efd     - \u7d66\u5b78\u5f1f\u59b9\u7684\u77fd\u8c37 AI / Software \u6307\u5357</p> <p>\u5ef6\u4f38\u8207\u88fd\u9020\u96e3\u4ee5\u8655\u7406\u7684\u554f\u984c - \u5357\u5c71\u4eba\u58fd\u6848\u4f8b - \u7f8e\u806f\u793e\u5c0e\u5165SAP - \u7576\u4f60\u60f3\u5916\u5305\u5beb\u500b\u7a0b\u5f0f\uff0c\u8981\u5982\u4f55\u4fdd\u8b77\u81ea\u5df1 - Project from Hell | Project Failures     - \u5730\u7344\u5c08\u6848\u5f8c\u7e8c\u8ffd\u8e64 | \u5931\u6557\u5c08\u6848\u5927\u5168 | annotated by Jimmy     - https://x.com/rambler_zero/status/1922661251034821023?t=nkFGFQwRKbLWLzFoXIsU2g</p>"},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/#_3","title":"\u771f\u5be6\u4e16\u754c\u5be6\u969b\u9700\u6c42","text":""},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/#pos","title":"POS\u7cfb\u7d71\u8f49\u79fb\u81f3\u53e6\u4e00\u53f0","text":"<p>\u4e86\u89e3\u672c\u4f86\u6a5f\u53f0\u7684\u72c0\u6cc1 10\u5e74 \u9470\u5319 Win XP \u786c\u789f Intel(R) N10/ICH7 Family Serial ATA Storage Controller - 27C0 Drivers Download for Windows 10, 8.1, 7, Vista, XP</p>"},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/#_4","title":"\u89c0\u5bdf\u89d2\u5ea6","text":"<p>\u6b63\u78ba, \u901f\u5ea6, \u5b89\u5168, \u6210\u672c</p>"},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/#_5","title":"\u5916\u5305","text":"<ul> <li>\u7576\u4f60\u60f3\u5916\u5305\u5beb\u500b\u7a0b\u5f0f\uff0c\u8981\u5982\u4f55\u4fdd\u8b77\u81ea\u5df1</li> </ul>"},{"location":"hackmd/%E7%B3%BB%E7%B5%B1%E7%9A%84%E5%83%B9%E5%80%BC/#_6","title":"\u5176\u4ed6","text":"<ul> <li>\u8df3\u812b\u5efa\u69cb\u9677\u9631\uff1f\u50f9\u503c\u4ea4\u63db\u7cfb\u7d71 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>\u7522\u51fa(Output)\u3001\u7d50\u679c(Outcome)\u8207\u5efa\u69cb\u9677\u9631 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>\u57f9\u990a\u7b56\u7565\u6027\u601d\u7dad\u7684\u524d\u7f6e\u689d\u4ef6\uff1a\u91d0\u6e05\u7522\u54c1\u3001\u670d\u52d9\u3001\u5c08\u6848\u7684\u5dee\u7570 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>\u96f6\u552e\u696d\u7684\u5168\u901a\u8def\u9818\u57df\u5730\u5716</li> </ul>"},{"location":"hackmd/%E7%B5%B1%E8%A8%88%E5%9C%96%E8%A1%A8%E7%9A%84%E8%A1%A8%E9%81%94%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AF%84%E5%9C%8D/","title":"\u7d71\u8a08\u5716\u8868\u7684\u8868\u9054\u65b9\u5f0f\u4ee5\u53ca\u4f7f\u7528\u7684\u7bc4\u570d","text":"<p>line char -&gt; \u8da8\u52e2 Pie \u6bd4\u4f8b% -&gt; top n Bar \u5be6\u969b\u7684\u6578\u5b57 -&gt; top n table -&gt; log gauge -&gt; \u9580\u6abb\u503c \u6578\u5b57 -&gt; \u55ae\u4e00\u7684\u503c</p> <p>\u9577\u689d\u5716, \u76f4\u65b9\u5716, \u6298\u7dda\u5716, \u5713\u9905\u5716</p>"},{"location":"hackmd/%E7%B5%B1%E8%A8%88%E5%9C%96%E8%A1%A8%E7%9A%84%E8%A1%A8%E9%81%94%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AF%84%E5%9C%8D/#_1","title":"\u53c3\u8003","text":"<ul> <li>\u4e0d\u540c\u5716\u8868\u4e0d\u540c\u4f7f\u7528\u6642\u6a5f\uff0c\u6211\u7684\u5831\u8868\u9069\u5408\u4ec0\u9ebc\u5716\u5f62</li> <li>\u8cc7\u6599\u6574\u7406\u8207\u7d71\u8a08\u7684\u7c21\u4ecb</li> <li>\u4ec0\u9ebc\u662f\u7d71\u8a08\u5716\uff1f\u6709\u54ea\u4e9b\u5e38\u7528\u7684\u7d71\u8a08\u5716</li> <li>Getting started with Grafana dashboard design</li> <li>\u641e\u7b80\u5355\u7684\u6570\u636e\u5206\u6790\u6216\u53ef\u89c6\u5316</li> <li>View layer: Metabase - \u5716\u8868/\u8996\u89ba\u5316 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/","title":"\u865b\u64ec\u6a5f\u5668","text":"<ul> <li>\u5728\u5bb6\u6a5f\u5668\u5b78\u7fd2\uff1f\u7528\u865b\u64ec\u5316\u6280\u8853\u5be6\u73fe\u500b\u4eba AI \u74b0\u5883\u914d\u7f6e :: \u7b2c 12 \u5c46 iThome \u9435\u4eba\u8cfd\\</li> <li>Vagrant \u4ecb\u7d39\u8207\u57fa\u672c\u64cd\u4f5c - HackMD</li> <li>[\u9592\u804a] \u8981\u7d44VM\u53caVT-D, IOMMU\u529f\u80fd\u7684\u9ebb\u7169\u5148\u770b\u4e00\u4e0b - \u770b\u677f PC_Shopping - \u6279\u8e22\u8e22\u5be6\u696d\u574a</li> <li>GitHub - boxcutter/kvm: Packer templates for producing KVM images written in HCL</li> <li>\u958b\u6e90\u4f3a\u670d\u5668\u865b\u64ec\u5316\u5e73\u53f0\uff1aProxmox VE (\u4e00) - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929<ul> <li>\u7a81\u7834\u56f0\u5883\uff1a\u4f01\u696d\u958b\u6e90\u865b\u64ec\u5316\u7ba1\u7406\u5e73\u53f0</li> </ul> </li> <li>iOS\u7248UTM APP\u7684\u4f7f\u7528\u65b9\u6cd5 \\~ iPhone\u5b89\u88ddWindows\u865b\u64ec\u6a5f \u00b7 Ivon\u7684\u90e8\u843d\u683c<ul> <li>iOS\u8dd1Docker\u5bb9\u5668\uff0cUTM\u5b89\u88dd64\u4f4d\u5143Alpine Linux\u865b\u64ec\u6a5f\uff06\u5171\u4eab\u8cc7\u6599\u593e \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul> </li> <li>KVM\u865b\u64ec\u6a5f\u7576\u4e3b\u529b\u6a5f\u4f7f\u7528\uff0cLinux + Windows\u7684\u865b\u64ec\u6a5f\u591a\u958b\u5be6\u8e10 \u00b7 Ivon\u7684\u90e8\u843d\u683c</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#kvm","title":"KVM","text":"<ul> <li>KVM</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#virual-box","title":"Virual Box","text":"<ul> <li>VirtualBox networking explained</li> <li>\u589e\u52a0 VirtualBox \u865b\u64ec\u786c\u789f\u5927\u5c0f\uff08\u4f7f\u7528 GParted \u8abf\u6574\u5206\u5272\u5340\uff09 - G. T. Wang</li> <li>[FIX] Error 'No Such Partition - Grub Rescue' - Appuals.com</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#hype-v","title":"Hype V","text":"<ul> <li>windows 10 - Hyper-V VM won't boot from Cd, error: \"unsigned image's hash is not allowed\" - Super User</li> <li>windows subsystem for linux - Connect Hyper-V VM from WSL (Ubuntu) - Stack Overflow</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#network","title":"Network","text":"<ul> <li>\u8b93 Windows 10 \u7b46\u96fb\u5728\u900f\u904e Wi-Fi \u8207 DHCP \u4e0a\u7db2\u6642\u4e5f\u53ef\u4ee5\u6b63\u5e38\u4f7f\u7528 Hyper-V | The Will Will Web<ul> <li>Run like Hell: Hyper-V on Windows 8: External virtual switches do not work - Howto connect a virtual host to the internet</li> <li>Run like Hell: Hyper-V: Howto configure NAT for virtual machines</li> </ul> </li> <li>Day-07 Hyper-V 3.0\u5be6\u6230\u4e4b- \u865b\u64ec\u4ea4\u63db\u5668 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>Hyper-V\u900f\u904e\u5167\u90e8\u7db2\u8def\u5efa\u7acb\u672c\u6a5f\u8207\u865b\u64ec\u6a5f\u4e4b\u9593\u7684\u9023\u7dda - HackMD</li> </ul> <p>eth0 is from <code>internal type hype-v switch</code></p> <pre><code>root@homelab:~# ip a\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000\n    link/ether 00:15:5d:00:8b:10 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.137.2/24 brd 192.168.137.255 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::215:5dff:fe00:8b10/64 scope link\n       valid_lft forever preferred_lft forever\nroot@homelab:~#\n</code></pre> <pre><code># This is the network config written by 'subiquity'\nnetwork:\n  ethernets:\n    eth0:\n      addresses: [ 192.168.137.2/24 ]\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\n      routes:\n      - to: default\n        via: 192.168.137.1\n  version: 2\n</code></pre>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#rocky-linux","title":"Rocky Linux","text":"<ul> <li>Installing Rocky Linux on Windows 10 (Pro) Hyper-V | Patrick's Notebook</li> <li>Centos-8 EOL and Installation of Rocky Linux 8 on HyperV | in Urdu | - YouTube</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#vmware","title":"VMware","text":"<ul> <li>\u5c0f\u5c0f\u65b0\u624b\u5b78\u7fd2\u865b\u64ec\u5316\u4e4b\u5fc3\u5f97 :: 2022 iThome \u9435\u4eba\u8cfd<ul> <li>VMware ESXi 6.5.0 \u5b89\u88dd\u8aaa\u660e Step-By-Step Installation - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul> </li> <li>VMware Cloud Foundation Documentation<ul> <li>VMware Cloud Foundation Overview</li> <li>Deployment Overview of VMware Cloud Foundation<ul> <li>Deploy VMware Cloud Builder Appliance</li> <li>Deploying VMware Cloud Foundation - YouTube</li> </ul> </li> </ul> </li> <li>vmw-t1-3.pdf</li> <li>GitHub - lamw/vcf-automated-lab-deployment: Automated VMware Cloud Foundation Lab Deployment</li> <li>VMware Cloud Foundation 4 \u90e8\u7f72 Part I \u2013 \u555f\u7528 Management Domain | EH's Freedom Blog</li> <li>Mastering VMware Cloud Foundation Architecture: A Beginner's Guide to Building Your Own Cloud - YouTube<ul> <li>What is VMware Cloud Builder? - YouTube</li> <li>VMware Cloud Foundation Deployment Parameters Spreadsheet, DONE RIGHT! - YouTube</li> </ul> </li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#esxi","title":"ESXi","text":"<ul> <li>Boot the ESXi Installer by Using PXE and TFTP<ul> <li>Sample DHCP Configurations</li> <li>About the Default ks.cfg Installation Script</li> <li>Enter Boot Options to Run an Installation or Upgrade Script<ul> <li>Boot Options</li> </ul> </li> </ul> </li> <li>Boot the ESXi Installer by Using iPXE and HTTP</li> <li>Boot the ESXi Installer by Using Native UEFI HTTP</li> <li>Create an Installer ISO Image with a Custom Installation or Upgrade Script</li> <li>VMware ESXi \u5b89\u88dd\u548c\u8a2d\u5b9a - VMware vSphere 7.0</li> <li>Intel NUC 13 \u4f7f\u7528 PXE \u5b89\u88dd ESXi 8</li> <li>Using partedUtil command line disk partitioning utility on ESXi</li> <li>How to use HTTP Boot for VMWare VM UEFI client - Server Fault<ul> <li>VMware 7 UEFI does not support HTTP Boot</li> </ul> </li> <li>kickstart<ul> <li>Installation and Upgrade Script Commands<ul> <li>Appendix\u00a0B.\u00a0Kickstart commands and options reference | Red Hat Product Documentation<ul> <li>--device link which specifies the first interface with its link in the up state</li> </ul> </li> </ul> </li> <li>Scripted ESXi Installation<ul> <li>The installation script must be stored in a location that the host can access by HTTP, HTTPS, FTP, NFS, CDROM, or USB. You can PXE boot the ESXi installer or boot it from a CD/DVD or USB drive.</li> </ul> </li> <li>esxi kickstart examples \u00b7 GitHub</li> <li>ESXi Kickstart file \u00b7 GitHub</li> <li>Cisco Intersight Help Center<ul> <li>intersight-BMaaS/os-install/kickstart-samples/Esxi_SecureBoot.txt at main \u00b7 CiscoDevNet/intersight-BMaaS \u00b7 GitHub</li> </ul> </li> <li>enable SSH<ul> <li>Using ESXi Kickstart %firstboot with Secure Boot</li> <li>automation - how to enable vmware esxi 5 ssh interface - Super User</li> </ul> </li> </ul> </li> <li>\u6587\u5b57\u4ecb\u9762ESXCLI\u547d\u4ee4\u5de5\u5177\u3000vSphere\u65e5\u5e38\u7dad\u904b\u5982\u864e\u6dfb\u7ffc | \u7db2\u7ba1\u4eba<ul> <li>ESXCLI Reference | ESXCLI Command Reference</li> </ul> </li> <li>Changing the hostname of an ESXi host</li> <li>Using ESXi Shell in ESXi</li> <li>\u53d6\u6d88 ESXi \u5bc6\u78bc\u8907\u96dc\u5ea6\u653f\u7b56 \u00bb \u79d1\u4e00\u96fb\u8166</li> <li>Configure the VMware Host Client User Interface Session Timeout</li> <li>Changing an ESXi host root password</li> <li>debug<ul> <li>TFTP setup for ESXi 6.7 UEFI deployment - tftp error 24 - Virtualization - Spiceworks Community</li> </ul> </li> <li>hardware<ul> <li>esxi lsblk is not working</li> </ul> </li> <li>ansible<ul> <li>python - No module named pyVim - Stack Overflow</li> <li>Ansible \"msg\": \"Unable to connect to vCenter or ESXi API at IP on TCP/443: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)\" - Stack Overflow</li> </ul> </li> <li>ESXi \u7684 ESXi Shell \u548c SSH \u670d\u52d9\u5dee\u5225<ul> <li>ESXi shell: <code>Ctl + Alt + F2</code></li> <li>DCUI: <code>Alt + F2</code><ul> <li>exit 'Ctl + C'</li> </ul> </li> </ul> </li> <li>passwordless<ul> <li>Establish passwordless ssh between ubuntu and ESX host. | by Giridharaprasad | Medium</li> <li>ESXi keeps prompting for password after adding ssh public key to authorized_keys - Stack Overflow</li> </ul> </li> <li>log<ul> <li>ESXi Log File Locations</li> </ul> </li> <li>time<ul> <li>Configure Network Time Protocol (NTP)</li> </ul> </li> </ul> <pre><code>bootstate=0\ntitle=Loading ESXi installer\ntimeout=5\nprefix=ESXi-8.0U1a-21813344\nkernel=b.b00\nkernelopt=runweasel cdromBoot ks=http://172.19.57.10:8000/ks.cfg\nmodules=jumpstrt.gz --- useropts.gz --- features.gz --- k.b00 --- uc_intel.b00 --- uc_amd.b00 --- uc_hygon.b00 --- procfs.b00 --- vmx.v00 --- vim.v00 --- tpm.v00 --- sb.v00 --- s.v00 --- atlantic.v00 --- bcm_mpi3.v00 --- bnxtnet.v00 --- bnxtroce.v00 --- brcmfcoe.v00 --- cndi_igc.v00 --- dwi2c.v00 --- elxiscsi.v00 --- elxnet.v00 --- i40en.v00 --- iavmd.v00 --- icen.v00 --- igbn.v00 --- intelgpi.v00 --- ionic_en.v00 --- irdman.v00 --- iser.v00 --- ixgben.v00 --- lpfc.v00 --- lpnic.v00 --- lsi_mr3.v00 --- lsi_msgp.v00 --- lsi_msgp.v01 --- lsi_msgp.v02 --- mtip32xx.v00 --- ne1000.v00 --- nenic.v00 --- nfnic.v00 --- nhpsa.v00 --- nmlx5_co.v00 --- nmlx5_rd.v00 --- ntg3.v00 --- nvme_pci.v00 --- nvmerdma.v00 --- nvmetcp.v00 --- nvmxnet3.v00 --- nvmxnet3.v01 --- pvscsi.v00 --- qcnic.v00 --- qedentv.v00 --- qedrntv.v00 --- qfle3.v00 --- qfle3f.v00 --- qfle3i.v00 --- qflge.v00 --- rdmahl.v00 --- rste.v00 --- sfvmk.v00 --- smartpqi.v00 --- vmkata.v00 --- vmksdhci.v00 --- vmkusb.v00 --- vmw_ahci.v00 --- bmcal.v00 --- clusters.v00 --- crx.v00 --- elx_esx_.v00 --- btldr.v00 --- esx_dvfi.v00 --- esx_ui.v00 --- esxupdt.v00 --- tpmesxup.v00 --- weaselin.v00 --- esxio_co.v00 --- loadesx.v00 --- lsuv2_hp.v00 --- lsuv2_in.v00 --- lsuv2_ls.v00 --- lsuv2_nv.v00 --- lsuv2_oe.v00 --- lsuv2_oe.v01 --- lsuv2_sm.v00 --- native_m.v00 --- qlnative.v00 --- trx.v00 --- vdfs.v00 --- vds_vsip.v00 --- vmware_e.v00 --- vsan.v00 --- vsanheal.v00 --- vsanmgmt.v00 --- tools.t00 --- xorg.v00 --- gc.v00 --- imgdb.tgz --- basemisc.tgz --- resvibs.tgz --- esxiodpt.tgz --- imgpayld.tgz\nbuild=8.0.1-0.10.21813344\nupdated=0\n</code></pre> <pre><code># Sample ESXi Kickstart Configuration File\n\n# Accept the VMware End User License Agreement\nvmaccepteula\n\n# Set the root password\n# rootpw foo@123\n\n# Set the root password (same as above to ensure it's set)\n# rootpw --iscrypted &lt;hashed_password_here&gt;\n# $6$GPVUoEU3hYSLkzZJ$9IuUjJm1L6AbBj3KMeU9gMYbcCObyq.C5fmUMTJMjf1lIbMLfIDVkIWbOD0CkaJYGmgSSzlcvjlDRg8l66x0J1 from openssl passwd -6 \"Super123\"\nrootpw --iscrypted $6$GPVUoEU3hYSLkzZJ$9IuUjJm1L6AbBj3KMeU9gMYbcCObyq.C5fmUMTJMjf1lIbMLfIDVkIWbOD0CkaJYGmgSSzlcvjlDRg8l66x0J1\n\n# Install ESXi on the first local disk (overwrite VMFS partitions)\ninstall --firstdisk --overwritevmfs\n\n# Set the keyboard layout\n# keyboard 'US'\n\n# Set the root password (same as above to ensure it's set)\n# rootpw --iscrypted &lt;encrypted_password_here&gt;\n\n# Network configuration\n# network --bootproto=static --device=vmnic0 --ip=172.19.57.50 --netmask=255.255.255.0 --gateway=172.19.57.1 --nameserver=8.8.8.8 --hostname=jeffesxi1\nnetwork --bootproto=dhcp --device=vmnic0\n# Reboot the server after installation\nreboot\n\n# Enable SSH and allow remote SSH access\n%firstboot --interpreter=busybox\n\n# Enable SSH session for remote access\nvim-cmd hostsvc/enable_ssh\n\n# Start the SSH service\nvim-cmd hostsvc/start_ssh\n\n# Enable ESXi Shell\nvim-cmd hostsvc/enable_esx_shell\nvim-cmd hostsvc/start_esx_shell\n\n#Disable firewall\n#esxcli network firewall set --enabled false\n\n# Configure firewall to allow SSH access\n# esxcli network firewall ruleset set -e true -r sshClient\n\n\n# Enable the SSH server firewall ruleset\nesxcli network firewall ruleset set --enabled=true --ruleset-id=sshServer\n\n# Enable the SSH client firewall ruleset\nesxcli network firewall ruleset set --enabled=true --ruleset-id=sshClient\n\n# End of firstboot commands\n</code></pre>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#ansible","title":"ansible","text":"<ul> <li>Community.Vmware \u2014 Ansible Community Documentation</li> </ul> <p>``` yml= - name: validate ansible to esxi   hosts: all   gather_facts: yes   vars:     - esxi_server: 192.168.1.102     - esxi_username: root     - esxi_password: myp@ssw0rd   tasks:     - name: Provide information about a standalone ESXi server       community.vmware.vmware_about_info:         hostname: '{{ esxi_server }}'         username: '{{ esxi_username }}'         password: '{{ esxi_password }}'         validate_certs: no       delegate_to: localhost       register: esxi_about_info     - name: Gather vmware host facts       community.vmware.vmware_host_facts:         hostname: \"{{ esxi_server }}\"         username: \"{{ esxi_username }}\"         password: \"{{ esxi_password }}\"         validate_certs: no       register: host_facts       delegate_to: localhost     - name: tset ssh       shell:         cmd: \"esxcli\"       register: esxcli_result         #- name: change host name - method 1 - Update the TCP/IP stack configuration of the default         #  community.vmware.vmware_host_tcpip_stacks:         #    hostname: \"{{ esxi_server }}\"         #    username: \"{{ esxi_username }}\"         #    password: \"{{ esxi_password }}\"         #    validate_certs: no         #    esxi_hostname: \"sanfrancisco-a-esxi.example.com\"         #    default:         #      hostname: \"abc\"         #      domain: example.com         #      preferred_dns: 8.8.8.8         #      search_domains:         #        - example.com         #  delegate_to: localhost     - name: change host name - method 2       shell:         cmd: \"esxcli system hostname set --host=sanfrancisco-a-esxi\"       register: esxcli_change_hostname_result     - name: show info       debug:         msg:           - \"{{ esxi_about_info }}\"           - \"{{ host_facts }}\"           - \"{{ esxcli_result }}\"             #- \"{{ esxcli_change_hostname_result }}\"           - \"{{ ansible_facts }}\" <pre><code>#### Network\n- [VMware ESXi 7 : Add VMkernel NIC : Server World](https://www.server-world.info/en/note?os=ESXi_7&amp;p=network&amp;f=4)\n- [Link state up or down for a vmnic interface on ESXi](https://knowledge.broadcom.com/external/article/324496/link-state-up-or-down-for-a-vmnic-interf.html)\n- [Configuring vSwitch or vNetwork Distributed Switch from the command line in ESXi/ESX](https://knowledge.broadcom.com/external/article/326175)\n    - [VMware ESXi 7 : Add Uplink : Server World](https://www.server-world.info/en/note?os=ESXi_7&amp;p=network&amp;f=3)\n- [Restarting the Management agents in ESXi](https://knowledge.broadcom.com/external/article/320280/restarting-the-management-agents-in-esxi.html)\n    - [How to restart the ESXi management network via command-line?](https://williamlam.com/2014/01/how-to-restart-esxi-management-network.html)\n- [How to enable or disable vmnic on esxi - Hasan Altin](https://www.hasanaltin.com/how-to-enable-or-disable-vmnic-on-esxi/)\n- [Network Access to Your ESXi\u00a0Host](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.esxi.install.doc/GUID-6219B45D-036F-4D38-B6A2-BF404A3304EC.html)\n</code></pre> esxcli network nic list esxcli network nic up -n vmnic1 esxcli network nic down -n vmnic1 esxcli network ip interface set -e false -i vmk0; esxcli network ip interface set -e true -i vmk0 esxcli network vswitch standard uplink add --vswitch-name vSwitch0 --uplink-name vmnic1 esxcli network vswitch standard uplink remove --vswitch-name vSwitch0 --uplink-name vmnic0 esxcli network ip interface ipv4 get esxcli network vswitch standard list <pre><code>\n</code></pre> esxcli network nic list | awk '{print $1,$5,$8}' | grep vmnic</p> <p>esxcli network nic list | awk '{print $1,$5,$8}' | grep vmnic | while read -r interface status mac_address; do echo \"Interface: $interface\"     echo \"Status: $status\"     echo \"MAC Address: $mac_address\"     echo \"\"     if [ \"$status\" = \"Down\" ]; then         echo \"Status is Down. Executing command: network vswitch standard uplink remove --vswitch-name vSwitch0 --uplink-name $interface\"         network vswitch standard uplink remove --vswitch-name vSwitch0 --uplink-name \"$interface\"     fi done <pre><code>Currently, can not get the ip after the operations\nthe problem maybe the mac address will not be changed successfully after changing uplink\n</code></pre> esxcli network ip interface ipv4 get esxcli network ip interface list esxcli network vswitch standard list esxcli network vswitch standard uplink add --vswitch-name vSwitch0 --uplink-name vmnic3 esxcli network vswitch standard uplink remove --vswitch-name vSwitch0 --uplink-name vmnic0 esxcli network vswitch standard list esxcli network ip interface set -e false -i vmk0; esxcli network ip interface set -e true -i vmk0 esxcli network ip interface ipv4 get esxcli network ip interface list ```</p>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#vgpu","title":"vGPU","text":"<ul> <li>Nvidia doc<ul> <li>NVIDIA Virtual GPU (vGPU): VMware Deployment Guide (Latest) - NVIDIA Docs<ul> <li>Installing and configuring the NVIDIA vGPU Manager VIB - NVIDIA Docs<ul> <li>NVIDIA Virtual GPU (vGPU) Software - NVIDIA Docs<ul> <li>Supported Products - NVIDIA Docs</li> <li>Virtual GPU Certified Servers | NVIDIA GRID</li> </ul> </li> <li>Enabling the NVIDIA vGPU</li> <li>Installing the NVIDIA vGPU Driver: Linux</li> <li>Changing the Default Graphics Type in VMWare vSphere 6.5 and Later<ul> <li>Configuring Host Graphics</li> <li>install_nvidia_vgpu_vsphere.md \u00b7 GitHub<ul> <li>esxcli graphics host get</li> <li>esxcli graphics host set --default-type SharedPassthru</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Installing and configuring the NVIDIA VIB on ESXi</li> <li>Installing and configuring the NVIDIA vGPU Manager VIB \u2014 Omniverse Deployment latest documentation</li> <li>VMware ESXi\u5b89\u88c5NVIDIA GPU\u663e\u5361\u786c\u4ef6\u9a71\u52a8\u548c\u914d\u7f6evGPU\uff08\u542bGRID \u9a71\u52a8\u4e0b\u8f7d\uff09 \u2013 \u4e01\u8f89\u535a\u5ba2</li> <li>\u5728 ESXi \u4e3b\u6a5f\u4e0a\u5b89\u88dd\u9069\u7528\u65bc NVIDIA GRID vGPU \u5716\u5f62\u5361\u7684 VIB<ul> <li>Xorg service is no longer required for Nvidia vGPU profiles in vSphere 7.0 U1</li> <li>\u5728 Linux \u865b\u64ec\u6a5f\u5668\u4e0a\u91dd\u5c0d vGPU \u8a2d\u5b9a\u5171\u7528 PCI \u88dd\u7f6e</li> <li>\u5b89\u88dd NVIDIA GRID vGPU \u986f\u793a\u9a45\u52d5\u7a0b\u5f0f</li> </ul> </li> <li>\u4f7f\u7528\u500b\u5225 VIB \u66f4\u65b0\u4e3b\u6a5f</li> <li>\u5f9e\u4e3b\u6a5f\u79fb\u9664 VIB</li> <li>Do i Need vCenter Server for Nvidia vGPU - Virtualization - Spiceworks Community</li> <li>debug<ul> <li>Nvidia GPU RTX A4000 vgpu service not starting | Proxmox Support Forum<ul> <li>BIOS Secure Boot</li> </ul> </li> <li>VHI 6.0 update in case of Nvidia Virtual GPU drivers installed \u2013 Virtuozzo Technical Support</li> <li>VMWare ESXi 8 Update 1 + nVIDIA 15.2 vGPU Driver = A FAIL : r/virtualization<ul> <li>BIOS SR-IOV</li> <li>Single Root IO Virtualization (SR-IOV) - NVIDIA Docs</li> </ul> </li> <li>FAQ Entry | Online Support | Support - Super Micro Computer, Inc.<ul> <li>patch too old</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#pci-passthrough","title":"PCI Passthrough","text":"<ul> <li>GPU Device in PCI Passthrough<ul> <li>Configuring VMDirectPath I/O pass-through devices on a VMware ESX or VMware ESXi host</li> <li>Release Notes :: NVIDIA AI Enterprise Documentation<ul> <li>Some GPUs require 64 GB or more of MMIO space. When a vGPU on a GPU that requires 64 GB or more of MMIO space is assigned to a VM with 32 GB or more of memory on ESXi</li> </ul> </li> </ul> </li> <li>VMware ESXi DirectPath I/O \u76f4\u901aGPU\u5361\u7ed9\u865a\u62df\u673a\u4f7f\u7528 \u2013 \u4e01\u8f89\u535a\u5ba2</li> <li>\u555f\u7528 GPU \u900f\u901a - IBM \u8aaa\u660e\u6587\u4ef6</li> <li>esxcli<ul> <li>VMware ESXi 7 : GPU Passthrough : Server World</li> </ul> </li> <li>How to pass through a GPU in VMware ESXi 8 - YouTube</li> <li>GitHub - JeffersonQin/esxi-pci-passthrough-auto-enable: Solve the problem that the PCI passthrough deactivates after reboot, also hard to reset due to UI flickering</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#plug-in","title":"Plug-in","text":"<ul> <li>Enhancing vCenter Capabilities with VMware vCenter Plugins: A Deep Dive - Calsoft Blog</li> <li>Developing Remote Plug-ins with the vSphere Client SDK<ul> <li>Deployment Requirements for a vSphere Client Remote Plug-in</li> </ul> </li> <li>Getting Started with Remote Plug-Ins in the vSphere Client (vSphere 7.0) - YouTube</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#vcenter","title":"vCenter","text":"<ul> <li>Mount Iso Image | vSphere Automation API<ul> <li>Creating and Using Content Library - VMware vSphere Blog</li> <li>Is it possible to Move Datastore ISO files to content library ? | VMware vSphere</li> <li>impossible</li> </ul> </li> <li>Vm Hardware Cdrom APIs | vSphere Automation API</li> <li>Vm Hardware Boot APIs | vSphere Automation API</li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#vlcm","title":"vLCM","text":"<ul> <li>About vSphere Lifecycle Manager<ul> <li>Introducing vSphere Lifecycle Management (vLCM) pdf<ul> <li>What is the difference between vLCM Desired Image vs vLCM Baseline? pdf</li> <li>What Is the Difference Between vSphere Lifecycle Manager Images and Baselines</li> </ul> </li> <li>\u5099\u4efd\u5b89\u88dd\u79fb\u8f49\u8a2d\u5b9a\u7167\u6b65\u4f86\u3000vSphere 7\u7121\u75db\u5347\u7d1a(\u4e0b) | \u7db2\u7ba1\u4eba</li> <li>Day 30 \u88dc\u5145 - iT \u90a6\u5e6b\u5fd9</li> <li>Using vSphere Lifecycle Manager (vLCM) image-based updates for vSphere 7.0 Update 2a ESXi updates - YouTube</li> </ul> </li> <li>Create<ul> <li>DMware.nl \u00bb Create a custom ESXi ISO Image through vSphere LifeCycle Manager #</li> <li>Creating custom ESXi images using vSphere Lifecycle Manager (vLCM) UI and PowerCLI cmdlets for vSphere 8</li> </ul> </li> <li>Bulletins, Components, Add-Ons, and ESXi Base Images<ul> <li>\"A general system error occurred: Failed to download VIB(s): Error: HTTP Error Code: 403\", vLCM fails to download the ESXi patches and images from online repositories</li> </ul> </li> <li>API<ul> <li>Retrieving detailed vSphere Lifecycle Manager (vLCM) Image information from vSphere Cluster using PowerCLI</li> </ul> </li> <li>Hardware Support Manager (HSM)<ul> <li>Firmware lifecycle made simple with vSphere Lifecycle Manager - VMware Cloud Foundation (VCF) Blog</li> </ul> </li> </ul>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#vibs","title":"VIBs","text":"<ul> <li>Bulletins, Components, Add-Ons, and ESXi Base Images</li> <li>VMware vSphere downloads, OEM custom images, patches and addons in the Broadcom Support Portal<ul> <li>VMware ESXi Images for HPE Servers | HPE EUROPE</li> <li>Readme of Fujitsu Custom Image - facts-fj-vmware-esxi7-customized-image-en.pdf</li> </ul> </li> </ul> <p>A VIB is a software package that contains metadata and a binary payload, which represents the actual piece of software to be installed on ESXi. </p> <p>\u985e\u4f3cdeb, rpm</p> <p>the VIB is the smallest installable software unit that VMware and other software vendors ship.</p> <p>vSphere Lifecycle Manager does not consume and work with individual VIBs. VIBs must be further packaged into a higher-level construct.</p>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#bulletins","title":"Bulletins","text":"<p>The bulletin is a grouping of one or more VIBs. Bulletins are defined within the metadata of the VIB.</p> <p>You use bulletins, and not individual VIBs, to create vSphere Lifecycle Manager baselines, which you attach to inventory objects and use to update and upgrade ESXi hosts.</p>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#components","title":"Components","text":"<p>Starting with vSphere 7.0, the component becomes the basic packaging construct for VIBs. VMware, OEMs, and third-party software providers now deliver software in the form of components.</p> <p>The component is a bulletin with additional metadata specifying the name and the version of the component. </p> <p>Unlike the bulletin, the component is a logical grouping of VIBs that provides you with a complete and visible feature upon installation.</p> <p>VMware bundles components together into fully functional and bootable ESXi base images. OEMs bundle components together into vendor add-ons. Third-party software vendors create and ship software, for example drivers or adapters, as independent components.</p>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#base-images","title":"Base Images","text":"<ul> <li>Online and Offline Depots</li> </ul> <p>The base image is an ESXi image that VMware provides with every release of ESXi</p> <p>The base image is a collection of components that is complete and can boot up a server.</p>"},{"location":"hackmd/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8/#vendor-add-ons","title":"Vendor Add-Ons","text":"<p>OEMs pack one or multiple components into a unit called an add-on.</p> <p>You use vendor add-ons to customize an ESXi image with OEM content and drivers.</p> <p>The combination of a vendor add-on and an ESXi base image is practically identical to an OEM-provided custom image.</p> <p>Starting with vSphere 7.0, in addition to custom ISO images and offline bundles, OEMs can release ZIP files that contain only the vendor add-on, that is, the delta between the custom image and the ESXi base image.</p>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/","title":"\u8cc7\u6599\u5eab\u7dad\u904b","text":"<ul> <li>Copy MySQL Database From One Server To Another Remote Server</li> <li>How to export database from Amazon RDS MySQL instance to local instance?</li> <li>MySQL: ignore errors when importing?</li> <li>Migrating MySQL Databases with No Downtime \u2013 For Non-DBAs<ul> <li>AWS RDS<ul> <li>Importing data to an Amazon RDS MySQL or MariaDB DB instance with reduced downtime</li> </ul> </li> </ul> </li> <li>SHOW BINARY LOGS Statement</li> <li>mysqlbinlog \u8cc7\u6599\u5eab\u8655\u7406\u4e8c\u9032\u5236\u65e5\u8a8c\u6a94\u6848\u7684\u5be6\u7528\u5de5\u5177</li> <li>MySQL Connection Handling and Scaling</li> <li>HA<ul> <li>Galera Cluster for MySQL Multi-master Replication - \u5c0f\u60e1\u9b54 - AppleBOY</li> <li>MariaDB Galera cluster : Best practices | iThome</li> </ul> </li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/#user","title":"User","text":"<p>How to Create MySQL Users Accounts and Grant Privileges</p> <p>create a user that can connect from any host, use the '%' wildcard</p> <pre><code>CREATE USER 'newuser'@'%' IDENTIFIED BY 'user_password';\n</code></pre> <p>random password ```bash= openssl rand -base64 12 <pre><code>### Grant Privileges\nGrand all privileges to a user account over a specific database\n\n``` sql\nGRANT ALL PRIVILEGES ON database_name.* TO 'database_user'@'localhost';\n</code></pre></p> <pre><code>SHOW GRANTS\n\nSHOW GRANTS FOR 'database_user'@'localhost';\n</code></pre>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/#create-database","title":"Create Database","text":"<ul> <li>MySQL \u7de8\u78bc\u6311\u9078\u8207\u5dee\u7570\u6bd4\u8f03utf8_bin vs. utf8_unicode_ci vs. utf8_general_ci</li> </ul> <p><code>``sql= CREATE SCHEMA IF NOT EXISTS</code>database_name` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci  <pre><code>## 1040 Too many connections\nTo get total number of concurrent connections allowed\n```mysql=\nSHOW VARIABLES LIKE \"max_connections\";\n</code></pre></p> <p>how many concurrent connections are being used currently ```mysql= SHOW STATUS LIKE \"max_used_connections\"; <pre><code>- [Monitoring used connections on mysql to debug 'too many connections'](https://stackoverflow.com/questions/2453308/monitoring-used-connections-on-mysql-to-debug-too-many-connections)\n- [Max_used_connections](https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html#statvar_Max_used_connections)\n\n```mysql=\nshow variables like \"%max_connections%\";\nshow global status like \"%Max_used%\";\nshow status like \"%thread%\";\n</code></pre></p> <ul> <li>Why does max_used_connections status not get refreshed automatically once it reaches max_connections, even though the Threads_connected falls down</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/#mysqldump","title":"mysqldump","text":"<p>Skip certain tables with mysqldump</p> <p>migration.conf <pre><code>database=test\nprev=bar.internal.foo.com\nprev_bar=bar.internal.foo.com\nnext=bar-rds.internal.foo.com\nuser=foo\ndump_dir=dump\n</code></pre></p> <p>db_migration.sh ``` bash=</p>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/#binbash","title":"!/bin/bash","text":"<p>env=$1 source migration.conf read -sp 'Please input database password: ' db_password</p> <p>if [[ ! -d ${dump_dir} ]]; then     mkdir ${dump_dir} else     rm -rf ${dump_dir}     mkdir ${dump_dir} fi</p> <p>SECONDS=0 source create_db.sh source test.sh duration=$SECONDS echo \"$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed.\" <pre><code>test.sh\n``` bash=\n#!/bin/bash\n\necho \"export score db $database start: \"$(date)\nmysqldump -h ${env}-${prev_scoredb} \\\n    -u ${user} \\\n    -p${db_password} \\\n    --databases $database \\\n    --single-transaction \\\n    --order-by-primary \\\n    --result-file ${dump_dir}/${database}_SCORE_DB.sql\necho \"export $database done: \"$(date)\n\n\necho \"import score db $database start: \"$(date)\nmysql -h ${env}-${next} -u ${user} -p${db_password} -f &lt; ${dump_dir}/${database}_SCORE_DB.sql\necho \"import $database done: \"$(date)\n</code></pre></p>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/#change-character-set","title":"Change character set","text":"<ul> <li>(MySQL 5.7.19 AWS RDS) how to change table column character set without locking</li> <li>is this a safe way to change character set on a MySQL table to UTF-8</li> <li>which is the better way to change the character set for huge data tables</li> <li>Changing character set of MySQL tables</li> <li>How to change the CHARACTER SET (and COLLATION) throughout a database?</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E5%BA%AB%E7%B6%AD%E9%81%8B/#cluster","title":"Cluster","text":"<ul> <li>\u5982\u4f55\u5efa\u7f6e MariaDb Galera Cluster. mariadb galera cluster \u5efa\u7f6e\u6559\u5b78 | by Gary Ng | Medium</li> <li>MariaDB Galera Cluster - MariaDB Knowledge Base<ul> <li>Getting Started with MariaDB Galera Cluster - MariaDB Knowledge Base</li> </ul> </li> <li>Galera Cluster for MySQL Multi-master Replication - \u5c0f\u60e1\u9b54 - AppleBOY</li> <li>2.8.\u00a0Replicating MariaDB with Galera Red Hat Enterprise Linux 9 | Red Hat Customer Portal</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/","title":"\u8cc7\u6599\u6a21\u578b(Data Modeling)","text":"<p>\u8a2d\u8a08 =&gt; ER models, \u6b63\u898f\u5316, Primary Key, \u6642\u5340, Index \u4e00\u81f4\u6027 =&gt; ACID, Race condition, isolation level Backup Migration</p> <ul> <li>Query<ul> <li>SQL queries don't start with SELECT</li> <li>Most memorable graphic Figure 4-3. SELECT phases from @Apress \"The Definitive Guide to SQLite\"<ul> <li></li> </ul> </li> <li>SQL Lesson 12: Order of execution of a Query</li> <li>[MySQL / MariaDB] \u512a\u5316\u67e5\u8a62\u8a9e\u53e5OFFSET\u8d8a\u5927\u6642\u9593\u8d8a\u4e45\u7684\u554f\u984c</li> <li>\u300aEffective SQL\u300b\u8b80\u5f8c\u5206\u4eab | Yuanchieh's Blog</li> <li>How to Calculate the Difference Between Two Rows in SQL</li> <li>:star:The Best Medium-Hard Data Analyst SQL Interview Questions</li> <li>mysql - Select from same table as an Insert or Update - Stack Overflow</li> <li>Mysql inconsistent number of rows count(*) vs table.table_rows in information_schema - Stack Overflow<ul> <li>MySQL :: MySQL 8.0 Reference Manual :: 15.23 InnoDB Restrictions and Limitations<ul> <li> <p>SHOW TABLE STATUS does not provide accurate statistics for InnoDB tables except for the physical size reserved by the table. The row count is only a rough estimate used in SQL optimization.</p> </li> <li> <p>InnoDB does not keep an internal count of rows in a table because concurrent transactions might \u201csee\u201d different numbers of rows at the same time. Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction.</p> </li> <li>MySQL :: MySQL 8.0 Reference Manual :: 12.20.1 Aggregate Function Descriptions</li> </ul> </li> </ul> </li> <li>Is offset pagination dead? Why cursor pagination is taking over | by Megan C. | UX Collective</li> </ul> </li> <li>Query(Advence)<ul> <li>SQL \u7a97\u53e3\u51fd\u6578 Window Function\uff1a\u4e09\u5927\u61c9\u7528\u5feb\u901f\u6559\u5b78 \u2022 \u597d\u8c6a\u7b46\u8a18</li> <li>Transformation layer: SQL \u9032\u968e\u8a9e\u6cd5 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul> </li> <li>ACID<ul> <li>:star:\u8cc7\u6599\u5eab\u5c64\u7684\u96e3\u984c - \u55ae\u6a5f\u300e \u6545\u969c \u300f\u4e00\u81f4\u6027\u96e3\u984c<ul> <li>\u5929\u707d\u4eba\u798d(\u6545\u969c\u8207\u4f75\u767c)\u7684\u751f\u5b58\u4e4b\u9053</li> <li>ADI =&gt; C</li> </ul> </li> <li>:star:select...for update\u518dinsert\u9020\u6210deadlock\u7684\u9677\u9631</li> <li>\u5982\u4f55\u7406\u89e3\u8cc7\u6599\u5eab\u4e2d\u4e00\u81f4\u6027\u7684\u6982\u5ff5</li> <li>Transaction \u7b46\u8a18</li> <li>\u8cc7\u6599\u5eab\u9ad8\u4f75\u767c\u7684\u7b2c\u4e00\u6b65 \u2014 \u4e8b\u52d9\u9694\u96e2</li> <li>Lock<ul> <li>:star: \u6dfa\u8ac7MySQL\u8207PostgreSQL\u662f\u5982\u4f55\u8655\u7406\u4f75\u767c\u6bd4\u8f03 - AndyWu's Notes</li> <li>\u3010MySQL\u3011Lock \u8207 Index \u95dc\u4fc2\u548c Deadlock \u5206\u6790 | Yuanchieh's Blog</li> <li>\u9396( Lock )\u7684\u4ecb\u7d39\u8207\u6b7b\u9396\u5206\u6790. \u8a0e\u8ad6 mysql \u9694\u96e2\u7d1a\u5225\u5be6\u73fe\u6642\uff0c\u5e38\u4ee5\u9396\u7684\u985e\u578b \uff08 \u8b80\u9396/\u5beb\u9396 \uff09| by Team PHP Laravel | TWJOIN \u54f2\u715c\u79d1\u6280</li> </ul> </li> </ul> </li> <li>Design(Practice)<ul> <li>:star:Modeling Game Player Data with Amazon DynamoDB</li> <li>:star:Database Design in Practical Examples</li> <li>:star:Database schema templates</li> <li>:star:Redis Best Practices \u2013 Introduction and patterns</li> <li>Database Design of a Restaurant Management System from user story to relational Model</li> <li>Entity Relationship Modeling Examples</li> </ul> </li> <li>Design(Basic)<ul> <li>:star:Database Structure and Design Tutorial</li> <li>11 important database designing rules which I follow</li> <li>Get started with SQL: Plan and design a database</li> <li>A Quick-Start Tutorial on Relational Database Design</li> <li>Data Modeling 101</li> <li>Relational Database Schema Design Overview</li> <li>Pros and Cons of Database Normalization</li> <li>The Process of Database Refactoring: Strategies for Improving Database Quality</li> <li>Introduction | The Analytics Setup Guidebook</li> <li>:star:\u3010\u7522\u54c1\u3011\u4f7f\u7528 ER \u5716\u7de8\u5beb\u6e05\u6670\u7684\u8edf\u9ad4\u898f\u683c\uff5csomeone.tw | blog.someone.tw<ul> <li>Stack Overflow Data | Kaggle</li> </ul> </li> <li>Payment Service(\u4e00): \u4ed8\u6b3e\u6d41\u7a0b - Hjoru's sharing - Medium</li> <li>\u6b63\u898f\u5316<ul> <li>:star:\u6dfa\u8ac7\u8cc7\u6599\u5eab\u6b63\u898f\u5316<ul> <li>\u4f8b\u5b50\u8209\u5f97\u5f88\u68d2!</li> </ul> </li> <li>:star:Good RDB Design with the Concept of Normal Forms<ul> <li>\u8ab0\u662f\u8001\u5927, \u62c6\u5718</li> </ul> </li> <li>30-17\u4e4bMongoDB\u7684\u8a2d\u8a08---\u6b63\u898f\u8207\u53cd\u6b63\u898f\u5316\u7684\u6230\u722d</li> </ul> </li> <li>MySQL<ul> <li>:star:MySQL\u958b\u767c\u5be6\u6230<ul> <li>\u95dc\u65bc\u6642\u5340(\u4e00)</li> <li>\u95dc\u65bc\u6642\u5340(\u4e8c)</li> </ul> </li> <li>\u8cc7\u6599\u5eab\u5c64\u7684\u512a\u5316 - \u8868\u7684\u8a2d\u8a08</li> <li>\u6dfa\u8ac7MySQL\u8868\u7d50\u69cb\u8a2d\u8a08</li> <li>MySQL DB Schema \u8a2d\u8a08\u539f\u5247</li> </ul> </li> <li>Guide<ul> <li>SQL\u6a23\u5f0f\u6307\u5357 \u00b7 SQL Style Guide</li> <li>Enterprise Data Models</li> </ul> </li> </ul> </li> <li>Design(Advance)<ul> <li>\u6070\u5982\u5176\u5206\u7684 MySQL \u8a2d\u8a08\u6280\u5de7 - Modern Web 2016</li> <li>\u8cc7\u6599\u5eab\u7d22\u5f15\u6578\u64da\u7d50\u69cb\u53ca\u4e3b\u9375\u8a2d\u8a08</li> <li>Don't Do This - PostgreSQL wiki</li> <li>fulltext search<ul> <li>\u7528mysql fulltext search\u5efa\u7acb\u7c21\u6613\u641c\u5c0b\u5f15\u64ce</li> <li>Performance of LIKE queries on multmillion row tables, MySQL</li> <li>What is Full Text Search vs LIKE</li> <li>MySQL FULLTEXT query issue</li> <li>Elastic search full text vs mysql full text?</li> </ul> </li> <li>partition<ul> <li>MySQL Partitioning \u512a\u5316\u4e4b\u8def. 17 APP \u4e0a\u7dda\u81f3\u4eca\u5df2\u7d93\u597d\u5e7e\u5e74\u4e86\uff0c\u96a8\u8457\u6642\u9593\u904e\u53bb DB\u2026 | by Jiazhen | 17LIVE Tech Insight | Medium</li> <li>Day.24 \u63d0\u5347\u5927\u6578\u64da\u8cc7\u6599\u7ba1\u7406 - \u8cc7\u6599\u8868\u5206\u5340 ( MYSQL Partition) - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>\u90a3\u4e9b\u5728MySQL\u4e0a\u7684\u5206\u5340\u65b9\u5f0f \u2013 Peter \u5de5\u7a0b\u65e5\u8a8c</li> <li>What's MySQL partition</li> </ul> </li> <li>statistics<ul> <li>mysql - Database table structure for storing statistics data - Stack Overflow</li> </ul> </li> <li>bit mask relational database <ul> <li>sql - Storing Combinatorial Values in a MySQL database - Bit masking, foreign keys, junction tables, or what? - Stack Overflow</li> <li>patterns and practices - Advantages and disadvantages of using bit masks in database - Software Engineering Stack Exchange</li> <li>sql - Any disadvantages to bit flags in database columns? - Stack Overflow</li> <li>sql - Optimize mysql query to use index on a Bitwise where clause - Stack Overflow</li> <li>sql - MySQL doesn't use indexes when query over BIT field using bitwise functions - Stack Overflow</li> </ul> </li> <li>how to store tags in mysql<ul> <li>performance - Storing multiple tags on analytics database - Database Administrators Stack Exchange</li> <li>database design - SET or VARCHAR for list of tags in a MySQL photos table? - Database Administrators Stack Exchange</li> <li>mysql - SELECT items that has one or more specific TAGS - Database Administrators Stack Exchange</li> </ul> </li> <li>json field<ul> <li>How to search JSON array in MySQL? - Stack Overflow</li> <li>sql - MySQL How to Index a JSON array? - Stack Overflow</li> <li>MySQL :: MySQL 8.0 Reference Manual :: 13.1.15 CREATE INDEX Statement - Multi-Valued Indexes</li> <li>MySQL 8 split string by comma and convert it into JSON ARRAY - Stack Overflow</li> </ul> </li> <li>others<ul> <li>performance - SQL Database Schema Design For Large 3 Billion Relationship Database - Stack Overflow</li> <li>mysql - Database table with million of rows - Stack Overflow</li> <li>MySQL \u4e2d\u7684 temporary table (\u81e8\u6642\u8868) \u89c0\u5ff5 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>Decomposing Transactional Systems</li> </ul> </li> </ul> </li> <li>Migration<ul> <li>\u4e0d\u505c\u6a5f migration \u907f\u514d\u9396\u8868\u7684\u5e7e\u7a2e\u64cd\u4f5c</li> <li>Evolutionary Database Design</li> <li>Breaking Free From the ORM: Decoupling Database Migrations</li> <li>Decoupling database migrations from server startup: why and how</li> <li>\u8cc7\u6599\u5eab\u4e5f\u6709\u7248\u672c\u63a7\u5236 :: 2022 iThome \u9435\u4eba\u8cfd</li> <li>[MySQL] \u8cc7\u6599\u8868\u7d50\u69cb\u9077\u79fb\u7684\u597d\u5e6b\u624b pt-online-schema-change | \u5f9e\u5165\u9580\u5230\u653e\u68c4</li> <li>GitHub \u767c\u5c55\u51fa\u4f86\u7684 ALTER TABLE \u65b9\u5f0f \u2013 Gea-Suan Lin's BLOG</li> <li>Eventbrite \u7684 MySQL \u5347\u7d1a\u8a08\u756b \u2013 Gea-Suan Lin's BLOG</li> <li>PostgreSQL \u4e0a\u5c0d\u61c9 pt-online-schema-change \u7684\u5de5\u5177 pg-osc \u2013 Gea-Suan Lin's BLOG</li> <li>sql - ALTER TABLE without locking the table? - Stack Overflow</li> <li>Squashing Migrations</li> </ul> </li> <li>Error<ul> <li>mysql - Temporary table is full - Database Administrators Stack Exchange</li> </ul> </li> <li>Microsoft \u8cc7\u6599\u67b6\u69cb\u6307\u5357<ul> <li>\u7dda\u4e0a\u4ea4\u6613\u8655\u7406 OLTP</li> <li>\u7dda\u4e0a\u5206\u6790\u8655\u7406 OLAP</li> <li>\u975e\u95dc\u806f\u5f0f\u8cc7\u6599\u548c NoSQL</li> </ul> </li> <li>Race Condition<ul> <li>Real world<ul> <li>JPMorgan Chase</li> <li>Starbucks</li> </ul> </li> <li>github-race condition demo<ul> <li>kkent030315/race-condition-demonstrate</li> <li>CyCTW/Database Race Condition Testing Demo</li> <li>nsf/sqlrace</li> </ul> </li> <li>\u8907\u7fd2\u8cc7\u6599\u5eab\u7684 Isolation Level \u8207\u5716\u89e3\u4e94\u500b\u5e38\u898b\u7684 Race Conditions</li> <li>\u6dfa\u8ac7MySQL\u9694\u96e2\u5c64\u7d1a\u70baRR(\u53ef\u91cd\u5fa9\u8b80)\u6642\u4e0d\u80fd\u907f\u514dPhantom Read(\u5e7b\u8b80)</li> <li>\u5c0d\u65bc MySQL Repeatable Read Isolation \u5e38\u898b\u7684\u4e09\u500b\u8aa4\u89e3</li> <li>\u8cc7\u6599\u5eab\u4ea4\u6613\u7684 Isolation</li> <li>MySQL Deadlock \u554f\u984c\u6392\u67e5\u8207\u8655\u7406</li> <li>All you need to know about Database transaction concurrency control \u2014 locks, Isolation level, MVCC | by LORY | Sep, 2023 | Medium</li> <li>\u597d\u50cf\u8981\u9396\u4e00\u4e0b\u311f(\u60b2\u89c0\u9396\u3001\u6a02\u89c0\u9396) - HackMD</li> <li>\u4f7f\u7528Redis\u4f86\u9032\u884c\u5206\u6563\u5f0f\u9396 - HackMD</li> </ul> </li> <li>\u5b89\u5168<ul> <li>How SQL Injection attack works</li> </ul> </li> <li>\u4ea4\u63db<ul> <li>What is the Parquet File Format and Why You Should Use It</li> </ul> </li> <li>\u5de5\u5177<ul> <li>dbdiagram \u7b46\u8a18 - HackMD</li> </ul> </li> <li>High Availability<ul> <li>Galera Cluster for MySQL Multi-master Replication - \u5c0f\u60e1\u9b54 - AppleBOY</li> <li>\u5982\u4f55\u5efa\u7f6e MariaDb Galera Cluster. mariadb galera cluster \u5efa\u7f6e\u6559\u5b78 | by Gary Ng | Medium</li> <li>Galera Cluster\u771f\u7684\u6c92\u6709\u540c\u6b65\u5ef6\u9072\u55ce?- \u9032\u64ca\u7684\u7db2\u7ba1Jay</li> </ul> </li> <li>\u5176\u4ed6<ul> <li> - Tachunn Publication <li>17LIVE Next-Gen Database\u9078\u578b\u5206\u6790. \u5b8f\u89c0\u4e0a\u4f86\u770b\uff0c\u5404\u6642\u671f\u7684\u8cc7\u6599\u5eab\u4e26\u6c92\u6709\u5f37\u5f31\u4e4b\u5206\uff0c\u90fd\u662f\u70ba\u4e86\u6eff\u8db3\u7576\u524d\u6642\u4ee3\u9700\u6c42\u800c\u6f14\u9032\u7684\u578b\u614b\uff0c\u2026 | by Pink Yu | 17LIVE Tech Insight | Medium</li> <li>How to Efficiently Choose the Right Database for Your Applications</li> <li>Choosing between a relational database and a NoSQL database</li> <li>Relational Database Vs NoSQL: A Comprehensive Analysis</li> <li>RDBMS\u6536\u8cbb\u8ab2\u7a0b\u7528\u7684\u6559\u6750 - Triton Ho</li> <li>JSON in PostgreSQL\uff0c\u5efa\u8b70\u8ddf\u4e0d\u5efa\u8b70 - Rubin<ul> <li>https://www.youtube.com/watch?v=l5Z_cE6jGxA</li> </ul> </li> <li>\u8a72\u7528 MySQL \u6216 MongoDB\uff1f\u9078\u64c7\u8cc7\u6599\u5eab\u524d\u4f60\u8a72\u4e86\u89e3\u7684\u4e8b</li> <li>mysql add foreign key constraint referencing a view</li> <li>Database development mistakes made by application developers - Stack Overflow</li> <li>\u6dfa\u5165\u6dfa\u51fa MySQL Ep2 : \u6211\u7684 SQL \u600e\u9ebc\u57f7\u884c\u6211\u7684\u67e5\u8a62 | by vic | Medium</li> <li>MySQL Explain\u5206\u6790\u8207Index\u8a2d\u5b9a\u67e5\u8a62\u512a\u5316 | Yuanchieh's Blog</li> <li>MySQL\u6709\u4ec0\u4e48\u63a8\u8350\u7684\u5b66\u4e60\u4e66\u7c4d\uff1f - \u77e5\u4e4e</li> <li>\u5982\u4f55\u5f9e\u95dc\u806f\u5f0f\u8cc7\u6599\u5eab\u8f49\u578b</li> <li>\u4f7f\u7528 Docker Compose \u5efa\u7acb\u555f\u7528 X-Pack \u7684 Elasticsearch \u8207 Kibana - Yowko's Notes</li> <li>A 5 years+ tech lead said they shard a database to scale but then he failed to answer this question | by LORY | Medium</li> <li> - Tachunn Publication <li> - Tachunn Publication <li> - Tachunn Publication <li>DDIA \u9010\u7ae0\u7cbe\u8bfb</li> <li>\u7576\u4ee3\u8cc7\u6599\u5de5\u7a0b\u8207\u8cc7\u6599\u5206\u6790 :: 2023 iThome \u9435\u4eba\u8cfd</li> <li>\u80fd\u5920\u505a\u5230\u5e73\u884c\u904b\u7b97\u7684 ClickHouse Distributed Table Engine - AndyWu's Notes</li> <li>gitlab<ul> <li>\u95dc\u65bc GitLab \u7684 SQL \u8a2d\u8a08 \u2013 Gea-Suan Lin's BLOG</li> <li>My Notes on GitLab Postgres Schema Design \u2013 Shekhar Gulati</li> </ul> </li>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/#_1","title":"\u8a2d\u8a08","text":"<p>\u9700\u6c42 - \u5546\u696d - \u8cc7\u6599\u91cf\u7d1a - \u5b89\u5168</p> <p>\u6536\u96c6\u8207\u68b3\u7406\u8cc7\u8a0a - \u73fe\u5834\u4f7f\u7528\u7684\u4eba - \u73fe\u6709\u8868\u55ae(invoices, timesheets, surveys) - \u73fe\u6709\u8cc7\u6599\u7cfb\u7d71</p> <p>what kinds of data the database will include where that data comes from how it will be used</p> <p>ERD Primary Key Cardinality</p> <p>Index B+ Tree =&gt; \u53ea\u6709\u6700\u4e0b\u9762\u7684\u7bc0\u9ede\u6709\u8cc7\u6599\uff0c\u5176\u5b83\u4e0a\u9762\u7684\u7bc0\u9ede\u53ea\u5b58\u7d22\u5f15</p> <p>Clustered Index =&gt; \u5728innodb\u4e2d, \u5b83\u5c31\u662f\u9019\u4efd\u8cc7\u6599\u5be6\u969b\u4e0a\u5132\u5b58\u7684\u7d50\u69cb(B+ Tree)</p> <p>Secondary Index =&gt; \u53ef\u4ee5\u81ea\u884c\u5efa\u7acb\u7684\u7d22\u5f15, \u6700\u57fa\u672c\u4f7f\u7528 secondary Index \u7684\u6b65\u9a5f, \u81f3 secondary Index \u5c0b\u627e PK, \u518d\u81f3 clustered Index \u53d6\u5f97\u5b8c\u6574\u8cc7\u6599</p> <p>\u770b\u770b\u5019\u9078\u6b04\u4f4d\u7684\u57fa\u6578\u5927\u5c0f, \u57fa\u6578\u5c31\u662f\u6307\u9019\u500b\u6b04\u4f4d\u7684\u503c\u7684\u53ef\u80fd\u6027</p> <p><pre><code>SELECT COUNT(DISTINCT {field}/COUNT(*))\n</code></pre> \u4e00\u822c\u7d22\u5f15(\u8986\u84cb\u7d22\u5f15) \u9023\u5408\u7d22\u5f15 : \u5e38\u5e38\u9700\u8981\u8207\u5176\u5b83\u6b04\u4f4d\u4e00\u8d77\u67e5\u8a62\uff0c\u9069\u5408\u5efa\u7acb\u3002\u4f46\u662f\u8981\u6ce8\u610f\u5148\u5f8c\u9806\u5e8f\uff0c\u57fa\u672c\u6700\u5e38\u67e5\u8a62\u7684\u8207\u57fa\u6578\u9ad8\u7684\u9069\u5408\u653e\u6700\u5de6\u908a \u524d\u7db4\u7d22\u5f15 : \u9019\u7a2e\u5927\u81f4\u4e0a\u7528\u5728\u5982\u679c\u8981\u91dd\u5c0d\u67d0\u6bb5\u6587\u5b57\u9032\u884c\u524d\u7db4\u641c\u5c0b\u7684\u60c5\u6cc1</p>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/#keyword-search","title":"Keyword search","text":"<ul> <li>\u7528mysql fulltext search\u5efa\u7acb\u7c21\u6613\u641c\u5c0b\u5f15\u64ce</li> <li>Pattern Matching Queries vs. Full-Text Indexes</li> <li>What is Full Text Search vs LIKE</li> <li>Performance analysis of MySQL's FULLTEXT indexes and LIKE queries for full text search</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/#redis","title":"Redis","text":"<ul> <li>Redis Fundamental</li> <li>Redis Developer</li> <li>Redis Best Practices</li> <li>\u4f7f\u7528 Redis \u7576\u4f5c API Rate limit \u7684\u4e09\u7a2e\u65b9\u6cd5</li> <li>How to build a Rate Limiter using Redis</li> <li>Redis Lock (Redlock) \u5206\u6563\u5f0f lock \u539f\u7406\u5206\u6790\u8207\u5be6\u4f5c</li> <li>Finding non-expiring keys in Redis - Stack Overflow</li> <li>Redis Explained</li> <li>Redis \u8207\u4f5c\u8005 antirez \u7684\u6545\u4e8b | \u8edf\u9ad4\u8003\u53e4\u5b78\u5bb6</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/#elasticsearch","title":"ElasticSearch","text":"<ul> <li>Elasticsearch \u7cfb\u7d71\u4ecb\u7d39\u8207\u8a55\u4f30 | Yuanchieh's Blog</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/#hadoop-ecosystem","title":"Hadoop ecosystem","text":"<ul> <li>Hadoop ecosystem \u5de5\u5177\u7c21\u4ecb, \u5b89\u88dd\u6559\u5b78\u8207\u5404\u7a2e\u60c5\u5883\u4f7f\u7528 :: 2018 iT \u90a6\u5e6b\u5fd9\u9435\u4eba\u8cfd</li> <li>Day 15-HBase SQL\u5de5\u5177\u4ecb\u7d39 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>\u5feb\u901f\u5165\u9580\uff1aApache HBase \u8207 Apache Phoenix - Azure HDInsight | Microsoft Learn</li> <li>6\u5927\u4e3b\u6d41\u958b\u6e90SQL\u5f15\u64ce\u7e3d\u7d50\uff0c\u9059\u9059\u9818\u5148\u7684\u662f\u8ab0\uff1f | \u5e06\u8edf\u8edf\u9ad4</li> </ul>"},{"location":"hackmd/%E8%B3%87%E6%96%99%E6%A8%A1%E5%9E%8B%28Data%20Modeling%29/#dbeaver","title":"Dbeaver","text":"<ul> <li>How to create a connection from a template in CloudBeaver</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/","title":"\u8cc7\u8a0a\u5b89\u5168","text":"<ul> <li>Sanitize Your Inputs?</li> <li>The Basics of Web Application Security</li> <li>\u5206\u5e03\u5f0f\u7cfb\u7d71\u4e0b\u7684\u8a8d\u8b49\u8207\u6388\u6b0a</li> <li>\u9a57\u8b49\u8207\u6388\u6b0a\u7684\u5dee\u5225\uff0c\u6dfa\u8ac7 OAuth 2.0 \u8207 OpenID Connect<ul> <li>Understanding access tokens, refresh tokens, and ID tokens in OpenID Connect (OIDC) protocol \u00b7 Logto blog</li> <li>Differences between Kerberos, SAML, OAuth, and OpenID Connect (OIDC)</li> <li>https://chatgpt.com/share/681475a5-dd74-8009-85cb-3a49637a25f2</li> </ul> </li> <li>Day03 - \u3010\u5165\u9580\u7bc7\u3011\u6dfa\u8ac7\u8eab\u4efd\u9a57\u8b49\u8207\u6388\u6b0a</li> <li>\u7814\u7a76\u5fae\u670d\u52d9\u4e0b\u7684\u6388\u6b0a\u8a2d\u8a08 - Google Zanzibar \u8207 Open Policy Agent</li> <li>How does using an auth server for mobile app and not storing API keys on client add security</li> <li>Using Machine to Machine (M2M) Authorization<ul> <li>Client Credentials Flow<ul> <li>The OAuth 2.0 Authorization Framework<ul> <li>OAuth 2.0 Security Best Current Practice</li> </ul> </li> <li>RFC 6819: OAuth 2.0 Threat Model and Security Considerations - Threat: Obtaining Client Secrets</li> <li>What is the worst that can happen if your OAuth client secret is leaked<ul> <li>Protecting Apps with PKCE - OAuth 2.0 Simplified</li> <li>Authorization Code Flow with Proof Key for Code Exchange (PKCE)</li> <li>\u5982\u4f55\u900f\u904e Golang \u958b\u767c OAuth2 \u7684 PKCE - \u4ee5 LINE Login \u70ba\u4f8b</li> <li>Day18 - \u3010\u6982\u5ff5\u7bc7\u3011OAuth flows: PKCE - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> </ul> </li> <li>The Client ID and Secret - OAuth 2.0 Simplified</li> <li>The <code>client credentials grant</code> from OAuth 2.0 attempts to fulfill the need for these scenarios. </li> <li>In the client credentials grant, the client holds two pieces of information: the client ID and the client secret.</li> </ul> </li> <li>\u5f8c\u7aef\u5de5\u7a0b\u5e2b\u9762\u8a66\u8003\u4ec0\u9ebc \u2014 OAuth 2.0 - MyApollo</li> <li>\u5f8c\u7aef\u5de5\u7a0b\u5e2b\u9762\u8a66\u8003\u4ec0\u9ebc \u2014 \u5f9e SSO (Single Sign-On) \u5230 SAML 2.0 - MyApollo</li> </ul> </li> <li>Refresh Token Rotation</li> <li>PKI<ul> <li>\u8a8d\u8b58 PKI \u67b6\u69cb\u4e0b\u7684\u6578\u4f4d\u6191\u8b49\u683c\u5f0f\u8207\u6191\u8b49\u683c\u5f0f\u8f49\u63db\u7684\u5fc3\u5f97\u5206\u4eab | The Will Will Web</li> <li>What Are the Differences Between RSA, DSA, and ECC Encryption Algorithms?<ul> <li>The key size or bit length of public keys determines the strength of protection</li> <li>RSA encryption maximum data size<ul> <li>getting a IllegalBlockSizeException: Data must not be longer than 256 bytes when using rsa</li> </ul> </li> <li>RSA is only able to encrypt data to a maximum amount equal to your key size (2048 bits = 256 bytes), minus any padding and header data (11 bytes for PKCS#1 v1.5 padding).</li> <li>Difference Between RSA-OAEP and RSA-PKCS1.5<ul> <li>\u804a\u804a\u5bc6\u78bc\u5b78\u4e2d\u7684padding</li> </ul> </li> <li>What is RSA OAEP &amp; RSA PSS in simple terms</li> <li>Why can't I use RSA OAEP padding when encrypting with a private key?</li> </ul> </li> <li>Can we have multiple public keys with a single private key for RSA</li> <li>What is the difference between a certificate and a private key? - Information Security Stack Exchange</li> <li>Openssl Demo: Encrypting/Decrypting files using both Symmetric and Asymmetric Encryption</li> <li>cryptography - What is the actual value of a certificate fingerprint? - Information Security Stack Exchange</li> <li>Online Certificate Status Protocol - Wikipedia<ul> <li>\u3010\u8336\u5305\u5c04\u624b\u65e5\u8a18\u3011\u540c\u4e00\u7db2\u7ad9 Chrome \u700f\u89bd\u6b63\u5e38 IE \u5947\u6162-\u9ed1\u6697\u57f7\u884c\u7dd2</li> </ul> </li> <li>:star:\u6709\u5173 TLS/SSL \u8bc1\u4e66\u7684\u4e00\u5207 | \u5361\u74e6\u90a6\u5676\uff01</li> <li>:star:\u5f9e\u5be6\u52d9\u7d93\u9a57\u91cd\u65b0\u8a8d\u8b58 TLS | omegaatt</li> </ul> </li> <li>GPG<ul> <li>\u4f7f\u7528 GnuPG \u78ba\u4fdd\u50b3\u8f38\u91cd\u8981\u6a94\u6848\u6216\u6587\u4ef6\u7684\u904e\u7a0b\u80fd\u78ba\u4fdd\u6a5f\u5bc6\u6027\u8207\u5b8c\u6574\u6027 | The Will Will Web</li> <li>\u5982\u4f55\u50b3\u9001\u654f\u611f\u8cc7\u8a0a - GnuPG | CodingMan</li> <li>\u5bc6\u78bc\u7ba1\u7406\u5fc3\u5f97\u7b46\u8a18 \u00b7 \u7ffc\u4e4b\u90fd<ul> <li>YubiKey</li> </ul> </li> <li>\u7528 gpg \u6307\u4ee4\u52a0\u5bc6\u5e33\u865f\u5bc6\u78bc\uff0c\u5b89\u5fc3\u5171\u4eab\u6a5f\u654f\u8cc7\u8a0a - MyApollo</li> <li>Coding4Fun - \u6211\u7684 GPG \u91d1\u9470\u7d19\u672c\u5099\u4efd\u89e3\u6c7a\u65b9\u6848-\u9ed1\u6697\u57f7\u884c\u7dd2</li> </ul> </li> <li>Master password/key<ul> <li>How to remember / where to store master password? - Ask the Community / Archive - Bitwarden Community Forums</li> </ul> </li> <li>IOT Security<ul> <li>IoT device authentication options | Azure \u90e8\u843d\u683c\u8207\u66f4\u65b0 | Microsoft Azure<ul> <li>\u4fe1\u8cf4\u5e73\u53f0\u6a21\u7d44\u6280\u8853\u6982\u89c0 (Windows) - Windows security | Microsoft Learn</li> <li>X.509 client certificates - AWS IoT Core</li> <li>Device provisioning - AWS IoT Core</li> <li>draft-hsothers-iotsens-ps-02 - The Need for New Authentication Methods for Internet of Things</li> <li>Authentication and Authorization for IoT Devices in Disadvantaged Environments | IEEE Conference Publication | IEEE Xplore</li> <li>Modern Authentication for Network Devices | by Leo Lee | Airwalk Reply | Medium</li> <li>How to Authenticate a Device? Formal Authentication Models for M2M Communications Defending against Ghost Compromising Attack - Wei Ren, Linchen Yu, Liangli Ma, Yi Ren, 2013</li> </ul> </li> </ul> </li> <li>\u770b\u5b8c\u773c\u7736\u6fd5\u6fd5\u7684App\u958b\u767c\u8005\u6158\u70c8\u5c0d\u6297\u96aa\u60e1\u8cc7\u5b89\u74b0\u5883\u8840\u8207\u6dda\u7684\u63a7\u8a34</li> <li>Password cracking speed - the Security Factory<ul> <li>Coding4Fun - \u8a08\u7b97\u4e0d\u540c\u5bc6\u78bc\u9577\u5ea6\u8207\u8907\u96dc\u5ea6\u6240\u9700\u66b4\u529b\u7834\u89e3\u6642\u9593-\u9ed1\u6697\u57f7\u884c\u7dd2</li> </ul> </li> <li>\u5982\u4f55\u4f7f\u7528 One Time Password \u52a0\u5f37 Ubuntu \u4f3a\u670d\u5668 SSH \u5b89\u5168\u6027 | CodingMan</li> <li>Orange: \u5f9e 2013 \u5230 2023: Web Security \u5341\u5e74\u4e4b\u9032\u5316\u8207\u8da8\u52e2!</li> <li>20220811 - Web Conf 2023 - \u4f7f\u7528 Passkeys \u6253\u9020\u7121\u5bc6\u78bc\u9a57\u8b49\u670d\u52d9<ul> <li>\u73a9\u5177\u70cf\u6258\u90a6: \u5716\u89e3\u7121\u5bc6\u78bc\u767b\u5165\u7684 non-resident key \u6a5f\u5236</li> <li>WebAuthn \u7121\u5bc6\u78bc\u767b\u5165\u4e0d\u7b49\u65bc Passkey-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>Google Passkey \u7b46\u8a18 - \u4f7f\u7528\u624b\u6a5f\u514d\u5bc6\u78bc\u767b\u5165 Google \u5e33\u865f-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>DHK dao | Passkey\uff1a\u6700\u5b89\u5168\u7684\u5bc6\u78bc\u662f\u4e0d\u4f7f\u7528\u5bc6\u78bc</li> </ul> </li> <li>\u9592\u804a - Y2Q \u5012\u6578\u8207 Q-Day\uff0c\u7576\u4ee3\u8cc7\u8a0a\u5b89\u5168\u9632\u7dda\u5373\u5c07\u5d29\u6f70-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u5bc6\u78bc\u90fd\u653e Vault \u88e1\u4e86\uff0c\u7136\u5f8c\u5462\uff1f\uff01. \u7576\u7136\u8981\u4f86\u8ac7\u8ac7\u600e\u9ebc\u7ba1\u7406 Vault \uff3e\uff3e | by smalltown | Starbugs Weekly \u661f\u5df4\u54e5\u6280\u8853\u5c08\u6b04 | Medium</li> <li>PQC \u7b46\u8a18 1 - \u9760\u8fd1\u4e00\u9ede\u770b\u91cf\u5b50\u96fb\u8166\u5c0d\u7576\u4ee3\u5bc6\u78bc\u5b78\u7684\u5a01\u8105-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>PQC \u7b46\u8a18 2 - \u7c21\u55ae\u8a8d\u8b58\u5f8c\u91cf\u5b50\u6642\u4ee3\u5bc6\u78bc\u5b78\u6f14\u7b97\u6cd5-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u6709\u8da3\u7684\u5c0f\u904a\u6232 - Gandalf Adventures \u4e4b prompt injection \u653b\u7565 | \u662f Ray \u4e0d\u662f Array</li> <li>\u7b46\u8a18 - \u53ef\u5fae\u8abf Personal Access Token \u8b93 Github \u5b58\u53d6\u66f4\u5b89\u5168-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u5728\u4f01\u696d\u88e1\u9762\u7ba1\u7406\u5bc6\u78bc\u7684\u9078\u64c7 \u2013 Gea-Suan Lin's BLOG</li> <li>SPIFFE/SPIRE \u4ece\u5165\u95e8\u5230\u5165\u95e8 | \u4f2a\u67b6\u6784\u5e08</li> <li>[SSL] \u4e00\u6b21\u5f04\u61c2 Let\u2019s Encrypt \u4ee5\u53ca\u5efa\u8b70\u4f7f\u7528\u7684\u5de5\u5177 \u2013 DNSroboCert \u2013 \u4e00\u4ecb\u8cc7\u7537</li> <li>RBAC<ul> <li>\u4ec0\u9ebc\u662f\u57fa\u65bc\u89d2\u8272\u7684\u5b58\u53d6\u63a7\u5236 (RBAC)\uff1f | Cloudflare<ul> <li>\u5982\u4f55\u5229\u7528 Open Policy Agent \u914d\u5408 Golang \u5efa\u69cb\u5f48\u6027\u7684 RBAC \u6a21\u7d44 | omegaatt</li> </ul> </li> </ul> </li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#_2","title":"\u5f31\u9ede\u6383\u63cf","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#xss","title":"XSS","text":"<p>https://stackoverflow.com/questions/64152836/checkmarx-how-to-validate-and-sanitize-httpservletrequest-getinputstream-to-p https://stackoverflow.com/questions/1265282/what-is-the-recommended-way-to-escape-html-symbols-in-plain-java https://stackoverflow.com/questions/11478813/request-getparameter-protect-against-xss-what-is-the-best-practice</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#code-injection","title":"Code injection","text":"<p>https://stackoverflow.com/questions/15197673/using-pythons-eval-vs-ast-literal-eval</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#insecure-randomness","title":"Insecure Randomness","text":"<p>\u5982\u679c\u9019\u7d44\u507d\u96a8\u6a5f\u503c\u88ab\u7528\u505a\u4efb\u4f55\u5b89\u5168\u6027\u4f7f\u7528\uff0c\u5982\u5bc6\u78bc\u3001\u91d1\u9470\u3001Session\u6216\u662f\u96b1\u5bc6\u8fa8\u8b58\u503c\uff0c\u653b\u64ca\u8005\u5c31\u53ef\u4ee5 \u9810\u6e2c\u4e0b\u4e00\u500b\u6216\u5df2\u7d93\u7522\u751f\u7684\u6578\u503c</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#uncontrolled-format-string","title":"Uncontrolled Format String","text":"<p>https://www.netsparker.com/blog/web-security/format-string-vulnerabilities/ Format strings are used in many programming languages to insert values into a text string. In some cases, this mechanism can be abused to perform  - buffer overflow attacks - extract information - execute arbitrary code.</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#command_injection","title":"Command_Injection","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#python","title":"python","text":"<p>https://docs.python.org/3.6/library/subprocess.html#subprocess.Popen</p> <p>args is required for all calls and should be a string, or a sequence of program arguments.</p> <p>Providing a sequence of arguments is generally preferred, as it allows the module to take care of any required escaping and quoting of arguments (e.g. to permit spaces in file names).</p> <p>If passing a single string, either shell must be True (see below) or else the string must simply name the program to be executed without specifying any arguments.</p> <p>``` python=</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#subprocesscallping-c-1-8888-rm-test_file-shelltrue","title":"subprocess.call([\"ping -c 1 8.8.8.8; rm test_file\"], shell=True)","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#the-test_file-will-be-removed","title":"the test_file will be removed","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#subprocesscallping-c-1-8888-rm-test_file-shelltrue_1","title":"subprocess.call([\"ping\", \"-c\", \"1\", \"8.8.8.8\", \"rm\", \"test_file\"], shell=True)","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#ping-usage-error-destination-address-required","title":"ping: usage error: Destination address required","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#subprocesscallping-c-1-8888-rm-test_file","title":"subprocess.call([\"ping\", \"-c\", \"1\", \"8.8.8.8\", \"rm\", \"test_file\"])","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#ping-test_file-temporary-failure-in-name-resolution","title":"ping: test_file: Temporary failure in name resolution","text":"<p>```</p> <p>Popen Constructor , the default shell=False</p> <p>If env is not None, it must be a mapping that defines the environment variables for the new process; these are used instead of the default behavior of inheriting the current process\u2019 environment. Python - subprocess and the env argument</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#java","title":"java","text":"<p>On Command Injection over Java\u2019s ProcessBuilder</p>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#_3","title":"\u4e8b\u4ef6","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#log4j-vulnerability","title":"log4j vulnerability","text":"<ul> <li>Log4Shell log4j vulnerability (CVE-2021-44228 / CVE-2021-45046) - cheat-sheet reference guide</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#certificate","title":"Certificate","text":"<ul> <li>Generate a full self-signed certificate chain (Root -&gt; Intermediate CA -&gt; Server) using keytool, that can be used for 'localhost' development \u00b7 GitHub</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#authorization-authentication","title":"Authorization &amp; Authentication","text":"<ul> <li>Day08 - \u3010\u5165\u9580\u7bc7\u3011OAuth 2.0 Playground</li> <li>Day09 - \u3010\u6982\u5ff5\u7bc7\u3011\u518d\u8ac7\u8eab\u4efd\u9a57\u8b49\u8207\u6388\u6b0a</li> <li>Oso - Authorization Academy<ul> <li>Authorization Academy - What is Authorization?</li> <li>Authorization Academy - Role-Based Access Control (RBAC)</li> <li>Authorization Academy - Relationship-Based Access Control (ReBAC)</li> <li>Authorization Academy - Authorization Enforcement</li> <li>Authorization Academy - Microservices Authorization</li> </ul> </li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#keycloak","title":"Keycloak","text":"<ul> <li>[Keycloak] \u74b0\u5883\u6e96\u5099 &amp; \u57fa\u672c\u8a2d\u5b9a | CK's Notepad</li> <li>\u5982\u4f55\u7528 Docker \u5feb\u901f\u4e0a\u624b Keycloak \u958b\u767c\u6a21\u5f0f | The Will Will Web</li> <li>\u3010\u7528Keycloak\u5b78\u7fd2\u8eab\u4efd\u9a57\u8b49\u8207\u6388\u6b0a\u3011\u7cfb\u5217\u76ee\u9304 | \u53c8LAG\u96a8\u6027\u7b46\u8a18<ul> <li>\u7528Keycloak\u5b78\u7fd2\u8eab\u4efd\u9a57\u8b49\u8207\u6388\u6b0a :: 2021 iThome \u9435\u4eba\u8cfd</li> </ul> </li> <li>container<ul> <li>\u5982\u4f55\u7528 Docker \u5feb\u901f\u4e0a\u624b Keycloak \u958b\u767c\u6a21\u5f0f | The Will Will Web</li> <li>GitHub - slominskir/keycloak_ldap: Docker Compose with Keycloak and 389 LDAP Directory Server</li> <li>https<ul> <li>Keycloak 22.0.5 Docker production deployment SSL certificate error - Stack Overflow</li> <li>GitHub - ahmedbaberkhan/keycloak-with-nginx-over-https: Streamline Keycloak Setup: Context Path, Nginx Proxy, HTTPS, and SSL/TLS Certificates<ul> <li>Using a reverse proxy - Keycloak</li> </ul> </li> <li>Keycloak Behind a Reverse Proxy with HTTPS | by Manas Pe\u00e7enek | Medium</li> </ul> </li> </ul> </li> <li>Keycloak\u4f7f\u7528\u7fa4\u6656Synology Directory Server\u4f5c\u4e3aAD/LDAP\u7528\u6237\u6570\u636e\u6e90</li> <li>\u8a2d\u5b9aKeycloak v19\u4e32\u63a5Windows AD / LDAP - Jovepater<ul> <li>user and group</li> </ul> </li> <li>Keycloak, Mariadb, and OpenLDAP</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#oso","title":"Oso","text":"<ul> <li>\u5b58\u53d6\u63a7\u5236\u8207 Oso | \u516d\u5c0f\u7de8 Editor Leon</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#malware-analysis","title":"Malware analysis","text":"<ul> <li>CS6038/CS5138 Malware Analysis</li> <li>awesome-executable-packing</li> <li>How to create a computer virus in Python</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#_4","title":"\u5de5\u5177","text":""},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#fail2ban","title":"Fail2ban","text":"<ul> <li>\u904b\u7528 Fail2ban \u81ea\u52d5\u5c01\u9396\u653b\u64ca\u8005\u7684 IP</li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#infisical","title":"Infisical","text":"<ul> <li>Infisical - Open Source SecretOps - MyApollo<ul> <li>\u958b\u6e90\u7684\u6a5f\u5bc6\u7ba1\u7406\u5e73\u53f0\uff0c\u5c08\u9580\u7528\u4ee5\u5132\u5b58\u8cc7\u6599\u5eab\u5e33\u5bc6\u3001 API key, Token \u7b49\u6a5f\u654f\u6027\u7684\u8cc7\u6599\uff0c\u53ef\u4ee5\u8b93\u6a5f\u5bc6\u7684\u7ba1\u7406\u66f4\u52a0\u65b9\u4fbf</li> </ul> </li> </ul>"},{"location":"hackmd/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8/#_5","title":"\u9632\u6bd2\u6280\u8853","text":"<ul> <li>AV Test</li> <li>av-comparatives</li> </ul> <p>\u3010\u79d1\u666e\u30112017\u5404\u6b3e\u9632\u6bd2\u8edf\u9ad4\u6280\u8853\u539f\u7406\u5256\u6790 2017 \u9810\u9632\u5c1a\u672a\u9032\u5165\u9632\u6bd2\u8cc7\u6599\u5eab\u7684\u672a\u77e5\u5a01\u8105 - \u555f\u767c\u6cd5: \u901a\u904e\u4e00\u7cfb\u5217\u7684\u898f\u5247\u8a66\u5716\u63a8\u7406\u51fa\u53ef\u80fd\u7684\u76ee\u6a19\uff0c\u5be6\u969b\u4e0a\uff0c\u901a\u904e\u4e00\u7cfb\u5217\u624b\u6bb5\u9084\u539f\u51fa\u53ef\u57f7\u884c\u6a94\u6848\u7684\u5be6\u969b\u884c\u70ba\uff0c\u4e26\u5c07\u5176\u8207\u8a18\u9304\u75c5\u6bd2\u884c\u70ba\u7684\u555f\u767c\u7279\u5fb5\u5eab\u76f8\u6bd4\u5c0d     - \u975c\u614b\u555f\u767c: \u5728\u53ef\u7591\u6587\u4ef6\u8b80\u5165\u5230\u8a18\u61b6\u9ad4\u57f7\u884c\u524d\uff0c\u5148\u884c\u4e00\u6b65\u53cd\u7de8\u8b6f\uff0c\u6839\u64da\u5f97\u5230\u7684\u4ee3\u78bc\u5206\u6790\u51fa\u7a0b\u5f0f\u53ef\u57f7\u884c\u7684\u547d\u4ee4\u7a2e\u985e\u548c\u9806\u5e8f\uff0c\u518d\u8207\u555f\u767c\u7279\u5fb5\u5eab\u4e2d\u7684\u884c\u70ba\u6bd4\u8f03\uff0c\u8fd1\u4f3c\u8005\u5831\u6bd2     - \u52d5\u614b\u555f\u767c: \u5efa\u7acb\u4e00\u500b\u9694\u96e2\u7684\u865b\u64ec\u74b0\u5883\u9810\u5148\u57f7\u884c\u8981\u6383\u63cf\u7684\u7a0b\u5f0f\u5e7e\u5341\u6beb\u79d2\u3002\u901a\u904e\u76e3\u63a7\u7a0b\u5f0f\u6700\u521d\u7684\u5e7e\u689d\u6216\u5e7e\u5341\u689d\u6307\u4ee4\u4f86\u5224\u65b7\u7a0b\u5f0f\u662f\u5426\u53ef\u7591\uff08\u6b63\u5e38\u7a0b\u5f0f\u4e00\u822c\u6703\u5148\u8abf\u7528\u5716\u5f62 API \u7e6a\u88fd\u754c\u9762\u7b49\uff0c\u4f46\u75c5\u6bd2\u901a\u5e38\u76f4\u63a5\u958b\u59cb\u8b80\u5beb\u786c\u789f\uff0c\u6ce8\u5165\u5176\u4ed6\u7a0b\u5e8f\uff09 - \u884c\u70ba\u6514\u622a\uff08Behavior Blocker\uff09 - HIPS: \u4e3b\u6a5f\u5165\u4fb5\u9632\u79a6\u7684\u82f1\u6587\u7e2e\u5beb\uff0c\u5206\u70ba AD \u61c9\u7528\u7a0b\u5f0f\u9632\u8b77\u3001RD \u8a3b\u518a\u8868\u9632\u8b77\u3001FD \u6587\u4ef6\u9632\u8b77\u4e09\u584a\u3002\u5728\u7a0b\u5f0f\u57f7\u884c\u6642\u6514\u622a\u6240\u6709\u884c\u70ba\u4e26\u8a62\u554f\u7528\u6236\u662f\u5426\u653e\u884c - \u4e3b\u52d5\u9632\u79a6: \u6709\u555f\u767c\u80fd\u529b\u7684 HIPS\uff0c\u8207\u555f\u767c\u5f0f\u7684\u4e0d\u540c\u5728\u65bc\uff0c\u64c1\u6709\u4e3b\u52d5\u9632\u79a6\u7684\u9632\u6bd2\u53ef\u4ee5\u5728\u7a0b\u5f0f\u6b63\u5e38\u57f7\u884c\uff08\u4e0d\u9694\u96e2\uff09\u7684\u60c5\u6cc1\u4e0b\u4e0d\u9593\u65b7\u5730\u76e3\u8996\u7a0b\u5f0f\u7684\u884c\u70ba\uff0c\u767c\u73fe\u8207\u555f\u767c\u7279\u5fb5\u5eab\u5339\u914d\u7684\u52d5\u4f5c\u4fbf\u7d42\u6b62\u8a72\u7a0b\u5e8f - \u96f2\u5206\u6790 - \u4eba\u5de5\u667a\u6167\uff08AI\uff09: \u5206\u6790\u96f2\u7aef\u7684\u5927\u91cf\u8cc7\u6599\uff0c\u6a5f\u5668\u5b78\u7fd2\u5f8c\u518d\u4e0b\u653e\u5230\u672c\u5730 - \u5ee3\u8b5c/\u57fa\u56e0: \u901a\u904e\u8861\u91cf\u67d0\u500b\u672a\u77e5\u7684\u6587\u4ef6\u548c\u5df2\u77e5\u60e1\u610f\u6587\u4ef6\u7684\u76f8\u4f3c\u5ea6\u4f86\u9032\u884c\u5224\u5225\u3002\u5982\u679c\u4e00\u500b\u672a\u77e5\u6587\u4ef6\u5728\u95dc\u9375\u7684\u5730\u65b9\u548c\u5df2\u77e5\u60e1\u610f\u5a01\u8105\u9ad8\u5ea6\u76f8\u4f3c\u5247\u5224\u70ba\u6709\u5bb3 - \u6c99\u76d2\uff08SandBox\uff09</p> <p>\u4e3b\u9632\u548c HIPS \u90fd\u5c6c\u65bc\u57f7\u884c\u5f8c\u4fdd\u8b77\uff0c\u5728\u5176\u904b\u4f5c\u6642\uff0c\u53ef\u7591\u7a0b\u5f0f\u5df2\u7d93\u5728\u8a18\u61b6\u9ad4\u4e2d\u57f7\u884c\uff0c\u53ef\u4ee5\u8aaa\u662f\u9632\u6bd2\u8edf\u9ad4\u7684\u6700\u5f8c\u4e00\u9053\u95dc\u5361</p> <ul> <li>Comodo<ul> <li>\u4ee5\u9632\u8b77\u70ba\u91cd\uff0c\u67e5\u6bba\u70ba\u8f14</li> <li>\u9632\u8b77\u601d\u8def<ul> <li>\u7b2c\u4e00\u6b65\u4e00\u6a23\u7531 AntiVirus \u505a\u5224\u65b7\uff0c\u4e26\u9023\u63a5\u5230\u96f2\u4fe1\u8b7d\u5eab\uff0c\u767d\u540d\u55ae\u6587\u4ef6\u653e\u884c\uff0c\u6c92\u6aa2\u6e2c\u5230\u75c5\u6bd2\u53c8\u4e0d\u5728\u767d\u540d\u55ae\u88e1\u7684\u6587\u4ef6\u81ea\u52d5\u5165\u6c99\uff1bViruscope \u518d\u5c0d\u6c99\u76d2\u88e1\u7684\u6a94\u6848\u9032\u884c\u884c\u70ba\u5206\u6790\uff0c\u5224\u65b7\u70ba\u6709\u5bb3\u7acb\u5373\u6e05\u9664</li> </ul> </li> </ul> </li> <li>Bitdefender<ul> <li>\u5c0d\u65bc\u75c5\u6bd2\u7684\u6aa2\u6e2c\u7387\u76f8\u7576\u7cbe\u6e96\uff0c\u5f88\u5c11\u6709\u8aa4\u5224\u7684\u60c5\u6cc1\u767c\u751f</li> <li>\u9632\u8b77\u6d41\u7a0b\u5305\u542b\u56db\u500b\u6b65\u9a5f<ul> <li>\u5165\u53e3\u9632\u8b77\uff0c\u4f7f\u7528\u6d41\u91cf\u6383\u63cf\uff08\u542b Web\u3001Email\u3001IM\uff09</li> <li>\u5230\u9054\u672c\u5730\u7684\u6587\u4ef6\u5c07 hash \u6838\u5c0d\u7c3d\u540d\u6578\u64da\u5eab</li> <li>\u5982\u679c\u6c92\u6709\u7c3d\u540d\u5339\u914d\uff0c\u6703\u4f7f\u7528 B-HAVE \u5f15\u64ce\u9032\u884c\u555f\u767c\u6aa2\u6e2c</li> <li>\u4e3b\u9632\u76e3\u63a7\u7a0b\u5f0f\u7684\u884c\u70ba\uff0c\u7576\u5206\u6578\u9054\u5230\u95be\u503c\u7acb\u523b\u963b\u6b62\u57f7\u884c</li> </ul> </li> <li>ATC \u4e3b\u9632</li> </ul> </li> <li>Kaspersky<ul> <li>\u6240\u6709\u7684\u96f2\u90fd\u6703\u9760 MD5\u3001Hash \u4f86\u5224\u65b7\u6a94\u6848\u7684\u5b89\u5168\u6027\uff0c\u9019\u5c31\u662f\u6240\u8b02\u7684\u96f2\u62c9\u9ed1\uff0cMD5 \u662f\u4e00\u500b\u5feb\u901f\u5224\u65b7\u6a94\u6848\u7684\u597d\u65b9\u6cd5\uff0c\u4f46\u5c0d\u65bc\u5361\u5df4\u4f86\u8aaa\u4e0d\u662f\u552f\u4e00\u65b9\u6cd5\u3002\u9996\u6b21\u57f7\u884c\u7a0b\u5f0f\u6703\u5148\u9032\u5165 KSN \u9032\u884c\u96f2\u6578\u64da\u5eab\u5339\u914d\uff0c\u767d Hash \u76f4\u63a5\u653e\u5165\u4fe1\u4efb\u7d44\uff0c\u9ed1\u540d\u55ae\u5831 DangerousObject\uff1b\u800c\u672a\u77e5\u61c9\u7528\u81ea\u52d5\u5206\u6790\u5b89\u5168\u7684\u8a71\u653e\u5165\u9650\u5236\u7d44\uff08\u9700\u642d\u914d HIPS \u6a21\u584a\uff09\uff0c\u7b26\u5408\u96f2\u5371\u96aa\u6a21\u578b\u5831 DangerousPattern</li> <li>\u5361\u5df4\u65af\u57fa\u6709\u591a\u500b\u9632\u8b77\u5c64\u3002\u7b2c\u4e00\u5c64\u662f Web \u9632\u8b77\uff0c\u7db2\u9801\u7684\u6728\u99ac\u5728\u7b2c\u4e00\u5c64\u5c31\u88ab\u64cb\u4e0b\uff1b\u82e5\u75c5\u6bd2\u4e0d\u5e78\u88ab\u4e0b\u8f09\u5230\u672c\u5730\uff0c\u6703\u88ab\u7279\u5fb5\u78bc\u548c\u555f\u767c\u6aa2\u6e2c\u5230\uff1b\u5982\u679c\u6a94\u6848\u8cc7\u6599\u6c92\u6709\u88ab\u6536\u5165\u5728\u672c\u5730\u75c5\u6bd2\u5eab\uff0c\u9084\u6703\u9023\u4e0a KSN \u67e5\u8a62\uff1b\u518d\u4e0b\u4e00\u5c64\u662f\u4e3b\u52d5\u9632\u79a6\u6a21\u584a\uff0c\u5206\u6790\u7a0b\u5f0f\u7684\u884c\u70ba\uff0c\u82e5\u6709\u53ef\u7591\u6d3b\u52d5\u7acb\u523b\u963b\u6b62</li> </ul> </li> <li>F-Secure</li> </ul>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E5%B8%AB%E7%9A%84%E5%B0%88%E6%A5%AD%E5%92%8C%E9%80%9A%E8%AD%98/","title":"\u8edf\u9ad4\u5de5\u7a0b\u5e2b\u7684\u5c08\u696d\u548c\u901a\u8b58","text":"<ul> <li>\u8edf\u9ad4\u958b\u767c\u9031\u671f<ul> <li>My life as a CTO \u2014 Technology (Daily Work) | by Jocelin Ho | Apr, 2024 | Medium</li> <li>SRE \u5e38\u898b\u554f\u984c - \u8a2a\u8ac7\u7d00\u9304 | Complete Think</li> <li>vgod \u5b78\u9577\u8a2a\u8ac7\u8207 Dropbox \u53c3\u8a2a\u7d00\u9304 | Cheng-Wei Hu</li> <li>\u4f7f\u7528 Github Projects \u505a\u4e1a\u4f59\u9879\u76ee\u7ba1\u7406 | \u5317\u706b</li> <li>\u5f9e API First \u5230 AI First \u2014 \u5b89\u5fb7\u9b6f\u7684\u90e8\u843d\u683c<ul> <li>Building LLM-powered products \u2014 Part 2 | by R\u00e9mi Toffoli | Medium</li> </ul> </li> <li>RACI<ul> <li>\u3010\u8cac\u4efb\u6307\u6d3e\u77e9\u9663\u3011\uff1a\u7528\u4f86\u5c0d\u8a72\u9805\u76ee\u7684\u5718\u968a\u6210\u54e1\u9032\u884c\u5206\u5de5\uff0c\u660e\u78ba\u8a02\u5b9a\u51fa\u4f55\u7a2e\u89d2\u8272\u5c0d\u61c9\u4f55\u7a2e\u8077\u8cac\u7684\u5de5\u5177 | Titansoft</li> <li>RACI \u8868 \u2013 \u7d42\u6975\u6307\u5357 (\u9644\u7bc4\u4f8b) [2024] \u2022 Asana</li> <li>RACI \u77e9\u9663\u662f\u4ec0\u9ebc\uff1f\u8cac\u4efb\u6307\u6d3e\u900f\u660e\u5316\uff0c\u8b93\u5c08\u6848\u7ba1\u7406\u66f4\u6709\u6548\u7387\uff01 | Cake</li> </ul> </li> </ul> </li> <li>Microsoft<ul> <li>CSE Code-With Engineering Playbook</li> <li>Engineering Fundamentals Checklist</li> <li>api-guidelines/Guidelines.md at vNext \u00b7 microsoft/api-guidelines \u00b7 GitHub</li> </ul> </li> <li>Gitlab<ul> <li>Handbook</li> <li>Gitlab Engineering \u628a\u958b\u6703\u7684\u904e\u7a0b\u90fd\u653e\u5728 YT \u4e0a\u9762, \u8a0e\u8ad6\u7684\u5167\u5bb9\u5c31\u50cf\u6211\u5011\u5e73\u6642\u6211\u5011\u7684\u65e5\u5e38. \u5305\u542b\u63cf\u8ff0\u53ca\u89e3\u6c7a\u554f\u984c\u7684\u904e\u7a0b, \u9084\u6709\u958b\u6703\u904e\u7a0b / Twitter<ul> <li>2023-05-17 - Runway Design Session - YouTube</li> </ul> </li> </ul> </li> <li>Dropbox<ul> <li>Dropbox Engineering Career Framework</li> </ul> </li> <li>Plan<ul> <li>\u4f60\u7684\u9748\u9b42 - \u8ac7\u7522\u54c1\u540d\u7a31\u7684\u547d\u540d | Complete Think</li> <li>Breaking Down Tasks - Jacob Kaplan-Moss</li> </ul> </li> <li>System Analysis<ul> <li>Tool<ul> <li>Entity Relationship Diagram (ERD)<ul> <li>\u552f\u4e00\u6027</li> <li>\u4f7f\u7528 ER \u5716\u7de8\u5beb\u6e05\u6670\u7684\u8edf\u9ad4\u898f\u683c</li> </ul> </li> <li>Sequence Diagram<ul> <li>mermaid-js/mermaid-live-editor: Edit, preview and share mermaid charts/diagrams. New implementation of the live editor.<ul> <li>Online FlowChart &amp; Diagrams Editor - Mermaid Live Editor</li> </ul> </li> </ul> </li> <li>genai-demo/docs/uml/README.md at main \u00b7 \u8a02\u55ae\u7cfb\u7d71 UML \u6587\u6a94\u8aaa\u660e</li> <li>\u7cfb\u7d71\u5206\u6790\u5e2b\u7684\u7d93\u9a57\u5206\u4eab(SA)\uff1a\u5728\u6280\u8853\u8207\u9700\u6c42\u9593\u642d\u5efa\u6a4b\u6a11| by Spyua | spyua | Medium</li> </ul> </li> <li>Funtional<ul> <li>\u67b6\u69cb\u9762\u8a66\u984c #4 - \u62bd\u8c61\u5316\u8a2d\u8a08\uff1b\u6298\u6263\u898f\u5247\u7684\u8a2d\u8a08\u6a5f\u5236 (06/25 \u88dc\u5b8c) \u2014 \u5b89\u5fb7\u9b6f\u7684\u90e8\u843d\u683c</li> <li>\u67b6\u69cb\u5e2b\u89c0\u9ede - API Design Workshop \u2014 \u5b89\u5fb7\u9b6f\u7684\u90e8\u843d\u683c<ul> <li>\u4ee5{\u6703\u54e1}\u8cc7\u6599\u70ba\u4e3b\u9ad4, API \u662f\u570d\u7e5e\u5728\u4e3b\u9ad4\u7684\u751f\u547d\u9031\u671f\u4e2d, \u6703\u5f71\u97ff{\u72c0\u614b}\u8207{\u8cc7\u8a0a\u8b8a\u5316}\u7684\u4e3b\u8981\u64cd\u4f5c</li> <li>\u4ee5\u72c0\u614b\u6a5f\u70ba\u57fa\u790e\uff0c\u4e00\u8def\u628a\u6211\u9700\u8981\u7684\u8cc7\u8a0a\u4e00\u4e00\u6a19\u8a18\u4e0a\u53bb\uff0c\u4e26\u4e14\u5148\u5728\u8166\u888b\u88e1\u9762\u8f49\u904e\u5e7e\u500b\u6848\u4f8b\uff0c\u78ba\u8a8d\u53ef\u884c\u5f8c\u624d\u958b\u59cb\u82b1\u6642\u9593\u628a\u7a0b\u5f0f\u78bc\u8ddf\u898f\u683c\u5beb\u51fa\u4f86\u2026\u3002\u6709\u90a3\u4e9b\u6771\u897f\u662f\u7269\u4ef6\u5728\u610f\u7684? \u6211\u81ea\u5df1\u7684\u6163\u4f8b\u662f\u8981\u5206\u6790\u9019\u5e7e\u9805<ul> <li>\u72c0\u614b</li> <li>\u64cd\u4f5c (\u6703\u6539\u8b8a\u72c0\u614b\u7684)</li> <li>\u64cd\u4f5c (\u4e0d\u6703\u6539\u8b8a\u72c0\u614b\u7684)</li> <li>\u7269\u4ef6\u76f8\u95dc\u8cc7\u8a0a (\u9644\u52a0\u65bc\u7269\u4ef6\u8eab\u4e0a\u7684\u8cc7\u8a0a)</li> <li>\u4e8b\u4ef6 (\u5916\u754c\u95dc\u6ce8\u7269\u4ef6\u672c\u8eab\u7684\u8b8a\u5316\uff0c\u800c\u5c0d\u61c9\u7684\u53cd\u61c9)</li> </ul> </li> <li>https://www.youtube.com/watch?v=mfWfsjypd04</li> <li>slide<ul> <li>Meetup/Andrew-APIDesignWorkshop.pptx at master \u00b7 andrew0928/Meetup \u00b7 GitHub</li> <li>DevOpsDaysTaipei2022-Andrew, DevOps \u6f6e\u6d41\u4e0b\u7684 API First \u958b\u767c\u7b56\u7565 (release) - Google \u7c21\u5831</li> </ul> </li> </ul> </li> <li>\u5fae\u670d\u52d9\u67b6\u69cb - \u5f9e\u72c0\u614b\u5716\u4f86\u9a45\u52d5 API \u7684\u8a2d\u8a08</li> <li>SaaS \u95dc\u9375\u8a2d\u8a08 - Multi-Tenancy - \u63a2\u8a0e\u771f\u5be6\u4e16\u754c\u7684\u79df\u8cc3\u95dc\u4fc2 | Complete Think</li> </ul> </li> <li>Non-Funtional<ul> <li>Performance planning - taking average requests per second and guessing peak</li> </ul> </li> </ul> </li> <li>System Design<ul> <li>\u600e\u9ebc\u61c9\u5c0dSystem Design Interview<ul> <li>\u662f\u5426\u6709\u80fd\u529b\u4e3b\u5c0e\u63a8\u52d5\u6574\u500b\u5c08\u6848</li> <li>\u4ecb\u7d39\u904e\u7a0b\u4e2d\u7684\u63cf\u8ff0\u548c\u9806\u5e8f\uff0c\u53ef\u4ee5\u5c55\u73fe\u50f9\u503c\u89c0</li> <li>\u662f\u5426\u80fd\u627e\u51fa\u95dc\u9375\u96e3\u9ede\u4e26\u8655\u7406</li> <li>\u6c7a\u7b56\u904e\u7a0b\u548ctrade-off</li> </ul> </li> <li>\u6709\u6548\u7684Review<ul> <li>\u985e\u4f3cPR Review</li> <li>The Anatomy of an Amazon 6-pager</li> </ul> </li> <li>\u9078\u64c7\u7121\u804a\u7684\u6280\u8853<ul> <li>boring in the sense that it\u2019s well understood. It\u2019s bad, but you know why it\u2019s bad</li> <li>In the reality, maintenance cost dominates</li> </ul> </li> <li>Multitenancy<ul> <li>How to Implement Multitenancy in Cloud Computing</li> </ul> </li> <li>UX<ul> <li>When life gives you lemons, write better error messages</li> </ul> </li> <li>Others<ul> <li>MySQL\ud83d\udc2c InnoDB \u6559\u6211\u7684\u4e8b\uff1a \u6700\u8fd1\u6700\u5c11\u4f7f\u7528 LRU \u4e32\u5217\u7684\u512a\u5316 | by Jayden Lin | \u7a0b\u5f0f\u733f\u5403\u9999\u8549 | Medium</li> <li> - Tachunn Publication <li> - Tachunn Publication<ul> <li>\u73fe\u5be6\u4e16\u754c\u662f Database \u53ea\u662f\u7528\u4f86\u8f14\u52a9\u6211\u5011\u60f3\u8981\u63a8\u884c\u7522\u54c1\u7684\u5de5\u5177\u800c\u5df2</li> </ul> <li> - Tachunn Publication <li>How Discord Stores Trillions of Messages</li> <li>How Levels.fyi scaled to millions of users with Google Sheets as a backend</li> <li>\u70ba\u4ec0\u9ebc\u4f60\u61c9\u8a72\u4f7f\u7528 OSS\uff08\u7269\u4ef6\u5b58\u5132\u670d\u52d9\uff09\u800c\u4e0d\u662f\u76f4\u63a5\u5b58\u5728\u672c\u5730\uff1f| Yuanlin Lin \u6797\u6c85\u9716</li> <li>A Discussion On Stateless &amp; Stateful Services (Managing User State On The Backend) - Scaleyourapp</li> <li>2024\u5e74\u7684\u4e91\u539f\u751f\u67b6\u6784\u9700\u8981\u54ea\u4e9b\u6280\u672f\u6808 | crossoverJie's Blog</li> <li>\u5f8c\u7aef\u5de5\u7a0b\u5e2b\u9762\u8a66\u8003\u4ec0\u9ebc \u2014 Load Balancer vs. Reverse Proxy vs. API Gateway vs. HAProxy - MyApollo</li> <li>Identifier Design Consideration | Complete Think</li> <li>Coding<ul> <li>The Code Review Pyramid - Gunnar Morling</li> <li>\u4f75\u767c\u7de8\u7a0b\u26a1\u8ac7\u8ac7\u9396\u8207\u8cc7\u6e90. \u5728\u5beb\u4f75\u767c\u7a0b\u5f0f\u7684\u6642\u5019\uff0c\u300c\u9396\u300d\u548c\u300c\u8cc7\u6e90\u300d\u662f\u5169\u500b\u4e0d\u540c\u7684\u6771\u897f\uff0c\u5982\u679c\u6c92\u6709\u5f04\u6e05\u695a\uff0c\u6709\u6642\u6703\u51fa\u73fe\u2026 | by Jayden Lin | \u7a0b\u5f0f\u733f\u5403\u9999\u8549 | Sep, 2022 | Medium</li> <li>\u6df1\u5165 GIL: \u5982\u4f55\u5beb\u51fa\u5feb\u901f\u4e14 thread-safe \u7684 Python - Grok the GIL: How to write fast and thread-safe Python | louie_lu's blog</li> <li>Domain Model Layer Convention (Model \u5c64\u7d1a\u7ba1\u7406) \u00b7 GitHub</li> <li>Multi-processing vs multi-threading vs async-await vs Goroutine | by LORY | Jul, 2023 | Medium</li> <li>GitHub Copilot \u5165\u9580 - Huan-Lin \u5b78\u7fd2\u7b46\u8a18</li> <li>Google Testing Blog: Code Health: Reduce Nesting, Reduce Complexity</li> <li>GitHub Copilot \u597d\u96e3\u7528\uff1f\u8aaa\u4e0d\u5b9a\u662f\u4f60\u4e0d\u61c2 Copilot \u4e4b\u6280\u5de7\u5168\u653b\u7565\u4e0d\u85cf\u79c1\uff01 | \u662f Ray \u4e0d\u662f Array</li> <li>\u63a8\u8350\u4e00\u4e9b\u503c\u5f97\u5b66\u4e60\u7684\u5f00\u6e90\u9879\u76ee\u548c\u6846\u67b6 | crossoverJie's Blog</li> <li>Cognitive load is what matters</li> <li>\u4f7f\u7528\u6d6e\u9ede\u6578\u6700\u6700\u57fa\u672c\u7684\u89c0\u5ff5</li> <li>log<ul> <li>logging - When to use the different log levels - Stack Overflow</li> </ul> </li> <li>CLI<ul> <li>\u3010\u7b28\u554f\u984c\u3011CLI \u53c3\u6578\u70ba\u4ec0\u9ebc\u6709\u6642\u8981\u52a0 \"--\"\uff1f POSIX \u53c3\u6578\u6163\u4f8b\u7684\u51b7\u77e5\u8b58-\u9ed1\u6697\u57f7\u884c\u7dd2</li> </ul> </li> <li>Review<ul> <li>\u7576 Senior Python \u5de5\u7a0b\u5e2b\u7684 Pull-Request \u88ab Code Review (\u7a0b\u5f0f\u78bc\u5be9\u67e5) | by Keith Yang | iCHEF | Medium</li> </ul> </li> <li>Commit<ul> <li>\u512a\u96c5\u6574\u5408 Linter\u3001Husky\u3001Lint-Staged\uff1a\u5beb\u6263\u770b\u6263\u7686\u5927\u6b61\u559c\u7684\u5bc6\u6280 | Summer\u3002\u6851\u83ab\u3002\u590f\u5929</li> <li>Pre-push Mechanism | Summer\u3002\u6851\u83ab\u3002\u590f\u5929</li> </ul> </li> </ul> </li> <li>\u6e2c\u8a66<ul> <li>Testing Strategies in a Microservice Architecture<ul> <li>\u5716\u793a\u53ef\u4ee5\u5f88\u597d\u5730\u8868\u9054\u7cfb\u7d71\u5167\u90e8\u548c\u5916\u90e8\u7684\u95dc\u4fc2</li> </ul> </li> <li>\u6f2b\u8ac7\u670d\u52d9\u7aef\u6027\u80fd\u6e2c\u8a66</li> <li>\u8b93\u958b\u767c\u4eba\u54e1\u5982\u6c90\u6625\u98a8\u7684\u58d3\u529b\u6e2c\u8a66\u5de5\u5177 - K6-\u9ed1\u6697\u57f7\u884c\u7dd2</li> <li>\u3010GitHub\u3011\u5efa\u7acb\u7b2c\u4e00\u500b Issue Template | \u5fcd\u8005\u5de5\u574a</li> </ul> </li> <li>Release<ul> <li>\u5982\u4f55\u81ea\u52d5\u5316 GitHub Releases \u6d41\u7a0b</li> <li>CHANGE LOG<ul> <li>GitHub - pawamoy/git-changelog: Automatic Changelog generator using Jinja2 templates.<ul> <li>Usage - git-changelog</li> <li>Conventional Commits</li> </ul> </li> <li>How To Automatically Generate A Helpful Changelog From Your Git Commit Messages | Michael Hoffmann</li> <li>git-cliff: Generate changelog for your Git repositories from the command line : r/linux</li> <li>use origin git<ul> <li>How to generate Release Notes / Changelog from Git Commits since last git tag? - How To - Bitrise Discussions</li> <li>\u7528 git \u6307\u4ee4\u7522\u751f Change log \u683c\u5f0f - \u5c0f\u60e1\u9b54 - AppleBOY</li> </ul> </li> <li>commit lint<ul> <li>commitlint/commitlint - Docker Image | Docker Hub</li> <li>[Git Note] - \u7d71\u4e00\u5718\u968a\u7684 Git Commit \u683c\u5f0f\u5427\uff01\u4e0d\u8981\u518d\u8b93 Commit \u4e82\u7cdf\u7cdf | RexHung's Blog</li> <li>21 - Commitlint - Lint Commit \u8a0a\u606f - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>commitlint \u00b7 PyPI</li> </ul> </li> <li>git hook<ul> <li>20 - Husky - Git Hooks \u5de5\u5177 - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT \u4eba\u7684\u4e00\u5929</li> <li>Python \u958b\u767c\uff1apre-commit \u8a2d\u5b9a Git Hooks \u6559\u5b78 - Code and Me</li> <li>Python Table Manners - Commitizen: \u898f\u683c\u5316 commit message</li> </ul> </li> </ul> </li> </ul> </li> <li>\u901a\u8b58<ul> <li>\u5fc3\u614b<ul> <li>\u5728\u5718\u968a\u4e2d\u9700\u8981\u5177\u5099\u7684\u5fc3\u614b<ul> <li>\u6bd4\u8d77\u81ea\u5df1\u6210\u70ba\u5927\u5e2b\uff0c\u66f4\u91cd\u8981\u7684\u662f\u8981\u5b8c\u6210\u5718\u968a\u76ee\u6a19</li> </ul> </li> <li>\u8edf\u9ad4\u958b\u767c\u8005\u7684\u57f9\u990a by \u5361\u7c73\u54e5 | Medium</li> <li>Meta\u88c1\u54e1\u3001\u8abf\u6574\u65b9\u5411\u3001\u91cd\u65b0\u51fa\u767c - UXeastmeetswest - Medium</li> <li>Code Simplicity: The Fundamentals of Software is Now Free \u00bb Code Simplicity</li> <li>\u9081\u5411\u8cc7\u6df1\u5de5\u7a0b\u5e2b\u4e4b\u8def\uff1a\u51dd\u7df4\u81ea\u5df1\u7684\u89c0\u9ede - \u5433\u660e\u502b MingLun Wu</li> <li>\u3010LINE TV \u5be6\u7fd2\u5fc3\u5f97\u3011\u5f9e\u7a0b\u5f0f\u83dc\u9ce5\u5230\u8edf\u9ad4\u5de5\u7a0b\u5e2b | Cheng-Wei Hu</li> <li>\u6211\u5728 Meta \u7576 Staff Engineer. credit\u2026 | by Denny | Dec, 2024 | Medium</li> </ul> </li> <li>\u5169\u5927\u985e\u96a8\u624b\u8a18 - \u5169\u5927\u985e\u96a8\u624b\u8a18</li> <li>\u6e9d\u901a<ul> <li>:star:\u90a3\u4e9b\u52a0\u500d\u6703\u8b70\u6548\u7387\u7684\u5c0f\u79d8\u8a23. \u7d93\u9a57\u4e0a\u53ef\u4ee5\u780d\u534a\u6703\u8b70\u6642\u9593\uff0c\u8b93\u4e00\u5c0f\u6642\u7684\u6703\u8b70\u5728 30 \u5206\u9418\u751a\u81f3 15\u2026 | by Mosky Liu | Medium</li> <li>\u7d66\u56de\u994b\u597d\u96e3\uff1f\u4f60\u9700\u8981\u90a3\u689d\u300c\u8def\u300d - Mosky Liu - Medium</li> <li>\u51dd\u805a\u5718\u968a\u5171\u8b58\u7684\u6e9d\u901a\u65b9\u6cd5 | Complete Think</li> <li>\u8981\u6210\u70ba\u4e00\u500b\u597d\u7684\u5de5\u7a0b\u5e2b\uff0c\u4f60\u7d55\u5c0d\u4e0d\u80fd\u53ea\u61c2\u5f97\u5982\u4f55\u5bebcode - Jocelin Ho - Medium</li> </ul> </li> <li>\u5718\u968a<ul> <li>\u5f9e 20 \u54e9\u884c\u8ecd\u7684\u6545\u4e8b\uff0c\u770b\u5982\u4f55\u9762\u5c0d\u4e0d\u78ba\u5b9a\u6027</li> <li>My life as a CTO \u2014 Technology (Daily Work) | by Jocelin Ho | Apr, 2024 | Medium</li> <li>\u5e36\u9818\u5718\u968a\u7684\u904e\u7a0b</li> <li>\u90a3\u4e9b\u7406\u6240\u7576\u7136\uff0c\u537b\u50cf\u7a7a\u6c23\u822c\u91cd\u8981\u7684\u5c0f\u4e8b\uff1a\u8ac7\u958b\u767c\u6d41\u7a0b\u3001\u7a0b\u5f0f\u67b6\u69cb\u8207\u8077\u6daf\u767c\u5c55 - PJ (\u9673\u67cf\u878d) - HackMD<ul> <li>slide</li> </ul> </li> <li>Average Manager vs. Great Manager | by Julie Zhuo | The Year of the Looking Glass | Medium</li> <li>Event storming \u662f\u500b\u597d\u6771\u897f\uff1a\u5e6b\u52a9\u5718\u968a\u770b\u898b\u5168\u8c8c\uff0c\u5f15\u767c\u5718\u968a\u8b8a\u9769\u65b0\u5951\u6a5f | \u8266\u9577\uff0c\u4f60\u6709\u4e8b\u55ce\uff1f</li> <li>\u5fc3\u5f97 \u2014 \u5f9e\u904a\u6232\u5b78\u7ba1\u7406 | Kalan's Blog</li> <li>\u65b7\u6389\u7684\u8cc7\u8a0a\u6d41\uff0c\u9435\u6253\u7684\u4e3b\u7ba1\uff0c\u8207\u6d41\u6c34\u7684\u54e1\u5de5 \u2013 \u592a\u967d\u62f3\u7684\u842c\u4eba\u6575\u4e4b\u8853</li> <li>\u4ee4\u6211\u5370\u8c61\u6df1\u523b\u7684\u7ba1\u7406. \u8077\u6daf\u8d70\u4e86\u4e00\u6bb5\u6642\u9593\uff0c\u671f\u9593\u7d93\u904e\u4e0d\u5c11\u7684\u7ba1\u7406\u8005\uff0c\u6709\u4e9b\u5df2\u7d93\u6c92\u6709\u806f\u7d61\u4e86\uff0c\u4f46\u5927\u90e8\u5206\u5728\u5de5\u4f5c\u7f6e\u63db\u5f8c\u2026 | by Spyua | spyua | Medium</li> </ul> </li> <li>My life as a CTO \u2014 Technology (Day 1) | by Jocelin Ho | Apr, 2024 | Medium</li> <li>Scrum\uff0c\u4f46\u6bcf\u9031\u53ea\u7528\u4e00\u5c0f\u6642\u30fb\u7d30\u7bc0\u7bc7</li> <li>Dropbox Engineering Career Framework</li> <li>ITHOME \u9435\u4eba\u8cfd\u89c0\u6230\u5340</li> <li>My Vision: The Roadmap</li> <li>[\u751f\u6d3b\u8a18\u9304] 2023 \u534a\u5e74\u5de5\u4f5c\u56de\u9867 | Marsen's Blog</li> <li>DevOpsDays Taipei 2023 \u7d00\u9304\u6587\u8207\u611f\u6069\u6587 | \u8266\u9577\uff0c\u4f60\u6709\u4e8b\u55ce\uff1f</li> <li>\u66ff\u4f60\u7684\u61c9\u7528\u7a0b\u5f0f\u52a0\u4e0a\u667a\u6167! \u8ac7 LLM \u7684\u61c9\u7528\u7a0b\u5f0f\u958b\u767c \u2014 \u5b89\u5fb7\u9b6f\u7684\u90e8\u843d\u683c</li> <li>Complexity Has to Live Somewhere<ul> <li>Embrace Complexity; Tighten Your Feedback Loops</li> </ul> </li> <li>\u3010\u5fc3\u5f97\u3011\u505a\u5feb\u4e94\u5e74\u6280\u8853\u54e1\u8f49\u8077\u5bebPython \u5de5\u7a0b\u5e2b\u5169\u5e74\u5fc3\u5f97\u3002 @\u8077\u5834\u7518\u82e6\u8ac7 \u54c8\u5566\u677f - \u5df4\u54c8\u59c6\u7279</li> <li>\ud83c\udf89\u6211\u662f\u5982\u4f55\u4ece\u96f6\u5230\u6210\u4e3a Apache \u9876\u7ea7\u9879\u76ee\u7684 Committer | crossoverJie's Blog</li> <li>Good First Issue: Make your first open-source contribution</li> <li>\u96f2\u7aef GPU \u4f5c\u696d\u5e73\u53f0-COSCUP - Google \u7c21\u5831</li> <li>\u5b8c\u5168\u770b\u61c2 ARM \u8655\u7406\u5668\uff1aRISC \u8207 CISC \u662f\u4ec0\u9ebc\uff1f\u6b77\u53f2\u3001\u67b6\u69cb\u4e00\u6b21\u770b\u900f | T\u5ba2\u90a6</li> <li>\u8ffd MediaWiki \u9801\u9762\u5f88\u6162\u7684\u554f\u984c \u2013 Gea-Suan Lin's BLOG</li> <li>\u8d85\u6df7\u300c\u5e7d\u9748\u5de5\u7a0b\u5e2b\u300d\u6b63\u5543\u98df\u79d1\u6280\u5de8\u982d\uff01\u5168\u7403\u6bcf\u5e74\u6d6a\u8cbb 900 \u5104\u7f8e\u5143 - INSIDE</li> <li>\u5982\u4f55\u9009\u62e9\u53ef\u4ee5\u641e\u94b1\u7684\u6280\u672f\u6808 | crossoverJie's Blog</li> <li>\u7c21\u55ae\u7d00\u9304 2024 iThome \u9435\u4eba\u8cfd\u5b8c\u8cfd\u5fc3\u5f97</li> <li>#\u5206\u4eab google\u5e74\u672b\u8003\u7e3e\u7684\u7262\u9a37\u00a0-\u00a0\u79d1\u6280\u696d\u677f\u00a0|\u00a0Dcard</li> <li>AI \u6642\u4ee3\u8edf\u9ad4\u5de5\u7a0b\u5e2b\u7684\u6301\u7e8c\u5347\u7d1a - Mosky Liu - Speaker Deck</li> <li>\u842c\u4e8b\u842c\u7269\u7686\u662f LOG \u2014 \u7cfb\u7d71\u67b6\u69cb\u4e5f\u4f86\u9ede\u79d1\u666e - Dev.Poga</li> <li>\u6587\u4ef6<ul> <li>\u8aaa\u660e\u6587\u4ef6\u5982\u4f55\u904b\u4f5c\uff0c\u4e26\u4e14\u61c9\u7528\u5728\u4f60\u7684\u5c08\u6848 - PyCon 2017 How documentation works, and how to make it work for your project | louie_lu's blog</li> <li>GitHub - squidfunk/mkdocs-material: Documentation that simply works<ul> <li>Writing Your Docs - MkDocs</li> <li>mkdocs serve -a localhost:8888</li> </ul> </li> <li>GitHub - jgm/pandoc: Universal markup converter<ul> <li>\u4ecb\u7d39\u597d\u7528\u5de5\u5177\uff1aPandoc ( \u842c\u7528\u7684\u6587\u4ef6\u8f49\u63db\u5668 ) | The Will Will Web</li> </ul> </li> <li>grip, pypdf<ul> <li>grip: md to html<ul> <li>grip doc/control-node-install-config-guide.md --export doc/control-node-install-config-guide.html</li> </ul> </li> <li>pypdf: html to pdf<ul> <li>cat doc/control-node-install-config-guide.html | pyppdf -o doc/control-node-install-config-guide.pdf --goto temp</li> </ul> </li> <li>html to docx<ul> <li>docker run --rm --volume \"<code>pwd</code>:/data\" --user <code>id -u</code>:<code>id -g</code> pandoc/latex doc/control-node-install-config-guide.html -o doc/control-node-install-config-guide.docx</li> </ul> </li> </ul> </li> <li>Every pricing page should have GIFs (and how to make them)</li> <li>Diataxis-2024-COSCUP - Speaker Deck<ul> <li>\u4f7f\u7528 Diataxis \u5efa\u69cb\u9ad8\u8cea\u91cf\u6280\u8853\u6587\u4ef6 - jneo8 - HackMD</li> </ul> </li> <li>Other Open Source Documentation Platforms \u00b7 BookStack</li> <li>\u62dc\u8a17\u4f60\u770b\u770b\u6587\u4ef6\u597d\u4e0d\u597d?? - \u6dfa\u8ac7 Documentation System | Byte and Ink</li> <li>\u6211\u4e5f\u60f3\u597d\u597d\u5beb\u6587\u4ef6 - Documentation System \u7684\u5177\u9ad4\u5beb\u4f5c\u6307\u5f15 | Byte and Ink</li> <li>Basic<ul> <li>Release Notes</li> <li>Installation Guide</li> <li>User Guide</li> <li>Troubleshooting Guide</li> </ul> </li> </ul> </li> <li>CNCF<ul> <li>CNCF Landscape</li> <li>20231129 \u5982\u4f55\u9078\u64c7\u9069\u7576\u7684 CNCF Project \u4f86\u4f7f\u7528 - Speaker Deck</li> <li>CLOTributor</li> </ul> </li> <li>\u6388\u6b0a<ul> <li>\u958b\u653e\u6e90\u78bc\u6388\u6b0a\u6982\u89c0\uff08\u4e0a\uff09. \u5728 AMIS \u5de5\u4f5c\u6642\u7d93\u5e38\u9700\u8981\u4f7f\u7528\u6216\u662f\u4fee\u6539\u5404\u5f0f\u5404\u6a23\u7684\u958b\u653e\u6e90\u78bc\u8edf\u9ad4\uff0c\u7279\u5225\u662f\u5728\u2026 | by Yuren Ju | getamis</li> <li>\u958b\u653e\u6e90\u78bc\u6388\u6b0a\u6982\u89c0\uff08\u4e0b\uff09. \u5728\u672c\u6587\u7684\u4e0a\u7bc7\u6982\u7565\u8b1b\u89e3\u4e86\u958b\u6e90\u6388\u6b0a\u5b9a\u7fa9\u8207\u4f7f\u7528\u60c5\u5883\uff0c\u4f46\u662f\u4e0d\u540c\u7684\u6388\u6b0a\u4e4b\u9593\u9084\u662f\u6709\u7d30\u5fae\u7684\u5dee\u5225\u2026 | by Yuren Ju | getamis</li> <li>\u5e38\u898b\u958b\u6e90\u8edf\u9ad4\u6388\u6b0a\u689d\u6b3e\u5c0d\u7167\u8868 - \u9060\u8ddd\u4e0a\u73ed\u8edf\u9ad4\u5de5\u5177\u7db2\u7ad9 - \u8ca1\u5718\u6cd5\u4eba\u8cc7\u8a0a\u5de5\u696d\u7b56\u9032\u6703</li> <li>GPL\u985e</li> <li>\u5546\u696d\u5229\u7528\u600e\u9ebc\u884c\uff1f - \u5f9e\u958b\u6e90\u6388\u6b0a\u5341\u500b\u5e38\u898b FAQ \u4f86\u4e86\u89e3</li> <li>\u4f01\u696d\u4f7f\u7528\u958b\u653e\u539f\u59cb\u78bc\u8edf\u9ad4\u61c9\u6ce8\u610f\u4e4b\u6cd5\u5f8b\u554f\u984c\uff08\u53f0\u7063\uff09</li> <li>[\u958b\u6e90\u6559]\u6559\u6211\u6b63\u78ba\u9078\u64c7\u8edf\u9ad4\u6388\u6b0a - HackMD</li> </ul> </li> <li>\u9762\u8a66<ul> <li>\u958b\u767c\u4eba\u54e1\u7684\u9762\u8a66\u6307\u5357 - A developer\u2019s guide to interviewing | louie_lu's blog</li> <li>\u5e38\u898b Behavior questions \u554f\u984c\u8490\u96c6 - \u9762\u8a66\u5b98\u60f3\u77e5\u9053\u4ec0\u9ebc\u548c\u5982\u4f55\u56de\u7b54\u7684\u63d0\u793a - HackMD</li> <li>Reactive Resume - A free and open-source resume builder<ul> <li>GitHub - AmruthPillai/Reactive-Resume: A one-of-a-kind resume builder that keeps your privacy in mind. Completely secure, customizable, portable, open-source and free forever. Try it out today!</li> <li>Self-Hosting Reactive Resume using Docker | Reactive Resume</li> </ul> </li> <li>GitHub - xitanggg/open-resume: OpenResume is a powerful open-source resume builder and resume parser. https://open-resume.com/</li> <li>GitHub - casualwriter/casual-markdown-cv: markdown resume and other templates</li> <li>\u5982\u4f55\u8b93 FAANG \u7684\u4eba\u8cc7\u4e00\u773c\u770b\u4e0a\u4f60 - \u5c65\u6b77\u7bc7 | \u5de5\u7a0b\u5e2b\u82f1\u570b\u627e\u5de5\u4f5c\u7d00\u9304 :: \u6293\u4f4f\u90a3\u500b\u5de5\u7a0b\u5e2b</li> <li>\u5f9e\u9762\u8a66\u5b98\u89d2\u5ea6\u4f86\u770b\u7a0b\u5f0f\u9762\u8a66\uff1a\u5169\u5927\u80fd\u529b\u8207\u4e03\u500b\u968e\u6bb5 - \u7063\u5340\u4e0b\u5348\u8336</li> <li>\u5982\u4f55\u6253\u9020\u51fa\u8272\u7684\u5c65\u6b77 | Summer\u3002\u6851\u83ab\u3002\u590f\u5929</li> <li>\u5982\u4f55\u505a\u4e00\u4e2a\u597d\u7684\u9762\u8bd5</li> </ul> </li> <li>The Twelve-Factor App<ul> <li>[Architecture] The 12 factor App \u7b46\u8a18</li> <li>PEP 581 \u2013 Using GitHub Issues for CPython<ul> <li>twitter\u4e0b\u65b9\u6709\u4eba\u554f\u539f\u56e0\uff0c\u6709\u53e6\u4e00\u500b\u4eba\u56de\u8986\u4e86\u9019\u4e00\u7bc7\uff0c\u503c\u5f97\u5b78\u7fd2\uff0c\u628a\u70ba\u4ec0\u9ebc\u548c\u512a\u52e2\u98a8\u96aa\u90fd\u8aaa\u6e05\u695a\u4e86</li> </ul> </li> </ul> </li> </ul> </li> <li>Infographic<ul> <li> Software Development Lifecycle</li> <li></li> <li></li> <li></li> <li></li> </ul> </li>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E5%B8%AB%E7%9A%84%E5%B0%88%E6%A5%AD%E5%92%8C%E9%80%9A%E8%AD%98/#_2","title":"\u597d\u7684\u8edf\u9ad4\u7522\u54c1\u7bc4\u4f8b","text":"<ul> <li>Rundeck<ul> <li>\u89e3\u6c7a\u7684\u554f\u984c<ul> <li>Why Rundeck</li> <li>Scenario<ul> <li>Integrate with Ansible</li> <li>Manage Kubernetes with Rundeck</li> </ul> </li> </ul> </li> <li>\u6587\u4ef6<ul> <li>Install guide<ul> <li>container</li> </ul> </li> <li>Welcom/Demo project which help to understand the concept<ul> <li>Turorial</li> </ul> </li> </ul> </li> <li>\u6982\u5ff5\u8aaa\u660e<ul> <li>Getting Started</li> <li>Manual/User Guide</li> <li>Terminology</li> </ul> </li> <li>Community and Enterprise version</li> <li>Release Note</li> </ul> </li> </ul> <p>Install <pre><code>docker run --name rundeck-demo -d -p 4440:4440 -v rundeck-data:/home/rundeck/server/data -e RUNDECK_GRAILS_URL=http://172.19.57.10:4440 rundeck/rundeck:5.11.1\n</code></pre></p> <p>Install with Welcom/Demo project <pre><code>wget https://github.com/rundeck/welcome-project-community/archive/refs/heads/main.zip &amp;&amp; unzip main.zip\ncd welcome-project-community-main/\n# modify RUNDECK_GRAILS_URL and ciao port if 3000 is used\n# RUNDECK_GRAILS_URL: http://172.19.57.10:4440\n# ciao:\n#         container_name: ciao\n#         image: brotandgames/ciao\n#         ports:\n#           - '3001:3000'\ndocker compose up -d\n</code></pre></p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E5%B8%AB%E7%9A%84%E5%B0%88%E6%A5%AD%E5%92%8C%E9%80%9A%E8%AD%98/#_3","title":"\u5c08\u696d","text":"<p>\u50f9\u503c\u548c\u672c\u8cea</p> <p>\u5be6\u969b\u554f\u984c \u8cc7\u6599\u5efa\u6a21 \u8cc7\u6599\u4ea4\u63db \u8a08\u7b97 \u5132\u5b58 \u50b3\u8f38</p> <p>\u7d93\u7531\u5408\u7406\u7684\u8cc7\u6599\u5efa\u6a21\uff0c\u91dd\u5c0d\u4f7f\u7528\u60c5\u5883\u548c\u8cc7\u6599\u7279\u6027\uff0c\u5584\u7528\u8a08\u7b97\u3001\u5132\u5b58\u548c\u50b3\u8f38\u7684\u7279\u6027\uff0c\u4ee5\u5408\u7406\u7684\u8cc7\u6e90\u8655\u7406\u548c\u7ba1\u7406\u771f\u5be6\u4e16\u754c\u7684\u72c0\u6cc1\u548c\u60c5\u5883 https://twitter.com/j2hongming/status/1535272113153912832?s=20&amp;t=rtGJSf6ce97JcYRIozECCg</p> <p>\u8edf\u9ad4\u548c\u8edf\u9ad4\u5de5\u7a0b\u7684\u5dee\u7570\u5728\u65bc\uff0c\u5f8c\u8005\u91dd\u5c0d\u771f\u5be6\u7269\u7406\u4e16\u754c\u5efa\u69cb\u7684\u8cc7\u6599\u6a21\u578b\u80fd\u5920\u5728\u6642\u9593\u8ef8\u548c\u74b0\u5883\u7684\u63a8\u9032\u6240\u9020\u6210\u7684\u8b8a\u52d5\uff0c\u9084\u80fd\u5920\u4f7f\u7528\u5408\u7406\u7684\u6210\u672c\u4fdd\u6301\u7a69\u5b9a\u6027 https://twitter.com/j2hongming/status/1542369761052733440</p> <ul> <li>\u8cc7\u6599\u6a21\u578b\u5316: \u5206\u6790\u4e26\u5efa\u7acb\u5408\u7406\u8cc7\u6599\u6a21\u578b\u7684\u80fd\u529b<ul> <li>DDD</li> <li>\u8cc7\u6599\u5eab\u8a2d\u8a08<ul> <li>\u6dfa\u8ac7\u8cc7\u6599\u5eab\u6b63\u898f\u5316</li> <li>Modeling Game Player Data with Amazon DynamoDB</li> </ul> </li> </ul> </li> <li>\u6a21\u7d44\u5316\u8a2d\u8a08<ul> <li>\u53ef\u64f4\u5145\u6027\u548c\u53ef\u7dad\u8b77\u6027</li> </ul> </li> </ul> <p>\u901a\u8b58 \u5718\u9ad4\u5354\u4f5c \u6e9d\u901a\u5354\u8abf</p> <p>\u524d\u7aef \u8868\u9054\u80fd\u529b \u8cc7\u6599\u5206\u6790 \u8ad6\u8ff0\u80fd\u529b \u5f8c\u7aef \u601d\u8003\u80fd\u529b</p> <p>\u6e9d\u901a API\u4ecb\u9762\u8a2d\u8a08</p> <p>\u8cc7\u6599\u6a21\u578b\u5316 \u8cc7\u6599\u7d50\u69cb \u7269\u4ef6\u5c0e\u5411\u8a2d\u8a08</p> <p>\u8cc7\u6599\u6301\u4e45\u5316 \u8cc7\u6599\u5eab\u8a2d\u8a08</p> <p>\u958b\u767c\u8005\u53cb\u597d\u7684\u8edf\u9ad4\u8a2d\u8a08 Spotify System Architecture \u4f5c\u8005\u60f3\u8981\u8ddf\u5927\u5bb6\u89e3\u91cb\u66f4\u591a\u6709\u95dc\u65bc Spotify \u9019\u500b\u97f3\u6a02\u4e32\u6d41\u670d\u52d9\uff0c\u9996\u5148\u5f9e\u4ed6\u7684\u7cfb\u7d71\u529f\u80fd\u9700\u6c42\u958b\u59cb\u5206\u6790\u8d77\uff0c\u4f8b\u5982\u53ef\u4ee5\u4e0b\u8f09\u6b4c\u66f2\uff0c\u767c\u73fe\u97f3\u6a02\uff0cSpotify Connect\u2026\u7b49\uff0c\u63a5\u8457\u9810\u4f30\u4ed6\u7684 Scale \u6709\u591a\u5927\uff0c\u4f8b\u5982\u6709\u591a\u5c11\u4f7f\u7528\u8005\uff0c\u6b4c\u66f2\u7684\u4e32\u6d41\u54c1\u8cea\u9700\u8981\u7684\u983b\u5bec\uff0c\u53ef\u4ee5\u4e0b\u8f09\u591a\u5c11\u9996\u6b4c\uff0c\u652f\u63f4\u591a\u5c11\u7a2e\u8a9e\u8a00\u2026\u7b49\uff0c\u7136\u5f8c\u6839\u64da\u9019\u4e9b\u8981\u9ede\u5c07\u7cfb\u7d71\u67b6\u69cb\u7d66\u52fe\u52d2\u51fa\u4f86\uff0c\u4e26\u4e14\u9010\u6b65\u5206\u6790\u6bcf\u4e00\u500b\u5143\u4ef6\u4f7f\u7528\u7684\u6280\u8853\uff0c\u51fd\u5f0f\u5eab\u8207\u6f14\u7b97\u6cd5\u2026\u7b49\uff0c\u8b93\u8b80\u8005\u53ef\u4ee5\u8ddf\u8457\u6587\u7ae0\u4e00\u6b65\u4e00\u6b65\u53bb\u505a\u4e00\u6b21\u5b8c\u6574\u7684\u7cfb\u7d71\u67b6\u5206\u6790 \u8edf\u9ad4\u5de5\u7a0b\u662f\u500b\u9eb5\u5305\u6a5f \u8edf\u9ad4\u958b\u767c\u8005\u7684\u57f9\u990a</p> <p>\u6211\u7684\u4f7f\u7528\u8005\u662f\u8ab0 \u6211\u8981\u7ba1\u7406\u7684\u8cc7\u6599\u662f\u4ec0\u9ebc(Entity)(identifier) \u6211\u7684\u8cc7\u6599\u5132\u5b58\u9ad4\u6709\u54ea\u4e9b \u6211\u8981\u5982\u4f55\u5229\u7528\u8cc7\u6599\u8207\u5448\u73fe\uff0c\u683c\u5f0f\u70ba\u4f55</p> <p>\u8981\u8a18\u4f4f\u4ec0\u9ebc \u600e\u9ebc\u8a18(\u7d50\u69cb, \u683c\u5f0f, \u5b58\u53d6) \u8a18\u591a\u4e45</p> <p>https://twitter.com/j2hongming/status/1508956605098106883?s=21&amp;t=uSFa7pP8G6ylwy-FZ8qkuA \u91d0\u6e05task\u662fio bound\u9084\u662fcpu bound \u91d0\u6e05data\u662fOLTP\u9084\u662fOLAP \u91d0\u6e05\u8f38\u5165\u548c\u8f38\u51fa</p> <p>https://rezio.io/zh-TW/product API\u6587\u4ef6 \u4f7f\u7528\u6307\u5357 \u7cfb\u7d71\u72c0\u614b</p> <p>API https://app.swaggerhub.com/apis-docs/nwo665/Payment_Gateway/1.0.0#/subscription/post__version__subscription_prorate_info</p> <p>API Operations - Cyren Cloud Security Documentation - Confluence Create License - Cyren Cloud Security Documentation - Confluence UX https://xd.adobe.com/view/bf694d9c-bcfc-4218-b9e3-b4d8becac546-ea3a/screen/99079d77-fa98-472c-a9a3-694d3c40f894/</p> <p>real time multiplayer edit How Multiplayer Data Structures Work Diving into Conflict-Free Replicated Data Types (CRDTs) | Redis</p> <p>\u5de5\u7a0b - MySQL Partitioning \u512a\u5316\u4e4b\u8def. 17 APP \u4e0a\u7dda\u81f3\u4eca\u5df2\u7d93\u597d\u5e7e\u5e74\u4e86\uff0c\u96a8\u8457\u6642\u9593\u904e\u53bb DB\u2026 | by Jiazhen | 17LIVE Tech Insight | Medium - \u5728 17 Media \u64d4\u4efb SRE \u7684\u6240\u898b\u53ca\u6240\u805e | by 17 Media Technology | 17LIVE Tech Insight | Medium</p> <p>\u8cc7\u6599 - 17 Media \u8cc7\u6599\u751f\u547d\u9031\u671f\u6982\u8ff0. Data team \u5982\u4f55\u5229\u7528\u7522\u751f\u7684\u8cc7\u6599\u5b8c\u6210\u71df\u904b\u7684\u6578\u64da\u5206\u6790 | by 17 Media Technology | 17LIVE Tech Insight | Medium</p> <p>License - Sentinel EMS | Entitlement Management System</p> <p>\u8996\u89ba\u5316 - \u73a9\u5177\u70cf\u6258\u90a6: \u7c21\u55ae\u6613\u4e0a\u624b\u7684\u8cc7\u6599\u8996\u89ba\u5316\u7db2\u7ad9\uff1a rawgraphs</p> <p>Demo - Make Your CLI Demos a Breeze with Zero Stress and Zero Mistakes | Martin Heinz | Personal Website &amp; Blog</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/","title":"\u8edf\u9ad4\u9700\u6c42\u6e9d\u901a","text":"<p>Cynefin Framework =&gt; 2-2 \u9700\u6c42\u5206\u5c64 =&gt; 2-3 \u8a2d\u8a08\u554f\u984c\u7684\u7522\u751f\u56e0\u5b50 (Generators of design problems) =&gt; 2-5 \u7a40\u5009\u6548\u61c9</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#2","title":"\u7b2c2\u7ae0 \u6838\u5fc3\u89c0\u5ff5 \u8edf\u9ad4\u9700\u6c42","text":"<p>\u503c\u5f97\u4e00\u770b - \u55ae\u5143\u4e09, \u55ae\u5143\u56db - \u55ae\u5143\u4e94, \u55ae\u5143\u516d - \u55ae\u5143\u4e03, \u55ae\u5143\u516b</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_2","title":"\u55ae\u5143\u4e00","text":"<p>\u4e0d\u66c9\u5f97\u70ba\u4ec0\u9ebc\u6703\u63d0\u51fa\u8de8\u8077\u80fd\u5718\u968a\u7684\u8aaa\u660e, \u8108\u7d61\u4e0d\u77e5\u5f9e\u4f55\u800c\u4f86</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_3","title":"\u55ae\u5143\u4e8c","text":"<p>\u6240\u7528\u7684\u554f\u984c\u5206\u985e\u6846\u67b6\u611f\u89ba\u6709\u9ede\u9ad8\u5927\u4e0a, \u7406\u8ad6, \u4e0d\u66c9\u5f97\u5be6\u52d9\u4e0a\u771f\u6b63\u7684\u60c5\u6cc1</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_4","title":"\u55ae\u5143\u4e09","text":"<p>\u503c\u5f97\u4e00\u770b, \u6982\u5ff5\u4e0a\u5c31\u662fExternal\u548cInternal\u7684\u611f\u89ba; </p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_5","title":"\u55ae\u5143\u56db","text":"<p>\u5c55\u793a\u4e86\u55ae\u5143\u4e09\u7684\u5be6\u969b\u7bc4\u4f8b, \u5148\u5206\u985e\u518d\u5206\u5c64\u7684\u6280\u5de7\u53ef\u4ee5\u5b78\u8d77\u4f86\u4e26\u5957\u7528\u5728\u500b\u4eba\u8cc7\u8a0a\u7cfb\u7d71v2\u95dc\u65bc\u4efb\u52d9\u7684\u90e8\u5206 \u55ae\u5143\u4e09\u548c\u55ae\u5143\u56db\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\u770b</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_6","title":"\u55ae\u5143\u4e94","text":"<p>\u4e3b\u8981\u8a0e\u8ad6\u5728\u6642\u9593\u548c\u8cc7\u6e90\u6709\u9650\u7684\u689d\u4ef6\u4e0b, prioritize something \u7684\u65b9\u6cd5\u8ad6, \u900f\u904e\u8a2d\u8a08\u554f\u984c\u7684\u5206\u5c64 (Hierarchy of design problems)</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_7","title":"\u55ae\u5143\u516d","text":"<p>\u8a0e\u8ad6\u9700\u6c42\u5206\u5c64\u7684\u5404\u5c64\u4e4b\u9593\u5c0d\u65bc\u8edf\u9ad4\u67b6\u69cb\u53ef\u80fd\u6703\u9020\u6210\u7684\u5f71\u97ff, \u55ae\u5143\u4e94\u548c\u55ae\u5143\u516d\u53ef\u4ee5\u653e\u5728\u4e00\u8d77\u770b</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_8","title":"\u55ae\u5143\u4e03","text":"<p>\u8a0e\u8ad6\u529f\u80fd\u6027\u9700\u6c42\u548c\u975e\u529f\u80fd\u6027\u9700\u6c42\u7684\u7279\u6027, \u5982\u4f55\u5f9e\u9700\u6c42\u53bb\u8b58\u5225\u80cc\u5f8c\u7684\u6280\u8853\u98a8\u96aa, \u76f8\u5c0d\u55ae\u5143\u4e09\u548c\u56db\uff0c\u89ba\u5f97\u6e05\u695a\u7684\u7a0b\u5ea6\u76f8\u5c0d\u8f03\u4f4e</p> <p>\u529f\u80fd\u6027\u9700\u6c42\u6307\u5b9a\u4e86\u8edf\u9ad4\u5728\u67d0\u4e9b\u8f38\u5165\u4e0b\uff0c\u61c9\u8a72\u5982\u4f55\u5de5\u4f5c\u548c\u8868\u73fe\u3002\u529f\u80fd\u6027\u9700\u6c42\u53ef\u4ee5\u662f\u5c0d\u8f38\u5165\u7684\u5167\u5bb9\u3001\u8f38\u51fa\u7684\u5167\u5bb9\u3001\u6216\u662f\u884c\u70ba\u64cd\u4f5c\u7b49\u7b49\u7684\u529f\u80fd\u4fee\u6539\u3002 \u975e\u529f\u80fd\u6027\u9700\u6c42\u662f\u90a3\u4e9b\u70ba\u826f\u597d\u7528\u6236\u9ad4\u9a57 (Good User Experience) \u5960\u5b9a\u57fa\u790e\u7684\u9700\u6c42\u3002\u5b83\u4fdd\u8b49\u4e86\u8edf\u9ad4\u7684\u8cea\u91cf\u5c6c\u6027\u4e26\u78ba\u4fdd\u529f\u80fd\u7684\u6709\u6548\u6027 \u5f9e\u9700\u6c42\u8b58\u5225\u6280\u8853\u98a8\u96aa:  - \u6574\u5408\u9ede     - \u5bb9\u932f\u3001\u53ef\u7dad\u8b77\u6027\u3001\u53ef\u9760\u6027 - \u6301\u7e8c\u4e0d\u80fd\u4e2d\u65b7     - \u53ef\u9760\u6027  - \u6642\u9593\u983b\u7387     - \u6548\u80fd\u3001\u6e96\u6642\u3001\u53ef\u9760 - \u6578\u91cf\u898f\u6a21 by \u6578\u91cf, \u8655\u7406\u6578\u91cf, \u5730\u5340\u7684\u8b8a\u5316     - \u53ef\u7dad\u8b77\u6027, \u6548\u80fd, \u53ef\u9760\u6027  - \u985e\u5225\u64f4\u5145     - \u53ef\u7dad\u8b77\u6027</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_9","title":"\u55ae\u5143\u516b","text":"<p>\u5f9e\u4e09\u500b\u89d2\u5ea6\u5b9a\u7fa9\u975e\u529f\u80fd\u6027\u9700\u6c42 - \u696d\u52d9\u5bb9\u91cf\u8981\u6c42     - Throughput: \u55ae\u4f4d\u6642\u9593\u5167\u5b8c\u6210\u7684\u6b21\u6578     - Latency: \u4e00\u6b21\u8981\u82b1\u591a\u4e45\u6642\u9593     - Concurrent - \u7528\u6236\u9ad4\u9a57 - \u707d\u96e3\u56de\u5fa9</p> <p>Concurrent = Throughput * Latency</p> <p>\u4f8b\u5b501: \u5546\u696d\u76ee\u6a19\u662f\u6bcf\u500b\u6708\u6d3b\u8e8d\u7528\u6236 100 \u842c\u4eba, \u4f3a\u670d\u5668\u541e\u5410\u91cf \u7528\u6236\u6578\u91cf =&gt; \u7528\u6236\u7684\u6bcf\u79d2\u8981\u5b8c\u6210\u7684\u8acb\u6c42\u91cf =&gt; \u4f3a\u670d\u5668\u541e\u5410\u91cf \u5e73\u5747\u5206\u6563 vs \u5c16\u5cf0\u6d41\u91cf\u6821\u6b63</p> <p>\u4f8b\u5b502: \u8981\u6c42\u67d0\u4ef6\u4e8b\u5728\u591a\u4e45\u6642\u9593\u5167\u5b8c\u6210, \u8a08\u7b97\u6392\u968a\u6d41\u7a0b\u7684\u5bb9\u91cf \u7528\u6236\u7684\u5ee3\u544a\u9001\u5be9\u5f8c\u572824\u5c0f\u6642\u5167\u5b8c\u6210 \u7528\u6236\u767c\u51fa\u5fd8\u8a18\u5bc6\u78bc\u8981\u6c42\u5f8c\uff0c\u8981\u57283\u5206\u9418\u5167\u767c\u9001\u8a8d\u8b49\u7c21\u8a0a</p> <p>\u6392\u968a\u6578 = \u8655\u7406\u901f\u7387 * \u5141\u8a31\u5ef6\u9072       = 2 (\u6b21/\u5206\u9418) * 3(\u5206\u9418/\u6b21)       = 6 3\u5206\u9418 =&gt; \u8655\u7406\u901f\u7387 2 (\u6b21/\u5206\u9418) =&gt; \u6392\u968a\u6578 6 3\u5206\u9418\u662f\u5df2\u77e5\uff0c\u8981\u80fd\u5920\u63a8\u4f30\u51fa\u672a\u77e5\u7684\u8655\u7406\u901f\u7387 2 (\u6b21/\u5206\u9418)\u548c \u6392\u968a\u6578 6</p> <p>\u7576\u6392\u968a\u6578\u904e\u9577\u7684\u8a71\uff0c\u53ef\u4ee5 - \u63d0\u5347\u8655\u7406\u6548\u7387 - \u964d\u4f4e\u6392\u968a\u58d3\u529b(\u900f\u904epriority)</p> <p>\u4f8b\u5b503: \u91cd\u8981\u6b65\u9a5f\u6578\u503c\u91cf\u6e2c \u8a08\u7b97\u91cd\u8981\u6b65\u9a5f\u7684\u5e73\u5747\u503c\uff0c\u6700\u5927\u503c\u4ee5\u53ca\u6700\u5c0f\u503c \u8a08\u7b97\u91cd\u8981\u6b65\u9a5f\u9593\u82b1\u8cbb\u7684\u6642\u9593\uff0c\u8a2d\u7f6e\u8b66\u5831</p> <p>PageSpeed Insights</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_10","title":"\u55ae\u5143\u4e5d","text":"<p>\u5206\u4eab\u9700\u6c42\u6e9d\u901a\u8a0e\u8ad6\u904e\u7a0b\u4e2d\u5e38\u898b\u7684\u627f\u8afe\uff0c\u885d\u7a81\u548c\u548c\u58d3\u529b\u7684\u7d93\u9a57\u548c\u61c9\u5c0d, \u53c3\u8003\u7528\uff0c\u4e0d\u4e00\u5b9a\u8981\u5168\u4fe1</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#3","title":"\u7b2c3\u7ae0 \u6838\u5fc3\u89c0\u5ff5 \u8edf\u9ad4\u67b6\u69cb","text":"<p>\u503c\u5f97\u4e00\u770b - \u55ae\u5143\u4e8c - \u55ae\u5143\u4e09 - \u55ae\u5143\u56db - \u55ae\u5143\u516d</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_11","title":"\u55ae\u5143\u4e00","text":"<p>\u67b6\u69cb\u672c\u8cea\u70ba\u5143\u4ef6\u4e4b\u9593\u7684\u5207\u5206\u8207\u6e9d\u901a\uff0c\u7d66\u51fa\u5167\u805a\u548c\u8026\u5408\u7684\u8aaa\u660e\uff0c\u4f46\u5c0f\u5fc3\u8ff7\u5931\u5728\u5176\u4e2d</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_12","title":"\u55ae\u5143\u4e8c","text":"<p>\u63d0\u5230\u5206\u5c64\u67b6\u69cb(Layers)\u8207\u5176\u512a\u7f3a\u9ede\uff0c\u958b\u653e\u5c64(\u904a\u6a02\u5712\u7684\u5feb\u901f\u901a\u9053) \u63d2\u4ef6\u67b6\u69cb(Plugin-in Architecture), Plugin\u4e4b\u9593\u5fc5\u9808\u900f\u904e\u6838\u5fc3\u7cfb\u7d71\u624d\u80fd\u505a\u6e9d\u901a, \u8209\u4f8b\u4f86\u8aaa: \u700f\u89bd\u5668\u64f4\u5145\u529f\u80fd, iOS APP</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_13","title":"\u55ae\u5143\u4e09","text":"<p>\u8b1b\u89e3\u7ba1\u7dda\u8207\u7be9\u9078\u5668\u9019\u500b\u67b6\u69cb\u7684\u7279\u6027</p> <p>\u6b64\u8edf\u9ad4\u67b6\u69cb\u901a\u5e38\u88ab\u61c9\u7528\u5728\u300c\u6578\u64da\u6d41\u300d\u7b49\u8cc7\u6599\u8655\u7406\u7684\u7cfb\u7d71\uff0c\u4f8b\u5982\uff1a\u5831\u8868\u7cfb\u7d71\u7684\u6578\u64da\u6d41\u8655\u7406\u3001\u71b1\u9580\u95dc\u9375\u5b57\u7684\u6578\u64da\u6d41\u8655\u7406\u7b49\u7b49</p> <p>\u4f7f\u7528\u7684\u72c0\u614b\u61c9\u8a72\u76e1\u91cf\u5c11\u4e14\u7c21\u55ae\uff0c\u4e14\u907f\u514d\u72c0\u614b\u76f8\u4f9d\u6027 \u82e5\u662f\u8981\u8d77\u8dd1\u524d\u8981\u78ba\u8a8d\u592a\u591a\u72c0\u614b (State)\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u5728\u62bd\u63db/\u6dfb\u52a0\u7be9\u9078\u5668\u4f4d\u7f6e\u7684\u6642\u5019\uff0c\u4e5f\u8981\u76f8\u5c0d\u61c9\u5730\u8abf\u6574\u8981\u78ba\u8a8d\u7684\u72c0\u614b (State)\uff0c\u72c0\u614b\u904e\u591a\u6216\u5177\u6709\u76f8\u4f9d\u6027\u7684\u60c5\u6cc1\uff0c\u4fbf\u4e0d\u9069\u5408\u4f7f\u7528\u6b64\u6a21\u5f0f\u3002</p> <p>\u4ee5\u5927\u968a\u63a5\u529b\u70ba\u4f8b</p> <ul> <li>\u7ba1\u9053\u8207\u7be9\u9078\u5668\u6a21\u5f0f - Azure</li> </ul> <p>:::info Allen\uff0e5 \u500b\u6708\u524d03 \u8001\u5e2b\u597d\uff0c</p> <p>\u5176\u5be6\u6211\u4e5f\u4e0d\u77e5\u9053\u8ddf\u9019\u500b\u4e3b\u984c\u6709\u6c92\u6709\u95dc</p> <p>\u76ee\u524d\u6211\u5728\u8655\u7406\u4ee5\u6392\u7a0b\u53bb\u5f59\u6574\u4ea4\u6613\u8cc7\u6599\u6210\u5831\u8868\u8cc7\u6599</p> <p>\u5206\u5225\u7522\u751f\u696d\u52d9\u8cc7\u6599\u3001\u91d1\u9322\u8cc7\u6599\u5b58\u5165table</p> <p>Q1.\u4e00\u822c\u800c\u8a00\uff0c\u9019\u4e9b\u8cc7\u6599\u80fd\u600e\u9ebc\u7e7c\u7e8c\u8655\u7406?</p> <p>\u5047\u8a2d\u6211\u6574\u7406\u4e8650\u7b46\u8cc7\u6599\uff0c\u8655\u7406\u5b8c\u5b58\u5165\u8cc7\u6599\u5eab\u5f8c\uff0c\u7dca\u63a5\u8005\u547c\u53eb\u53e6\u4e00\u6bb5\u7a0b\u5f0f\uff0c\u91dd\u5c0d\u901950\u7b46\u7e7c\u7e8c\u8655\u7406\u50cf\u6708\u71df\u6536\u6216\u6210\u9577\u7387\u4e4b\u985e\u7684\u55ce?</p> <p>Q2.\u5831\u8868\u7684\u8cc7\u6599\u7b97\u662f\u53ca\u6642\u66f4\u52d5\u662f\u5e38\u614b\u55ce?</p> <p>\u8b6c\u5982\uff0c\u4eca\u5929\u9032\u4e86\u4e00\u7b46\u4ea4\u6613\uff0c\u6211\u5c31\u8a72\u5728\u71df\u6536\u6216\u6210\u9577\u7387\u770b\u5230\u8b8a\u52d5</p> <p>\u5f9e\u524d\u8f29\u7d93\u9a57\u90fd\u662f\u53ef\u80fd\u6708\u4e2d\u6708\u5e95\u6216\u6bcf\u500b\u79ae\u62dc\u624d\u6574\u7406\u8cc7\u6599\uff0c\u4f46\u5ba2\u6236\u7684\u8981\u6c42\u90fd\u662f\u7576\u65e5\u770b\u5230\u8b8a\u5316</p> <p>Q3.\u56e0\u70ba\u696d\u52d9\u8cc7\u6599\u53ef\u80fd\u6703\u5728\u4e00\u500b\u6708\u5f8c\u6216\u8a31\u4e45\u4e4b\u5f8c\uff0c\u9032\u884c\u6539\u52d5</p> <p>\u56e0\u70ba\u4ea4\u6613\u8cc7\u6599\u8207\u5831\u8868\u8cc7\u6599\u7684\u8655\u7406\u662f\u4e0d\u76f8\u5e72\u7684\uff0c\u90a3\u5831\u8868\u8cc7\u6599\u812b\u9264\uff0c\u6709\u4ec0\u9ebc\u5efa\u8b70\u7684\u8655\u7406\u65b9\u5f0f\u55ce?</p> <p>(\u6211\u6709\u8a66\u904e\u589e\u52a0\u72c0\u614b\u8207\u6642\u9593\uff0c\u8b6c\u5982\u8dd1\u4e94\u5e74\u524d\u5230\u4eca\u5929\uff0c\u6216\u4e00\u5e74\u524d\u5230\u4eca\u5929\u6488\u53d6\u8b8a\u66f4\u72c0\u614b\uff0c\u4f46\u8cc7\u6599\u91cf\u4e00\u5b9a\u6703\u904e\u5927\u5c0e\u81f4timeout) :::</p> <p>:::success Hi Allen, \u4ee5\u4e0b\u5206\u5225\u56de\u8986\u554f\u984c\uff1a</p> <p>Q1.\u4e00\u822c\u800c\u8a00\uff0c\u9019\u4e9b\u8cc7\u6599\u80fd\u600e\u9ebc\u7e7c\u7e8c\u8655\u7406? \u9996\u5148\uff0c\u5831\u8868\u8cc7\u6599\u5132\u5b58\u7684\u4f4d\u7f6e\u901a\u5e38\u662f\u7368\u7acb\u7684\uff0c\u5982\u679c\u8cc7\u6599\u91cf\u5927\u7684\u8a71\uff0c\u4e0d\u6703\u9078\u64c7\u50b3\u7d71\u7684 DBMS \u505a\u5132\u5b58\uff0c\u800c\u662f\u6703\u9078\u64c7 Hive \u7b49\u5927\u6578\u64da\u7684\u5132\u5b58\u65b9\u5f0f\u3002</p> <p>\u8cc7\u6599\u6703\u5b9a\u671f(\u4f8b\u5982\uff1a\u6bcf\u4e00\u5929)\u5411\u5831\u8868\u7cfb\u7d71\u7684\u5132\u5b58\u7a7a\u9593\u9001\uff0c\u5728\u9001\u7684\u904e\u7a0b\u4e2d\u6703\u5c0d\u8cc7\u6599\u505a\u9810\u5148\u8655\u7406\uff0c\u4f8b\u5982\uff1a\u591a\u4efd\u8cc7\u6599\u5148 join \u8d77\u4f86\uff0c\u6216\u662f\u505a\u7be9\u9078 (filter)\uff0c\u6216\u662f\u52a0\u4e0a timestamp \u7b49\u7b49\u8a0a\u606f\u3002\u7c21\u55ae\u4f86\u8aaa\uff0c\u5148\u628a\u8cc7\u6599\u6574\u7406\u6210\u9069\u5408\u8f38\u51fa\u6210\u5831\u8868\u7684\u6a23\u5b50\uff0c\u7576\u4f60\u5728\u5beb\u5831\u8868\u7a0b\u5f0f\u7684\u6642\u5019\uff0c\u8cc7\u6599\u6bd4\u8f03\u65b9\u4fbf\u6488\u53d6\u3002</p> <p>Q2.\u5831\u8868\u7684\u8cc7\u6599\u7b97\u662f\u53ca\u6642\u66f4\u52d5\u662f\u5e38\u614b\u55ce? \u9019\u4e00\u9ede\u4e3b\u8981\u770b\u696d\u52d9\u9700\u6c42\uff0c\u6642\u9593\u9700\u8981\u7cbe\u78ba\u5230\u6bcf\u5206\u9418\uff1f\u6bcf\u5c0f\u6642\uff1f\u6bcf\u5929\uff1f\u6216\u662f\u6bcf\u500b\u6708\uff1f\u5404\u7a2e\u4e0d\u540c\u7684\u5373\u6642\u6027\u66f4\u52d5\u90fd\u662f\u6709\u53ef\u80fd\u7684\u3002</p> <p>\u4ee5\u4f60\u7684\u4f8b\u5b50\u4f86\u8aaa\uff0c\u5ba2\u6236\u8981\u6c42\u7cbe\u78ba\u5230\u6bcf\u5929\u7684\u7d1a\u5225\uff0c\u53ef\u4ee5\u53c3\u8003 Apache Druid \u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u5b83\u7684\u539f\u7406\u662f\u4e8b\u524d\u5e6b\u4f60\u628a\u5404\u500b\u6642\u9593\u7dad\u5ea6\u7684\u8cc7\u6599\u5148\u805a\u5408 (Aggregate) \u8d77\u4f86\uff0c\u4f8b\u5982\uff1a\u7576\u4f60\u628a\u6bcf\u5c0f\u6642\u7684\u8cc7\u6599\u5b9a\u671f\u9001\u7d66 Druid\uff0c\u5b83\u53ef\u4ee5\u5e6b\u4f60\u628a\u6bcf\u5c0f\u6642\u7684\u8cc7\u6599\u8a08\u7b97\u6210\u300c\u6bcf\u5929\u300d\u7684\u71df\u6536\uff0c\u4e8b\u5148\u5132\u5b58\u5728\u4e00\u500b\u5730\u65b9\uff0c\u7576\u4f60\u8981\u6488\u300c\u6bcf\u5468\u300d\u7684\u71df\u6536\u6642\uff0c\u56e0\u70ba\u5b83\u5df2\u7d93\u4e8b\u524d\u805a\u5408\u597d\u300c\u6bcf\u5929\u300d\u7684\u8cc7\u6599\uff0c\u6240\u4ee5 Druid \u53ef\u4ee5\u5f88\u5feb\u5730\u7528\u300c\u6bcf\u5929\u300d\u7684\u8cc7\u6599\u7b97\u51fa\u300c\u6bcf\u9031\u300d\u7684\u8cc7\u6599\u3002</p> <p>Q3.\u56e0\u70ba\u696d\u52d9\u8cc7\u6599\u53ef\u80fd\u6703\u5728\u4e00\u500b\u6708\u5f8c\u6216\u8a31\u4e45\u4e4b\u5f8c\uff0c\u9032\u884c\u6539\u52d5</p> <p>\u5728\u5831\u8868\u7684\u9818\u57df\uff0c\u8cc7\u6599\u6709\u5206 Dimension Data \u8207 Fact Data \u5169\u7a2e\uff0c\u5982\u679c\u662f Fact Data \u901a\u5e38\u662f\u4e0d\u6703\u5c0d\u539f\u59cb\u6578\u64da\u505a\u4fee\u6539\u7684\u3002</p> <p>\u807d\u8d77\u4f86\u4f60\u9762\u5c0d\u7684\u554f\u984c\u662f\uff1a \u9762\u5c0dDimension Data \u7684\u8b8a\u52d5\uff0c\u5e0c\u671b\u5831\u8868\u7cfb\u7d71\u8207\u4ea4\u6613\u7cfb\u7d71\u812b\u9264\u3002</p> <p>\u5728\u8655\u7406\u4e0a\uff0c\u5831\u8868\u7cfb\u7d71\u7684 Dimention Data \u4e5f\u9700\u8981\u5f9e\u4ea4\u6613\u7cfb\u7d71\u8907\u88fd\u4e00\u4efd\u51fa\u4f86\u5230\u5831\u8868\u7cfb\u7d71\u7684\u5132\u5b58\u7a7a\u9593\u7684\u3002\u505a\u6cd5\u540c\u6a23\u662f\u5b9a\u671f\u5730\u628a\u8cc7\u6599\u5012\u51fa\u4f86(\u4f8b\u5982\uff1a\u6bcf\u4e00\u5929)\u3002\u9019\u88e1\u6709\u500b\u5c0f\u7d30\u7bc0\u9700\u8981\u6ce8\u610f\uff0c\u6bcf\u4e00\u7b46 Dimention Data \u662f\u6709\u591a\u500b\u7248\u672c\u7684\uff0c\u6240\u4ee5\u6b04\u4f4d\u8981\u52a0\u4e0a\u300c\u8f09\u5165\u6642\u9593\u300d\u7684\u7dad\u5ea6\uff0c\u9019\u500b\u300c\u8f09\u5165\u6642\u9593\u300d\u5c31\u662f\u4f60\u628a\u8cc7\u6599\u5012\u51fa\u4f86\u7684\u6642\u9593\uff0c\u8cc7\u6599\u6b04\u4f4d\u985e\u4f3c\uff1a</p> <p>\u5ba2\u6236\u5730\u5740, \u5ba2\u6236\u540d\u7a31, \u8f09\u5165\u6642\u9593</p> <p>\u5982\u6b64\u4e00\u4f86\uff0c\u4f60\u5728\u8f38\u51fa\u5831\u8868\u7684\u6642\u5019\uff0c\u5c31\u53ef\u4ee5\u77e5\u9053\u8981\u53bb\u6293\u54ea\u500b\u6642\u9593\u7684 Dimension Data \u4f86\u548c Fact table \u9032\u884c join\uff0c\u8f38\u51fa\u8cc7\u6599\u53ef\u4ee5\u7cbe\u78ba\u5230\u4e00\u5e74\u524d\u7684\u67d0\u4e00\u5929\u7684 Dimension\u3002\u5982\u679c\u4f60\u7684\u8cc7\u6599\u592a\u591a\uff0c\u5efa\u8b70\u53ef\u4ee5\u653e\u5230\u5927\u6578\u64da\u76f8\u95dc\u7684\u5132\u5b58\u7a7a\u9593\u4f86\u9032\u884c\u64cd\u4f5c\uff0c\u4f8b\u5982\uff1aHive \u7b49\u7b49 :) :::</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_14","title":"\u55ae\u5143\u56db","text":"<p>\u4e8b\u4ef6\u9a45\u52d5\u67b6\u69cb\uff0c\u4ee5\u90f5\u5c40\u70ba\u4f8b\u8aaa\u660e\u96c6\u4e2d\u5f0f\u548c\u975e\u96c6\u4e2d\u5f0f\uff0c</p> <p>\u4ee5\u5ee3\u544a\u66f4\u65b0\u70ba\u4f8b\u89e3\u91cb\u96c6\u4e2d\u5f0f\uff0c\u9700\u8981\u6709\u4e8b\u4ef6\u4e2d\u4ecb\uff0c\u4e8b\u4ef6\u4e4b\u9593\u7121\u76f8\u4f9d\u6027\uff0c\u9032\u5165\u4e8b\u4ef6\u968a\u5217\u5f8c\u4e0d\u4fdd\u8b49\u4f55\u6642\u57f7\u884c</p> <p>\u5df2\u522a\u9664\u5ee3\u544a\u70ba\u4f8b\u89e3\u91cb\u975e\u96c6\u4e2d\u5f0f\uff0c\u4e8b\u4ef6\u4e4b\u9593\u6709\u76f8\u4f9d\u6027</p> <p>\u512a\u52e2: \u4e8b\u4ef6\u8655\u7406\u5668\u5f7c\u6b64\u7368\u7acb\uff0c\u5bb9\u6613\u64f4\u5145</p> <p>\u52a3\u52e2: \u4e8b\u4ef6\u76f8\u4f9d\u6027\u904e\u591a\uff0c\u51fa\u554f\u984c\u6642\u96e3\u4ee5\u8ffd\u8e64\uff1b\u72c0\u614b\u4e00\u81f4\u6027\u96e3\u9054\u6210</p> <p>\u5982\u4f55\u514b\u670d\u4e00\u81f4\u6027\u8b70\u984c: </p> <ol> <li>\u8b80\u53d6\u6a21\u578b: \u5be6\u4f5c\u55ae\u7d14\uff0c\u50c5\u80fd\u8655\u7406\u5c0d\u65bc\u6642\u9593\u5dee\u8f03\u4e0d\u654f\u611f\u7684\u8cc7\u6599\u985e\u578b\uff0c\u7121\u6cd5\u8655\u7406\u4ea4\u6613(transaction)\u985e\u578b\u7684\u8cc7\u6599</li> <li>\u5206\u5272\u4e8b\u4ef6\u968a\u5217: \u76f4\u63a5\u8b80\u53d6\u968a\u5217\u5167\u5bb9\uff0c\u4f46\u5fc5\u9808\u5b9a\u671f\u66f4\u65b0\u8d77\u59cb\u72c0\u614b</li> <li>\u6a02\u89c0\u9396: \u8655\u7406\u8cc7\u6599\u5beb\u5165\u885d\u7a81\u554f\u984c\uff0c\u95dc\u9375\u5728\u65bc\u5beb\u5165\u524d\u8981\u78ba\u8a8d\uff0c\u6211\u5beb\u7684\u8cc7\u6599\u6709\u6c92\u6709\u88ab\u5176\u4ed6\u4eba\u6539\u904e</li> </ol>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_15","title":"\u55ae\u5143\u4e94","text":"<p>\u8861\u91cf\u65b9\u5f0f\u8207\u5be6\u6230\u8981\u9ede</p> <p>\u8edf\u9ad4\u67b6\u69cb\u6703\u63ed\u9732\u8a72\u8edf\u9ad4\u7684\u91cd\u5927\u8a2d\u8a08\u6c7a\u5b9a</p> <p>\u6700\u7d42\u76ee\u7684\u70ba\u964d\u4f4e\u4fee\u6539\u6210\u672c</p> <p>\u597d\u7684\u67b6\u69cb \u21d2 \u6210\u529f\u964d\u4f4e\u4fee\u6539\u6210\u672c\u7684\u67b6\u69cb</p> <p>\u67b6\u69cb\u8207\u529f\u80fd: \u4e0d\u4e00\u5b9a\u7e3d\u662f\u76f8\u95dc</p> <p>\u67b6\u69cb\u60f3\u50b3\u905e\u7684\u610f\u5716</p> <ul> <li>\u4e8b\u4ef6\u9a45\u52d5\u67b6\u69cb\u6bd4\u8f03\u96e3\u8655\u7406\u4ea4\u6613\u985e\u7684\u8cc7\u6599</li> <li>\u7ba1\u7dda\u8207\u7be9\u9078\u5668\u67b6\u69cb\u6bd4\u8f03\u96e3\u8655\u7406\u8207\u5916\u90e8\u72c0\u614b\u7684\u806f\u7e6b</li> </ul> <p>\u67b6\u69cb\u8981\u80fd\u4fc3\u9032\u958b\u767c\u3001\u90e8\u5c6c\u8207\u7dad\u8b77</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_16","title":"\u55ae\u5143\u516d","text":"<p>\u5b78\u6703\u8a55\u4f30\u7cfb\u7d71\u9650\u5236</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#4","title":"\u7b2c4\u7ae0 \u6838\u5fc3\u89c0\u5ff5 \u654f\u6377\u958b\u767c","text":"<p>\u503c\u5f97\u4e00\u770b</p> <ul> <li>\u55ae\u5143\u4e09</li> <li>\u55ae\u5143\u56db(\u96c6\u5927\u6210)</li> </ul>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_17","title":"\u55ae\u5143\u4e09: \u9700\u6c42\u600e\u9ebc\u7d00\u9304","text":"<p>\u7522\u54c1\u9700\u6c42\u898f\u5283\u6587\u4ef6 1. \u7522\u54c1\u9858\u666f 2. \u7522\u54c1\u6982\u8ff0 3. \u6848\u4f8b 4. \u7522\u54c1\u6d41\u7a0b\u5716</p> <p>\u6709\u6548\u7684\u5c0d\u8a71</p> <p>\u900f\u904e\u4f7f\u7528\u6848\u4f8b\u3001\u4f7f\u7528\u8005\u6545\u4e8b\u3001\u4e8b\u4ef6\u98a8\u66b4</p> <p>\u7522\u51fa\u9700\u6c42\u898f\u683c(\u529f\u80fd\u6027\u3001\u975e\u529f\u80fd\u6027)\u3001\u7522\u54c1\u9a57\u6536\u6a19\u6e96\u3001\u7522\u54c1\u6d41\u7a0b\u5716(\u53ef\u900f\u904e\u4e8b\u4ef6\u98a8\u66b4\u9032\u884c\u63a2\u7d22)</p> <p>\u5de5\u7a0b\u8a2d\u8a08\u898f\u5283\u6587\u4ef6 - API\u898f\u683c - \u8cc7\u6599\u6a21\u578b\u8a2d\u8a08 - \u7a0b\u5f0f\u5143\u4ef6\u898f\u5283 - \u9a57\u8b49\u689d\u4ef6 - \u7b2c\u4e09\u65b9\u4e32\u63a5</p>"},{"location":"hackmd/%E8%BB%9F%E9%AB%94%E9%9C%80%E6%B1%82%E6%BA%9D%E9%80%9A/#_18","title":"\u55ae\u5143\u56db: \u8edf\u9ad4\u958b\u767c\u6838\u5fc3\u89c0\u5ff5","text":"<p>\u5c0d\u6297\u98a8\u96aa 1. \u5546\u696d 2. \u5718\u968a 3. \u6280\u8853 4. \u6210\u672c</p> <p>\u5275\u9020\u50f9\u503c</p>"}]}